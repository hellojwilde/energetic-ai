var __create = Object.create;
var __defProp = Object.defineProperty;
var __defProps = Object.defineProperties;
var __getOwnPropDesc = Object.getOwnPropertyDescriptor;
var __getOwnPropDescs = Object.getOwnPropertyDescriptors;
var __getOwnPropNames = Object.getOwnPropertyNames;
var __getOwnPropSymbols = Object.getOwnPropertySymbols;
var __getProtoOf = Object.getPrototypeOf;
var __hasOwnProp = Object.prototype.hasOwnProperty;
var __propIsEnum = Object.prototype.propertyIsEnumerable;
var __defNormalProp = (obj, key, value) => key in obj ? __defProp(obj, key, { enumerable: true, configurable: true, writable: true, value }) : obj[key] = value;
var __spreadValues = (a, b) => {
  for (var prop in b ||= {})
    if (__hasOwnProp.call(b, prop))
      __defNormalProp(a, prop, b[prop]);
  if (__getOwnPropSymbols)
    for (var prop of __getOwnPropSymbols(b)) {
      if (__propIsEnum.call(b, prop))
        __defNormalProp(a, prop, b[prop]);
    }
  return a;
};
var __spreadProps = (a, b) => __defProps(a, __getOwnPropDescs(b));
var __commonJS = (cb, mod) => function __require() {
  return mod || (0, cb[__getOwnPropNames(cb)[0]])((mod = { exports: {} }).exports, mod), mod.exports;
};
var __export = (target, all) => {
  for (var name in all)
    __defProp(target, name, { get: all[name], enumerable: true });
};
var __copyProps = (to, from, except, desc) => {
  if (from && typeof from === "object" || typeof from === "function") {
    for (let key of __getOwnPropNames(from))
      if (!__hasOwnProp.call(to, key) && key !== except)
        __defProp(to, key, { get: () => from[key], enumerable: !(desc = __getOwnPropDesc(from, key)) || desc.enumerable });
  }
  return to;
};
var __reExport = (target, mod, secondTarget) => (__copyProps(target, mod, "default"), secondTarget && __copyProps(secondTarget, mod, "default"));
var __toESM = (mod, isNodeMode, target) => (target = mod != null ? __create(__getProtoOf(mod)) : {}, __copyProps(
  // If the importer is in node compatibility mode or this is not an ESM
  // file that has been converted to a CommonJS file using a Babel-
  // compatible transform (i.e. "__esModule" has not been set), then set
  // "default" to the CommonJS "module.exports" for node compatibility.
  isNodeMode || !mod || !mod.__esModule ? __defProp(target, "default", { value: mod, enumerable: true }) : target,
  mod
));
var __toCommonJS = (mod) => __copyProps(__defProp({}, "__esModule", { value: true }), mod);

// ../../node_modules/@tensorflow/tfjs-core/dist/tf-core.node.js
var require_tf_core_node = __commonJS({
  "../../node_modules/@tensorflow/tfjs-core/dist/tf-core.node.js"(exports) {
    "use strict";
    function _mergeNamespaces(n, m) {
      m.forEach(function(e) {
        e && typeof e !== "string" && !Array.isArray(e) && Object.keys(e).forEach(function(k) {
          if (k !== "default" && !(k in n)) {
            var d = Object.getOwnPropertyDescriptor(e, k);
            Object.defineProperty(n, k, d.get ? d : {
              enumerable: true,
              get: function() {
                return e[k];
              }
            });
          }
        });
      });
      return n;
    }
    var extendStatics = function(d, b) {
      extendStatics = Object.setPrototypeOf || { __proto__: [] } instanceof Array && function(d2, b2) {
        d2.__proto__ = b2;
      } || function(d2, b2) {
        for (var p in b2)
          if (Object.prototype.hasOwnProperty.call(b2, p))
            d2[p] = b2[p];
      };
      return extendStatics(d, b);
    };
    function __extends(d, b) {
      if (typeof b !== "function" && b !== null)
        throw new TypeError("Class extends value " + String(b) + " is not a constructor or null");
      extendStatics(d, b);
      function __() {
        this.constructor = d;
      }
      d.prototype = b === null ? Object.create(b) : (__.prototype = b.prototype, new __());
    }
    function __awaiter(thisArg, _arguments, P, generator) {
      function adopt(value) {
        return value instanceof P ? value : new P(function(resolve2) {
          resolve2(value);
        });
      }
      return new (P || (P = Promise))(function(resolve2, reject) {
        function fulfilled(value) {
          try {
            step2(generator.next(value));
          } catch (e) {
            reject(e);
          }
        }
        function rejected(value) {
          try {
            step2(generator["throw"](value));
          } catch (e) {
            reject(e);
          }
        }
        function step2(result) {
          result.done ? resolve2(result.value) : adopt(result.value).then(fulfilled, rejected);
        }
        step2((generator = generator.apply(thisArg, _arguments || [])).next());
      });
    }
    function __generator(thisArg, body) {
      var _ = { label: 0, sent: function() {
        if (t[0] & 1)
          throw t[1];
        return t[1];
      }, trys: [], ops: [] }, f, y, t, g;
      return g = { next: verb(0), "throw": verb(1), "return": verb(2) }, typeof Symbol === "function" && (g[Symbol.iterator] = function() {
        return this;
      }), g;
      function verb(n) {
        return function(v) {
          return step2([n, v]);
        };
      }
      function step2(op2) {
        if (f)
          throw new TypeError("Generator is already executing.");
        while (_)
          try {
            if (f = 1, y && (t = op2[0] & 2 ? y["return"] : op2[0] ? y["throw"] || ((t = y["return"]) && t.call(y), 0) : y.next) && !(t = t.call(y, op2[1])).done)
              return t;
            if (y = 0, t)
              op2 = [op2[0] & 2, t.value];
            switch (op2[0]) {
              case 0:
              case 1:
                t = op2;
                break;
              case 4:
                _.label++;
                return { value: op2[1], done: false };
              case 5:
                _.label++;
                y = op2[1];
                op2 = [0];
                continue;
              case 7:
                op2 = _.ops.pop();
                _.trys.pop();
                continue;
              default:
                if (!(t = _.trys, t = t.length > 0 && t[t.length - 1]) && (op2[0] === 6 || op2[0] === 2)) {
                  _ = 0;
                  continue;
                }
                if (op2[0] === 3 && (!t || op2[1] > t[0] && op2[1] < t[3])) {
                  _.label = op2[1];
                  break;
                }
                if (op2[0] === 6 && _.label < t[1]) {
                  _.label = t[1];
                  t = op2;
                  break;
                }
                if (t && _.label < t[2]) {
                  _.label = t[2];
                  _.ops.push(op2);
                  break;
                }
                if (t[2])
                  _.ops.pop();
                _.trys.pop();
                continue;
            }
            op2 = body.call(thisArg, _);
          } catch (e) {
            op2 = [6, e];
            y = 0;
          } finally {
            f = t = 0;
          }
        if (op2[0] & 5)
          throw op2[1];
        return { value: op2[0] ? op2[1] : void 0, done: true };
      }
    }
    function __values(o) {
      var s = typeof Symbol === "function" && Symbol.iterator, m = s && o[s], i = 0;
      if (m)
        return m.call(o);
      if (o && typeof o.length === "number")
        return {
          next: function() {
            if (o && i >= o.length)
              o = void 0;
            return { value: o && o[i++], done: !o };
          }
        };
      throw new TypeError(s ? "Object is not iterable." : "Symbol.iterator is not defined.");
    }
    function __read(o, n) {
      var m = typeof Symbol === "function" && o[Symbol.iterator];
      if (!m)
        return o;
      var i = m.call(o), r, ar = [], e;
      try {
        while ((n === void 0 || n-- > 0) && !(r = i.next()).done)
          ar.push(r.value);
      } catch (error) {
        e = { error };
      } finally {
        try {
          if (r && !r.done && (m = i["return"]))
            m.call(i);
        } finally {
          if (e)
            throw e.error;
        }
      }
      return ar;
    }
    function __spreadArray(to, from, pack) {
      if (pack || arguments.length === 2)
        for (var i = 0, l = from.length, ar; i < l; i++) {
          if (ar || !(i in from)) {
            if (!ar)
              ar = Array.prototype.slice.call(from, 0, i);
            ar[i] = from[i];
          }
        }
      return to.concat(ar || Array.prototype.slice.call(from));
    }
    var EPSILON_FLOAT32 = 1e-7;
    var EPSILON_FLOAT16 = 1e-4;
    var DataStorage = (
      /** @class */
      function() {
        function DataStorage2(backend2, dataMover) {
          this.backend = backend2;
          this.dataMover = dataMover;
          this.data = /* @__PURE__ */ new WeakMap();
          this.dataIdsCount = 0;
        }
        DataStorage2.prototype.get = function(dataId) {
          if (!this.data.has(dataId)) {
            this.dataMover.moveData(this.backend, dataId);
          }
          return this.data.get(dataId);
        };
        DataStorage2.prototype.set = function(dataId, value) {
          this.dataIdsCount++;
          this.data.set(dataId, value);
        };
        DataStorage2.prototype.has = function(dataId) {
          return this.data.has(dataId);
        };
        DataStorage2.prototype.delete = function(dataId) {
          this.dataIdsCount--;
          return this.data.delete(dataId);
        };
        DataStorage2.prototype.numDataIds = function() {
          return this.dataIdsCount;
        };
        return DataStorage2;
      }()
    );
    var KernelBackend = (
      /** @class */
      function() {
        function KernelBackend2() {
        }
        KernelBackend2.prototype.refCount = function(dataId) {
          return notYetImplemented("refCount");
        };
        KernelBackend2.prototype.incRef = function(dataId) {
          return notYetImplemented("incRef");
        };
        KernelBackend2.prototype.timerAvailable = function() {
          return true;
        };
        KernelBackend2.prototype.time = function(f) {
          return notYetImplemented("time");
        };
        KernelBackend2.prototype.read = function(dataId) {
          return notYetImplemented("read");
        };
        KernelBackend2.prototype.readSync = function(dataId) {
          return notYetImplemented("readSync");
        };
        KernelBackend2.prototype.readToGPU = function(dataId, options) {
          return notYetImplemented("readToGPU");
        };
        KernelBackend2.prototype.numDataIds = function() {
          return notYetImplemented("numDataIds");
        };
        KernelBackend2.prototype.disposeData = function(dataId, force) {
          return notYetImplemented("disposeData");
        };
        KernelBackend2.prototype.write = function(values, shape, dtype) {
          return notYetImplemented("write");
        };
        KernelBackend2.prototype.move = function(dataId, values, shape, dtype, refCount) {
          return notYetImplemented("move");
        };
        KernelBackend2.prototype.createTensorFromGPUData = function(values, shape, dtype) {
          return notYetImplemented("createTensorFromGPUData");
        };
        KernelBackend2.prototype.memory = function() {
          return notYetImplemented("memory");
        };
        KernelBackend2.prototype.floatPrecision = function() {
          return notYetImplemented("floatPrecision");
        };
        KernelBackend2.prototype.epsilon = function() {
          return this.floatPrecision() === 32 ? EPSILON_FLOAT32 : EPSILON_FLOAT16;
        };
        KernelBackend2.prototype.dispose = function() {
          return notYetImplemented("dispose");
        };
        return KernelBackend2;
      }()
    );
    function notYetImplemented(kernelName) {
      throw new Error("'".concat(kernelName, "' not yet implemented or not found in the registry. ") + "This kernel may not be supported by the tfjs backend you have chosen");
    }
    function shuffle(array) {
      var counter = array.length;
      var index = 0;
      while (counter > 0) {
        index = Math.random() * counter | 0;
        counter--;
        swap(array, counter, index);
      }
    }
    function shuffleCombo(array, array2) {
      if (array.length !== array2.length) {
        throw new Error("Array sizes must match to be shuffled together " + "First array length was ".concat(array.length) + "Second array length was ".concat(array2.length));
      }
      var counter = array.length;
      var index = 0;
      while (counter > 0) {
        index = Math.random() * counter | 0;
        counter--;
        swap(array, counter, index);
        swap(array2, counter, index);
      }
    }
    function clamp(min2, x, max2) {
      return Math.max(min2, Math.min(x, max2));
    }
    function nearestLargerEven(val) {
      return val % 2 === 0 ? val : val + 1;
    }
    function swap(object, left, right) {
      var temp = object[left];
      object[left] = object[right];
      object[right] = temp;
    }
    function sum$1(arr) {
      var sum2 = 0;
      for (var i = 0; i < arr.length; i++) {
        sum2 += arr[i];
      }
      return sum2;
    }
    function randUniform(a, b) {
      var r = Math.random();
      return b * r + (1 - r) * a;
    }
    function distSquared(a, b) {
      var result = 0;
      for (var i = 0; i < a.length; i++) {
        var diff = Number(a[i]) - Number(b[i]);
        result += diff * diff;
      }
      return result;
    }
    function assert(expr, msg) {
      if (!expr) {
        throw new Error(typeof msg === "string" ? msg : msg());
      }
    }
    function assertShapesMatch(shapeA, shapeB, errorMessagePrefix) {
      if (errorMessagePrefix === void 0) {
        errorMessagePrefix = "";
      }
      assert(arraysEqual(shapeA, shapeB), function() {
        return errorMessagePrefix + " Shapes ".concat(shapeA, " and ").concat(shapeB, " must match");
      });
    }
    function assertNonNull(a) {
      assert(a != null, function() {
        return "The input to the tensor constructor must be a non-null value.";
      });
    }
    function sizeFromShape(shape) {
      if (shape.length === 0) {
        return 1;
      }
      var size = shape[0];
      for (var i = 1; i < shape.length; i++) {
        size *= shape[i];
      }
      return size;
    }
    function isScalarShape(shape) {
      return shape.length === 0;
    }
    function arraysEqualWithNull(n1, n2) {
      if (n1 === n2) {
        return true;
      }
      if (n1 == null || n2 == null) {
        return false;
      }
      if (n1.length !== n2.length) {
        return false;
      }
      for (var i = 0; i < n1.length; i++) {
        if (n1[i] !== null && n2[i] !== null && n1[i] !== n2[i]) {
          return false;
        }
      }
      return true;
    }
    function arraysEqual(n1, n2) {
      if (n1 === n2) {
        return true;
      }
      if (n1 == null || n2 == null) {
        return false;
      }
      if (n1.length !== n2.length) {
        return false;
      }
      for (var i = 0; i < n1.length; i++) {
        if (n1[i] !== n2[i]) {
          return false;
        }
      }
      return true;
    }
    function isInt(a) {
      return a % 1 === 0;
    }
    function tanh$1(x) {
      if (Math.tanh != null) {
        return Math.tanh(x);
      }
      if (x === Infinity) {
        return 1;
      } else if (x === -Infinity) {
        return -1;
      } else {
        var e2x = Math.exp(2 * x);
        return (e2x - 1) / (e2x + 1);
      }
    }
    function sizeToSquarishShape(size) {
      var width = Math.ceil(Math.sqrt(size));
      return [width, Math.ceil(size / width)];
    }
    function createShuffledIndices(n) {
      var shuffledIndices = new Uint32Array(n);
      for (var i = 0; i < n; ++i) {
        shuffledIndices[i] = i;
      }
      shuffle(shuffledIndices);
      return shuffledIndices;
    }
    function rightPad(a, size) {
      if (size <= a.length) {
        return a;
      }
      return a + " ".repeat(size - a.length);
    }
    function repeatedTry(checkFn, delayFn, maxCounter, scheduleFn) {
      if (delayFn === void 0) {
        delayFn = function(counter) {
          return 0;
        };
      }
      return new Promise(function(resolve2, reject) {
        var tryCount = 0;
        var tryFn = function() {
          if (checkFn()) {
            resolve2();
            return;
          }
          tryCount++;
          var nextBackoff = delayFn(tryCount);
          if (maxCounter != null && tryCount >= maxCounter) {
            reject();
            return;
          }
          if (scheduleFn != null) {
            scheduleFn(tryFn, nextBackoff);
          } else {
            setTimeout(tryFn, nextBackoff);
          }
        };
        tryFn();
      });
    }
    function inferFromImplicitShape(shape, size) {
      var shapeProd = 1;
      var implicitIdx = -1;
      for (var i = 0; i < shape.length; ++i) {
        if (shape[i] >= 0) {
          shapeProd *= shape[i];
        } else if (shape[i] === -1) {
          if (implicitIdx !== -1) {
            throw Error("Shapes can only have 1 implicit size. " + "Found -1 at dim ".concat(implicitIdx, " and dim ").concat(i));
          }
          implicitIdx = i;
        } else if (shape[i] < 0) {
          throw Error("Shapes can not be < 0. Found ".concat(shape[i], " at dim ").concat(i));
        }
      }
      if (implicitIdx === -1) {
        if (size > 0 && size !== shapeProd) {
          throw Error("Size(".concat(size, ") must match the product of shape ").concat(shape));
        }
        return shape;
      }
      if (shapeProd === 0) {
        throw Error("Cannot infer the missing size in [".concat(shape, "] when ") + "there are 0 elements");
      }
      if (size % shapeProd !== 0) {
        throw Error("The implicit shape can't be a fractional number. " + "Got ".concat(size, " / ").concat(shapeProd));
      }
      var newShape = shape.slice();
      newShape[implicitIdx] = size / shapeProd;
      return newShape;
    }
    function parseAxisParam(axis, shape) {
      var rank = shape.length;
      axis = axis == null ? shape.map(function(s, i) {
        return i;
      }) : [].concat(axis);
      assert(axis.every(function(ax) {
        return ax >= -rank && ax < rank;
      }), function() {
        return "All values in axis param must be in range [-".concat(rank, ", ").concat(rank, ") but ") + "got axis ".concat(axis);
      });
      assert(axis.every(function(ax) {
        return isInt(ax);
      }), function() {
        return "All values in axis param must be integers but " + "got axis ".concat(axis);
      });
      return axis.map(function(a) {
        return a < 0 ? rank + a : a;
      });
    }
    function squeezeShape(shape, axis) {
      var newShape = [];
      var keptDims = [];
      var isEmptyArray = axis != null && Array.isArray(axis) && axis.length === 0;
      var axes = axis == null || isEmptyArray ? null : parseAxisParam(axis, shape).sort();
      var j = 0;
      for (var i = 0; i < shape.length; ++i) {
        if (axes != null) {
          if (axes[j] === i && shape[i] !== 1) {
            throw new Error("Can't squeeze axis ".concat(i, " since its dim '").concat(shape[i], "' is not 1"));
          }
          if ((axes[j] == null || axes[j] > i) && shape[i] === 1) {
            newShape.push(shape[i]);
            keptDims.push(i);
          }
          if (axes[j] <= i) {
            j++;
          }
        }
        if (shape[i] !== 1) {
          newShape.push(shape[i]);
          keptDims.push(i);
        }
      }
      return { newShape, keptDims };
    }
    function getTypedArrayFromDType(dtype, size) {
      return getArrayFromDType(dtype, size);
    }
    function getArrayFromDType(dtype, size) {
      var values = null;
      if (dtype == null || dtype === "float32") {
        values = new Float32Array(size);
      } else if (dtype === "int32") {
        values = new Int32Array(size);
      } else if (dtype === "bool") {
        values = new Uint8Array(size);
      } else if (dtype === "string") {
        values = new Array(size);
      } else {
        throw new Error("Unknown data type ".concat(dtype));
      }
      return values;
    }
    function checkConversionForErrors(vals, dtype) {
      for (var i = 0; i < vals.length; i++) {
        var num = vals[i];
        if (isNaN(num) || !isFinite(num)) {
          throw Error("A tensor of type ".concat(dtype, " being uploaded contains ").concat(num, "."));
        }
      }
    }
    function isValidDtype(dtype) {
      return dtype === "bool" || dtype === "complex64" || dtype === "float32" || dtype === "int32" || dtype === "string";
    }
    function hasEncodingLoss(oldType, newType) {
      if (newType === "complex64") {
        return false;
      }
      if (newType === "float32" && oldType !== "complex64") {
        return false;
      }
      if (newType === "int32" && oldType !== "float32" && oldType !== "complex64") {
        return false;
      }
      if (newType === "bool" && oldType === "bool") {
        return false;
      }
      return true;
    }
    function bytesPerElement(dtype) {
      if (dtype === "float32" || dtype === "int32") {
        return 4;
      } else if (dtype === "complex64") {
        return 8;
      } else if (dtype === "bool") {
        return 1;
      } else {
        throw new Error("Unknown dtype ".concat(dtype));
      }
    }
    function bytesFromStringArray(arr) {
      if (arr == null) {
        return 0;
      }
      var bytes = 0;
      arr.forEach(function(x) {
        return bytes += x.length;
      });
      return bytes;
    }
    function isString(value) {
      return typeof value === "string" || value instanceof String;
    }
    function isBoolean(value) {
      return typeof value === "boolean";
    }
    function isNumber(value) {
      return typeof value === "number";
    }
    function inferDtype(values) {
      if (Array.isArray(values)) {
        return inferDtype(values[0]);
      }
      if (values instanceof Float32Array) {
        return "float32";
      } else if (values instanceof Int32Array || values instanceof Uint8Array || values instanceof Uint8ClampedArray) {
        return "int32";
      } else if (isNumber(values)) {
        return "float32";
      } else if (isString(values)) {
        return "string";
      } else if (isBoolean(values)) {
        return "bool";
      }
      return "float32";
    }
    function isFunction(f) {
      return !!(f && f.constructor && f.call && f.apply);
    }
    function nearestDivisor(size, start) {
      for (var i = start; i < size; ++i) {
        if (size % i === 0) {
          return i;
        }
      }
      return size;
    }
    function computeStrides(shape) {
      var rank = shape.length;
      if (rank < 2) {
        return [];
      }
      var strides = new Array(rank - 1);
      strides[rank - 2] = shape[rank - 1];
      for (var i = rank - 3; i >= 0; --i) {
        strides[i] = strides[i + 1] * shape[i + 1];
      }
      return strides;
    }
    function createNestedArray(offset, shape, a, isComplex) {
      if (isComplex === void 0) {
        isComplex = false;
      }
      var ret = new Array();
      if (shape.length === 1) {
        var d = shape[0] * (isComplex ? 2 : 1);
        for (var i = 0; i < d; i++) {
          ret[i] = a[offset + i];
        }
      } else {
        var d = shape[0];
        var rest = shape.slice(1);
        var len = rest.reduce(function(acc, c) {
          return acc * c;
        }) * (isComplex ? 2 : 1);
        for (var i = 0; i < d; i++) {
          ret[i] = createNestedArray(offset + i * len, rest, a, isComplex);
        }
      }
      return ret;
    }
    function toNestedArray(shape, a, isComplex) {
      if (isComplex === void 0) {
        isComplex = false;
      }
      if (shape.length === 0) {
        return a[0];
      }
      var size = shape.reduce(function(acc, c) {
        return acc * c;
      }) * (isComplex ? 2 : 1);
      if (size === 0) {
        return [];
      }
      if (size !== a.length) {
        throw new Error("[".concat(shape, "] does not match the input size ").concat(a.length).concat(isComplex ? " for a complex tensor" : "", "."));
      }
      return createNestedArray(0, shape, a, isComplex);
    }
    function convertBackendValuesAndArrayBuffer(data, dtype) {
      if (Array.isArray(data)) {
        return data;
      }
      if (dtype === "float32") {
        return data instanceof Float32Array ? data : new Float32Array(data);
      } else if (dtype === "int32") {
        return data instanceof Int32Array ? data : new Int32Array(data);
      } else if (dtype === "bool" || dtype === "string") {
        return Uint8Array.from(new Int32Array(data));
      } else {
        throw new Error("Unknown dtype ".concat(dtype));
      }
    }
    function makeOnesTypedArray(size, dtype) {
      var array = makeZerosTypedArray(size, dtype);
      for (var i = 0; i < array.length; i++) {
        array[i] = 1;
      }
      return array;
    }
    function makeZerosTypedArray(size, dtype) {
      if (dtype == null || dtype === "float32" || dtype === "complex64") {
        return new Float32Array(size);
      } else if (dtype === "int32") {
        return new Int32Array(size);
      } else if (dtype === "bool") {
        return new Uint8Array(size);
      } else {
        throw new Error("Unknown data type ".concat(dtype));
      }
    }
    function makeZerosNestedTypedArray(shape, dtype) {
      var size = shape.reduce(function(prev, curr) {
        return prev * curr;
      }, 1);
      if (dtype == null || dtype === "float32") {
        return toNestedArray(shape, new Float32Array(size));
      } else if (dtype === "int32") {
        return toNestedArray(shape, new Int32Array(size));
      } else if (dtype === "bool") {
        return toNestedArray(shape, new Uint8Array(size));
      } else {
        throw new Error("Unknown data type ".concat(dtype));
      }
    }
    function assertNonNegativeIntegerDimensions(shape) {
      shape.forEach(function(dimSize) {
        assert(Number.isInteger(dimSize) && dimSize >= 0, function() {
          return "Tensor must have a shape comprised of positive integers but got " + "shape [".concat(shape, "].");
        });
      });
    }
    function locToIndex(locs, rank, strides) {
      if (rank === 0) {
        return 0;
      } else if (rank === 1) {
        return locs[0];
      }
      var index = locs[locs.length - 1];
      for (var i = 0; i < locs.length - 1; ++i) {
        index += strides[i] * locs[i];
      }
      return index;
    }
    function indexToLoc(index, rank, strides) {
      if (rank === 0) {
        return [];
      } else if (rank === 1) {
        return [index];
      }
      var locs = new Array(rank);
      for (var i = 0; i < locs.length - 1; ++i) {
        locs[i] = Math.floor(index / strides[i]);
        index -= locs[i] * strides[i];
      }
      locs[locs.length - 1] = index;
      return locs;
    }
    function isPromise(object) {
      return object && object.then && typeof object.then === "function";
    }
    var TENSORFLOWJS_FLAGS_PREFIX = "tfjsflags";
    var Environment = (
      /** @class */
      function() {
        function Environment2(global2) {
          this.global = global2;
          this.flags = {};
          this.flagRegistry = {};
          this.urlFlags = {};
          this.getQueryParams = getQueryParams;
          this.populateURLFlags();
        }
        Environment2.prototype.setPlatform = function(platformName, platform) {
          if (this.platform != null) {
            if (!(env().getBool("IS_TEST") || env().getBool("PROD"))) {
              console.warn("Platform ".concat(this.platformName, " has already been set. ") + "Overwriting the platform with ".concat(platformName, "."));
            }
          }
          this.platformName = platformName;
          this.platform = platform;
        };
        Environment2.prototype.registerFlag = function(flagName, evaluationFn, setHook) {
          this.flagRegistry[flagName] = { evaluationFn, setHook };
          if (this.urlFlags[flagName] != null) {
            var flagValue = this.urlFlags[flagName];
            if (!(env().getBool("IS_TEST") || env().getBool("PROD"))) {
              console.warn("Setting feature override from URL ".concat(flagName, ": ").concat(flagValue, "."));
            }
            this.set(flagName, flagValue);
          }
        };
        Environment2.prototype.getAsync = function(flagName) {
          return __awaiter(this, void 0, void 0, function() {
            var _a, _b;
            return __generator(this, function(_c) {
              switch (_c.label) {
                case 0:
                  if (flagName in this.flags) {
                    return [2, this.flags[flagName]];
                  }
                  _a = this.flags;
                  _b = flagName;
                  return [4, this.evaluateFlag(flagName)];
                case 1:
                  _a[_b] = _c.sent();
                  return [2, this.flags[flagName]];
              }
            });
          });
        };
        Environment2.prototype.get = function(flagName) {
          if (flagName in this.flags) {
            return this.flags[flagName];
          }
          var flagValue = this.evaluateFlag(flagName);
          if (isPromise(flagValue)) {
            throw new Error("Flag ".concat(flagName, " cannot be synchronously evaluated. ") + "Please use getAsync() instead.");
          }
          this.flags[flagName] = flagValue;
          return this.flags[flagName];
        };
        Environment2.prototype.getNumber = function(flagName) {
          return this.get(flagName);
        };
        Environment2.prototype.getBool = function(flagName) {
          return this.get(flagName);
        };
        Environment2.prototype.getString = function(flagName) {
          return this.get(flagName);
        };
        Environment2.prototype.getFlags = function() {
          return this.flags;
        };
        Object.defineProperty(Environment2.prototype, "features", {
          // For backwards compatibility.
          get: function() {
            return this.flags;
          },
          enumerable: false,
          configurable: true
        });
        Environment2.prototype.set = function(flagName, value) {
          if (this.flagRegistry[flagName] == null) {
            throw new Error("Cannot set flag ".concat(flagName, " as it has not been registered."));
          }
          this.flags[flagName] = value;
          if (this.flagRegistry[flagName].setHook != null) {
            this.flagRegistry[flagName].setHook(value);
          }
        };
        Environment2.prototype.evaluateFlag = function(flagName) {
          if (this.flagRegistry[flagName] == null) {
            throw new Error("Cannot evaluate flag '".concat(flagName, "': no evaluation function found."));
          }
          return this.flagRegistry[flagName].evaluationFn();
        };
        Environment2.prototype.setFlags = function(flags) {
          this.flags = Object.assign({}, flags);
        };
        Environment2.prototype.reset = function() {
          this.flags = {};
          this.urlFlags = {};
          this.populateURLFlags();
        };
        Environment2.prototype.populateURLFlags = function() {
          var _this = this;
          if (typeof this.global === "undefined" || typeof this.global.location === "undefined" || typeof this.global.location.search === "undefined") {
            return;
          }
          var urlParams = this.getQueryParams(this.global.location.search);
          if (TENSORFLOWJS_FLAGS_PREFIX in urlParams) {
            var keyValues = urlParams[TENSORFLOWJS_FLAGS_PREFIX].split(",");
            keyValues.forEach(function(keyValue) {
              var _a = __read(keyValue.split(":"), 2), key = _a[0], value = _a[1];
              _this.urlFlags[key] = parseValue(key, value);
            });
          }
        };
        return Environment2;
      }()
    );
    function getQueryParams(queryString) {
      var params = {};
      queryString.replace(/[?&]([^=?&]+)(?:=([^&]*))?/g, function(s) {
        var t = [];
        for (var _i = 1; _i < arguments.length; _i++) {
          t[_i - 1] = arguments[_i];
        }
        decodeParam(params, t[0], t[1]);
        return t.join("=");
      });
      return params;
    }
    function decodeParam(params, name, value) {
      params[decodeURIComponent(name)] = decodeURIComponent(value || "");
    }
    function parseValue(flagName, value) {
      var lowerCaseValue = value.toLowerCase();
      if (lowerCaseValue === "true" || lowerCaseValue === "false") {
        return lowerCaseValue === "true";
      } else if ("".concat(+lowerCaseValue) === lowerCaseValue) {
        return +lowerCaseValue;
      } else {
        return value;
      }
    }
    function env() {
      return exports.ENV;
    }
    exports.ENV = null;
    function setEnvironmentGlobal(environment) {
      exports.ENV = environment;
    }
    var globalNameSpace;
    function getGlobalNamespace() {
      if (globalNameSpace == null) {
        var ns = void 0;
        if (typeof window !== "undefined") {
          ns = window;
        } else if (typeof global !== "undefined") {
          ns = global;
        } else if (typeof process !== "undefined") {
          ns = process;
        } else if (typeof self !== "undefined") {
          ns = self;
        } else {
          throw new Error("Could not find a global object");
        }
        globalNameSpace = ns;
      }
      return globalNameSpace;
    }
    function getGlobalMap() {
      var ns = getGlobalNamespace();
      if (ns._tfGlobals == null) {
        ns._tfGlobals = /* @__PURE__ */ new Map();
      }
      return ns._tfGlobals;
    }
    function getGlobal(key, init) {
      var globalMap = getGlobalMap();
      if (globalMap.has(key)) {
        return globalMap.get(key);
      } else {
        var singleton = init();
        globalMap.set(key, singleton);
        return globalMap.get(key);
      }
    }
    var Abs = "Abs";
    var Acos = "Acos";
    var Acosh = "Acosh";
    var Add = "Add";
    var AddN = "AddN";
    var All = "All";
    var Any = "Any";
    var ArgMax = "ArgMax";
    var ArgMin = "ArgMin";
    var Asin = "Asin";
    var Asinh = "Asinh";
    var Atan = "Atan";
    var Atanh = "Atanh";
    var Atan2 = "Atan2";
    var AvgPool = "AvgPool";
    var AvgPoolGrad = "AvgPoolGrad";
    var AvgPool3D = "AvgPool3D";
    var AvgPool3DGrad = "AvgPool3DGrad";
    var BatchMatMul = "BatchMatMul";
    var BatchToSpaceND = "BatchToSpaceND";
    var Bincount = "Bincount";
    var BitwiseAnd = "BitwiseAnd";
    var BroadcastTo = "BroadcastTo";
    var BroadcastArgs = "BroadcastArgs";
    var Cast = "Cast";
    var Ceil = "Ceil";
    var ClipByValue = "ClipByValue";
    var Complex = "Complex";
    var ComplexAbs = "ComplexAbs";
    var Concat = "Concat";
    var Conv2D = "Conv2D";
    var Conv2DBackpropFilter = "Conv2DBackpropFilter";
    var Conv2DBackpropInput = "Conv2DBackpropInput";
    var Conv3D = "Conv3D";
    var Conv3DBackpropFilterV2 = "Conv3DBackpropFilterV2";
    var Conv3DBackpropInputV2 = "Conv3DBackpropInputV2";
    var Cos = "Cos";
    var Cosh = "Cosh";
    var Cumprod = "Cumprod";
    var Cumsum = "Cumsum";
    var CropAndResize = "CropAndResize";
    var DenseBincount = "DenseBincount";
    var DepthToSpace = "DepthToSpace";
    var DepthwiseConv2dNative = "DepthwiseConv2dNative";
    var DepthwiseConv2dNativeBackpropFilter = "DepthwiseConv2dNativeBackpropFilter";
    var DepthwiseConv2dNativeBackpropInput = "DepthwiseConv2dNativeBackpropInput";
    var Diag = "Diag";
    var Dilation2D = "Dilation2D";
    var Dilation2DBackpropInput = "Dilation2DBackpropInput";
    var Dilation2DBackpropFilter = "Dilation2DBackpropFilter";
    var RealDiv = "RealDiv";
    var Einsum = "Einsum";
    var Elu = "Elu";
    var EluGrad = "EluGrad";
    var Erf = "Erf";
    var Equal = "Equal";
    var Exp = "Exp";
    var ExpandDims = "ExpandDims";
    var Expm1 = "Expm1";
    var FFT = "FFT";
    var Fill = "Fill";
    var FlipLeftRight = "FlipLeftRight";
    var Floor = "Floor";
    var FloorDiv = "FloorDiv";
    var FusedBatchNorm = "FusedBatchNorm";
    var GatherV2 = "GatherV2";
    var GatherNd = "GatherNd";
    var Greater = "Greater";
    var GreaterEqual = "GreaterEqual";
    var Identity = "Identity";
    var IFFT = "IFFT";
    var Imag = "Imag";
    var IsFinite = "IsFinite";
    var IsInf = "IsInf";
    var IsNan = "IsNan";
    var LeakyRelu = "LeakyRelu";
    var Less = "Less";
    var LessEqual = "LessEqual";
    var LinSpace = "LinSpace";
    var Log = "Log";
    var Log1p = "Log1p";
    var LogicalAnd = "LogicalAnd";
    var LogicalNot = "LogicalNot";
    var LogicalOr = "LogicalOr";
    var LogicalXor = "LogicalXor";
    var LogSoftmax = "LogSoftmax";
    var LowerBound = "LowerBound";
    var LRN = "LRN";
    var LRNGrad = "LRNGrad";
    var MatrixBandPart = "MatrixBandPart";
    var Max = "Max";
    var Maximum = "Maximum";
    var MaxPool = "MaxPool";
    var MaxPoolGrad = "MaxPoolGrad";
    var MaxPool3D = "MaxPool3D";
    var MaxPool3DGrad = "MaxPool3DGrad";
    var MaxPoolWithArgmax = "MaxPoolWithArgmax";
    var Mean = "Mean";
    var Min = "Min";
    var Minimum = "Minimum";
    var MirrorPad = "MirrorPad";
    var Mod = "Mod";
    var Multinomial = "Multinomial";
    var Multiply = "Multiply";
    var Neg = "Neg";
    var NotEqual = "NotEqual";
    var NonMaxSuppressionV3 = "NonMaxSuppressionV3";
    var NonMaxSuppressionV4 = "NonMaxSuppressionV4";
    var NonMaxSuppressionV5 = "NonMaxSuppressionV5";
    var OnesLike = "OnesLike";
    var OneHot = "OneHot";
    var Pack = "Pack";
    var PadV2 = "PadV2";
    var Pool = "Pool";
    var Pow = "Pow";
    var Prelu = "Prelu";
    var Prod = "Prod";
    var RaggedGather = "RaggedGather";
    var RaggedRange = "RaggedRange";
    var RaggedTensorToTensor = "RaggedTensorToTensor";
    var Range = "Range";
    var Real = "Real";
    var Reciprocal = "Reciprocal";
    var Relu = "Relu";
    var Reshape = "Reshape";
    var ResizeNearestNeighbor = "ResizeNearestNeighbor";
    var ResizeNearestNeighborGrad = "ResizeNearestNeighborGrad";
    var ResizeBilinear = "ResizeBilinear";
    var ResizeBilinearGrad = "ResizeBilinearGrad";
    var Relu6 = "Relu6";
    var Reverse = "Reverse";
    var Round = "Round";
    var Rsqrt = "Rsqrt";
    var ScatterNd = "ScatterNd";
    var TensorScatterUpdate = "TensorScatterUpdate";
    var SearchSorted = "SearchSorted";
    var Select = "Select";
    var Selu = "Selu";
    var Slice = "Slice";
    var Sin = "Sin";
    var Sinh = "Sinh";
    var Sign = "Sign";
    var Sigmoid = "Sigmoid";
    var Softplus = "Softplus";
    var Sqrt = "Sqrt";
    var Sum = "Sum";
    var SpaceToBatchND = "SpaceToBatchND";
    var SplitV = "SplitV";
    var Softmax = "Softmax";
    var SparseFillEmptyRows = "SparseFillEmptyRows";
    var SparseReshape = "SparseReshape";
    var SparseSegmentMean = "SparseSegmentMean";
    var SparseSegmentSum = "SparseSegmentSum";
    var SparseToDense = "SparseToDense";
    var SquaredDifference = "SquaredDifference";
    var Square = "Square";
    var StaticRegexReplace = "StaticRegexReplace";
    var StridedSlice = "StridedSlice";
    var StringNGrams = "StringNGrams";
    var StringSplit = "StringSplit";
    var StringToHashBucketFast = "StringToHashBucketFast";
    var Sub = "Sub";
    var Tan = "Tan";
    var Tanh = "Tanh";
    var Tile = "Tile";
    var TopK = "TopK";
    var Transform = "Transform";
    var Transpose = "Transpose";
    var Unique = "Unique";
    var Unpack = "Unpack";
    var UnsortedSegmentSum = "UnsortedSegmentSum";
    var UpperBound = "UpperBound";
    var ZerosLike = "ZerosLike";
    var Step = "Step";
    var FromPixels = "FromPixels";
    var RotateWithOffset = "RotateWithOffset";
    var _FusedMatMul = "_FusedMatMul";
    var FusedConv2D = "FusedConv2D";
    var FusedDepthwiseConv2D = "FusedDepthwiseConv2D";
    function warn() {
      var msg = [];
      for (var _i = 0; _i < arguments.length; _i++) {
        msg[_i] = arguments[_i];
      }
      if (!(env().getBool("IS_TEST") || env().getBool("PROD"))) {
        console.warn.apply(console, __spreadArray([], __read(msg), false));
      }
    }
    function log$1() {
      var msg = [];
      for (var _i = 0; _i < arguments.length; _i++) {
        msg[_i] = arguments[_i];
      }
      if (!(env().getBool("IS_TEST") || env().getBool("PROD"))) {
        console.log.apply(console, __spreadArray([], __read(msg), false));
      }
    }
    var kernelRegistry = getGlobal("kernelRegistry", function() {
      return /* @__PURE__ */ new Map();
    });
    var gradRegistry = getGlobal("gradRegistry", function() {
      return /* @__PURE__ */ new Map();
    });
    function getKernel(kernelName, backendName) {
      var key = makeKey(kernelName, backendName);
      return kernelRegistry.get(key);
    }
    function getGradient(kernelName) {
      return gradRegistry.get(kernelName);
    }
    function getKernelsForBackend(backendName) {
      var it = kernelRegistry.entries();
      var result = [];
      while (true) {
        var _a = it.next(), done = _a.done, value = _a.value;
        if (done) {
          break;
        }
        var _b = __read(value, 2), key = _b[0], config = _b[1];
        var _c = __read(key.split("_"), 1), backend2 = _c[0];
        if (backend2 === backendName) {
          result.push(config);
        }
      }
      return result;
    }
    function registerKernel(config) {
      var kernelName = config.kernelName, backendName = config.backendName;
      var key = makeKey(kernelName, backendName);
      if (kernelRegistry.has(key)) {
        warn("The kernel '".concat(kernelName, "' for backend ") + "'".concat(backendName, "' is already registered"));
      }
      kernelRegistry.set(key, config);
    }
    function registerGradient(config) {
      var kernelName = config.kernelName;
      if (gradRegistry.has(kernelName)) {
        if (env().getBool("DEBUG")) {
          warn("Overriding the gradient for '".concat(kernelName, "'"));
        }
      }
      gradRegistry.set(kernelName, config);
    }
    function unregisterKernel(kernelName, backendName) {
      var key = makeKey(kernelName, backendName);
      if (!kernelRegistry.has(key)) {
        throw new Error("The kernel '".concat(kernelName, "' for backend ") + "'".concat(backendName, "' is not registered"));
      }
      kernelRegistry.delete(key);
    }
    function unregisterGradient(kernelName) {
      if (!gradRegistry.has(kernelName)) {
        throw new Error("The gradient '".concat(kernelName, "' for backend is not registered"));
      }
      gradRegistry.delete(kernelName);
    }
    function copyRegisteredKernels(registeredBackendName, newBackendName) {
      var kernels = getKernelsForBackend(registeredBackendName);
      kernels.forEach(function(kernelConfig) {
        var newKernelConfig = Object.assign({}, kernelConfig, { backendName: newBackendName });
        registerKernel(newKernelConfig);
      });
    }
    function makeKey(kernelName, backendName) {
      return "".concat(backendName, "_").concat(kernelName);
    }
    function isTypedArrayBrowser(a) {
      return a instanceof Float32Array || a instanceof Int32Array || a instanceof Uint8Array || a instanceof Uint8ClampedArray;
    }
    var commonjsGlobal = typeof globalThis !== "undefined" ? globalThis : typeof window !== "undefined" ? window : typeof global !== "undefined" ? global : typeof self !== "undefined" ? self : {};
    function getDefaultExportFromCjs(x) {
      return x && x.__esModule && Object.prototype.hasOwnProperty.call(x, "default") ? x["default"] : x;
    }
    var long = Long$1;
    var wasm = null;
    try {
      wasm = new WebAssembly.Instance(new WebAssembly.Module(new Uint8Array([
        0,
        97,
        115,
        109,
        1,
        0,
        0,
        0,
        1,
        13,
        2,
        96,
        0,
        1,
        127,
        96,
        4,
        127,
        127,
        127,
        127,
        1,
        127,
        3,
        7,
        6,
        0,
        1,
        1,
        1,
        1,
        1,
        6,
        6,
        1,
        127,
        1,
        65,
        0,
        11,
        7,
        50,
        6,
        3,
        109,
        117,
        108,
        0,
        1,
        5,
        100,
        105,
        118,
        95,
        115,
        0,
        2,
        5,
        100,
        105,
        118,
        95,
        117,
        0,
        3,
        5,
        114,
        101,
        109,
        95,
        115,
        0,
        4,
        5,
        114,
        101,
        109,
        95,
        117,
        0,
        5,
        8,
        103,
        101,
        116,
        95,
        104,
        105,
        103,
        104,
        0,
        0,
        10,
        191,
        1,
        6,
        4,
        0,
        35,
        0,
        11,
        36,
        1,
        1,
        126,
        32,
        0,
        173,
        32,
        1,
        173,
        66,
        32,
        134,
        132,
        32,
        2,
        173,
        32,
        3,
        173,
        66,
        32,
        134,
        132,
        126,
        34,
        4,
        66,
        32,
        135,
        167,
        36,
        0,
        32,
        4,
        167,
        11,
        36,
        1,
        1,
        126,
        32,
        0,
        173,
        32,
        1,
        173,
        66,
        32,
        134,
        132,
        32,
        2,
        173,
        32,
        3,
        173,
        66,
        32,
        134,
        132,
        127,
        34,
        4,
        66,
        32,
        135,
        167,
        36,
        0,
        32,
        4,
        167,
        11,
        36,
        1,
        1,
        126,
        32,
        0,
        173,
        32,
        1,
        173,
        66,
        32,
        134,
        132,
        32,
        2,
        173,
        32,
        3,
        173,
        66,
        32,
        134,
        132,
        128,
        34,
        4,
        66,
        32,
        135,
        167,
        36,
        0,
        32,
        4,
        167,
        11,
        36,
        1,
        1,
        126,
        32,
        0,
        173,
        32,
        1,
        173,
        66,
        32,
        134,
        132,
        32,
        2,
        173,
        32,
        3,
        173,
        66,
        32,
        134,
        132,
        129,
        34,
        4,
        66,
        32,
        135,
        167,
        36,
        0,
        32,
        4,
        167,
        11,
        36,
        1,
        1,
        126,
        32,
        0,
        173,
        32,
        1,
        173,
        66,
        32,
        134,
        132,
        32,
        2,
        173,
        32,
        3,
        173,
        66,
        32,
        134,
        132,
        130,
        34,
        4,
        66,
        32,
        135,
        167,
        36,
        0,
        32,
        4,
        167,
        11
      ])), {}).exports;
    } catch (e) {
    }
    function Long$1(low, high, unsigned) {
      this.low = low | 0;
      this.high = high | 0;
      this.unsigned = !!unsigned;
    }
    Long$1.prototype.__isLong__;
    Object.defineProperty(Long$1.prototype, "__isLong__", { value: true });
    function isLong(obj) {
      return (obj && obj["__isLong__"]) === true;
    }
    Long$1.isLong = isLong;
    var INT_CACHE = {};
    var UINT_CACHE = {};
    function fromInt(value, unsigned) {
      var obj, cachedObj, cache;
      if (unsigned) {
        value >>>= 0;
        if (cache = 0 <= value && value < 256) {
          cachedObj = UINT_CACHE[value];
          if (cachedObj)
            return cachedObj;
        }
        obj = fromBits(value, (value | 0) < 0 ? -1 : 0, true);
        if (cache)
          UINT_CACHE[value] = obj;
        return obj;
      } else {
        value |= 0;
        if (cache = -128 <= value && value < 128) {
          cachedObj = INT_CACHE[value];
          if (cachedObj)
            return cachedObj;
        }
        obj = fromBits(value, value < 0 ? -1 : 0, false);
        if (cache)
          INT_CACHE[value] = obj;
        return obj;
      }
    }
    Long$1.fromInt = fromInt;
    function fromNumber(value, unsigned) {
      if (isNaN(value))
        return unsigned ? UZERO : ZERO;
      if (unsigned) {
        if (value < 0)
          return UZERO;
        if (value >= TWO_PWR_64_DBL)
          return MAX_UNSIGNED_VALUE;
      } else {
        if (value <= -TWO_PWR_63_DBL)
          return MIN_VALUE;
        if (value + 1 >= TWO_PWR_63_DBL)
          return MAX_VALUE;
      }
      if (value < 0)
        return fromNumber(-value, unsigned).neg();
      return fromBits(value % TWO_PWR_32_DBL | 0, value / TWO_PWR_32_DBL | 0, unsigned);
    }
    Long$1.fromNumber = fromNumber;
    function fromBits(lowBits, highBits, unsigned) {
      return new Long$1(lowBits, highBits, unsigned);
    }
    Long$1.fromBits = fromBits;
    var pow_dbl = Math.pow;
    function fromString(str, unsigned, radix) {
      if (str.length === 0)
        throw Error("empty string");
      if (str === "NaN" || str === "Infinity" || str === "+Infinity" || str === "-Infinity")
        return ZERO;
      if (typeof unsigned === "number") {
        radix = unsigned, unsigned = false;
      } else {
        unsigned = !!unsigned;
      }
      radix = radix || 10;
      if (radix < 2 || 36 < radix)
        throw RangeError("radix");
      var p;
      if ((p = str.indexOf("-")) > 0)
        throw Error("interior hyphen");
      else if (p === 0) {
        return fromString(str.substring(1), unsigned, radix).neg();
      }
      var radixToPower = fromNumber(pow_dbl(radix, 8));
      var result = ZERO;
      for (var i = 0; i < str.length; i += 8) {
        var size = Math.min(8, str.length - i), value = parseInt(str.substring(i, i + size), radix);
        if (size < 8) {
          var power = fromNumber(pow_dbl(radix, size));
          result = result.mul(power).add(fromNumber(value));
        } else {
          result = result.mul(radixToPower);
          result = result.add(fromNumber(value));
        }
      }
      result.unsigned = unsigned;
      return result;
    }
    Long$1.fromString = fromString;
    function fromValue(val, unsigned) {
      if (typeof val === "number")
        return fromNumber(val, unsigned);
      if (typeof val === "string")
        return fromString(val, unsigned);
      return fromBits(val.low, val.high, typeof unsigned === "boolean" ? unsigned : val.unsigned);
    }
    Long$1.fromValue = fromValue;
    var TWO_PWR_16_DBL = 1 << 16;
    var TWO_PWR_24_DBL = 1 << 24;
    var TWO_PWR_32_DBL = TWO_PWR_16_DBL * TWO_PWR_16_DBL;
    var TWO_PWR_64_DBL = TWO_PWR_32_DBL * TWO_PWR_32_DBL;
    var TWO_PWR_63_DBL = TWO_PWR_64_DBL / 2;
    var TWO_PWR_24 = fromInt(TWO_PWR_24_DBL);
    var ZERO = fromInt(0);
    Long$1.ZERO = ZERO;
    var UZERO = fromInt(0, true);
    Long$1.UZERO = UZERO;
    var ONE = fromInt(1);
    Long$1.ONE = ONE;
    var UONE = fromInt(1, true);
    Long$1.UONE = UONE;
    var NEG_ONE = fromInt(-1);
    Long$1.NEG_ONE = NEG_ONE;
    var MAX_VALUE = fromBits(4294967295 | 0, 2147483647 | 0, false);
    Long$1.MAX_VALUE = MAX_VALUE;
    var MAX_UNSIGNED_VALUE = fromBits(4294967295 | 0, 4294967295 | 0, true);
    Long$1.MAX_UNSIGNED_VALUE = MAX_UNSIGNED_VALUE;
    var MIN_VALUE = fromBits(0, 2147483648 | 0, false);
    Long$1.MIN_VALUE = MIN_VALUE;
    var LongPrototype = Long$1.prototype;
    LongPrototype.toInt = function toInt() {
      return this.unsigned ? this.low >>> 0 : this.low;
    };
    LongPrototype.toNumber = function toNumber() {
      if (this.unsigned)
        return (this.high >>> 0) * TWO_PWR_32_DBL + (this.low >>> 0);
      return this.high * TWO_PWR_32_DBL + (this.low >>> 0);
    };
    LongPrototype.toString = function toString(radix) {
      radix = radix || 10;
      if (radix < 2 || 36 < radix)
        throw RangeError("radix");
      if (this.isZero())
        return "0";
      if (this.isNegative()) {
        if (this.eq(MIN_VALUE)) {
          var radixLong = fromNumber(radix), div2 = this.div(radixLong), rem1 = div2.mul(radixLong).sub(this);
          return div2.toString(radix) + rem1.toInt().toString(radix);
        } else
          return "-" + this.neg().toString(radix);
      }
      var radixToPower = fromNumber(pow_dbl(radix, 6), this.unsigned), rem = this;
      var result = "";
      while (true) {
        var remDiv = rem.div(radixToPower), intval = rem.sub(remDiv.mul(radixToPower)).toInt() >>> 0, digits = intval.toString(radix);
        rem = remDiv;
        if (rem.isZero())
          return digits + result;
        else {
          while (digits.length < 6)
            digits = "0" + digits;
          result = "" + digits + result;
        }
      }
    };
    LongPrototype.getHighBits = function getHighBits() {
      return this.high;
    };
    LongPrototype.getHighBitsUnsigned = function getHighBitsUnsigned() {
      return this.high >>> 0;
    };
    LongPrototype.getLowBits = function getLowBits() {
      return this.low;
    };
    LongPrototype.getLowBitsUnsigned = function getLowBitsUnsigned() {
      return this.low >>> 0;
    };
    LongPrototype.getNumBitsAbs = function getNumBitsAbs() {
      if (this.isNegative())
        return this.eq(MIN_VALUE) ? 64 : this.neg().getNumBitsAbs();
      var val = this.high != 0 ? this.high : this.low;
      for (var bit = 31; bit > 0; bit--)
        if ((val & 1 << bit) != 0)
          break;
      return this.high != 0 ? bit + 33 : bit + 1;
    };
    LongPrototype.isZero = function isZero() {
      return this.high === 0 && this.low === 0;
    };
    LongPrototype.eqz = LongPrototype.isZero;
    LongPrototype.isNegative = function isNegative() {
      return !this.unsigned && this.high < 0;
    };
    LongPrototype.isPositive = function isPositive() {
      return this.unsigned || this.high >= 0;
    };
    LongPrototype.isOdd = function isOdd() {
      return (this.low & 1) === 1;
    };
    LongPrototype.isEven = function isEven() {
      return (this.low & 1) === 0;
    };
    LongPrototype.equals = function equals(other) {
      if (!isLong(other))
        other = fromValue(other);
      if (this.unsigned !== other.unsigned && this.high >>> 31 === 1 && other.high >>> 31 === 1)
        return false;
      return this.high === other.high && this.low === other.low;
    };
    LongPrototype.eq = LongPrototype.equals;
    LongPrototype.notEquals = function notEquals(other) {
      return !this.eq(
        /* validates */
        other
      );
    };
    LongPrototype.neq = LongPrototype.notEquals;
    LongPrototype.ne = LongPrototype.notEquals;
    LongPrototype.lessThan = function lessThan(other) {
      return this.comp(
        /* validates */
        other
      ) < 0;
    };
    LongPrototype.lt = LongPrototype.lessThan;
    LongPrototype.lessThanOrEqual = function lessThanOrEqual(other) {
      return this.comp(
        /* validates */
        other
      ) <= 0;
    };
    LongPrototype.lte = LongPrototype.lessThanOrEqual;
    LongPrototype.le = LongPrototype.lessThanOrEqual;
    LongPrototype.greaterThan = function greaterThan(other) {
      return this.comp(
        /* validates */
        other
      ) > 0;
    };
    LongPrototype.gt = LongPrototype.greaterThan;
    LongPrototype.greaterThanOrEqual = function greaterThanOrEqual(other) {
      return this.comp(
        /* validates */
        other
      ) >= 0;
    };
    LongPrototype.gte = LongPrototype.greaterThanOrEqual;
    LongPrototype.ge = LongPrototype.greaterThanOrEqual;
    LongPrototype.compare = function compare(other) {
      if (!isLong(other))
        other = fromValue(other);
      if (this.eq(other))
        return 0;
      var thisNeg = this.isNegative(), otherNeg = other.isNegative();
      if (thisNeg && !otherNeg)
        return -1;
      if (!thisNeg && otherNeg)
        return 1;
      if (!this.unsigned)
        return this.sub(other).isNegative() ? -1 : 1;
      return other.high >>> 0 > this.high >>> 0 || other.high === this.high && other.low >>> 0 > this.low >>> 0 ? -1 : 1;
    };
    LongPrototype.comp = LongPrototype.compare;
    LongPrototype.negate = function negate() {
      if (!this.unsigned && this.eq(MIN_VALUE))
        return MIN_VALUE;
      return this.not().add(ONE);
    };
    LongPrototype.neg = LongPrototype.negate;
    LongPrototype.add = function add2(addend) {
      if (!isLong(addend))
        addend = fromValue(addend);
      var a48 = this.high >>> 16;
      var a32 = this.high & 65535;
      var a16 = this.low >>> 16;
      var a00 = this.low & 65535;
      var b48 = addend.high >>> 16;
      var b32 = addend.high & 65535;
      var b16 = addend.low >>> 16;
      var b00 = addend.low & 65535;
      var c48 = 0, c32 = 0, c16 = 0, c00 = 0;
      c00 += a00 + b00;
      c16 += c00 >>> 16;
      c00 &= 65535;
      c16 += a16 + b16;
      c32 += c16 >>> 16;
      c16 &= 65535;
      c32 += a32 + b32;
      c48 += c32 >>> 16;
      c32 &= 65535;
      c48 += a48 + b48;
      c48 &= 65535;
      return fromBits(c16 << 16 | c00, c48 << 16 | c32, this.unsigned);
    };
    LongPrototype.subtract = function subtract(subtrahend) {
      if (!isLong(subtrahend))
        subtrahend = fromValue(subtrahend);
      return this.add(subtrahend.neg());
    };
    LongPrototype.sub = LongPrototype.subtract;
    LongPrototype.multiply = function multiply(multiplier) {
      if (this.isZero())
        return ZERO;
      if (!isLong(multiplier))
        multiplier = fromValue(multiplier);
      if (wasm) {
        var low = wasm.mul(this.low, this.high, multiplier.low, multiplier.high);
        return fromBits(low, wasm.get_high(), this.unsigned);
      }
      if (multiplier.isZero())
        return ZERO;
      if (this.eq(MIN_VALUE))
        return multiplier.isOdd() ? MIN_VALUE : ZERO;
      if (multiplier.eq(MIN_VALUE))
        return this.isOdd() ? MIN_VALUE : ZERO;
      if (this.isNegative()) {
        if (multiplier.isNegative())
          return this.neg().mul(multiplier.neg());
        else
          return this.neg().mul(multiplier).neg();
      } else if (multiplier.isNegative())
        return this.mul(multiplier.neg()).neg();
      if (this.lt(TWO_PWR_24) && multiplier.lt(TWO_PWR_24))
        return fromNumber(this.toNumber() * multiplier.toNumber(), this.unsigned);
      var a48 = this.high >>> 16;
      var a32 = this.high & 65535;
      var a16 = this.low >>> 16;
      var a00 = this.low & 65535;
      var b48 = multiplier.high >>> 16;
      var b32 = multiplier.high & 65535;
      var b16 = multiplier.low >>> 16;
      var b00 = multiplier.low & 65535;
      var c48 = 0, c32 = 0, c16 = 0, c00 = 0;
      c00 += a00 * b00;
      c16 += c00 >>> 16;
      c00 &= 65535;
      c16 += a16 * b00;
      c32 += c16 >>> 16;
      c16 &= 65535;
      c16 += a00 * b16;
      c32 += c16 >>> 16;
      c16 &= 65535;
      c32 += a32 * b00;
      c48 += c32 >>> 16;
      c32 &= 65535;
      c32 += a16 * b16;
      c48 += c32 >>> 16;
      c32 &= 65535;
      c32 += a00 * b32;
      c48 += c32 >>> 16;
      c32 &= 65535;
      c48 += a48 * b00 + a32 * b16 + a16 * b32 + a00 * b48;
      c48 &= 65535;
      return fromBits(c16 << 16 | c00, c48 << 16 | c32, this.unsigned);
    };
    LongPrototype.mul = LongPrototype.multiply;
    LongPrototype.divide = function divide(divisor) {
      if (!isLong(divisor))
        divisor = fromValue(divisor);
      if (divisor.isZero())
        throw Error("division by zero");
      if (wasm) {
        if (!this.unsigned && this.high === -2147483648 && divisor.low === -1 && divisor.high === -1) {
          return this;
        }
        var low = (this.unsigned ? wasm.div_u : wasm.div_s)(this.low, this.high, divisor.low, divisor.high);
        return fromBits(low, wasm.get_high(), this.unsigned);
      }
      if (this.isZero())
        return this.unsigned ? UZERO : ZERO;
      var approx, rem, res;
      if (!this.unsigned) {
        if (this.eq(MIN_VALUE)) {
          if (divisor.eq(ONE) || divisor.eq(NEG_ONE))
            return MIN_VALUE;
          else if (divisor.eq(MIN_VALUE))
            return ONE;
          else {
            var halfThis = this.shr(1);
            approx = halfThis.div(divisor).shl(1);
            if (approx.eq(ZERO)) {
              return divisor.isNegative() ? ONE : NEG_ONE;
            } else {
              rem = this.sub(divisor.mul(approx));
              res = approx.add(rem.div(divisor));
              return res;
            }
          }
        } else if (divisor.eq(MIN_VALUE))
          return this.unsigned ? UZERO : ZERO;
        if (this.isNegative()) {
          if (divisor.isNegative())
            return this.neg().div(divisor.neg());
          return this.neg().div(divisor).neg();
        } else if (divisor.isNegative())
          return this.div(divisor.neg()).neg();
        res = ZERO;
      } else {
        if (!divisor.unsigned)
          divisor = divisor.toUnsigned();
        if (divisor.gt(this))
          return UZERO;
        if (divisor.gt(this.shru(1)))
          return UONE;
        res = UZERO;
      }
      rem = this;
      while (rem.gte(divisor)) {
        approx = Math.max(1, Math.floor(rem.toNumber() / divisor.toNumber()));
        var log2 = Math.ceil(Math.log(approx) / Math.LN2), delta = log2 <= 48 ? 1 : pow_dbl(2, log2 - 48), approxRes = fromNumber(approx), approxRem = approxRes.mul(divisor);
        while (approxRem.isNegative() || approxRem.gt(rem)) {
          approx -= delta;
          approxRes = fromNumber(approx, this.unsigned);
          approxRem = approxRes.mul(divisor);
        }
        if (approxRes.isZero())
          approxRes = ONE;
        res = res.add(approxRes);
        rem = rem.sub(approxRem);
      }
      return res;
    };
    LongPrototype.div = LongPrototype.divide;
    LongPrototype.modulo = function modulo(divisor) {
      if (!isLong(divisor))
        divisor = fromValue(divisor);
      if (wasm) {
        var low = (this.unsigned ? wasm.rem_u : wasm.rem_s)(this.low, this.high, divisor.low, divisor.high);
        return fromBits(low, wasm.get_high(), this.unsigned);
      }
      return this.sub(this.div(divisor).mul(divisor));
    };
    LongPrototype.mod = LongPrototype.modulo;
    LongPrototype.rem = LongPrototype.modulo;
    LongPrototype.not = function not() {
      return fromBits(~this.low, ~this.high, this.unsigned);
    };
    LongPrototype.and = function and(other) {
      if (!isLong(other))
        other = fromValue(other);
      return fromBits(this.low & other.low, this.high & other.high, this.unsigned);
    };
    LongPrototype.or = function or(other) {
      if (!isLong(other))
        other = fromValue(other);
      return fromBits(this.low | other.low, this.high | other.high, this.unsigned);
    };
    LongPrototype.xor = function xor(other) {
      if (!isLong(other))
        other = fromValue(other);
      return fromBits(this.low ^ other.low, this.high ^ other.high, this.unsigned);
    };
    LongPrototype.shiftLeft = function shiftLeft(numBits) {
      if (isLong(numBits))
        numBits = numBits.toInt();
      if ((numBits &= 63) === 0)
        return this;
      else if (numBits < 32)
        return fromBits(this.low << numBits, this.high << numBits | this.low >>> 32 - numBits, this.unsigned);
      else
        return fromBits(0, this.low << numBits - 32, this.unsigned);
    };
    LongPrototype.shl = LongPrototype.shiftLeft;
    LongPrototype.shiftRight = function shiftRight(numBits) {
      if (isLong(numBits))
        numBits = numBits.toInt();
      if ((numBits &= 63) === 0)
        return this;
      else if (numBits < 32)
        return fromBits(this.low >>> numBits | this.high << 32 - numBits, this.high >> numBits, this.unsigned);
      else
        return fromBits(this.high >> numBits - 32, this.high >= 0 ? 0 : -1, this.unsigned);
    };
    LongPrototype.shr = LongPrototype.shiftRight;
    LongPrototype.shiftRightUnsigned = function shiftRightUnsigned(numBits) {
      if (isLong(numBits))
        numBits = numBits.toInt();
      numBits &= 63;
      if (numBits === 0)
        return this;
      else {
        var high = this.high;
        if (numBits < 32) {
          var low = this.low;
          return fromBits(low >>> numBits | high << 32 - numBits, high >>> numBits, this.unsigned);
        } else if (numBits === 32)
          return fromBits(high, 0, this.unsigned);
        else
          return fromBits(high >>> numBits - 32, 0, this.unsigned);
      }
    };
    LongPrototype.shru = LongPrototype.shiftRightUnsigned;
    LongPrototype.shr_u = LongPrototype.shiftRightUnsigned;
    LongPrototype.toSigned = function toSigned() {
      if (!this.unsigned)
        return this;
      return fromBits(this.low, this.high, false);
    };
    LongPrototype.toUnsigned = function toUnsigned() {
      if (this.unsigned)
        return this;
      return fromBits(this.low, this.high, true);
    };
    LongPrototype.toBytes = function toBytes(le) {
      return le ? this.toBytesLE() : this.toBytesBE();
    };
    LongPrototype.toBytesLE = function toBytesLE() {
      var hi = this.high, lo = this.low;
      return [
        lo & 255,
        lo >>> 8 & 255,
        lo >>> 16 & 255,
        lo >>> 24,
        hi & 255,
        hi >>> 8 & 255,
        hi >>> 16 & 255,
        hi >>> 24
      ];
    };
    LongPrototype.toBytesBE = function toBytesBE() {
      var hi = this.high, lo = this.low;
      return [
        hi >>> 24,
        hi >>> 16 & 255,
        hi >>> 8 & 255,
        hi & 255,
        lo >>> 24,
        lo >>> 16 & 255,
        lo >>> 8 & 255,
        lo & 255
      ];
    };
    Long$1.fromBytes = function fromBytes(bytes, unsigned, le) {
      return le ? Long$1.fromBytesLE(bytes, unsigned) : Long$1.fromBytesBE(bytes, unsigned);
    };
    Long$1.fromBytesLE = function fromBytesLE(bytes, unsigned) {
      return new Long$1(bytes[0] | bytes[1] << 8 | bytes[2] << 16 | bytes[3] << 24, bytes[4] | bytes[5] << 8 | bytes[6] << 16 | bytes[7] << 24, unsigned);
    };
    Long$1.fromBytesBE = function fromBytesBE(bytes, unsigned) {
      return new Long$1(bytes[4] << 24 | bytes[5] << 16 | bytes[6] << 8 | bytes[7], bytes[0] << 24 | bytes[1] << 16 | bytes[2] << 8 | bytes[3], unsigned);
    };
    var long$1 = /* @__PURE__ */ getDefaultExportFromCjs(long);
    var LongExports = /* @__PURE__ */ _mergeNamespaces({
      __proto__: null,
      default: long$1
    }, [long]);
    var Long = (
      // tslint:disable-next-line
      long$1 || LongExports
    );
    function hexToLong(hex) {
      return Long.fromString(hex, true, 16);
    }
    var k0 = hexToLong("c3a5c85c97cb3127");
    var k1 = hexToLong("b492b66fbe98f273");
    var k2 = hexToLong("9ae16a3b2f90404f");
    function shiftMix(val) {
      return val.xor(val.shru(47));
    }
    function fetch$2(s, offset, numBytes) {
      var bytes = s.slice(offset, offset + numBytes);
      return Long.fromBytes(Array.from(bytes), true, true);
    }
    function fetch64(s, offset) {
      return fetch$2(s, offset, 8);
    }
    function fetch32(s, offset) {
      return fetch$2(s, offset, 4);
    }
    function rotate64(val, shift) {
      return shift === 0 ? val : val.shru(shift).or(val.shl(64 - shift));
    }
    function hashLen16(u, v, mul2) {
      if (mul2 === void 0) {
        mul2 = hexToLong("9ddfea08eb382d69");
      }
      var a = u.xor(v).mul(mul2);
      a = a.xor(a.shru(47));
      var b = v.xor(a).mul(mul2);
      b = b.xor(b.shru(47));
      b = b.mul(mul2);
      return b;
    }
    function weakHashLen32WithSeeds(w, x, y, z, a, b) {
      a = a.add(w);
      b = rotate64(b.add(a).add(z), 21);
      var c = a;
      a = a.add(x);
      a = a.add(y);
      b = b.add(rotate64(a, 44));
      return [a.add(z), b.add(c)];
    }
    function weakHashLen32WithSeedsStr(s, offset, a, b) {
      return weakHashLen32WithSeeds(fetch64(s, offset), fetch64(s, offset + 8), fetch64(s, offset + 16), fetch64(s, offset + 24), a, b);
    }
    function hashLen0to16(s, len) {
      if (len === void 0) {
        len = s.length;
      }
      if (len >= 8) {
        var mul2 = k2.add(len * 2);
        var a = fetch64(s, 0).add(k2);
        var b = fetch64(s, len - 8);
        var c = rotate64(b, 37).mul(mul2).add(a);
        var d = rotate64(a, 25).add(b).mul(mul2);
        return hashLen16(c, d, mul2);
      }
      if (len >= 4) {
        var mul2 = k2.add(len * 2);
        var a = fetch32(s, 0);
        return hashLen16(a.shl(3).add(len), fetch32(s, len - 4), mul2);
      }
      if (len > 0) {
        var a = s[0];
        var b = s[len >> 1];
        var c = s[len - 1];
        var y = a + (b << 8);
        var z = len + (c << 2);
        return shiftMix(k2.mul(y).xor(k0.mul(z))).mul(k2);
      }
      return k2;
    }
    function hashLen17to32(s, len) {
      if (len === void 0) {
        len = s.length;
      }
      var mul2 = k2.add(len * 2);
      var a = fetch64(s, 0).mul(k1);
      var b = fetch64(s, 8);
      var c = fetch64(s, len - 8).mul(mul2);
      var d = fetch64(s, len - 16).mul(k2);
      return hashLen16(rotate64(a.add(b), 43).add(rotate64(c, 30)).add(d), a.add(rotate64(b.add(k2), 18)).add(c), mul2);
    }
    function hashLen33to64(s, len) {
      if (len === void 0) {
        len = s.length;
      }
      var mul2 = k2.add(len * 2);
      var a = fetch64(s, 0).mul(k2);
      var b = fetch64(s, 8);
      var c = fetch64(s, len - 8).mul(mul2);
      var d = fetch64(s, len - 16).mul(k2);
      var y = rotate64(a.add(b), 43).add(rotate64(c, 30)).add(d);
      var z = hashLen16(y, a.add(rotate64(b.add(k2), 18)).add(c), mul2);
      var e = fetch64(s, 16).mul(mul2);
      var f = fetch64(s, 24);
      var g = y.add(fetch64(s, len - 32)).mul(mul2);
      var h = z.add(fetch64(s, len - 24)).mul(mul2);
      return hashLen16(rotate64(e.add(f), 43).add(rotate64(g, 30)).add(h), e.add(rotate64(f.add(a), 18)).add(g), mul2);
    }
    function fingerPrint64(s, len) {
      var _a, _b;
      if (len === void 0) {
        len = s.length;
      }
      var seed = Long.fromNumber(81, true);
      if (len <= 32) {
        if (len <= 16) {
          return hashLen0to16(s, len);
        } else {
          return hashLen17to32(s, len);
        }
      } else if (len <= 64) {
        return hashLen33to64(s, len);
      }
      var x = seed;
      var y = seed.mul(k1).add(113);
      var z = shiftMix(y.mul(k2).add(113)).mul(k2);
      var v = [Long.UZERO, Long.UZERO];
      var w = [Long.UZERO, Long.UZERO];
      x = x.mul(k2).add(fetch64(s, 0));
      var offset = 0;
      var end = (len - 1 >> 6) * 64;
      var last64 = end + (len - 1 & 63) - 63;
      do {
        x = rotate64(x.add(y).add(v[0]).add(fetch64(s, offset + 8)), 37).mul(k1);
        y = rotate64(y.add(v[1]).add(fetch64(s, offset + 48)), 42).mul(k1);
        x = x.xor(w[1]);
        y = y.add(v[0]).add(fetch64(s, offset + 40));
        z = rotate64(z.add(w[0]), 33).mul(k1);
        v = weakHashLen32WithSeedsStr(s, offset, v[1].mul(k1), x.add(w[0]));
        w = weakHashLen32WithSeedsStr(s, offset + 32, z.add(w[1]), y.add(fetch64(s, offset + 16)));
        _a = __read([x, z], 2), z = _a[0], x = _a[1];
        offset += 64;
      } while (offset !== end);
      var mul2 = k1.add(z.and(255).shl(1));
      offset = last64;
      w[0] = w[0].add(len - 1 & 63);
      v[0] = v[0].add(w[0]);
      w[0] = w[0].add(v[0]);
      x = rotate64(x.add(y).add(v[0]).add(fetch64(s, offset + 8)), 37).mul(mul2);
      y = rotate64(y.add(v[1]).add(fetch64(s, offset + 48)), 42).mul(mul2);
      x = x.xor(w[1].mul(9));
      y = y.add(v[0].mul(9).add(fetch64(s, offset + 40)));
      z = rotate64(z.add(w[0]), 33).mul(mul2);
      v = weakHashLen32WithSeedsStr(s, offset, v[1].mul(mul2), x.add(w[0]));
      w = weakHashLen32WithSeedsStr(s, offset + 32, z.add(w[1]), y.add(fetch64(s, offset + 16)));
      _b = __read([x, z], 2), z = _b[0], x = _b[1];
      return hashLen16(hashLen16(v[0], w[0], mul2).add(shiftMix(y).mul(k0)).add(z), hashLen16(v[1], w[1], mul2).add(x), mul2);
    }
    function createScalarValue(value, dtype) {
      if (dtype === "string") {
        return encodeString(value);
      }
      return toTypedArray([value], dtype);
    }
    function noConversionNeeded(a, dtype) {
      return a instanceof Float32Array && dtype === "float32" || a instanceof Int32Array && dtype === "int32" || a instanceof Uint8Array && dtype === "bool";
    }
    function toTypedArray(a, dtype) {
      if (dtype === "string") {
        throw new Error("Cannot convert a string[] to a TypedArray");
      }
      if (Array.isArray(a)) {
        a = flatten(a);
      }
      if (env().getBool("DEBUG")) {
        checkConversionForErrors(a, dtype);
      }
      if (noConversionNeeded(a, dtype)) {
        return a;
      }
      if (dtype == null || dtype === "float32" || dtype === "complex64") {
        return new Float32Array(a);
      } else if (dtype === "int32") {
        return new Int32Array(a);
      } else if (dtype === "bool") {
        var bool = new Uint8Array(a.length);
        for (var i = 0; i < bool.length; ++i) {
          if (Math.round(a[i]) !== 0) {
            bool[i] = 1;
          }
        }
        return bool;
      } else {
        throw new Error("Unknown data type ".concat(dtype));
      }
    }
    function now() {
      return env().platform.now();
    }
    function fetch$1(path, requestInits) {
      return env().platform.fetch(path, requestInits);
    }
    function encodeString(s, encoding) {
      if (encoding === void 0) {
        encoding = "utf-8";
      }
      encoding = encoding || "utf-8";
      return env().platform.encode(s, encoding);
    }
    function decodeString(bytes, encoding) {
      if (encoding === void 0) {
        encoding = "utf-8";
      }
      encoding = encoding || "utf-8";
      return env().platform.decode(bytes, encoding);
    }
    function isTypedArray(a) {
      if (env().platform.isTypedArray != null) {
        return env().platform.isTypedArray(a);
      } else {
        return isTypedArrayBrowser(a);
      }
    }
    function flatten(arr, result, skipTypedArray) {
      var e_1, _a;
      if (result === void 0) {
        result = [];
      }
      if (skipTypedArray === void 0) {
        skipTypedArray = false;
      }
      if (result == null) {
        result = [];
      }
      if (typeof arr === "boolean" || typeof arr === "number" || typeof arr === "string" || isPromise(arr) || arr == null || isTypedArray(arr) && skipTypedArray) {
        result.push(arr);
      } else if (Array.isArray(arr) || isTypedArray(arr)) {
        for (var i = 0; i < arr.length; ++i) {
          flatten(arr[i], result, skipTypedArray);
        }
      } else {
        var maxIndex = -1;
        try {
          for (var _b = __values(Object.keys(arr)), _c = _b.next(); !_c.done; _c = _b.next()) {
            var key = _c.value;
            if (/^([1-9]+[0-9]*|0)$/.test(key)) {
              maxIndex = Math.max(maxIndex, Number(key));
            }
          }
        } catch (e_1_1) {
          e_1 = { error: e_1_1 };
        } finally {
          try {
            if (_c && !_c.done && (_a = _b.return))
              _a.call(_b);
          } finally {
            if (e_1)
              throw e_1.error;
          }
        }
        for (var i = 0; i <= maxIndex; i++) {
          flatten(arr[i], result, skipTypedArray);
        }
      }
      return result;
    }
    var util2 = {
      __proto__: null,
      arraysEqual,
      arraysEqualWithNull,
      assert,
      assertNonNegativeIntegerDimensions,
      assertNonNull,
      assertShapesMatch,
      bytesFromStringArray,
      bytesPerElement,
      checkConversionForErrors,
      clamp,
      computeStrides,
      convertBackendValuesAndArrayBuffer,
      createScalarValue,
      createShuffledIndices,
      decodeString,
      distSquared,
      encodeString,
      fetch: fetch$1,
      fingerPrint64,
      flatten,
      getArrayFromDType,
      getTypedArrayFromDType,
      hasEncodingLoss,
      hexToLong,
      indexToLoc,
      inferDtype,
      inferFromImplicitShape,
      isBoolean,
      isFunction,
      isInt,
      isNumber,
      isPromise,
      isScalarShape,
      isString,
      isTypedArray,
      isValidDtype,
      locToIndex,
      makeOnesTypedArray,
      makeZerosNestedTypedArray,
      makeZerosTypedArray,
      nearestDivisor,
      nearestLargerEven,
      now,
      parseAxisParam,
      randUniform,
      repeatedTry,
      rightPad,
      shuffle,
      shuffleCombo,
      sizeFromShape,
      sizeToSquarishShape,
      squeezeShape,
      sum: sum$1,
      swap,
      tanh: tanh$1,
      toNestedArray,
      toTypedArray
    };
    var Profiler = (
      /** @class */
      function() {
        function Profiler2(backendTimer, logger) {
          this.backendTimer = backendTimer;
          this.logger = logger;
          if (logger == null) {
            this.logger = new Logger();
          }
        }
        Profiler2.prototype.profileKernel = function(kernelName, inputs, f) {
          var e_1, _a;
          var outputs;
          var holdResultWrapperFn = function() {
            outputs = f();
          };
          var timer;
          var start = now();
          if (this.backendTimer.timerAvailable()) {
            timer = this.backendTimer.time(holdResultWrapperFn);
          } else {
            holdResultWrapperFn();
            try {
              for (var outputs_1 = __values(outputs), outputs_1_1 = outputs_1.next(); !outputs_1_1.done; outputs_1_1 = outputs_1.next()) {
                var output = outputs_1_1.value;
                output.dataSync();
              }
            } catch (e_1_1) {
              e_1 = { error: e_1_1 };
            } finally {
              try {
                if (outputs_1_1 && !outputs_1_1.done && (_a = outputs_1.return))
                  _a.call(outputs_1);
              } finally {
                if (e_1)
                  throw e_1.error;
              }
            }
            timer = Promise.resolve({ kernelMs: now() - start });
          }
          if (env().getBool("CHECK_COMPUTATION_FOR_ERRORS")) {
            var _loop_1 = function(i2) {
              var output2 = outputs[i2];
              output2.data().then(function(tensorVals) {
                checkComputationForErrors(tensorVals, output2.dtype, kernelName);
              });
            };
            for (var i = 0; i < outputs.length; i++) {
              _loop_1(i);
            }
          }
          var kernelProfile = {
            kernelName,
            outputs,
            inputs,
            timeMs: timer.then(function(timing) {
              return timing.kernelMs;
            }),
            extraInfo: timer.then(function(timing) {
              return timing.getExtraProfileInfo != null ? timing.getExtraProfileInfo() : "";
            })
          };
          return kernelProfile;
        };
        Profiler2.prototype.logKernelProfile = function(kernelProfile) {
          var _this = this;
          var kernelName = kernelProfile.kernelName, outputs = kernelProfile.outputs, timeMs = kernelProfile.timeMs, inputs = kernelProfile.inputs, extraInfo = kernelProfile.extraInfo;
          outputs.forEach(function(result) {
            Promise.all([result.data(), timeMs, extraInfo]).then(function(valueContainer) {
              _this.logger.logKernelProfile(kernelName, result, valueContainer[0], valueContainer[1], inputs, valueContainer[2]);
            });
          });
        };
        return Profiler2;
      }()
    );
    function checkComputationForErrors(vals, dtype, kernelName) {
      if (dtype !== "float32") {
        return false;
      }
      for (var i = 0; i < vals.length; i++) {
        var num = vals[i];
        if (isNaN(num) || !isFinite(num)) {
          console.warn("Found ".concat(num, " in the result of '").concat(kernelName, "'"));
          return true;
        }
      }
      return false;
    }
    var Logger = (
      /** @class */
      function() {
        function Logger2() {
        }
        Logger2.prototype.logKernelProfile = function(name, result, vals, timeMs, inputs, extraInfo) {
          var time2 = typeof timeMs === "number" ? rightPad("".concat(timeMs, "ms"), 9) : timeMs["error"];
          var paddedName = rightPad(name, 25);
          var rank = result.rank;
          var size = result.size;
          var shape = rightPad(result.shape.toString(), 14);
          var inputShapesDescription = "";
          for (var name_1 in inputs) {
            var input = inputs[name_1];
            if (input != null) {
              var inputShape = input.shape || result.shape;
              var inputRank = inputShape.length;
              inputShapesDescription += "".concat(name_1, ": ").concat(inputRank, "D ").concat(inputRank > 0 ? inputShape : "", " ");
            }
          }
          console.log("%c".concat(paddedName, "	%c").concat(time2, "	%c").concat(rank, "D ").concat(shape, "	%c").concat(size, "	%c").concat(inputShapesDescription, "	%c").concat(extraInfo), "font-weight:bold", "color:red", "color:blue", "color: orange", "color: green", "color: steelblue");
        };
        return Logger2;
      }()
    );
    function getFilteredNodesXToY(tape, xs, y) {
      var tensorsFromX = {};
      var nodesFromX = {};
      for (var i = 0; i < xs.length; i++) {
        tensorsFromX[xs[i].id] = true;
      }
      for (var i = 0; i < tape.length; i++) {
        var node = tape[i];
        var nodeInputs = node.inputs;
        for (var inputName in nodeInputs) {
          var input = nodeInputs[inputName];
          var anyInputFromX = false;
          for (var j = 0; j < xs.length; j++) {
            if (tensorsFromX[input.id]) {
              node.outputs.forEach(function(output) {
                return tensorsFromX[output.id] = true;
              });
              anyInputFromX = true;
              nodesFromX[node.id] = true;
              break;
            }
          }
          if (anyInputFromX) {
            break;
          }
        }
      }
      var tensorsLeadToY = {};
      tensorsLeadToY[y.id] = true;
      var nodesToY = {};
      for (var i = tape.length - 1; i >= 0; i--) {
        var node = tape[i];
        var nodeInputs = node.inputs;
        for (var j = 0; j < node.outputs.length; j++) {
          if (tensorsLeadToY[node.outputs[j].id]) {
            for (var inputName in nodeInputs) {
              tensorsLeadToY[nodeInputs[inputName].id] = true;
              nodesToY[node.id] = true;
            }
            break;
          }
        }
      }
      var filteredTape = [];
      for (var i = 0; i < tape.length; i++) {
        var node = tape[i];
        if (nodesFromX[node.id] && nodesToY[node.id]) {
          var prunedInputs = {};
          for (var inputName in node.inputs) {
            var nodeInput = node.inputs[inputName];
            if (tensorsFromX[nodeInput.id]) {
              prunedInputs[inputName] = nodeInput;
            }
          }
          var prunedNode = Object.assign({}, node);
          prunedNode.inputs = prunedInputs;
          prunedNode.outputs = node.outputs;
          filteredTape.push(prunedNode);
        }
      }
      return filteredTape;
    }
    function backpropagateGradients(tensorAccumulatedGradientMap, filteredTape, tidy2, add2) {
      var _loop_1 = function(i2) {
        var node = filteredTape[i2];
        var dys = [];
        node.outputs.forEach(function(o) {
          var gradTensor = tensorAccumulatedGradientMap[o.id];
          if (gradTensor != null) {
            dys.push(gradTensor);
          } else {
            dys.push(null);
          }
        });
        if (node.gradient == null) {
          throw new Error("Cannot compute gradient: gradient function not found " + "for ".concat(node.kernelName, "."));
        }
        var inputGradients = node.gradient(dys);
        var _loop_2 = function(inputName2) {
          if (!(inputName2 in inputGradients)) {
            throw new Error("Cannot backprop through input ".concat(inputName2, ". ") + "Available gradients found: ".concat(Object.keys(inputGradients), "."));
          }
          var dx = tidy2(function() {
            return inputGradients[inputName2]();
          });
          if (dx.dtype !== "float32") {
            throw new Error("Error in gradient for op ".concat(node.kernelName, ". The gradient of input ") + "".concat(inputName2, " must have 'float32' dtype, but has '").concat(dx.dtype, "'"));
          }
          var x = node.inputs[inputName2];
          if (!arraysEqual(dx.shape, x.shape)) {
            throw new Error("Error in gradient for op ".concat(node.kernelName, ". The gradient of input ") + "'".concat(inputName2, "' has shape '").concat(dx.shape, "', which does not match ") + "the shape of the input '".concat(x.shape, "'"));
          }
          if (tensorAccumulatedGradientMap[x.id] == null) {
            tensorAccumulatedGradientMap[x.id] = dx;
          } else {
            var curGradient = tensorAccumulatedGradientMap[x.id];
            tensorAccumulatedGradientMap[x.id] = add2(curGradient, dx);
            curGradient.dispose();
          }
        };
        for (var inputName in node.inputs) {
          _loop_2(inputName);
        }
      };
      for (var i = filteredTape.length - 1; i >= 0; i--) {
        _loop_1(i);
      }
    }
    var FORMAT_LIMIT_NUM_VALS = 20;
    var FORMAT_NUM_FIRST_LAST_VALS = 3;
    var FORMAT_NUM_SIG_DIGITS = 7;
    function tensorToString(vals, shape, dtype, verbose) {
      var strides = computeStrides(shape);
      var padPerCol = computeMaxSizePerColumn(vals, shape, dtype, strides);
      var rank = shape.length;
      var valsLines = subTensorToString(vals, shape, dtype, strides, padPerCol);
      var lines = ["Tensor"];
      if (verbose) {
        lines.push("  dtype: ".concat(dtype));
        lines.push("  rank: ".concat(rank));
        lines.push("  shape: [".concat(shape, "]"));
        lines.push("  values:");
      }
      lines.push(valsLines.map(function(l) {
        return "    " + l;
      }).join("\n"));
      return lines.join("\n");
    }
    function computeMaxSizePerColumn(vals, shape, dtype, strides) {
      var n = sizeFromShape(shape);
      var numCols = strides[strides.length - 1];
      var padPerCol = new Array(numCols).fill(0);
      var rank = shape.length;
      var valuesOrTuples = dtype === "complex64" ? createComplexTuples(vals) : vals;
      if (rank > 1) {
        for (var row = 0; row < n / numCols; row++) {
          var offset = row * numCols;
          for (var j = 0; j < numCols; j++) {
            padPerCol[j] = Math.max(padPerCol[j], valToString(valuesOrTuples[offset + j], 0, dtype).length);
          }
        }
      }
      return padPerCol;
    }
    function valToString(val, pad2, dtype) {
      var valStr;
      if (Array.isArray(val)) {
        valStr = "".concat(parseFloat(val[0].toFixed(FORMAT_NUM_SIG_DIGITS)), " + ") + "".concat(parseFloat(val[1].toFixed(FORMAT_NUM_SIG_DIGITS)), "j");
      } else if (isString(val)) {
        valStr = "'".concat(val, "'");
      } else if (dtype === "bool") {
        valStr = boolNumToString(val);
      } else {
        valStr = parseFloat(val.toFixed(FORMAT_NUM_SIG_DIGITS)).toString();
      }
      return rightPad(valStr, pad2);
    }
    function boolNumToString(v) {
      return v === 0 ? "false" : "true";
    }
    function subTensorToString(vals, shape, dtype, strides, padPerCol, isLast) {
      if (isLast === void 0) {
        isLast = true;
      }
      var storagePerElement = dtype === "complex64" ? 2 : 1;
      var size = shape[0];
      var rank = shape.length;
      if (rank === 0) {
        if (dtype === "complex64") {
          var complexTuple = createComplexTuples(vals);
          return [valToString(complexTuple[0], 0, dtype)];
        }
        if (dtype === "bool") {
          return [boolNumToString(vals[0])];
        }
        return [vals[0].toString()];
      }
      if (rank === 1) {
        if (size > FORMAT_LIMIT_NUM_VALS) {
          var firstValsSize = FORMAT_NUM_FIRST_LAST_VALS * storagePerElement;
          var firstVals = Array.from(vals.slice(0, firstValsSize));
          var lastVals = Array.from(vals.slice((size - FORMAT_NUM_FIRST_LAST_VALS) * storagePerElement, size * storagePerElement));
          if (dtype === "complex64") {
            firstVals = createComplexTuples(firstVals);
            lastVals = createComplexTuples(lastVals);
          }
          return [
            "[" + firstVals.map(function(x, i2) {
              return valToString(x, padPerCol[i2], dtype);
            }).join(", ") + ", ..., " + lastVals.map(function(x, i2) {
              return valToString(x, padPerCol[size - FORMAT_NUM_FIRST_LAST_VALS + i2], dtype);
            }).join(", ") + "]"
          ];
        }
        var displayVals = dtype === "complex64" ? createComplexTuples(vals) : Array.from(vals);
        return [
          "[" + displayVals.map(function(x, i2) {
            return valToString(x, padPerCol[i2], dtype);
          }).join(", ") + "]"
        ];
      }
      var subshape = shape.slice(1);
      var substrides = strides.slice(1);
      var stride = strides[0] * storagePerElement;
      var lines = [];
      if (size > FORMAT_LIMIT_NUM_VALS) {
        for (var i = 0; i < FORMAT_NUM_FIRST_LAST_VALS; i++) {
          var start = i * stride;
          var end = start + stride;
          lines.push.apply(lines, __spreadArray([], __read(subTensorToString(
            vals.slice(start, end),
            subshape,
            dtype,
            substrides,
            padPerCol,
            false
            /* isLast */
          )), false));
        }
        lines.push("...");
        for (var i = size - FORMAT_NUM_FIRST_LAST_VALS; i < size; i++) {
          var start = i * stride;
          var end = start + stride;
          lines.push.apply(lines, __spreadArray([], __read(subTensorToString(
            vals.slice(start, end),
            subshape,
            dtype,
            substrides,
            padPerCol,
            i === size - 1
            /* isLast */
          )), false));
        }
      } else {
        for (var i = 0; i < size; i++) {
          var start = i * stride;
          var end = start + stride;
          lines.push.apply(lines, __spreadArray([], __read(subTensorToString(
            vals.slice(start, end),
            subshape,
            dtype,
            substrides,
            padPerCol,
            i === size - 1
            /* isLast */
          )), false));
        }
      }
      var sep = rank === 2 ? "," : "";
      lines[0] = "[" + (size > 0 ? lines[0] + sep : "");
      for (var i = 1; i < lines.length - 1; i++) {
        lines[i] = " " + lines[i] + sep;
      }
      var newLineSep = ",\n";
      for (var i = 2; i < rank; i++) {
        newLineSep += "\n";
      }
      lines[lines.length - 1] = " " + lines[lines.length - 1] + "]" + (isLast ? "" : newLineSep);
      return lines;
    }
    function createComplexTuples(vals) {
      var complexTuples = [];
      for (var i = 0; i < vals.length; i += 2) {
        complexTuples.push([vals[i], vals[i + 1]]);
      }
      return complexTuples;
    }
    var TensorBuffer = (
      /** @class */
      function() {
        function TensorBuffer2(shape, dtype, values) {
          var _this = this;
          this.dtype = dtype;
          this.shape = shape.slice();
          this.size = sizeFromShape(shape);
          if (values != null) {
            var n_1 = values.length;
            assert(n_1 === this.size, function() {
              return "Length of values '".concat(n_1, "' does not match the size ") + "inferred by the shape '".concat(_this.size, "'.");
            });
          }
          if (dtype === "complex64") {
            throw new Error("complex64 dtype TensorBuffers are not supported. Please create a TensorBuffer for the real and imaginary parts separately and call tf.complex(real, imag).");
          }
          this.values = values || getArrayFromDType(dtype, this.size);
          this.strides = computeStrides(shape);
        }
        TensorBuffer2.prototype.set = function(value) {
          var _this = this;
          var locs = [];
          for (var _i = 1; _i < arguments.length; _i++) {
            locs[_i - 1] = arguments[_i];
          }
          if (locs.length === 0) {
            locs = [0];
          }
          assert(locs.length === this.rank, function() {
            return "The number of provided coordinates (".concat(locs.length, ") must ") + "match the rank (".concat(_this.rank, ")");
          });
          var index = this.locToIndex(locs);
          this.values[index] = value;
        };
        TensorBuffer2.prototype.get = function() {
          var e_1, _b;
          var locs = [];
          for (var _i = 0; _i < arguments.length; _i++) {
            locs[_i] = arguments[_i];
          }
          if (locs.length === 0) {
            locs = [0];
          }
          var i = 0;
          try {
            for (var locs_1 = __values(locs), locs_1_1 = locs_1.next(); !locs_1_1.done; locs_1_1 = locs_1.next()) {
              var loc = locs_1_1.value;
              if (loc < 0 || loc >= this.shape[i]) {
                var msg = "Requested out of range element at ".concat(locs, ". ") + "  Buffer shape=".concat(this.shape);
                throw new Error(msg);
              }
              i++;
            }
          } catch (e_1_1) {
            e_1 = { error: e_1_1 };
          } finally {
            try {
              if (locs_1_1 && !locs_1_1.done && (_b = locs_1.return))
                _b.call(locs_1);
            } finally {
              if (e_1)
                throw e_1.error;
            }
          }
          var index = locs[locs.length - 1];
          for (var i_1 = 0; i_1 < locs.length - 1; ++i_1) {
            index += this.strides[i_1] * locs[i_1];
          }
          return this.values[index];
        };
        TensorBuffer2.prototype.locToIndex = function(locs) {
          if (this.rank === 0) {
            return 0;
          } else if (this.rank === 1) {
            return locs[0];
          }
          var index = locs[locs.length - 1];
          for (var i = 0; i < locs.length - 1; ++i) {
            index += this.strides[i] * locs[i];
          }
          return index;
        };
        TensorBuffer2.prototype.indexToLoc = function(index) {
          if (this.rank === 0) {
            return [];
          } else if (this.rank === 1) {
            return [index];
          }
          var locs = new Array(this.shape.length);
          for (var i = 0; i < locs.length - 1; ++i) {
            locs[i] = Math.floor(index / this.strides[i]);
            index -= locs[i] * this.strides[i];
          }
          locs[locs.length - 1] = index;
          return locs;
        };
        Object.defineProperty(TensorBuffer2.prototype, "rank", {
          get: function() {
            return this.shape.length;
          },
          enumerable: false,
          configurable: true
        });
        TensorBuffer2.prototype.toTensor = function() {
          return trackerFn().makeTensor(this.values, this.shape, this.dtype);
        };
        return TensorBuffer2;
      }()
    );
    var trackerFn = null;
    var opHandler$1 = null;
    function setTensorTracker(fn) {
      trackerFn = fn;
    }
    function setOpHandler(handler) {
      opHandler$1 = handler;
    }
    var Tensor = (
      /** @class */
      function() {
        function Tensor2(shape, dtype, dataId, id) {
          this.kept = false;
          this.isDisposedInternal = false;
          this.shape = shape.slice();
          this.dtype = dtype || "float32";
          this.size = sizeFromShape(shape);
          this.strides = computeStrides(shape);
          this.dataId = dataId;
          this.id = id;
          this.rankType = this.rank < 5 ? this.rank.toString() : "higher";
        }
        Object.defineProperty(Tensor2.prototype, "rank", {
          get: function() {
            return this.shape.length;
          },
          enumerable: false,
          configurable: true
        });
        Tensor2.prototype.buffer = function() {
          return __awaiter(this, void 0, void 0, function() {
            var vals;
            return __generator(this, function(_b) {
              switch (_b.label) {
                case 0:
                  return [4, this.data()];
                case 1:
                  vals = _b.sent();
                  return [2, opHandler$1.buffer(this.shape, this.dtype, vals)];
              }
            });
          });
        };
        Tensor2.prototype.bufferSync = function() {
          return opHandler$1.buffer(this.shape, this.dtype, this.dataSync());
        };
        Tensor2.prototype.array = function() {
          return __awaiter(this, void 0, void 0, function() {
            var vals;
            return __generator(this, function(_b) {
              switch (_b.label) {
                case 0:
                  return [4, this.data()];
                case 1:
                  vals = _b.sent();
                  return [2, toNestedArray(this.shape, vals, this.dtype === "complex64")];
              }
            });
          });
        };
        Tensor2.prototype.arraySync = function() {
          return toNestedArray(this.shape, this.dataSync(), this.dtype === "complex64");
        };
        Tensor2.prototype.data = function() {
          return __awaiter(this, void 0, void 0, function() {
            var data, bytes;
            return __generator(this, function(_b) {
              switch (_b.label) {
                case 0:
                  this.throwIfDisposed();
                  data = trackerFn().read(this.dataId);
                  if (!(this.dtype === "string"))
                    return [3, 2];
                  return [4, data];
                case 1:
                  bytes = _b.sent();
                  try {
                    return [2, bytes.map(function(b) {
                      return decodeString(b);
                    })];
                  } catch (_a) {
                    throw new Error("Failed to decode the string bytes into utf-8. To get the original bytes, call tensor.bytes().");
                  }
                  _b.label = 2;
                case 2:
                  return [2, data];
              }
            });
          });
        };
        Tensor2.prototype.dataToGPU = function(options) {
          this.throwIfDisposed();
          return trackerFn().readToGPU(this.dataId, options);
        };
        Tensor2.prototype.dataSync = function() {
          this.throwIfDisposed();
          var data = trackerFn().readSync(this.dataId);
          if (this.dtype === "string") {
            try {
              return data.map(function(b) {
                return decodeString(b);
              });
            } catch (_a) {
              throw new Error("Failed to decode the string bytes into utf-8. To get the original bytes, call tensor.bytes().");
            }
          }
          return data;
        };
        Tensor2.prototype.bytes = function() {
          return __awaiter(this, void 0, void 0, function() {
            var data;
            return __generator(this, function(_b) {
              switch (_b.label) {
                case 0:
                  this.throwIfDisposed();
                  return [4, trackerFn().read(this.dataId)];
                case 1:
                  data = _b.sent();
                  if (this.dtype === "string") {
                    return [2, data];
                  } else {
                    return [2, new Uint8Array(data.buffer)];
                  }
              }
            });
          });
        };
        Tensor2.prototype.dispose = function() {
          if (this.isDisposed) {
            return;
          }
          trackerFn().disposeTensor(this);
          this.isDisposedInternal = true;
        };
        Object.defineProperty(Tensor2.prototype, "isDisposed", {
          get: function() {
            return this.isDisposedInternal;
          },
          enumerable: false,
          configurable: true
        });
        Tensor2.prototype.throwIfDisposed = function() {
          if (this.isDisposed) {
            throw new Error("Tensor is disposed.");
          }
        };
        Tensor2.prototype.print = function(verbose) {
          if (verbose === void 0) {
            verbose = false;
          }
          return opHandler$1.print(this, verbose);
        };
        Tensor2.prototype.clone = function() {
          this.throwIfDisposed();
          return opHandler$1.clone(this);
        };
        Tensor2.prototype.toString = function(verbose) {
          if (verbose === void 0) {
            verbose = false;
          }
          var vals = this.dataSync();
          return tensorToString(vals, this.shape, this.dtype, verbose);
        };
        Tensor2.prototype.cast = function(dtype) {
          this.throwIfDisposed();
          return opHandler$1.cast(this, dtype);
        };
        Tensor2.prototype.variable = function(trainable, name, dtype) {
          if (trainable === void 0) {
            trainable = true;
          }
          this.throwIfDisposed();
          return trackerFn().makeVariable(this, trainable, name, dtype);
        };
        return Tensor2;
      }()
    );
    Object.defineProperty(Tensor, Symbol.hasInstance, {
      value: function(instance) {
        return !!instance && instance.data != null && instance.dataSync != null && instance.throwIfDisposed != null;
      }
    });
    function getGlobalTensorClass() {
      return getGlobal("Tensor", function() {
        return Tensor;
      });
    }
    getGlobalTensorClass();
    var Variable = (
      /** @class */
      function(_super) {
        __extends(Variable2, _super);
        function Variable2(initialValue, trainable, name, tensorId) {
          var _this = _super.call(this, initialValue.shape, initialValue.dtype, initialValue.dataId, tensorId) || this;
          _this.trainable = trainable;
          _this.name = name;
          return _this;
        }
        Variable2.prototype.assign = function(newValue) {
          if (newValue.dtype !== this.dtype) {
            throw new Error("dtype of the new value (".concat(newValue.dtype, ") and ") + "previous value (".concat(this.dtype, ") must match"));
          }
          if (!arraysEqual(newValue.shape, this.shape)) {
            throw new Error("shape of the new value (".concat(newValue.shape, ") and ") + "previous value (".concat(this.shape, ") must match"));
          }
          trackerFn().disposeTensor(this);
          this.dataId = newValue.dataId;
          trackerFn().incRef(
            this,
            null
            /* backend */
          );
        };
        Variable2.prototype.dispose = function() {
          trackerFn().disposeVariable(this);
          this.isDisposedInternal = true;
        };
        return Variable2;
      }(Tensor)
    );
    Object.defineProperty(Variable, Symbol.hasInstance, {
      value: function(instance) {
        return instance instanceof Tensor && instance.assign != null && instance.assign instanceof Function;
      }
    });
    exports.Rank = void 0;
    (function(Rank) {
      Rank["R0"] = "R0";
      Rank["R1"] = "R1";
      Rank["R2"] = "R2";
      Rank["R3"] = "R3";
      Rank["R4"] = "R4";
      Rank["R5"] = "R5";
      Rank["R6"] = "R6";
    })(exports.Rank || (exports.Rank = {}));
    var UpcastInt32AndMap;
    (function(UpcastInt32AndMap2) {
      UpcastInt32AndMap2["float32"] = "float32";
      UpcastInt32AndMap2["int32"] = "int32";
      UpcastInt32AndMap2["bool"] = "int32";
      UpcastInt32AndMap2["complex64"] = "complex64";
    })(UpcastInt32AndMap || (UpcastInt32AndMap = {}));
    var UpcastBoolAndMap;
    (function(UpcastBoolAndMap2) {
      UpcastBoolAndMap2["float32"] = "float32";
      UpcastBoolAndMap2["int32"] = "int32";
      UpcastBoolAndMap2["bool"] = "bool";
      UpcastBoolAndMap2["complex64"] = "complex64";
    })(UpcastBoolAndMap || (UpcastBoolAndMap = {}));
    var UpcastFloat32AndMap;
    (function(UpcastFloat32AndMap2) {
      UpcastFloat32AndMap2["float32"] = "float32";
      UpcastFloat32AndMap2["int32"] = "float32";
      UpcastFloat32AndMap2["bool"] = "float32";
      UpcastFloat32AndMap2["complex64"] = "complex64";
    })(UpcastFloat32AndMap || (UpcastFloat32AndMap = {}));
    var UpcastComplex64AndMap;
    (function(UpcastComplex64AndMap2) {
      UpcastComplex64AndMap2["float32"] = "complex64";
      UpcastComplex64AndMap2["int32"] = "complex64";
      UpcastComplex64AndMap2["bool"] = "complex64";
      UpcastComplex64AndMap2["complex64"] = "complex64";
    })(UpcastComplex64AndMap || (UpcastComplex64AndMap = {}));
    var upcastTypeMap = {
      "float32": UpcastFloat32AndMap,
      "int32": UpcastInt32AndMap,
      "bool": UpcastBoolAndMap,
      "complex64": UpcastComplex64AndMap
    };
    function upcastType(typeA, typeB) {
      if (typeA === "string" || typeB === "string") {
        if (typeA === "string" && typeB === "string") {
          return "string";
        }
        throw new Error("Can not upcast ".concat(typeA, " with ").concat(typeB));
      }
      return upcastTypeMap[typeA][typeB];
    }
    function sumOutType(type) {
      return upcastType(type, "int32");
    }
    function isWebGLData(values) {
      return values != null && typeof values === "object" && "texture" in values && values.texture instanceof WebGLTexture;
    }
    function isWebGPUData(values) {
      return typeof GPUBuffer !== "undefined" && values != null && typeof values === "object" && "buffer" in values && values.buffer instanceof GPUBuffer;
    }
    function makeTypesMatch(a, b) {
      if (a.dtype === b.dtype) {
        return [a, b];
      }
      var dtype = upcastType(a.dtype, b.dtype);
      return [a.cast(dtype), b.cast(dtype)];
    }
    function assertTypesMatch(a, b) {
      assert(a.dtype === b.dtype, function() {
        return "The dtypes of the first(".concat(a.dtype, ") and") + " second(".concat(b.dtype, ") input must match");
      });
    }
    function isTensorInList(tensor2, tensorList) {
      return tensorList.some(function(x) {
        return x.id === tensor2.id;
      });
    }
    function getTensorsInContainer(result) {
      var list = [];
      var seen = /* @__PURE__ */ new Set();
      walkTensorContainer(result, list, seen);
      return list;
    }
    function walkTensorContainer(container, list, seen) {
      if (container == null) {
        return;
      }
      if (container instanceof Tensor) {
        list.push(container);
        return;
      }
      if (!isIterable(container)) {
        return;
      }
      var iterable = container;
      for (var k in iterable) {
        var val = iterable[k];
        if (!seen.has(val)) {
          seen.add(val);
          walkTensorContainer(val, list, seen);
        }
      }
    }
    function isIterable(obj) {
      return Array.isArray(obj) || typeof obj === "object";
    }
    var tensor_util = {
      __proto__: null,
      assertTypesMatch,
      getTensorsInContainer,
      isTensorInList,
      makeTypesMatch
    };
    function isRegisteredKernelInvocation(kernelInvocation) {
      return kernelInvocation.kernelName != null;
    }
    var EngineState = (
      /** @class */
      function() {
        function EngineState2() {
          this.registeredVariables = {};
          this.nextTapeNodeId = 0;
          this.numBytes = 0;
          this.numTensors = 0;
          this.numStringTensors = 0;
          this.numDataBuffers = 0;
          this.gradientDepth = 0;
          this.kernelDepth = 0;
          this.scopeStack = [];
          this.numDataMovesStack = [];
          this.nextScopeId = 0;
          this.tensorInfo = /* @__PURE__ */ new WeakMap();
          this.profiling = false;
          this.activeProfile = {
            newBytes: 0,
            newTensors: 0,
            peakBytes: 0,
            kernels: [],
            result: null,
            get kernelNames() {
              return Array.from(new Set(this.kernels.map(function(k) {
                return k.name;
              })));
            }
          };
        }
        EngineState2.prototype.dispose = function() {
          for (var variableName in this.registeredVariables) {
            this.registeredVariables[variableName].dispose();
          }
        };
        return EngineState2;
      }()
    );
    var Engine = (
      /** @class */
      function() {
        function Engine2(ENV2) {
          this.ENV = ENV2;
          this.registry = {};
          this.registryFactory = {};
          this.pendingBackendInitId = 0;
          this.state = new EngineState();
        }
        Engine2.prototype.ready = function() {
          return __awaiter(this, void 0, void 0, function() {
            var sortedBackends, i, backendName, success;
            return __generator(this, function(_a) {
              switch (_a.label) {
                case 0:
                  if (this.pendingBackendInit != null) {
                    return [2, this.pendingBackendInit.then(function() {
                    })];
                  }
                  if (this.backendInstance != null) {
                    return [
                      2
                      /*return*/
                    ];
                  }
                  sortedBackends = this.getSortedBackends();
                  i = 0;
                  _a.label = 1;
                case 1:
                  if (!(i < sortedBackends.length))
                    return [3, 5];
                  backendName = sortedBackends[i];
                  return [4, this.initializeBackend(backendName).success];
                case 2:
                  success = _a.sent();
                  if (!success)
                    return [3, 4];
                  return [4, this.setBackend(backendName)];
                case 3:
                  _a.sent();
                  return [
                    2
                    /*return*/
                  ];
                case 4:
                  i++;
                  return [3, 1];
                case 5:
                  throw new Error("Could not initialize any backends, all backend initializations failed.");
              }
            });
          });
        };
        Object.defineProperty(Engine2.prototype, "backend", {
          get: function() {
            if (this.pendingBackendInit != null) {
              throw new Error("Backend '".concat(this.backendName, "' has not yet been initialized. Make ") + "sure to await tf.ready() or await tf.setBackend() before calling other methods");
            }
            if (this.backendInstance == null) {
              var _a = this.initializeBackendsAndReturnBest(), name = _a.name, asyncInit = _a.asyncInit;
              if (asyncInit) {
                throw new Error("The highest priority backend '".concat(name, "' has not yet been ") + "initialized. Make sure to await tf.ready() or await tf.setBackend() before calling other methods");
              }
              this.setBackend(name);
            }
            return this.backendInstance;
          },
          enumerable: false,
          configurable: true
        });
        Engine2.prototype.backendNames = function() {
          return Object.keys(this.registryFactory);
        };
        Engine2.prototype.findBackend = function(backendName) {
          if (!(backendName in this.registry)) {
            if (backendName in this.registryFactory) {
              var asyncInit = this.initializeBackend(backendName).asyncInit;
              if (asyncInit) {
                return null;
              }
            } else {
              return null;
            }
          }
          return this.registry[backendName];
        };
        Engine2.prototype.findBackendFactory = function(backendName) {
          if (!(backendName in this.registryFactory)) {
            return null;
          }
          return this.registryFactory[backendName].factory;
        };
        Engine2.prototype.registerBackend = function(backendName, factory, priority) {
          if (priority === void 0) {
            priority = 1;
          }
          if (backendName in this.registryFactory) {
            warn("".concat(backendName, " backend was already registered. ") + "Reusing existing backend factory.");
            return false;
          }
          this.registryFactory[backendName] = { factory, priority };
          return true;
        };
        Engine2.prototype.setBackend = function(backendName) {
          return __awaiter(this, void 0, void 0, function() {
            var _a, success, asyncInit, result, _b;
            return __generator(this, function(_c) {
              switch (_c.label) {
                case 0:
                  if (this.registryFactory[backendName] == null) {
                    throw new Error("Backend name '".concat(backendName, "' not found in registry"));
                  }
                  this.backendName = backendName;
                  if (!(this.registry[backendName] == null))
                    return [3, 4];
                  this.backendInstance = null;
                  _a = this.initializeBackend(backendName), success = _a.success, asyncInit = _a.asyncInit;
                  if (!asyncInit)
                    return [3, 2];
                  return [4, success];
                case 1:
                  _b = _c.sent();
                  return [3, 3];
                case 2:
                  _b = success;
                  _c.label = 3;
                case 3:
                  result = _b;
                  if (!result) {
                    return [2, false];
                  }
                  _c.label = 4;
                case 4:
                  this.backendInstance = this.registry[backendName];
                  this.setupRegisteredKernels();
                  this.profiler = new Profiler(this.backendInstance);
                  return [2, true];
              }
            });
          });
        };
        Engine2.prototype.setupRegisteredKernels = function() {
          var _this = this;
          var kernels = getKernelsForBackend(this.backendName);
          kernels.forEach(function(kernel) {
            if (kernel.setupFunc != null) {
              kernel.setupFunc(_this.backendInstance);
            }
          });
        };
        Engine2.prototype.disposeRegisteredKernels = function(backendName) {
          var _this = this;
          var kernels = getKernelsForBackend(backendName);
          kernels.forEach(function(kernel) {
            if (kernel.disposeFunc != null) {
              kernel.disposeFunc(_this.registry[backendName]);
            }
          });
        };
        Engine2.prototype.initializeBackend = function(backendName) {
          var _this = this;
          var registryFactoryEntry = this.registryFactory[backendName];
          if (registryFactoryEntry == null) {
            throw new Error("Cannot initialize backend ".concat(backendName, ", no registration found."));
          }
          try {
            var backend2 = registryFactoryEntry.factory();
            if (backend2 && !(backend2 instanceof KernelBackend) && typeof backend2.then === "function") {
              var promiseId_1 = ++this.pendingBackendInitId;
              var success = backend2.then(function(backendInstance) {
                if (promiseId_1 < _this.pendingBackendInitId) {
                  return false;
                }
                _this.registry[backendName] = backendInstance;
                _this.pendingBackendInit = null;
                return true;
              }).catch(function(err) {
                if (promiseId_1 < _this.pendingBackendInitId) {
                  return false;
                }
                _this.pendingBackendInit = null;
                warn("Initialization of backend ".concat(backendName, " failed"));
                warn(err.stack || err.message);
                return false;
              });
              this.pendingBackendInit = success;
              return { success, asyncInit: true };
            } else {
              this.registry[backendName] = backend2;
              return { success: true, asyncInit: false };
            }
          } catch (err) {
            warn("Initialization of backend ".concat(backendName, " failed"));
            warn(err.stack || err.message);
            return { success: false, asyncInit: false };
          }
        };
        Engine2.prototype.removeBackend = function(backendName) {
          if (!(backendName in this.registryFactory)) {
            throw new Error("".concat(backendName, " backend not found in registry"));
          }
          if (this.backendName === backendName && this.pendingBackendInit != null) {
            this.pendingBackendInitId++;
          }
          if (backendName in this.registry) {
            this.disposeRegisteredKernels(backendName);
            this.registry[backendName].dispose();
            delete this.registry[backendName];
          }
          delete this.registryFactory[backendName];
          if (this.backendName === backendName) {
            this.pendingBackendInit = null;
            this.backendName = null;
            this.backendInstance = null;
          }
        };
        Engine2.prototype.getSortedBackends = function() {
          var _this = this;
          if (Object.keys(this.registryFactory).length === 0) {
            throw new Error("No backend found in registry.");
          }
          return Object.keys(this.registryFactory).sort(function(a, b) {
            return _this.registryFactory[b].priority - _this.registryFactory[a].priority;
          });
        };
        Engine2.prototype.initializeBackendsAndReturnBest = function() {
          var sortedBackends = this.getSortedBackends();
          for (var i = 0; i < sortedBackends.length; i++) {
            var backendName = sortedBackends[i];
            var _a = this.initializeBackend(backendName), success = _a.success, asyncInit = _a.asyncInit;
            if (asyncInit || success) {
              return { name: backendName, asyncInit };
            }
          }
          throw new Error("Could not initialize any backends, all backend initializations failed.");
        };
        Engine2.prototype.moveData = function(backend2, dataId) {
          var info = this.state.tensorInfo.get(dataId);
          var srcBackend = info.backend;
          var values = this.readSync(dataId);
          var refCount = srcBackend.refCount(dataId);
          srcBackend.disposeData(dataId, true);
          info.backend = backend2;
          backend2.move(dataId, values, info.shape, info.dtype, refCount);
          if (this.shouldCheckForMemLeaks()) {
            this.state.numDataMovesStack[this.state.numDataMovesStack.length - 1]++;
          }
        };
        Engine2.prototype.tidy = function(nameOrFn, fn) {
          var _this = this;
          var name = null;
          if (fn == null) {
            if (typeof nameOrFn !== "function") {
              throw new Error("Please provide a function to tidy()");
            }
            fn = nameOrFn;
          } else {
            if (typeof nameOrFn !== "string" && !(nameOrFn instanceof String)) {
              throw new Error("When calling with two arguments, the first argument to tidy() must be a string");
            }
            if (typeof fn !== "function") {
              throw new Error("When calling with two arguments, the 2nd argument to tidy() must be a function");
            }
            name = nameOrFn;
          }
          var result;
          return this.scopedRun(function() {
            return _this.startScope(name);
          }, function() {
            return _this.endScope(result);
          }, function() {
            result = fn();
            if (result instanceof Promise) {
              console.error("Cannot return a Promise inside of tidy.");
            }
            return result;
          });
        };
        Engine2.prototype.scopedRun = function(start, end, f) {
          start();
          try {
            var res = f();
            end();
            return res;
          } catch (ex) {
            end();
            throw ex;
          }
        };
        Engine2.prototype.nextTensorId = function() {
          return Engine2.nextTensorId++;
        };
        Engine2.prototype.nextVariableId = function() {
          return Engine2.nextVariableId++;
        };
        Engine2.prototype.clone = function(x) {
          var y = ENGINE.runKernel(Identity, { x });
          var inputs = { x };
          var grad2 = function(dy) {
            return {
              x: function() {
                var dtype = "float32";
                var gradInputs = { x: dy };
                var attrs = { dtype };
                return ENGINE.runKernel(
                  Cast,
                  gradInputs,
                  // tslint:disable-next-line: no-unnecessary-type-assertion
                  attrs
                );
              }
            };
          };
          var saved = [];
          this.addTapeNode(this.state.activeScope.name, inputs, [y], grad2, saved, {});
          return y;
        };
        Engine2.prototype.runKernel = function(kernelName, inputs, attrs) {
          if (this.backendName == null) {
            this.backend;
          }
          var hasKernel = getKernel(kernelName, this.backendName) != null;
          if (!hasKernel) {
            throw new Error("Kernel '".concat(kernelName, "' not registered for backend '").concat(this.backendName, "'"));
          }
          return this.runKernelFunc({ kernelName, inputs, attrs });
        };
        Engine2.prototype.shouldCheckForMemLeaks = function() {
          return this.ENV.getBool("IS_TEST");
        };
        Engine2.prototype.checkKernelForMemLeak = function(kernelName, numDataIdsBefore, outInfos) {
          var numDataIdsAfter = this.backend.numDataIds();
          var numOutputDataIds = 0;
          outInfos.forEach(function(info) {
            numOutputDataIds += info.dtype === "complex64" ? 3 : 1;
          });
          var numMoves = this.state.numDataMovesStack[this.state.numDataMovesStack.length - 1];
          var dataIdsLeaked = numDataIdsAfter - numDataIdsBefore - numOutputDataIds - numMoves;
          if (dataIdsLeaked > 0) {
            throw new Error("Backend '".concat(this.backendName, "' has an internal memory leak ") + "(".concat(dataIdsLeaked, " data ids) after running '").concat(kernelName, "'"));
          }
        };
        Engine2.prototype.runKernelFunc = function(kernelParams) {
          var _this = this;
          var outputs;
          var saved = [];
          var isTapeOn = this.isTapeOn();
          var startingBytecount = this.state.numBytes;
          var startingNumTensors = this.state.numTensors;
          if (this.shouldCheckForMemLeaks()) {
            this.state.numDataMovesStack.push(0);
          }
          var kernelFunc;
          if (this.backendName == null) {
            this.backend;
          }
          var out;
          var kernelOrScopeName = isRegisteredKernelInvocation(kernelParams) ? kernelParams.kernelName : this.state.activeScope != null ? this.state.activeScope.name : "";
          if (isRegisteredKernelInvocation(kernelParams)) {
            var kernelName_1 = kernelParams.kernelName, inputs_1 = kernelParams.inputs, attrs_1 = kernelParams.attrs;
            if (this.backendName == null) {
              this.backend;
            }
            var kernel_1 = getKernel(kernelName_1, this.backendName);
            assert(kernel_1 != null, function() {
              return "Cannot find registered kernel '".concat(kernelName_1, "' for backend '").concat(_this.backendName, "'");
            });
            kernelFunc = function() {
              var numDataIdsBefore = _this.backend.numDataIds();
              out = kernel_1.kernelFunc({ inputs: inputs_1, attrs: attrs_1, backend: _this.backend });
              var outInfos = Array.isArray(out) ? out : [out];
              if (_this.shouldCheckForMemLeaks()) {
                _this.checkKernelForMemLeak(kernelName_1, numDataIdsBefore, outInfos);
              }
              var outTensors = outInfos.map(function(outInfo) {
                if (outInfo.rank != null) {
                  return outInfo;
                }
                return _this.makeTensorFromTensorInfo(outInfo);
              });
              if (isTapeOn) {
                var tensorsToSave = _this.getTensorsForGradient(kernelName_1, inputs_1, outTensors);
                saved = _this.saveTensorsForBackwardMode(tensorsToSave);
              }
              return outTensors;
            };
          } else {
            var forwardFunc_1 = kernelParams.forwardFunc;
            var saveFunc_1 = function(tensors) {
              if (!isTapeOn) {
                return;
              }
              saved = tensors.map(function(tensor2) {
                return _this.keep(_this.clone(tensor2));
              });
            };
            kernelFunc = function() {
              var numDataIdsBefore = _this.backend.numDataIds();
              out = _this.tidy(function() {
                return forwardFunc_1(_this.backend, saveFunc_1);
              });
              var outs = Array.isArray(out) ? out : [out];
              if (_this.shouldCheckForMemLeaks()) {
                _this.checkKernelForMemLeak(kernelOrScopeName, numDataIdsBefore, outs);
              }
              return outs;
            };
          }
          var inputs = kernelParams.inputs, attrs = kernelParams.attrs;
          var backwardsFunc = isRegisteredKernelInvocation(kernelParams) ? null : kernelParams.backwardsFunc;
          var kernelProfile;
          this.scopedRun(
            // Stop recording to a tape when running a kernel.
            function() {
              return _this.state.kernelDepth++;
            },
            function() {
              return _this.state.kernelDepth--;
            },
            function() {
              if (!_this.ENV.getBool("DEBUG") && !_this.state.profiling) {
                outputs = kernelFunc();
              } else {
                kernelProfile = _this.profiler.profileKernel(kernelOrScopeName, inputs, function() {
                  return kernelFunc();
                });
                if (_this.ENV.getBool("DEBUG")) {
                  _this.profiler.logKernelProfile(kernelProfile);
                }
                outputs = kernelProfile.outputs;
              }
            }
          );
          if (isTapeOn) {
            this.addTapeNode(kernelOrScopeName, inputs, outputs, backwardsFunc, saved, attrs);
          }
          if (this.state.profiling) {
            this.state.activeProfile.kernels.push({
              name: kernelOrScopeName,
              bytesAdded: this.state.numBytes - startingBytecount,
              totalBytesSnapshot: this.state.numBytes,
              tensorsAdded: this.state.numTensors - startingNumTensors,
              totalTensorsSnapshot: this.state.numTensors,
              inputShapes: Object.keys(inputs).map(function(key) {
                return inputs[key] != null ? inputs[key].shape : null;
              }),
              outputShapes: outputs.map(function(item) {
                return item.shape;
              }),
              kernelTimeMs: kernelProfile.timeMs,
              extraInfo: kernelProfile.extraInfo
            });
          }
          return Array.isArray(out) ? outputs : outputs[0];
        };
        Engine2.prototype.saveTensorsForBackwardMode = function(tensors) {
          var _this = this;
          var saved = tensors.map(function(tensor2) {
            return _this.keep(_this.clone(tensor2));
          });
          return saved;
        };
        Engine2.prototype.getTensorsForGradient = function(kernelName, inputs, outputs) {
          var gradConfig = getGradient(kernelName);
          if (gradConfig != null) {
            var inputsToSave = gradConfig.inputsToSave || [];
            var outputsToSave_1 = gradConfig.outputsToSave || [];
            var inputTensorsToSave = void 0;
            if (gradConfig.saveAllInputs) {
              assert(Array.isArray(inputs), function() {
                return "saveAllInputs is true, expected inputs to be an array.";
              });
              inputTensorsToSave = Object.keys(inputs).map(function(key) {
                return inputs[key];
              });
            } else {
              inputTensorsToSave = inputsToSave.map(function(inputName) {
                return inputs[inputName];
              });
            }
            var outputTensorsToSave = outputs.filter(function(_, i) {
              return outputsToSave_1[i];
            });
            return inputTensorsToSave.concat(outputTensorsToSave);
          }
          return [];
        };
        Engine2.prototype.makeTensor = function(values, shape, dtype, backend2) {
          if (values == null) {
            throw new Error("Values passed to engine.makeTensor() are null");
          }
          dtype = dtype || "float32";
          backend2 = backend2 || this.backend;
          var backendVals = values;
          if (dtype === "string" && isString(values[0])) {
            backendVals = values.map(function(d) {
              return encodeString(d);
            });
          }
          var dataId = backend2.write(backendVals, shape, dtype);
          var t = new Tensor(shape, dtype, dataId, this.nextTensorId());
          this.trackTensor(t, backend2);
          if (dtype === "string") {
            var info = this.state.tensorInfo.get(dataId);
            var newBytes = bytesFromStringArray(backendVals);
            this.state.numBytes += newBytes - info.bytes;
            info.bytes = newBytes;
          }
          return t;
        };
        Engine2.prototype.makeTensorFromDataId = function(dataId, shape, dtype, backend2) {
          dtype = dtype || "float32";
          var tensorInfo = { dataId, shape, dtype };
          return this.makeTensorFromTensorInfo(tensorInfo, backend2);
        };
        Engine2.prototype.makeTensorFromTensorInfo = function(tensorInfo, backend2) {
          var dataId = tensorInfo.dataId, shape = tensorInfo.shape, dtype = tensorInfo.dtype;
          var t = new Tensor(shape, dtype, dataId, this.nextTensorId());
          this.trackTensor(t, backend2);
          return t;
        };
        Engine2.prototype.makeVariable = function(initialValue, trainable, name, dtype) {
          if (trainable === void 0) {
            trainable = true;
          }
          name = name || this.nextVariableId().toString();
          if (dtype != null && dtype !== initialValue.dtype) {
            initialValue = initialValue.cast(dtype);
          }
          var v = new Variable(initialValue, trainable, name, this.nextTensorId());
          if (this.state.registeredVariables[v.name] != null) {
            throw new Error("Variable with name ".concat(v.name, " was already registered"));
          }
          this.state.registeredVariables[v.name] = v;
          this.incRef(v, this.backend);
          return v;
        };
        Engine2.prototype.trackTensor = function(a, backend2) {
          this.state.numTensors++;
          if (a.dtype === "string") {
            this.state.numStringTensors++;
          }
          var bytes = 0;
          if (a.dtype !== "complex64" && a.dtype !== "string") {
            bytes = a.size * bytesPerElement(a.dtype);
          }
          this.state.numBytes += bytes;
          if (!this.state.tensorInfo.has(a.dataId)) {
            this.state.numDataBuffers++;
            this.state.tensorInfo.set(a.dataId, {
              backend: backend2 || this.backend,
              dtype: a.dtype,
              shape: a.shape,
              bytes
            });
          }
          if (!(a instanceof Variable)) {
            this.track(a);
          }
        };
        Engine2.prototype.incRef = function(a, backend2) {
          this.trackTensor(a, backend2);
          this.backend.incRef(a.dataId);
        };
        Engine2.prototype.removeDataId = function(dataId, backend2) {
          if (this.state.tensorInfo.has(dataId) && this.state.tensorInfo.get(dataId).backend === backend2) {
            this.state.tensorInfo.delete(dataId);
            this.state.numDataBuffers--;
          }
        };
        Engine2.prototype.disposeTensor = function(a) {
          if (!this.state.tensorInfo.has(a.dataId)) {
            return;
          }
          var info = this.state.tensorInfo.get(a.dataId);
          this.state.numTensors--;
          if (a.dtype === "string") {
            this.state.numStringTensors--;
            this.state.numBytes -= info.bytes;
          }
          if (a.dtype !== "complex64" && a.dtype !== "string") {
            var bytes = a.size * bytesPerElement(a.dtype);
            this.state.numBytes -= bytes;
          }
          if (info.backend.disposeData(a.dataId)) {
            this.removeDataId(a.dataId, info.backend);
          }
        };
        Engine2.prototype.disposeVariables = function() {
          for (var varName in this.state.registeredVariables) {
            var v = this.state.registeredVariables[varName];
            this.disposeVariable(v);
          }
        };
        Engine2.prototype.disposeVariable = function(v) {
          this.disposeTensor(v);
          if (this.state.registeredVariables[v.name] != null) {
            delete this.state.registeredVariables[v.name];
          }
        };
        Engine2.prototype.memory = function() {
          var info = this.backend.memory();
          info.numTensors = this.state.numTensors;
          info.numDataBuffers = this.state.numDataBuffers;
          info.numBytes = this.state.numBytes;
          if (this.state.numStringTensors > 0) {
            info.unreliable = true;
            if (info.reasons == null) {
              info.reasons = [];
            }
            info.reasons.push("Memory usage by string tensors is approximate (2 bytes per character)");
          }
          return info;
        };
        Engine2.prototype.profile = function(query) {
          return __awaiter(this, void 0, void 0, function() {
            var startBytes, startNumTensors, _a, _b, _c, kernel, _d, _e, e_1_1;
            var e_1, _f;
            return __generator(this, function(_g) {
              switch (_g.label) {
                case 0:
                  this.state.profiling = true;
                  startBytes = this.state.numBytes;
                  startNumTensors = this.state.numTensors;
                  this.state.activeProfile.kernels = [];
                  _a = this.state.activeProfile;
                  return [4, query()];
                case 1:
                  _a.result = _g.sent();
                  this.state.profiling = false;
                  this.state.activeProfile.peakBytes = Math.max.apply(Math, __spreadArray([], __read(this.state.activeProfile.kernels.map(function(d) {
                    return d.totalBytesSnapshot;
                  })), false));
                  this.state.activeProfile.newBytes = this.state.numBytes - startBytes;
                  this.state.activeProfile.newTensors = this.state.numTensors - startNumTensors;
                  _g.label = 2;
                case 2:
                  _g.trys.push([2, 8, 9, 10]);
                  _b = __values(this.state.activeProfile.kernels), _c = _b.next();
                  _g.label = 3;
                case 3:
                  if (!!_c.done)
                    return [3, 7];
                  kernel = _c.value;
                  _d = kernel;
                  return [4, kernel.kernelTimeMs];
                case 4:
                  _d.kernelTimeMs = _g.sent();
                  _e = kernel;
                  return [4, kernel.extraInfo];
                case 5:
                  _e.extraInfo = _g.sent();
                  _g.label = 6;
                case 6:
                  _c = _b.next();
                  return [3, 3];
                case 7:
                  return [3, 10];
                case 8:
                  e_1_1 = _g.sent();
                  e_1 = { error: e_1_1 };
                  return [3, 10];
                case 9:
                  try {
                    if (_c && !_c.done && (_f = _b.return))
                      _f.call(_b);
                  } finally {
                    if (e_1)
                      throw e_1.error;
                  }
                  return [
                    7
                    /*endfinally*/
                  ];
                case 10:
                  return [2, this.state.activeProfile];
              }
            });
          });
        };
        Engine2.prototype.isTapeOn = function() {
          return this.state.gradientDepth > 0 && this.state.kernelDepth === 0;
        };
        Engine2.prototype.addTapeNode = function(kernelName, inputs, outputs, gradientsFunc, saved, attrs) {
          var _this = this;
          var tapeNode = { id: this.state.nextTapeNodeId++, kernelName, inputs, outputs, saved };
          var gradConfig = getGradient(kernelName);
          if (gradConfig != null) {
            gradientsFunc = gradConfig.gradFunc;
          }
          if (gradientsFunc != null) {
            tapeNode.gradient = function(dys) {
              dys = dys.map(function(dy, i) {
                if (dy == null) {
                  var output = outputs[i];
                  var vals = makeZerosTypedArray(output.size, output.dtype);
                  return _this.makeTensor(vals, output.shape, output.dtype);
                }
                return dy;
              });
              return gradientsFunc(dys.length > 1 ? dys : dys[0], saved, attrs);
            };
          }
          this.state.activeTape.push(tapeNode);
        };
        Engine2.prototype.keep = function(result) {
          result.kept = true;
          return result;
        };
        Engine2.prototype.startTape = function() {
          if (this.state.gradientDepth === 0) {
            this.state.activeTape = [];
          }
          this.state.gradientDepth++;
        };
        Engine2.prototype.endTape = function() {
          this.state.gradientDepth--;
        };
        Engine2.prototype.startScope = function(name) {
          var scopeInfo = {
            track: [],
            name: "unnamed scope",
            id: this.state.nextScopeId++
          };
          if (name) {
            scopeInfo.name = name;
          }
          this.state.scopeStack.push(scopeInfo);
          this.state.activeScope = scopeInfo;
        };
        Engine2.prototype.endScope = function(result) {
          var _this = this;
          var tensorsToTrackInParent = getTensorsInContainer(result);
          var tensorsToTrackInParentSet = new Set(tensorsToTrackInParent.map(function(t) {
            return t.id;
          }));
          for (var i = 0; i < this.state.activeScope.track.length; i++) {
            var tensor2 = this.state.activeScope.track[i];
            if (!tensor2.kept && !tensorsToTrackInParentSet.has(tensor2.id)) {
              tensor2.dispose();
            }
          }
          var oldScope = this.state.scopeStack.pop();
          this.state.activeScope = this.state.scopeStack.length === 0 ? null : this.state.scopeStack[this.state.scopeStack.length - 1];
          tensorsToTrackInParent.forEach(function(tensor3) {
            if (!tensor3.kept && tensor3.scopeId === oldScope.id) {
              _this.track(tensor3);
            }
          });
        };
        Engine2.prototype.gradients = function(f, xs, dy, allowNoGradients) {
          var _this = this;
          if (allowNoGradients === void 0) {
            allowNoGradients = false;
          }
          assert(xs.length > 0, function() {
            return "gradients() received an empty list of xs.";
          });
          if (dy != null && dy.dtype !== "float32") {
            throw new Error("dy must have 'float32' dtype, but has '".concat(dy.dtype, "'"));
          }
          var y = this.scopedRun(function() {
            return _this.startTape();
          }, function() {
            return _this.endTape();
          }, function() {
            return _this.tidy("forward", f);
          });
          assert(y instanceof Tensor, function() {
            return "The result y returned by f() must be a tensor.";
          });
          var filteredTape = getFilteredNodesXToY(this.state.activeTape, xs, y);
          if (!allowNoGradients && filteredTape.length === 0 && xs.length > 0) {
            throw new Error("Cannot compute gradient of y=f(x) with respect to x. Make sure that the f you passed encloses all operations that lead from x to y.");
          }
          return this.tidy("backward", function() {
            var accumulatedGradientMap = {};
            accumulatedGradientMap[y.id] = dy == null ? ones$1(y.shape) : dy;
            backpropagateGradients(
              accumulatedGradientMap,
              filteredTape,
              // Pass the tidy function to avoid circular dep with `tape.ts`.
              function(f2) {
                return _this.tidy(f2);
              },
              // Pass an add function to avoide a circular dep with `tape.ts`.
              add$1
            );
            var grads2 = xs.map(function(x) {
              return accumulatedGradientMap[x.id];
            });
            if (_this.state.gradientDepth === 0) {
              _this.state.activeTape.forEach(function(node) {
                var e_2, _a;
                try {
                  for (var _b = __values(node.saved), _c = _b.next(); !_c.done; _c = _b.next()) {
                    var tensor2 = _c.value;
                    tensor2.dispose();
                  }
                } catch (e_2_1) {
                  e_2 = { error: e_2_1 };
                } finally {
                  try {
                    if (_c && !_c.done && (_a = _b.return))
                      _a.call(_b);
                  } finally {
                    if (e_2)
                      throw e_2.error;
                  }
                }
              });
              _this.state.activeTape = null;
            }
            return { value: y, grads: grads2 };
          });
        };
        Engine2.prototype.customGrad = function(f) {
          var _this = this;
          assert(isFunction(f), function() {
            return "The f passed in customGrad(f) must be a function.";
          });
          return function() {
            var inputs = [];
            for (var _i = 0; _i < arguments.length; _i++) {
              inputs[_i] = arguments[_i];
            }
            assert(inputs.every(function(t) {
              return t instanceof Tensor;
            }), function() {
              return "The args passed in customGrad(f)(x1, x2,...) must all be tensors";
            });
            var res;
            var inputMap = {};
            inputs.forEach(function(input, i) {
              inputMap[i] = input;
            });
            var forwardFunc = function(_, save) {
              res = f.apply(void 0, __spreadArray([], __read(__spreadArray(__spreadArray([], __read(inputs), false), [save], false)), false));
              assert(res.value instanceof Tensor, function() {
                return "The function f passed in customGrad(f) must return an object where `obj.value` is a tensor";
              });
              assert(isFunction(res.gradFunc), function() {
                return "The function f passed in customGrad(f) must return an object where `obj.gradFunc` is a function.";
              });
              return res.value;
            };
            var backwardsFunc = function(dy, saved) {
              var gradRes = res.gradFunc(dy, saved);
              var grads2 = Array.isArray(gradRes) ? gradRes : [gradRes];
              assert(grads2.length === inputs.length, function() {
                return "The function f passed in customGrad(f) must return an object where `obj.gradFunc` is a function that returns the same number of tensors as inputs passed to f(...).";
              });
              assert(grads2.every(function(t) {
                return t instanceof Tensor;
              }), function() {
                return "The function f passed in customGrad(f) must return an object where `obj.gradFunc` is a function that returns a list of only tensors.";
              });
              var gradMap = {};
              grads2.forEach(function(grad2, i) {
                gradMap[i] = function() {
                  return grad2;
                };
              });
              return gradMap;
            };
            return _this.runKernelFunc({
              forwardFunc,
              backwardsFunc,
              inputs: inputMap
            });
          };
        };
        Engine2.prototype.readSync = function(dataId) {
          var info = this.state.tensorInfo.get(dataId);
          return info.backend.readSync(dataId);
        };
        Engine2.prototype.read = function(dataId) {
          var info = this.state.tensorInfo.get(dataId);
          return info.backend.read(dataId);
        };
        Engine2.prototype.readToGPU = function(dataId, options) {
          var info = this.state.tensorInfo.get(dataId);
          return info.backend.readToGPU(dataId, options);
        };
        Engine2.prototype.time = function(query) {
          return __awaiter(this, void 0, void 0, function() {
            var start, timingInfo;
            return __generator(this, function(_a) {
              switch (_a.label) {
                case 0:
                  start = now();
                  return [4, this.backend.time(query)];
                case 1:
                  timingInfo = _a.sent();
                  timingInfo.wallMs = now() - start;
                  return [2, timingInfo];
              }
            });
          });
        };
        Engine2.prototype.track = function(result) {
          if (this.state.activeScope != null) {
            result.scopeId = this.state.activeScope.id;
            this.state.activeScope.track.push(result);
          }
          return result;
        };
        Object.defineProperty(Engine2.prototype, "registeredVariables", {
          get: function() {
            return this.state.registeredVariables;
          },
          enumerable: false,
          configurable: true
        });
        Engine2.prototype.reset = function() {
          this.pendingBackendInitId++;
          this.state.dispose();
          this.ENV.reset();
          this.state = new EngineState();
          for (var backendName in this.registry) {
            this.disposeRegisteredKernels(backendName);
            this.registry[backendName].dispose();
            delete this.registry[backendName];
          }
          this.backendName = null;
          this.backendInstance = null;
          this.pendingBackendInit = null;
        };
        return Engine2;
      }()
    );
    Engine.nextTensorId = 0;
    Engine.nextVariableId = 0;
    function ones$1(shape) {
      var values = makeOnesTypedArray(sizeFromShape(shape), "float32");
      return ENGINE.makeTensor(values, shape, "float32");
    }
    function getOrMakeEngine() {
      var ns = getGlobalNamespace();
      if (ns._tfengine == null) {
        var environment = new Environment(ns);
        ns._tfengine = new Engine(environment);
      }
      setEnvironmentGlobal(ns._tfengine.ENV);
      setTensorTracker(function() {
        return ns._tfengine;
      });
      return ns._tfengine;
    }
    var ENGINE = getOrMakeEngine();
    function add$1(a, b) {
      var inputs = { a, b };
      return ENGINE.runKernel(Add, inputs);
    }
    function _isNavigatorDefined() {
      return typeof navigator !== "undefined" && navigator != null;
    }
    var isMobileMockValue;
    function mockIsMobile(value) {
      isMobileMockValue = value;
    }
    function isMobile(nav) {
      if (isMobileMockValue !== void 0) {
        return isMobileMockValue;
      }
      if (nav || _isNavigatorDefined()) {
        if (!nav) {
          nav = navigator;
        }
        if (nav.product === "ReactNative") {
          return true;
        }
        var a = nav.userAgent || nav.vendor || // tslint:disable-next-line:no-any
        (typeof window !== "undefined" ? window.opera : "");
        if (!a) {
          var navAny = nav;
          return navAny.userAgentData && navAny.userAgentData.mobile;
        }
        return /(android|bb\d+|meego).+mobile|avantgo|bada\/|blackberry|blazer|compal|elaine|fennec|hiptop|iemobile|ip(hone|od)|iris|kindle|lge |maemo|midp|mmp|mobile.+firefox|netfront|opera m(ob|in)i|palm( os)?|phone|p(ixi|re)\/|plucker|pocket|psp|series(4|6)0|symbian|treo|up\.(browser|link)|vodafone|wap|windows ce|xda|xiino/i.test(a) || // tslint:disable-next-line:max-line-length
        /1207|6310|6590|3gso|4thp|50[1-6]i|770s|802s|a wa|abac|ac(er|oo|s\-)|ai(ko|rn)|al(av|ca|co)|amoi|an(ex|ny|yw)|aptu|ar(ch|go)|as(te|us)|attw|au(di|\-m|r |s )|avan|be(ck|ll|nq)|bi(lb|rd)|bl(ac|az)|br(e|v)w|bumb|bw\-(n|u)|c55\/|capi|ccwa|cdm\-|cell|chtm|cldc|cmd\-|co(mp|nd)|craw|da(it|ll|ng)|dbte|dc\-s|devi|dica|dmob|do(c|p)o|ds(12|\-d)|el(49|ai)|em(l2|ul)|er(ic|k0)|esl8|ez([4-7]0|os|wa|ze)|fetc|fly(\-|_)|g1 u|g560|gene|gf\-5|g\-mo|go(\.w|od)|gr(ad|un)|haie|hcit|hd\-(m|p|t)|hei\-|hi(pt|ta)|hp( i|ip)|hs\-c|ht(c(\-| |_|a|g|p|s|t)|tp)|hu(aw|tc)|i\-(20|go|ma)|i230|iac( |\-|\/)|ibro|idea|ig01|ikom|im1k|inno|ipaq|iris|ja(t|v)a|jbro|jemu|jigs|kddi|keji|kgt( |\/)|klon|kpt |kwc\-|kyo(c|k)|le(no|xi)|lg( g|\/(k|l|u)|50|54|\-[a-w])|libw|lynx|m1\-w|m3ga|m50\/|ma(te|ui|xo)|mc(01|21|ca)|m\-cr|me(rc|ri)|mi(o8|oa|ts)|mmef|mo(01|02|bi|de|do|t(\-| |o|v)|zz)|mt(50|p1|v )|mwbp|mywa|n10[0-2]|n20[2-3]|n30(0|2)|n50(0|2|5)|n7(0(0|1)|10)|ne((c|m)\-|on|tf|wf|wg|wt)|nok(6|i)|nzph|o2im|op(ti|wv)|oran|owg1|p800|pan(a|d|t)|pdxg|pg(13|\-([1-8]|c))|phil|pire|pl(ay|uc)|pn\-2|po(ck|rt|se)|prox|psio|pt\-g|qa\-a|qc(07|12|21|32|60|\-[2-7]|i\-)|qtek|r380|r600|raks|rim9|ro(ve|zo)|s55\/|sa(ge|ma|mm|ms|ny|va)|sc(01|h\-|oo|p\-)|sdk\/|se(c(\-|0|1)|47|mc|nd|ri)|sgh\-|shar|sie(\-|m)|sk\-0|sl(45|id)|sm(al|ar|b3|it|t5)|so(ft|ny)|sp(01|h\-|v\-|v )|sy(01|mb)|t2(18|50)|t6(00|10|18)|ta(gt|lk)|tcl\-|tdg\-|tel(i|m)|tim\-|t\-mo|to(pl|sh)|ts(70|m\-|m3|m5)|tx\-9|up(\.b|g1|si)|utst|v400|v750|veri|vi(rg|te)|vk(40|5[0-3]|\-v)|vm40|voda|vulc|vx(52|53|60|61|70|80|81|83|85|98)|w3c(\-| )|webc|whit|wi(g |nc|nw)|wmlb|wonu|x700|yas\-|your|zeto|zte\-/i.test(a.substr(0, 4));
      }
      return false;
    }
    function isBrowser() {
      return typeof window !== "undefined" && window.document != null || //@ts-ignore
      typeof WorkerGlobalScope !== "undefined";
    }
    var device_util = {
      __proto__: null,
      isBrowser,
      isMobile,
      mockIsMobile
    };
    var ENV = env();
    ENV.registerFlag("DEBUG", function() {
      return false;
    }, function(debugValue) {
      if (debugValue) {
        console.warn("Debugging mode is ON. The output of every math call will be downloaded to CPU and checked for NaNs. This significantly impacts performance.");
      }
    });
    ENV.registerFlag("IS_BROWSER", function() {
      return isBrowser();
    });
    ENV.registerFlag("IS_NODE", function() {
      return typeof process !== "undefined" && typeof process.versions !== "undefined" && typeof process.versions.node !== "undefined";
    });
    ENV.registerFlag("IS_CHROME", function() {
      return typeof navigator !== "undefined" && navigator != null && navigator.userAgent != null && /Chrome/.test(navigator.userAgent) && /Google Inc/.test(navigator.vendor);
    });
    ENV.registerFlag("IS_SAFARI", function() {
      return typeof navigator !== "undefined" && navigator != null && navigator.userAgent != null && /Safari/.test(navigator.userAgent) && /Apple/.test(navigator.vendor);
    });
    ENV.registerFlag("PROD", function() {
      return false;
    });
    ENV.registerFlag("TENSORLIKE_CHECK_SHAPE_CONSISTENCY", function() {
      return ENV.getBool("DEBUG");
    });
    ENV.registerFlag("DEPRECATION_WARNINGS_ENABLED", function() {
      return true;
    });
    ENV.registerFlag("IS_TEST", function() {
      return false;
    });
    ENV.registerFlag("CHECK_COMPUTATION_FOR_ERRORS", function() {
      return ENV.getBool("DEBUG");
    });
    ENV.registerFlag("WRAP_TO_IMAGEBITMAP", function() {
      return false;
    });
    ENV.registerFlag("CANVAS2D_WILL_READ_FREQUENTLY_FOR_GPU", function() {
      return false;
    });
    ENV.registerFlag("USE_SETTIMEOUTCUSTOM", function() {
      return false;
    });
    function inferShape(val, dtype) {
      var firstElem = val;
      if (isTypedArray(val)) {
        return dtype === "string" ? [] : [val.length];
      }
      if (isWebGLData(val)) {
        var usedChannels = val.channels || "RGBA";
        return [val.height, val.width * usedChannels.length];
      } else if (isWebGPUData(val)) {
        return [val.buffer.size / (dtype == null ? 4 : bytesPerElement(dtype))];
      }
      if (!Array.isArray(val)) {
        return [];
      }
      var shape = [];
      while (Array.isArray(firstElem) || isTypedArray(firstElem) && dtype !== "string") {
        shape.push(firstElem.length);
        firstElem = firstElem[0];
      }
      if (Array.isArray(val) && env().getBool("TENSORLIKE_CHECK_SHAPE_CONSISTENCY")) {
        deepAssertShapeConsistency(val, shape, []);
      }
      return shape;
    }
    function deepAssertShapeConsistency(val, shape, indices) {
      indices = indices || [];
      if (!Array.isArray(val) && !isTypedArray(val)) {
        assert(shape.length === 0, function() {
          return "Element arr[".concat(indices.join("]["), "] is a primitive, ") + "but should be an array/TypedArray of ".concat(shape[0], " elements");
        });
        return;
      }
      assert(shape.length > 0, function() {
        return "Element arr[".concat(indices.join("]["), "] should be a primitive, ") + "but is an array of ".concat(val.length, " elements");
      });
      assert(val.length === shape[0], function() {
        return "Element arr[".concat(indices.join("]["), "] should have ").concat(shape[0], " ") + "elements, but has ".concat(val.length, " elements");
      });
      var subShape = shape.slice(1);
      for (var i = 0; i < val.length; ++i) {
        deepAssertShapeConsistency(val[i], subShape, indices.concat(i));
      }
    }
    function assertDtype(expectedDtype, actualDType, argName, functionName) {
      if (expectedDtype === "string_or_numeric") {
        return;
      }
      if (expectedDtype == null) {
        throw new Error("Expected dtype cannot be null.");
      }
      if (expectedDtype !== "numeric" && expectedDtype !== actualDType || expectedDtype === "numeric" && actualDType === "string") {
        throw new Error("Argument '".concat(argName, "' passed to '").concat(functionName, "' must ") + "be ".concat(expectedDtype, " tensor, but got ").concat(actualDType, " tensor"));
      }
    }
    function convertToTensor(x, argName, functionName, parseAsDtype) {
      if (parseAsDtype === void 0) {
        parseAsDtype = "numeric";
      }
      if (x instanceof Tensor) {
        assertDtype(parseAsDtype, x.dtype, argName, functionName);
        return x;
      }
      var inferredDtype = inferDtype(x);
      if (inferredDtype !== "string" && ["bool", "int32", "float32"].indexOf(parseAsDtype) >= 0) {
        inferredDtype = parseAsDtype;
      }
      assertDtype(parseAsDtype, inferredDtype, argName, functionName);
      if (x == null || !isTypedArray(x) && !Array.isArray(x) && typeof x !== "number" && typeof x !== "boolean" && typeof x !== "string") {
        var type = x == null ? "null" : x.constructor.name;
        throw new Error("Argument '".concat(argName, "' passed to '").concat(functionName, "' must be a ") + "Tensor or TensorLike, but got '".concat(type, "'"));
      }
      var inferredShape = inferShape(x, inferredDtype);
      if (!isTypedArray(x) && !Array.isArray(x)) {
        x = [x];
      }
      var skipTypedArray = true;
      var values = inferredDtype !== "string" ? toTypedArray(x, inferredDtype) : flatten(x, [], skipTypedArray);
      return ENGINE.makeTensor(values, inferredShape, inferredDtype);
    }
    function convertToTensorArray(arg, argName, functionName, parseAsDtype) {
      if (parseAsDtype === void 0) {
        parseAsDtype = "numeric";
      }
      if (!Array.isArray(arg)) {
        throw new Error("Argument ".concat(argName, " passed to ").concat(functionName, " must be a ") + "`Tensor[]` or `TensorLike[]`");
      }
      var tensors = arg;
      return tensors.map(function(t, i) {
        return convertToTensor(t, "".concat(argName, "[").concat(i, "]"), functionName, parseAsDtype);
      });
    }
    var OP_SCOPE_SUFFIX = "__op";
    function op(f) {
      var keys = Object.keys(f);
      if (keys.length !== 1) {
        throw new Error("Please provide an object with a single key (operation name) mapping to a function. Got an object with " + "".concat(keys.length, " keys."));
      }
      var opName = keys[0];
      var fn = f[opName];
      if (opName.endsWith("_")) {
        opName = opName.substring(0, opName.length - 1);
      }
      opName = opName + OP_SCOPE_SUFFIX;
      var f2 = function() {
        var args = [];
        for (var _i = 0; _i < arguments.length; _i++) {
          args[_i] = arguments[_i];
        }
        ENGINE.startScope(opName);
        try {
          var result = fn.apply(void 0, __spreadArray([], __read(args), false));
          if (isPromise(result)) {
            console.error("Cannot return a Promise inside of tidy.");
          }
          ENGINE.endScope(result);
          return result;
        } catch (ex) {
          ENGINE.endScope(null);
          throw ex;
        }
      };
      Object.defineProperty(f2, "name", { value: opName, configurable: true });
      return f2;
    }
    function complex_(real2, imag2) {
      var $real = convertToTensor(real2, "real", "complex");
      var $imag = convertToTensor(imag2, "imag", "complex");
      assertShapesMatch($real.shape, $imag.shape, "real and imag shapes, ".concat($real.shape, " and ").concat($imag.shape, ", ") + "must match in call to tf.complex().");
      var inputs = { real: $real, imag: $imag };
      return ENGINE.runKernel(Complex, inputs);
    }
    var complex = /* @__PURE__ */ op({ complex_ });
    function makeTensor(values, shape, inferredShape, dtype) {
      if (dtype == null) {
        dtype = inferDtype(values);
      } else if (dtype === "complex64") {
        throw new Error("Cannot construct a complex64 tensor directly. Please use tf.complex(real, imag).");
      }
      if (isWebGPUData(values) || isWebGLData(values)) {
        if (dtype !== "float32" && dtype !== "int32") {
          throw new Error("Creating tensor from GPU data only supports " + "'float32'|'int32' dtype, while the dtype is ".concat(dtype, "."));
        }
        return ENGINE.backend.createTensorFromGPUData(values, shape || inferredShape, dtype);
      }
      if (!isTypedArray(values) && !Array.isArray(values) && typeof values !== "number" && typeof values !== "boolean" && typeof values !== "string") {
        throw new Error("values passed to tensor(values) must be a number/boolean/string or an array of numbers/booleans/strings, or a TypedArray");
      }
      if (shape != null) {
        assertNonNegativeIntegerDimensions(shape);
        var providedSize_1 = sizeFromShape(shape);
        var inferredSize_1 = sizeFromShape(inferredShape);
        assert(providedSize_1 === inferredSize_1, function() {
          return "Based on the provided shape, [".concat(shape, "], the tensor should have ") + "".concat(providedSize_1, " values but has ").concat(inferredSize_1);
        });
        for (var i = 0; i < inferredShape.length; ++i) {
          var inferred = inferredShape[i];
          var flatDimsDontMatch = i === inferredShape.length - 1 ? inferred !== sizeFromShape(shape.slice(i)) : true;
          assert(inferredShape[i] === shape[i] || !flatDimsDontMatch, function() {
            return "Error creating a new Tensor. Inferred shape " + "(".concat(inferredShape, ") does not match the provided ") + "shape (".concat(shape, "). ");
          });
        }
      }
      if (!isTypedArray(values) && !Array.isArray(values)) {
        values = [values];
      }
      shape = shape || inferredShape;
      values = dtype !== "string" ? toTypedArray(values, dtype) : flatten(values, [], true);
      return ENGINE.makeTensor(values, shape, dtype);
    }
    function tensor(values, shape, dtype) {
      var inferredShape = inferShape(values, dtype);
      return makeTensor(values, shape, inferredShape, dtype);
    }
    var DTYPE_VALUE_SIZE_MAP = {
      "float32": 4,
      "float16": 2,
      "int32": 4,
      "uint16": 2,
      "uint8": 1,
      "bool": 1,
      "complex64": 8
    };
    var NUM_BYTES_STRING_LENGTH = 4;
    function encodeWeights(tensors, group) {
      return __awaiter(this, void 0, void 0, function() {
        var specs, dataPromises, names, _loop_1, i, tensorValues;
        var _this = this;
        return __generator(this, function(_a) {
          switch (_a.label) {
            case 0:
              specs = [];
              dataPromises = [];
              names = Array.isArray(tensors) ? tensors.map(function(tensor2) {
                return tensor2.name;
              }) : Object.keys(tensors);
              _loop_1 = function(i2) {
                var name = names[i2];
                var t = Array.isArray(tensors) ? tensors[i2].tensor : tensors[name];
                if (t.dtype !== "float32" && t.dtype !== "int32" && t.dtype !== "bool" && t.dtype !== "string" && t.dtype !== "complex64") {
                  throw new Error("Unsupported dtype in weight '".concat(name, "': ").concat(t.dtype));
                }
                var spec = { name, shape: t.shape, dtype: t.dtype };
                if (t.dtype === "string") {
                  var utf8bytes = new Promise(function(resolve2) {
                    return __awaiter(_this, void 0, void 0, function() {
                      var vals, totalNumBytes, bytes, offset, i_1, val, bytesOfLength;
                      return __generator(this, function(_a2) {
                        switch (_a2.label) {
                          case 0:
                            return [4, t.bytes()];
                          case 1:
                            vals = _a2.sent();
                            totalNumBytes = vals.reduce(function(p, c) {
                              return p + c.length;
                            }, 0) + NUM_BYTES_STRING_LENGTH * vals.length;
                            bytes = new Uint8Array(totalNumBytes);
                            offset = 0;
                            for (i_1 = 0; i_1 < vals.length; i_1++) {
                              val = vals[i_1];
                              bytesOfLength = new Uint8Array(new Uint32Array([val.length]).buffer);
                              bytes.set(bytesOfLength, offset);
                              offset += NUM_BYTES_STRING_LENGTH;
                              bytes.set(val, offset);
                              offset += val.length;
                            }
                            resolve2(bytes);
                            return [
                              2
                              /*return*/
                            ];
                        }
                      });
                    });
                  });
                  dataPromises.push(utf8bytes);
                } else {
                  dataPromises.push(t.data());
                }
                if (group != null) {
                  spec.group = group;
                }
                specs.push(spec);
              };
              for (i = 0; i < names.length; ++i) {
                _loop_1(i);
              }
              return [4, Promise.all(dataPromises)];
            case 1:
              tensorValues = _a.sent();
              return [2, { data: concatenateTypedArrays(tensorValues), specs }];
          }
        });
      });
    }
    function decodeWeights(buffer2, specs) {
      var e_1, _a;
      var out = {};
      var float16Decode;
      var offset = 0;
      try {
        for (var specs_1 = __values(specs), specs_1_1 = specs_1.next(); !specs_1_1.done; specs_1_1 = specs_1.next()) {
          var spec = specs_1_1.value;
          var name = spec.name;
          var dtype = spec.dtype;
          var shape = spec.shape;
          var size = sizeFromShape(shape);
          var values = void 0;
          if ("quantization" in spec) {
            var quantization = spec.quantization;
            if (quantization.dtype === "uint8" || quantization.dtype === "uint16") {
              if (!("min" in quantization && "scale" in quantization)) {
                throw new Error("Weight ".concat(spec.name, " with quantization ").concat(quantization.dtype, " ") + "doesn't have corresponding metadata min and scale.");
              }
            } else if (quantization.dtype === "float16") {
              if (dtype !== "float32") {
                throw new Error("Weight ".concat(spec.name, " is quantized with ").concat(quantization.dtype, " ") + "which only supports weights of type float32 not ".concat(dtype, "."));
              }
            } else {
              throw new Error("Weight ".concat(spec.name, " has unknown ") + "quantization dtype ".concat(quantization.dtype, ". ") + "Supported quantization dtypes are: 'uint8', 'uint16', and 'float16'.");
            }
            var quantizationSizeFactor = DTYPE_VALUE_SIZE_MAP[quantization.dtype];
            var byteBuffer = buffer2.slice(offset, offset + size * quantizationSizeFactor);
            var quantizedArray = quantization.dtype === "uint8" ? new Uint8Array(byteBuffer) : new Uint16Array(byteBuffer);
            if (dtype === "float32") {
              if (quantization.dtype === "uint8" || quantization.dtype === "uint16") {
                values = new Float32Array(quantizedArray.length);
                for (var i = 0; i < quantizedArray.length; i++) {
                  var v = quantizedArray[i];
                  values[i] = v * quantization.scale + quantization.min;
                }
              } else if (quantization.dtype === "float16") {
                if (float16Decode === void 0) {
                  float16Decode = getFloat16Decoder();
                }
                values = float16Decode(quantizedArray);
              } else {
                throw new Error("Unsupported quantization type ".concat(quantization.dtype, " ") + "for weight type float32.");
              }
            } else if (dtype === "int32") {
              if (quantization.dtype !== "uint8" && quantization.dtype !== "uint16") {
                throw new Error("Unsupported quantization type ".concat(quantization.dtype, " ") + "for weight type int32.");
              }
              values = new Int32Array(quantizedArray.length);
              for (var i = 0; i < quantizedArray.length; i++) {
                var v = quantizedArray[i];
                values[i] = Math.round(v * quantization.scale + quantization.min);
              }
            } else {
              throw new Error("Unsupported dtype in weight '".concat(name, "': ").concat(dtype));
            }
            offset += size * quantizationSizeFactor;
          } else if (dtype === "string") {
            var size_1 = sizeFromShape(spec.shape);
            values = [];
            for (var i = 0; i < size_1; i++) {
              var byteLength = new Uint32Array(buffer2.slice(offset, offset + NUM_BYTES_STRING_LENGTH))[0];
              offset += NUM_BYTES_STRING_LENGTH;
              var bytes = new Uint8Array(buffer2.slice(offset, offset + byteLength));
              values.push(bytes);
              offset += byteLength;
            }
          } else {
            var dtypeFactor = DTYPE_VALUE_SIZE_MAP[dtype];
            var byteBuffer = buffer2.slice(offset, offset + size * dtypeFactor);
            if (dtype === "float32") {
              values = new Float32Array(byteBuffer);
            } else if (dtype === "int32") {
              values = new Int32Array(byteBuffer);
            } else if (dtype === "bool") {
              values = new Uint8Array(byteBuffer);
            } else if (dtype === "complex64") {
              values = new Float32Array(byteBuffer);
              var real2 = new Float32Array(values.length / 2);
              var image2 = new Float32Array(values.length / 2);
              for (var i = 0; i < real2.length; i++) {
                real2[i] = values[i * 2];
                image2[i] = values[i * 2 + 1];
              }
              var realTensor = tensor(real2, shape, "float32");
              var imageTensor = tensor(image2, shape, "float32");
              out[name] = complex(realTensor, imageTensor);
              realTensor.dispose();
              imageTensor.dispose();
            } else {
              throw new Error("Unsupported dtype in weight '".concat(name, "': ").concat(dtype));
            }
            offset += size * dtypeFactor;
          }
          if (dtype !== "complex64") {
            out[name] = tensor(values, shape, dtype);
          }
        }
      } catch (e_1_1) {
        e_1 = { error: e_1_1 };
      } finally {
        try {
          if (specs_1_1 && !specs_1_1.done && (_a = specs_1.return))
            _a.call(specs_1);
        } finally {
          if (e_1)
            throw e_1.error;
        }
      }
      return out;
    }
    function concatenateTypedArrays(xs) {
      if (xs === null) {
        throw new Error("Invalid input value: ".concat(JSON.stringify(xs)));
      }
      var totalByteLength = 0;
      var normalizedXs = [];
      xs.forEach(function(x) {
        totalByteLength += x.byteLength;
        normalizedXs.push(x.byteLength === x.buffer.byteLength ? x : new x.constructor(x));
        if (!(x instanceof Float32Array || x instanceof Int32Array || x instanceof Uint8Array)) {
          throw new Error("Unsupported TypedArray subtype: ".concat(x.constructor.name));
        }
      });
      var y = new Uint8Array(totalByteLength);
      var offset = 0;
      normalizedXs.forEach(function(x) {
        y.set(new Uint8Array(x.buffer), offset);
        offset += x.byteLength;
      });
      return y.buffer;
    }
    var useNodeBuffer = typeof Buffer !== "undefined" && (typeof Blob === "undefined" || typeof atob === "undefined" || typeof btoa === "undefined");
    function stringByteLength(str) {
      if (useNodeBuffer) {
        return Buffer.byteLength(str);
      }
      return new Blob([str]).size;
    }
    function arrayBufferToBase64String(buffer2) {
      if (useNodeBuffer) {
        return Buffer.from(buffer2).toString("base64");
      }
      var buf = new Uint8Array(buffer2);
      var s = "";
      for (var i = 0, l = buf.length; i < l; i++) {
        s += String.fromCharCode(buf[i]);
      }
      return btoa(s);
    }
    function base64StringToArrayBuffer(str) {
      if (useNodeBuffer) {
        var buf = Buffer.from(str, "base64");
        return buf.buffer.slice(buf.byteOffset, buf.byteOffset + buf.byteLength);
      }
      var s = atob(str);
      var buffer2 = new Uint8Array(s.length);
      for (var i = 0; i < s.length; ++i) {
        buffer2.set([s.charCodeAt(i)], i);
      }
      return buffer2.buffer;
    }
    function concatenateArrayBuffers(buffers) {
      if (buffers.length === 1) {
        return buffers[0];
      }
      var totalByteLength = 0;
      buffers.forEach(function(buffer2) {
        totalByteLength += buffer2.byteLength;
      });
      var temp = new Uint8Array(totalByteLength);
      var offset = 0;
      buffers.forEach(function(buffer2) {
        temp.set(new Uint8Array(buffer2), offset);
        offset += buffer2.byteLength;
      });
      return temp.buffer;
    }
    function basename(path) {
      var SEPARATOR = "/";
      path = path.trim();
      while (path.endsWith(SEPARATOR)) {
        path = path.slice(0, path.length - 1);
      }
      var items = path.split(SEPARATOR);
      return items[items.length - 1];
    }
    function getModelJSONForModelArtifacts(artifacts, manifest) {
      var result = {
        modelTopology: artifacts.modelTopology,
        format: artifacts.format,
        generatedBy: artifacts.generatedBy,
        convertedBy: artifacts.convertedBy,
        weightsManifest: manifest
      };
      if (artifacts.signature != null) {
        result.signature = artifacts.signature;
      }
      if (artifacts.userDefinedMetadata != null) {
        result.userDefinedMetadata = artifacts.userDefinedMetadata;
      }
      if (artifacts.modelInitializer != null) {
        result.modelInitializer = artifacts.modelInitializer;
      }
      if (artifacts.initializerSignature != null) {
        result.initializerSignature = artifacts.initializerSignature;
      }
      if (artifacts.trainingConfig != null) {
        result.trainingConfig = artifacts.trainingConfig;
      }
      return result;
    }
    function getModelArtifactsForJSONSync(modelJSON, weightSpecs, weightData) {
      var modelArtifacts = {
        modelTopology: modelJSON.modelTopology,
        format: modelJSON.format,
        generatedBy: modelJSON.generatedBy,
        convertedBy: modelJSON.convertedBy
      };
      if (modelJSON.trainingConfig != null) {
        modelArtifacts.trainingConfig = modelJSON.trainingConfig;
      }
      if (modelJSON.weightsManifest != null) {
        if (!weightSpecs) {
          throw new Error("modelJSON has weightsManifest but weightSpecs is null");
        }
        if (!weightData) {
          throw new Error("modelJSON has weightsManifest but weightData is null");
        }
        modelArtifacts.weightSpecs = weightSpecs;
        modelArtifacts.weightData = weightData;
      }
      if (modelJSON.signature != null) {
        modelArtifacts.signature = modelJSON.signature;
      }
      if (modelJSON.userDefinedMetadata != null) {
        modelArtifacts.userDefinedMetadata = modelJSON.userDefinedMetadata;
      }
      if (modelJSON.modelInitializer != null) {
        modelArtifacts.modelInitializer = modelJSON.modelInitializer;
      }
      if (modelJSON.initializerSignature != null) {
        modelArtifacts.initializerSignature = modelJSON.initializerSignature;
      }
      return modelArtifacts;
    }
    function getModelArtifactsForJSON(modelJSON, loadWeights2) {
      return __awaiter(this, void 0, void 0, function() {
        var weightSpecs, weightData;
        var _a;
        return __generator(this, function(_b) {
          switch (_b.label) {
            case 0:
              if (!(modelJSON.weightsManifest != null))
                return [3, 2];
              return [4, loadWeights2(modelJSON.weightsManifest)];
            case 1:
              _a = __read.apply(void 0, [_b.sent(), 2]), weightSpecs = _a[0], weightData = _a[1];
              _b.label = 2;
            case 2:
              return [2, getModelArtifactsForJSONSync(modelJSON, weightSpecs, weightData)];
          }
        });
      });
    }
    function getModelArtifactsInfoForJSON(modelArtifacts) {
      if (modelArtifacts.modelTopology instanceof ArrayBuffer) {
        throw new Error("Expected JSON model topology, received ArrayBuffer.");
      }
      return {
        dateSaved: /* @__PURE__ */ new Date(),
        modelTopologyType: "JSON",
        modelTopologyBytes: modelArtifacts.modelTopology == null ? 0 : stringByteLength(JSON.stringify(modelArtifacts.modelTopology)),
        weightSpecsBytes: modelArtifacts.weightSpecs == null ? 0 : stringByteLength(JSON.stringify(modelArtifacts.weightSpecs)),
        weightDataBytes: modelArtifacts.weightData == null ? 0 : modelArtifacts.weightData.byteLength
      };
    }
    function getWeightSpecs(weightsManifest) {
      var e_2, _a;
      var weightSpecs = [];
      try {
        for (var weightsManifest_1 = __values(weightsManifest), weightsManifest_1_1 = weightsManifest_1.next(); !weightsManifest_1_1.done; weightsManifest_1_1 = weightsManifest_1.next()) {
          var entry = weightsManifest_1_1.value;
          weightSpecs.push.apply(weightSpecs, __spreadArray([], __read(entry.weights), false));
        }
      } catch (e_2_1) {
        e_2 = { error: e_2_1 };
      } finally {
        try {
          if (weightsManifest_1_1 && !weightsManifest_1_1.done && (_a = weightsManifest_1.return))
            _a.call(weightsManifest_1);
        } finally {
          if (e_2)
            throw e_2.error;
        }
      }
      return weightSpecs;
    }
    function computeFloat16MantisaTable() {
      var convertMantissa = function(i2) {
        var m = i2 << 13;
        var e = 0;
        while ((m & 8388608) === 0) {
          e -= 8388608;
          m <<= 1;
        }
        m &= ~8388608;
        e += 947912704;
        return m | e;
      };
      var mantisaTable = new Uint32Array(2048);
      mantisaTable[0] = 0;
      for (var i = 1; i < 1024; i++) {
        mantisaTable[i] = convertMantissa(i);
      }
      for (var i = 1024; i < 2048; i++) {
        mantisaTable[i] = 939524096 + (i - 1024 << 13);
      }
      return mantisaTable;
    }
    function computeFloat16ExponentTable() {
      var exponentTable = new Uint32Array(64);
      exponentTable[0] = 0;
      exponentTable[31] = 1199570944;
      exponentTable[32] = 2147483648;
      exponentTable[63] = 3347054592;
      for (var i = 1; i < 31; i++) {
        exponentTable[i] = i << 23;
      }
      for (var i = 33; i < 63; i++) {
        exponentTable[i] = 2147483648 + (i - 32 << 23);
      }
      return exponentTable;
    }
    function computeFloat16OffsetTable() {
      var offsetTable = new Uint32Array(64);
      for (var i = 0; i < 64; i++) {
        offsetTable[i] = 1024;
      }
      offsetTable[0] = offsetTable[32] = 0;
      return offsetTable;
    }
    function getFloat16Decoder() {
      var mantisaTable = computeFloat16MantisaTable();
      var exponentTable = computeFloat16ExponentTable();
      var offsetTable = computeFloat16OffsetTable();
      return function(quantizedArray) {
        var buffer2 = new ArrayBuffer(4 * quantizedArray.length);
        var bufferUint32View = new Uint32Array(buffer2);
        for (var index = 0; index < quantizedArray.length; index++) {
          var float16Bits = quantizedArray[index];
          var float32Bits = mantisaTable[offsetTable[float16Bits >> 10] + (float16Bits & 1023)] + exponentTable[float16Bits >> 10];
          bufferUint32View[index] = float32Bits;
        }
        return new Float32Array(buffer2);
      };
    }
    var IORouterRegistry = (
      /** @class */
      function() {
        function IORouterRegistry2() {
          this.saveRouters = [];
          this.loadRouters = [];
        }
        IORouterRegistry2.getInstance = function() {
          if (IORouterRegistry2.instance == null) {
            IORouterRegistry2.instance = new IORouterRegistry2();
          }
          return IORouterRegistry2.instance;
        };
        IORouterRegistry2.registerSaveRouter = function(saveRouter) {
          IORouterRegistry2.getInstance().saveRouters.push(saveRouter);
        };
        IORouterRegistry2.registerLoadRouter = function(loadRouter) {
          IORouterRegistry2.getInstance().loadRouters.push(loadRouter);
        };
        IORouterRegistry2.getSaveHandlers = function(url) {
          return IORouterRegistry2.getHandlers(url, "save");
        };
        IORouterRegistry2.getLoadHandlers = function(url, loadOptions) {
          return IORouterRegistry2.getHandlers(url, "load", loadOptions);
        };
        IORouterRegistry2.getHandlers = function(url, handlerType, loadOptions) {
          var validHandlers = [];
          var routers = handlerType === "load" ? IORouterRegistry2.getInstance().loadRouters : IORouterRegistry2.getInstance().saveRouters;
          routers.forEach(function(router) {
            var handler = router(url, loadOptions);
            if (handler !== null) {
              validHandlers.push(handler);
            }
          });
          return validHandlers;
        };
        return IORouterRegistry2;
      }()
    );
    var registerSaveRouter = function(loudRouter) {
      return IORouterRegistry.registerSaveRouter(loudRouter);
    };
    var registerLoadRouter = function(loudRouter) {
      return IORouterRegistry.registerLoadRouter(loudRouter);
    };
    var getSaveHandlers = function(url) {
      return IORouterRegistry.getSaveHandlers(url);
    };
    var getLoadHandlers = function(url, loadOptions) {
      return IORouterRegistry.getLoadHandlers(url, loadOptions);
    };
    var DATABASE_NAME = "tensorflowjs";
    var DATABASE_VERSION = 1;
    var MODEL_STORE_NAME = "models_store";
    var INFO_STORE_NAME = "model_info_store";
    function getIndexedDBFactory() {
      if (!env().getBool("IS_BROWSER")) {
        throw new Error("Failed to obtain IndexedDB factory because the current environmentis not a web browser.");
      }
      var theWindow = typeof window === "undefined" ? self : window;
      var factory = theWindow.indexedDB || theWindow.mozIndexedDB || theWindow.webkitIndexedDB || theWindow.msIndexedDB || theWindow.shimIndexedDB;
      if (factory == null) {
        throw new Error("The current browser does not appear to support IndexedDB.");
      }
      return factory;
    }
    function setUpDatabase(openRequest) {
      var db = openRequest.result;
      db.createObjectStore(MODEL_STORE_NAME, { keyPath: "modelPath" });
      db.createObjectStore(INFO_STORE_NAME, { keyPath: "modelPath" });
    }
    var BrowserIndexedDB = (
      /** @class */
      function() {
        function BrowserIndexedDB2(modelPath) {
          this.indexedDB = getIndexedDBFactory();
          if (modelPath == null || !modelPath) {
            throw new Error("For IndexedDB, modelPath must not be null, undefined or empty.");
          }
          this.modelPath = modelPath;
        }
        BrowserIndexedDB2.prototype.save = function(modelArtifacts) {
          return __awaiter(this, void 0, void 0, function() {
            return __generator(this, function(_a) {
              if (modelArtifacts.modelTopology instanceof ArrayBuffer) {
                throw new Error("BrowserLocalStorage.save() does not support saving model topology in binary formats yet.");
              }
              return [2, this.databaseAction(this.modelPath, modelArtifacts)];
            });
          });
        };
        BrowserIndexedDB2.prototype.load = function() {
          return __awaiter(this, void 0, void 0, function() {
            return __generator(this, function(_a) {
              return [2, this.databaseAction(this.modelPath)];
            });
          });
        };
        BrowserIndexedDB2.prototype.databaseAction = function(modelPath, modelArtifacts) {
          var _this = this;
          return new Promise(function(resolve2, reject) {
            var openRequest = _this.indexedDB.open(DATABASE_NAME, DATABASE_VERSION);
            openRequest.onupgradeneeded = function() {
              return setUpDatabase(openRequest);
            };
            openRequest.onsuccess = function() {
              var db = openRequest.result;
              if (modelArtifacts == null) {
                var modelTx = db.transaction(MODEL_STORE_NAME, "readonly");
                var modelStore = modelTx.objectStore(MODEL_STORE_NAME);
                var getRequest_1 = modelStore.get(_this.modelPath);
                getRequest_1.onsuccess = function() {
                  if (getRequest_1.result == null) {
                    db.close();
                    return reject(new Error("Cannot find model with path '".concat(_this.modelPath, "' ") + "in IndexedDB."));
                  } else {
                    resolve2(getRequest_1.result.modelArtifacts);
                  }
                };
                getRequest_1.onerror = function(error) {
                  db.close();
                  return reject(getRequest_1.error);
                };
                modelTx.oncomplete = function() {
                  return db.close();
                };
              } else {
                var modelArtifactsInfo_1 = getModelArtifactsInfoForJSON(modelArtifacts);
                var infoTx_1 = db.transaction(INFO_STORE_NAME, "readwrite");
                var infoStore_1 = infoTx_1.objectStore(INFO_STORE_NAME);
                var putInfoRequest_1;
                try {
                  putInfoRequest_1 = infoStore_1.put({ modelPath: _this.modelPath, modelArtifactsInfo: modelArtifactsInfo_1 });
                } catch (error) {
                  return reject(error);
                }
                var modelTx_1;
                putInfoRequest_1.onsuccess = function() {
                  modelTx_1 = db.transaction(MODEL_STORE_NAME, "readwrite");
                  var modelStore2 = modelTx_1.objectStore(MODEL_STORE_NAME);
                  var putModelRequest;
                  try {
                    putModelRequest = modelStore2.put({
                      modelPath: _this.modelPath,
                      modelArtifacts,
                      modelArtifactsInfo: modelArtifactsInfo_1
                    });
                  } catch (error) {
                    return reject(error);
                  }
                  putModelRequest.onsuccess = function() {
                    return resolve2({ modelArtifactsInfo: modelArtifactsInfo_1 });
                  };
                  putModelRequest.onerror = function(error) {
                    infoStore_1 = infoTx_1.objectStore(INFO_STORE_NAME);
                    var deleteInfoRequest = infoStore_1.delete(_this.modelPath);
                    deleteInfoRequest.onsuccess = function() {
                      db.close();
                      return reject(putModelRequest.error);
                    };
                    deleteInfoRequest.onerror = function(error2) {
                      db.close();
                      return reject(putModelRequest.error);
                    };
                  };
                };
                putInfoRequest_1.onerror = function(error) {
                  db.close();
                  return reject(putInfoRequest_1.error);
                };
                infoTx_1.oncomplete = function() {
                  if (modelTx_1 == null) {
                    db.close();
                  } else {
                    modelTx_1.oncomplete = function() {
                      return db.close();
                    };
                  }
                };
              }
            };
            openRequest.onerror = function(error) {
              return reject(openRequest.error);
            };
          });
        };
        return BrowserIndexedDB2;
      }()
    );
    BrowserIndexedDB.URL_SCHEME = "indexeddb://";
    var indexedDBRouter = function(url) {
      if (!env().getBool("IS_BROWSER")) {
        return null;
      } else {
        if (!Array.isArray(url) && url.startsWith(BrowserIndexedDB.URL_SCHEME)) {
          return browserIndexedDB(url.slice(BrowserIndexedDB.URL_SCHEME.length));
        } else {
          return null;
        }
      }
    };
    IORouterRegistry.registerSaveRouter(indexedDBRouter);
    IORouterRegistry.registerLoadRouter(indexedDBRouter);
    function browserIndexedDB(modelPath) {
      return new BrowserIndexedDB(modelPath);
    }
    function maybeStripScheme$1(key) {
      return key.startsWith(BrowserIndexedDB.URL_SCHEME) ? key.slice(BrowserIndexedDB.URL_SCHEME.length) : key;
    }
    var BrowserIndexedDBManager = (
      /** @class */
      function() {
        function BrowserIndexedDBManager2() {
          this.indexedDB = getIndexedDBFactory();
        }
        BrowserIndexedDBManager2.prototype.listModels = function() {
          return __awaiter(this, void 0, void 0, function() {
            var _this = this;
            return __generator(this, function(_a) {
              return [2, new Promise(function(resolve2, reject) {
                var openRequest = _this.indexedDB.open(DATABASE_NAME, DATABASE_VERSION);
                openRequest.onupgradeneeded = function() {
                  return setUpDatabase(openRequest);
                };
                openRequest.onsuccess = function() {
                  var db = openRequest.result;
                  var tx = db.transaction(INFO_STORE_NAME, "readonly");
                  var store = tx.objectStore(INFO_STORE_NAME);
                  var getAllInfoRequest = store.getAll();
                  getAllInfoRequest.onsuccess = function() {
                    var e_1, _a2;
                    var out = {};
                    try {
                      for (var _b = __values(getAllInfoRequest.result), _c = _b.next(); !_c.done; _c = _b.next()) {
                        var item = _c.value;
                        out[item.modelPath] = item.modelArtifactsInfo;
                      }
                    } catch (e_1_1) {
                      e_1 = { error: e_1_1 };
                    } finally {
                      try {
                        if (_c && !_c.done && (_a2 = _b.return))
                          _a2.call(_b);
                      } finally {
                        if (e_1)
                          throw e_1.error;
                      }
                    }
                    resolve2(out);
                  };
                  getAllInfoRequest.onerror = function(error) {
                    db.close();
                    return reject(getAllInfoRequest.error);
                  };
                  tx.oncomplete = function() {
                    return db.close();
                  };
                };
                openRequest.onerror = function(error) {
                  return reject(openRequest.error);
                };
              })];
            });
          });
        };
        BrowserIndexedDBManager2.prototype.removeModel = function(path) {
          return __awaiter(this, void 0, void 0, function() {
            var _this = this;
            return __generator(this, function(_a) {
              path = maybeStripScheme$1(path);
              return [2, new Promise(function(resolve2, reject) {
                var openRequest = _this.indexedDB.open(DATABASE_NAME, DATABASE_VERSION);
                openRequest.onupgradeneeded = function() {
                  return setUpDatabase(openRequest);
                };
                openRequest.onsuccess = function() {
                  var db = openRequest.result;
                  var infoTx = db.transaction(INFO_STORE_NAME, "readwrite");
                  var infoStore = infoTx.objectStore(INFO_STORE_NAME);
                  var getInfoRequest = infoStore.get(path);
                  var modelTx;
                  getInfoRequest.onsuccess = function() {
                    if (getInfoRequest.result == null) {
                      db.close();
                      return reject(new Error("Cannot find model with path '".concat(path, "' ") + "in IndexedDB."));
                    } else {
                      var deleteInfoRequest = infoStore.delete(path);
                      var deleteModelData_1 = function() {
                        modelTx = db.transaction(MODEL_STORE_NAME, "readwrite");
                        var modelStore = modelTx.objectStore(MODEL_STORE_NAME);
                        var deleteModelRequest = modelStore.delete(path);
                        deleteModelRequest.onsuccess = function() {
                          return resolve2(getInfoRequest.result.modelArtifactsInfo);
                        };
                        deleteModelRequest.onerror = function(error) {
                          return reject(getInfoRequest.error);
                        };
                      };
                      deleteInfoRequest.onsuccess = deleteModelData_1;
                      deleteInfoRequest.onerror = function(error) {
                        deleteModelData_1();
                        db.close();
                        return reject(getInfoRequest.error);
                      };
                    }
                  };
                  getInfoRequest.onerror = function(error) {
                    db.close();
                    return reject(getInfoRequest.error);
                  };
                  infoTx.oncomplete = function() {
                    if (modelTx == null) {
                      db.close();
                    } else {
                      modelTx.oncomplete = function() {
                        return db.close();
                      };
                    }
                  };
                };
                openRequest.onerror = function(error) {
                  return reject(openRequest.error);
                };
              })];
            });
          });
        };
        return BrowserIndexedDBManager2;
      }()
    );
    var PATH_SEPARATOR = "/";
    var PATH_PREFIX = "tensorflowjs_models";
    var INFO_SUFFIX = "info";
    var MODEL_TOPOLOGY_SUFFIX = "model_topology";
    var WEIGHT_SPECS_SUFFIX = "weight_specs";
    var WEIGHT_DATA_SUFFIX = "weight_data";
    var MODEL_METADATA_SUFFIX = "model_metadata";
    function getModelKeys(path) {
      return {
        info: [PATH_PREFIX, path, INFO_SUFFIX].join(PATH_SEPARATOR),
        topology: [PATH_PREFIX, path, MODEL_TOPOLOGY_SUFFIX].join(PATH_SEPARATOR),
        weightSpecs: [PATH_PREFIX, path, WEIGHT_SPECS_SUFFIX].join(PATH_SEPARATOR),
        weightData: [PATH_PREFIX, path, WEIGHT_DATA_SUFFIX].join(PATH_SEPARATOR),
        modelMetadata: [PATH_PREFIX, path, MODEL_METADATA_SUFFIX].join(PATH_SEPARATOR)
      };
    }
    function removeItems(keys) {
      var e_1, _a;
      try {
        for (var _b = __values(Object.values(keys)), _c = _b.next(); !_c.done; _c = _b.next()) {
          var key = _c.value;
          window.localStorage.removeItem(key);
        }
      } catch (e_1_1) {
        e_1 = { error: e_1_1 };
      } finally {
        try {
          if (_c && !_c.done && (_a = _b.return))
            _a.call(_b);
        } finally {
          if (e_1)
            throw e_1.error;
        }
      }
    }
    function getModelPathFromKey(key) {
      var items = key.split(PATH_SEPARATOR);
      if (items.length < 3) {
        throw new Error("Invalid key format: ".concat(key));
      }
      return items.slice(1, items.length - 1).join(PATH_SEPARATOR);
    }
    function maybeStripScheme(key) {
      return key.startsWith(BrowserLocalStorage.URL_SCHEME) ? key.slice(BrowserLocalStorage.URL_SCHEME.length) : key;
    }
    var BrowserLocalStorage = (
      /** @class */
      function() {
        function BrowserLocalStorage2(modelPath) {
          if (!env().getBool("IS_BROWSER") || typeof window === "undefined" || typeof window.localStorage === "undefined") {
            throw new Error("The current environment does not support local storage.");
          }
          this.LS = window.localStorage;
          if (modelPath == null || !modelPath) {
            throw new Error("For local storage, modelPath must not be null, undefined or empty.");
          }
          this.modelPath = modelPath;
          this.keys = getModelKeys(this.modelPath);
        }
        BrowserLocalStorage2.prototype.save = function(modelArtifacts) {
          return __awaiter(this, void 0, void 0, function() {
            var topology, weightSpecs, modelArtifactsInfo, metadata;
            return __generator(this, function(_a) {
              if (modelArtifacts.modelTopology instanceof ArrayBuffer) {
                throw new Error("BrowserLocalStorage.save() does not support saving model topology in binary formats yet.");
              } else {
                topology = JSON.stringify(modelArtifacts.modelTopology);
                weightSpecs = JSON.stringify(modelArtifacts.weightSpecs);
                modelArtifactsInfo = getModelArtifactsInfoForJSON(modelArtifacts);
                try {
                  this.LS.setItem(this.keys.info, JSON.stringify(modelArtifactsInfo));
                  this.LS.setItem(this.keys.topology, topology);
                  this.LS.setItem(this.keys.weightSpecs, weightSpecs);
                  this.LS.setItem(this.keys.weightData, arrayBufferToBase64String(modelArtifacts.weightData));
                  metadata = {
                    format: modelArtifacts.format,
                    generatedBy: modelArtifacts.generatedBy,
                    convertedBy: modelArtifacts.convertedBy,
                    signature: modelArtifacts.signature != null ? modelArtifacts.signature : void 0,
                    userDefinedMetadata: modelArtifacts.userDefinedMetadata != null ? modelArtifacts.userDefinedMetadata : void 0,
                    modelInitializer: modelArtifacts.modelInitializer != null ? modelArtifacts.modelInitializer : void 0,
                    initializerSignature: modelArtifacts.initializerSignature != null ? modelArtifacts.initializerSignature : void 0,
                    trainingConfig: modelArtifacts.trainingConfig != null ? modelArtifacts.trainingConfig : void 0
                  };
                  this.LS.setItem(this.keys.modelMetadata, JSON.stringify(metadata));
                  return [2, { modelArtifactsInfo }];
                } catch (err) {
                  removeItems(this.keys);
                  throw new Error("Failed to save model '".concat(this.modelPath, "' to local storage: ") + "size quota being exceeded is a possible cause of this failure: " + "modelTopologyBytes=".concat(modelArtifactsInfo.modelTopologyBytes, ", ") + "weightSpecsBytes=".concat(modelArtifactsInfo.weightSpecsBytes, ", ") + "weightDataBytes=".concat(modelArtifactsInfo.weightDataBytes, "."));
                }
              }
              return [
                2
                /*return*/
              ];
            });
          });
        };
        BrowserLocalStorage2.prototype.load = function() {
          return __awaiter(this, void 0, void 0, function() {
            var info, out, topology, weightSpecs, metadataString, metadata, weightDataBase64;
            return __generator(this, function(_a) {
              info = JSON.parse(this.LS.getItem(this.keys.info));
              if (info == null) {
                throw new Error("In local storage, there is no model with name '".concat(this.modelPath, "'"));
              }
              if (info.modelTopologyType !== "JSON") {
                throw new Error("BrowserLocalStorage does not support loading non-JSON model topology yet.");
              }
              out = {};
              topology = JSON.parse(this.LS.getItem(this.keys.topology));
              if (topology == null) {
                throw new Error("In local storage, the topology of model '".concat(this.modelPath, "' ") + "is missing.");
              }
              out.modelTopology = topology;
              weightSpecs = JSON.parse(this.LS.getItem(this.keys.weightSpecs));
              if (weightSpecs == null) {
                throw new Error("In local storage, the weight specs of model '".concat(this.modelPath, "' ") + "are missing.");
              }
              out.weightSpecs = weightSpecs;
              metadataString = this.LS.getItem(this.keys.modelMetadata);
              if (metadataString != null) {
                metadata = JSON.parse(metadataString);
                out.format = metadata.format;
                out.generatedBy = metadata.generatedBy;
                out.convertedBy = metadata.convertedBy;
                if (metadata.signature != null) {
                  out.signature = metadata.signature;
                }
                if (metadata.userDefinedMetadata != null) {
                  out.userDefinedMetadata = metadata.userDefinedMetadata;
                }
                if (metadata.modelInitializer != null) {
                  out.modelInitializer = metadata.modelInitializer;
                }
                if (metadata.initializerSignature != null) {
                  out.initializerSignature = metadata.initializerSignature;
                }
                if (metadata.trainingConfig != null) {
                  out.trainingConfig = metadata.trainingConfig;
                }
              }
              weightDataBase64 = this.LS.getItem(this.keys.weightData);
              if (weightDataBase64 == null) {
                throw new Error("In local storage, the binary weight values of model " + "'".concat(this.modelPath, "' are missing."));
              }
              out.weightData = base64StringToArrayBuffer(weightDataBase64);
              return [2, out];
            });
          });
        };
        return BrowserLocalStorage2;
      }()
    );
    BrowserLocalStorage.URL_SCHEME = "localstorage://";
    var localStorageRouter = function(url) {
      if (!env().getBool("IS_BROWSER")) {
        return null;
      } else {
        if (!Array.isArray(url) && url.startsWith(BrowserLocalStorage.URL_SCHEME)) {
          return browserLocalStorage(url.slice(BrowserLocalStorage.URL_SCHEME.length));
        } else {
          return null;
        }
      }
    };
    IORouterRegistry.registerSaveRouter(localStorageRouter);
    IORouterRegistry.registerLoadRouter(localStorageRouter);
    function browserLocalStorage(modelPath) {
      return new BrowserLocalStorage(modelPath);
    }
    var BrowserLocalStorageManager = (
      /** @class */
      function() {
        function BrowserLocalStorageManager2() {
          assert(env().getBool("IS_BROWSER"), function() {
            return "Current environment is not a web browser";
          });
          assert(typeof window === "undefined" || typeof window.localStorage !== "undefined", function() {
            return "Current browser does not appear to support localStorage";
          });
          this.LS = window.localStorage;
        }
        BrowserLocalStorageManager2.prototype.listModels = function() {
          return __awaiter(this, void 0, void 0, function() {
            var out, prefix, suffix, i, key, modelPath;
            return __generator(this, function(_a) {
              out = {};
              prefix = PATH_PREFIX + PATH_SEPARATOR;
              suffix = PATH_SEPARATOR + INFO_SUFFIX;
              for (i = 0; i < this.LS.length; ++i) {
                key = this.LS.key(i);
                if (key.startsWith(prefix) && key.endsWith(suffix)) {
                  modelPath = getModelPathFromKey(key);
                  out[modelPath] = JSON.parse(this.LS.getItem(key));
                }
              }
              return [2, out];
            });
          });
        };
        BrowserLocalStorageManager2.prototype.removeModel = function(path) {
          return __awaiter(this, void 0, void 0, function() {
            var keys, info;
            return __generator(this, function(_a) {
              path = maybeStripScheme(path);
              keys = getModelKeys(path);
              if (this.LS.getItem(keys.info) == null) {
                throw new Error("Cannot find model at path '".concat(path, "'"));
              }
              info = JSON.parse(this.LS.getItem(keys.info));
              removeItems(keys);
              return [2, info];
            });
          });
        };
        return BrowserLocalStorageManager2;
      }()
    );
    var URL_SCHEME_SUFFIX = "://";
    var ModelStoreManagerRegistry = (
      /** @class */
      function() {
        function ModelStoreManagerRegistry2() {
          this.managers = {};
        }
        ModelStoreManagerRegistry2.getInstance = function() {
          if (ModelStoreManagerRegistry2.instance == null) {
            ModelStoreManagerRegistry2.instance = new ModelStoreManagerRegistry2();
          }
          return ModelStoreManagerRegistry2.instance;
        };
        ModelStoreManagerRegistry2.registerManager = function(scheme, manager) {
          assert(scheme != null, function() {
            return "scheme must not be undefined or null.";
          });
          if (scheme.endsWith(URL_SCHEME_SUFFIX)) {
            scheme = scheme.slice(0, scheme.indexOf(URL_SCHEME_SUFFIX));
          }
          assert(scheme.length > 0, function() {
            return "scheme must not be an empty string.";
          });
          var registry = ModelStoreManagerRegistry2.getInstance();
          assert(registry.managers[scheme] == null, function() {
            return "A model store manager is already registered for scheme '".concat(scheme, "'.");
          });
          registry.managers[scheme] = manager;
        };
        ModelStoreManagerRegistry2.getManager = function(scheme) {
          var manager = ModelStoreManagerRegistry2.getInstance().managers[scheme];
          if (manager == null) {
            throw new Error("Cannot find model manager for scheme '".concat(scheme, "'"));
          }
          return manager;
        };
        ModelStoreManagerRegistry2.getSchemes = function() {
          return Object.keys(ModelStoreManagerRegistry2.getInstance().managers);
        };
        return ModelStoreManagerRegistry2;
      }()
    );
    function parseURL(url) {
      if (url.indexOf(URL_SCHEME_SUFFIX) === -1) {
        throw new Error("The url string provided does not contain a scheme. Supported schemes are: " + "".concat(ModelStoreManagerRegistry.getSchemes().join(",")));
      }
      return {
        scheme: url.split(URL_SCHEME_SUFFIX)[0],
        path: url.split(URL_SCHEME_SUFFIX)[1]
      };
    }
    function cloneModelInternal(sourceURL, destURL, deleteSource) {
      if (deleteSource === void 0) {
        deleteSource = false;
      }
      return __awaiter(this, void 0, void 0, function() {
        var loadHandlers, loadHandler, saveHandlers, saveHandler, sourceScheme, sourcePath, sameMedium, modelArtifacts, saveResult;
        return __generator(this, function(_a) {
          switch (_a.label) {
            case 0:
              assert(sourceURL !== destURL, function() {
                return "Old path and new path are the same: '".concat(sourceURL, "'");
              });
              loadHandlers = IORouterRegistry.getLoadHandlers(sourceURL);
              assert(loadHandlers.length > 0, function() {
                return "Copying failed because no load handler is found for source URL ".concat(sourceURL, ".");
              });
              assert(loadHandlers.length < 2, function() {
                return "Copying failed because more than one (".concat(loadHandlers.length, ") ") + "load handlers for source URL ".concat(sourceURL, ".");
              });
              loadHandler = loadHandlers[0];
              saveHandlers = IORouterRegistry.getSaveHandlers(destURL);
              assert(saveHandlers.length > 0, function() {
                return "Copying failed because no save handler is found for destination " + "URL ".concat(destURL, ".");
              });
              assert(saveHandlers.length < 2, function() {
                return "Copying failed because more than one (".concat(loadHandlers.length, ") ") + "save handlers for destination URL ".concat(destURL, ".");
              });
              saveHandler = saveHandlers[0];
              sourceScheme = parseURL(sourceURL).scheme;
              sourcePath = parseURL(sourceURL).path;
              sameMedium = sourceScheme === parseURL(sourceURL).scheme;
              return [4, loadHandler.load()];
            case 1:
              modelArtifacts = _a.sent();
              if (!(deleteSource && sameMedium))
                return [3, 3];
              return [4, ModelStoreManagerRegistry.getManager(sourceScheme).removeModel(sourcePath)];
            case 2:
              _a.sent();
              _a.label = 3;
            case 3:
              return [4, saveHandler.save(modelArtifacts)];
            case 4:
              saveResult = _a.sent();
              if (!(deleteSource && !sameMedium))
                return [3, 6];
              return [4, ModelStoreManagerRegistry.getManager(sourceScheme).removeModel(sourcePath)];
            case 5:
              _a.sent();
              _a.label = 6;
            case 6:
              return [2, saveResult.modelArtifactsInfo];
          }
        });
      });
    }
    function listModels() {
      return __awaiter(this, void 0, void 0, function() {
        var schemes, out, schemes_1, schemes_1_1, scheme, schemeOut, path, url, e_1_1;
        var e_1, _a;
        return __generator(this, function(_b) {
          switch (_b.label) {
            case 0:
              schemes = ModelStoreManagerRegistry.getSchemes();
              out = {};
              _b.label = 1;
            case 1:
              _b.trys.push([1, 6, 7, 8]);
              schemes_1 = __values(schemes), schemes_1_1 = schemes_1.next();
              _b.label = 2;
            case 2:
              if (!!schemes_1_1.done)
                return [3, 5];
              scheme = schemes_1_1.value;
              return [4, ModelStoreManagerRegistry.getManager(scheme).listModels()];
            case 3:
              schemeOut = _b.sent();
              for (path in schemeOut) {
                url = scheme + URL_SCHEME_SUFFIX + path;
                out[url] = schemeOut[path];
              }
              _b.label = 4;
            case 4:
              schemes_1_1 = schemes_1.next();
              return [3, 2];
            case 5:
              return [3, 8];
            case 6:
              e_1_1 = _b.sent();
              e_1 = { error: e_1_1 };
              return [3, 8];
            case 7:
              try {
                if (schemes_1_1 && !schemes_1_1.done && (_a = schemes_1.return))
                  _a.call(schemes_1);
              } finally {
                if (e_1)
                  throw e_1.error;
              }
              return [
                7
                /*endfinally*/
              ];
            case 8:
              return [2, out];
          }
        });
      });
    }
    function removeModel(url) {
      return __awaiter(this, void 0, void 0, function() {
        var schemeAndPath, manager;
        return __generator(this, function(_a) {
          schemeAndPath = parseURL(url);
          manager = ModelStoreManagerRegistry.getManager(schemeAndPath.scheme);
          return [2, manager.removeModel(schemeAndPath.path)];
        });
      });
    }
    function copyModel(sourceURL, destURL) {
      return __awaiter(this, void 0, void 0, function() {
        var deleteSource;
        return __generator(this, function(_a) {
          deleteSource = false;
          return [2, cloneModelInternal(sourceURL, destURL, deleteSource)];
        });
      });
    }
    function moveModel(sourceURL, destURL) {
      return __awaiter(this, void 0, void 0, function() {
        var deleteSource;
        return __generator(this, function(_a) {
          deleteSource = true;
          return [2, cloneModelInternal(sourceURL, destURL, deleteSource)];
        });
      });
    }
    var PlatformBrowser = (
      /** @class */
      function() {
        function PlatformBrowser2() {
          this.messageName = "setTimeoutCustom";
          this.functionRefs = [];
          this.handledMessageCount = 0;
          this.hasEventListener = false;
        }
        PlatformBrowser2.prototype.fetch = function(path, init) {
          return fetch(path, init);
        };
        PlatformBrowser2.prototype.now = function() {
          return performance.now();
        };
        PlatformBrowser2.prototype.encode = function(text, encoding) {
          if (encoding !== "utf-8" && encoding !== "utf8") {
            throw new Error("Browser's encoder only supports utf-8, but got ".concat(encoding));
          }
          if (this.textEncoder == null) {
            this.textEncoder = new TextEncoder();
          }
          return this.textEncoder.encode(text);
        };
        PlatformBrowser2.prototype.decode = function(bytes, encoding) {
          return new TextDecoder(encoding).decode(bytes);
        };
        PlatformBrowser2.prototype.setTimeoutCustom = function(functionRef, delay) {
          var _this = this;
          if (typeof window === "undefined" || !env().getBool("USE_SETTIMEOUTCUSTOM")) {
            setTimeout(functionRef, delay);
            return;
          }
          this.functionRefs.push(functionRef);
          setTimeout(function() {
            window.postMessage({ name: _this.messageName, index: _this.functionRefs.length - 1 }, "*");
          }, delay);
          if (!this.hasEventListener) {
            this.hasEventListener = true;
            window.addEventListener("message", function(event) {
              if (event.source === window && event.data.name === _this.messageName) {
                event.stopPropagation();
                var functionRef_1 = _this.functionRefs[event.data.index];
                functionRef_1();
                _this.handledMessageCount++;
                if (_this.handledMessageCount === _this.functionRefs.length) {
                  _this.functionRefs = [];
                  _this.handledMessageCount = 0;
                }
              }
            }, true);
          }
        };
        PlatformBrowser2.prototype.isTypedArray = function(a) {
          return isTypedArrayBrowser(a);
        };
        return PlatformBrowser2;
      }()
    );
    if (env().get("IS_BROWSER")) {
      env().setPlatform("browser", new PlatformBrowser());
      try {
        ModelStoreManagerRegistry.registerManager(BrowserLocalStorage.URL_SCHEME, new BrowserLocalStorageManager());
      } catch (err) {
      }
      try {
        ModelStoreManagerRegistry.registerManager(BrowserIndexedDB.URL_SCHEME, new BrowserIndexedDBManager());
      } catch (err) {
      }
    }
    var getNodeFetch = {
      // tslint:disable-next-line:no-require-imports
      importFetch: function() {
        return require("node-fetch");
      }
    };
    var systemFetch;
    var PlatformNode = (
      /** @class */
      function() {
        function PlatformNode2() {
          this.util = require("util");
          this.textEncoder = new this.util.TextEncoder();
        }
        PlatformNode2.prototype.fetch = function(path, requestInits) {
          if (env().global.fetch != null) {
            return env().global.fetch(path, requestInits);
          }
          if (systemFetch == null) {
            systemFetch = getNodeFetch.importFetch();
          }
          return systemFetch(path, requestInits);
        };
        PlatformNode2.prototype.now = function() {
          var time2 = process.hrtime();
          return time2[0] * 1e3 + time2[1] / 1e6;
        };
        PlatformNode2.prototype.encode = function(text, encoding) {
          if (encoding !== "utf-8" && encoding !== "utf8") {
            throw new Error("Node built-in encoder only supports utf-8, but got ".concat(encoding));
          }
          return this.textEncoder.encode(text);
        };
        PlatformNode2.prototype.decode = function(bytes, encoding) {
          if (bytes.length === 0) {
            return "";
          }
          return new this.util.TextDecoder(encoding).decode(bytes);
        };
        PlatformNode2.prototype.isTypedArray = function(a) {
          return this.util.types.isFloat32Array(a) || this.util.types.isInt32Array(a) || this.util.types.isUint8Array(a) || this.util.types.isUint8ClampedArray(a);
        };
        return PlatformNode2;
      }()
    );
    if (env().get("IS_NODE") && !env().get("IS_BROWSER")) {
      env().setPlatform("node", new PlatformNode());
    }
    function buffer(shape, dtype, values) {
      if (dtype === void 0) {
        dtype = "float32";
      }
      dtype = dtype || "float32";
      assertNonNegativeIntegerDimensions(shape);
      return new TensorBuffer(shape, dtype, values);
    }
    function cast_(x, dtype) {
      var $x = convertToTensor(x, "x", "cast");
      if (!isValidDtype(dtype)) {
        throw new Error("Failed to cast to unknown dtype ".concat(dtype));
      }
      if (dtype === "string" && $x.dtype !== "string" || dtype !== "string" && $x.dtype === "string") {
        throw new Error("Only strings can be casted to strings");
      }
      var inputs = { x: $x };
      var attrs = { dtype };
      return ENGINE.runKernel(Cast, inputs, attrs);
    }
    var cast = /* @__PURE__ */ op({ cast_ });
    function clone_(x) {
      var $x = convertToTensor(x, "x", "clone", "string_or_numeric");
      var inputs = { x: $x };
      return ENGINE.runKernel(Identity, inputs);
    }
    var clone = /* @__PURE__ */ op({ clone_ });
    function print(x, verbose) {
      if (verbose === void 0) {
        verbose = false;
      }
      console.log(x.toString(verbose));
    }
    getOrMakeEngine();
    var opHandler = {
      buffer,
      cast,
      clone,
      print
    };
    setOpHandler(opHandler);
    function enableProdMode() {
      env().set("PROD", true);
    }
    function enableDebugMode() {
      env().set("DEBUG", true);
    }
    function disableDeprecationWarnings() {
      env().set("DEPRECATION_WARNINGS_ENABLED", false);
      console.warn("TensorFlow.js deprecation warnings have been disabled.");
    }
    function deprecationWarn(msg) {
      if (env().getBool("DEPRECATION_WARNINGS_ENABLED")) {
        console.warn(msg + " You can disable deprecation warnings with tf.disableDeprecationWarnings().");
      }
    }
    function disposeVariables() {
      ENGINE.disposeVariables();
    }
    function engine() {
      return ENGINE;
    }
    function memory() {
      return ENGINE.memory();
    }
    function profile(f) {
      return ENGINE.profile(f);
    }
    function tidy(nameOrFn, fn) {
      return ENGINE.tidy(nameOrFn, fn);
    }
    function dispose(container) {
      var tensors = getTensorsInContainer(container);
      tensors.forEach(function(tensor2) {
        return tensor2.dispose();
      });
    }
    function keep(result) {
      return ENGINE.keep(result);
    }
    function time(f) {
      return ENGINE.time(f);
    }
    function setBackend2(backendName) {
      return ENGINE.setBackend(backendName);
    }
    function ready() {
      return ENGINE.ready();
    }
    function getBackend() {
      return ENGINE.backendName;
    }
    function removeBackend(name) {
      ENGINE.removeBackend(name);
    }
    function findBackend(name) {
      return ENGINE.findBackend(name);
    }
    function findBackendFactory(name) {
      return ENGINE.findBackendFactory(name);
    }
    function registerBackend(name, factory, priority) {
      if (priority === void 0) {
        priority = 1;
      }
      return ENGINE.registerBackend(name, factory, priority);
    }
    function backend() {
      return ENGINE.backend;
    }
    function setPlatform(platformName, platform) {
      env().setPlatform(platformName, platform);
    }
    function add_(a, b) {
      var _a;
      var $a = convertToTensor(a, "a", "add");
      var $b = convertToTensor(b, "b", "add");
      _a = __read(makeTypesMatch($a, $b), 2), $a = _a[0], $b = _a[1];
      var inputs = { a: $a, b: $b };
      return ENGINE.runKernel(Add, inputs);
    }
    var add = /* @__PURE__ */ op({ add_ });
    function floorDiv_(a, b) {
      var _a;
      var $a = convertToTensor(a, "a", "floorDiv");
      var $b = convertToTensor(b, "b", "floorDiv");
      _a = __read(makeTypesMatch($a, $b), 2), $a = _a[0], $b = _a[1];
      var inputs = { a: $a, b: $b };
      return ENGINE.runKernel(FloorDiv, inputs);
    }
    var floorDiv = /* @__PURE__ */ op({ floorDiv_ });
    function div_(a, b) {
      var _a;
      var $a = convertToTensor(a, "a", "div");
      var $b = convertToTensor(b, "b", "div");
      _a = __read(makeTypesMatch($a, $b), 2), $a = _a[0], $b = _a[1];
      if ($a.dtype === "int32" && $b.dtype === "int32") {
        return floorDiv($a, $b);
      }
      var inputs = { a: $a, b: $b };
      var attrs = {};
      return ENGINE.runKernel(RealDiv, inputs, attrs);
    }
    var div = /* @__PURE__ */ op({ div_ });
    function mul_(a, b) {
      var _a;
      var $a = convertToTensor(a, "a", "mul");
      var $b = convertToTensor(b, "b", "mul");
      _a = __read(makeTypesMatch($a, $b), 2), $a = _a[0], $b = _a[1];
      var inputs = { a: $a, b: $b };
      return ENGINE.runKernel(Multiply, inputs);
    }
    var mul = /* @__PURE__ */ op({ mul_ });
    function abs_(x) {
      var $x = convertToTensor(x, "x", "abs");
      if ($x.dtype === "complex64") {
        var inputs = { x: $x };
        return ENGINE.runKernel(ComplexAbs, inputs);
      } else {
        var inputs = { x: $x };
        return ENGINE.runKernel(Abs, inputs);
      }
    }
    var abs = /* @__PURE__ */ op({ abs_ });
    function acos_(x) {
      var $x = convertToTensor(x, "x", "acos");
      var inputs = { x: $x };
      return ENGINE.runKernel(Acos, inputs);
    }
    var acos = /* @__PURE__ */ op({ acos_ });
    function acosh_(x) {
      var $x = convertToTensor(x, "x", "acosh");
      var inputs = { x: $x };
      return ENGINE.runKernel(Acosh, inputs);
    }
    var acosh = /* @__PURE__ */ op({ acosh_ });
    function addN_(tensors) {
      assert(Array.isArray(tensors), function() {
        return "The argument passed to tf.addN() must be a list of tensors";
      });
      assert(tensors.length >= 1, function() {
        return "Must pass at least one tensor to tf.addN(), but got " + "".concat(tensors.length);
      });
      var $tensors = tensors.map(function(t, i) {
        return convertToTensor(t, "tensors".concat(i), "addN");
      });
      var firstTensor = $tensors[0];
      $tensors.forEach(function(t) {
        if (t.dtype !== firstTensor.dtype) {
          throw new Error("All tensors passed to tf.addN() must have the same dtype");
        }
      });
      $tensors.forEach(function(t) {
        if (!arraysEqual(t.shape, firstTensor.shape)) {
          throw new Error("All tensors passed to tf.addN() must have the same shape");
        }
      });
      var inputs = $tensors;
      return ENGINE.runKernel(AddN, inputs);
    }
    var addN = /* @__PURE__ */ op({ addN_ });
    function all_(x, axis, keepDims) {
      if (axis === void 0) {
        axis = null;
      }
      if (keepDims === void 0) {
        keepDims = false;
      }
      var $x = convertToTensor(x, "x", "all", "bool");
      var inputs = { x: $x };
      var attrs = { axis, keepDims };
      return ENGINE.runKernel(All, inputs, attrs);
    }
    var all = /* @__PURE__ */ op({ all_ });
    function any_(x, axis, keepDims) {
      if (axis === void 0) {
        axis = null;
      }
      if (keepDims === void 0) {
        keepDims = false;
      }
      var $x = convertToTensor(x, "x", "any", "bool");
      var inputs = { x: $x };
      var attrs = { axis, keepDims };
      return ENGINE.runKernel(Any, inputs, attrs);
    }
    var any = /* @__PURE__ */ op({ any_ });
    function argMax_(x, axis) {
      if (axis === void 0) {
        axis = 0;
      }
      var $x = convertToTensor(x, "x", "argMax");
      var inputs = { x: $x };
      var attrs = { axis };
      return ENGINE.runKernel(ArgMax, inputs, attrs);
    }
    var argMax = /* @__PURE__ */ op({ argMax_ });
    function argMin_(x, axis) {
      if (axis === void 0) {
        axis = 0;
      }
      var $x = convertToTensor(x, "x", "argMin");
      var inputs = { x: $x };
      var attrs = { axis };
      return ENGINE.runKernel(ArgMin, inputs, attrs);
    }
    var argMin = /* @__PURE__ */ op({ argMin_ });
    function asin_(x) {
      var $x = convertToTensor(x, "x", "asin");
      var inputs = { x: $x };
      return ENGINE.runKernel(Asin, inputs);
    }
    var asin = /* @__PURE__ */ op({ asin_ });
    function asinh_(x) {
      var $x = convertToTensor(x, "x", "asinh");
      var inputs = { x: $x };
      return ENGINE.runKernel(Asinh, inputs);
    }
    var asinh = /* @__PURE__ */ op({ asinh_ });
    function atan_(x) {
      var $x = convertToTensor(x, "x", "atan");
      var inputs = { x: $x };
      return ENGINE.runKernel(Atan, inputs);
    }
    var atan = /* @__PURE__ */ op({ atan_ });
    function atan2_(a, b) {
      var _a;
      var $a = convertToTensor(a, "a", "atan2");
      var $b = convertToTensor(b, "b", "atan2");
      _a = __read(makeTypesMatch($a, $b), 2), $a = _a[0], $b = _a[1];
      var inputs = { a: $a, b: $b };
      return ENGINE.runKernel(Atan2, inputs);
    }
    var atan2 = /* @__PURE__ */ op({ atan2_ });
    function atanh_(x) {
      var $x = convertToTensor(x, "x", "atanh");
      var inputs = { x: $x };
      return ENGINE.runKernel(Atanh, inputs);
    }
    var atanh = /* @__PURE__ */ op({ atanh_ });
    function computeDilation2DInfo(inputShape, filterShape, strides, pad2, dataFormat, dilations) {
      if (dataFormat === void 0) {
        dataFormat = "NHWC";
      }
      var inputChannels = inputShape[3];
      var $filterShape = __spreadArray(__spreadArray([], __read(filterShape), false), [inputChannels], false);
      var $dataFormat = convertConv2DDataFormat(dataFormat);
      return computeConv2DInfo(inputShape, $filterShape, strides, dilations, pad2, null, null, $dataFormat);
    }
    function computePool2DInfo(inShape, filterSize, strides, dilations, pad2, roundingMode, dataFormat) {
      if (dataFormat === void 0) {
        dataFormat = "channelsLast";
      }
      var _a = __read(parseTupleParam(filterSize), 2), filterHeight = _a[0], filterWidth = _a[1];
      var filterShape;
      if (dataFormat === "channelsLast") {
        filterShape = [filterHeight, filterWidth, inShape[3], inShape[3]];
      } else if (dataFormat === "channelsFirst") {
        filterShape = [filterHeight, filterWidth, inShape[1], inShape[1]];
      } else {
        throw new Error("Unknown dataFormat ".concat(dataFormat));
      }
      return computeConv2DInfo(inShape, filterShape, strides, dilations, pad2, roundingMode, false, dataFormat);
    }
    function computePool3DInfo(inShape, filterSize, strides, dilations, pad2, roundingMode, dataFormat) {
      if (dataFormat === void 0) {
        dataFormat = "NDHWC";
      }
      var _a = __read(parse3TupleParam(filterSize), 3), filterDepth = _a[0], filterHeight = _a[1], filterWidth = _a[2];
      var filterShape;
      var $dataFormat;
      if (dataFormat === "NDHWC") {
        $dataFormat = "channelsLast";
        filterShape = [filterDepth, filterHeight, filterWidth, inShape[4], inShape[4]];
      } else if (dataFormat === "NCDHW") {
        $dataFormat = "channelsFirst";
        filterShape = [filterDepth, filterHeight, filterWidth, inShape[1], inShape[1]];
      } else {
        throw new Error("Unknown dataFormat ".concat(dataFormat));
      }
      return computeConv3DInfo(inShape, filterShape, strides, dilations, pad2, false, $dataFormat, roundingMode);
    }
    function computeConv2DInfo(inShape, filterShape, strides, dilations, pad2, roundingMode, depthwise, dataFormat) {
      var _a, _b;
      if (depthwise === void 0) {
        depthwise = false;
      }
      if (dataFormat === void 0) {
        dataFormat = "channelsLast";
      }
      var _c = __read([-1, -1, -1, -1], 4), batchSize = _c[0], inHeight = _c[1], inWidth = _c[2], inChannels = _c[3];
      if (dataFormat === "channelsLast") {
        _a = __read(inShape, 4), batchSize = _a[0], inHeight = _a[1], inWidth = _a[2], inChannels = _a[3];
      } else if (dataFormat === "channelsFirst") {
        _b = __read(inShape, 4), batchSize = _b[0], inChannels = _b[1], inHeight = _b[2], inWidth = _b[3];
      } else {
        throw new Error("Unknown dataFormat ".concat(dataFormat));
      }
      var _d = __read(filterShape, 4), filterHeight = _d[0], filterWidth = _d[1], filterChannels = _d[3];
      var _e = __read(parseTupleParam(strides), 2), strideHeight = _e[0], strideWidth = _e[1];
      var _f = __read(parseTupleParam(dilations), 2), dilationHeight = _f[0], dilationWidth = _f[1];
      var effectiveFilterHeight = getEffectiveFilterSize(filterHeight, dilationHeight);
      var effectiveFilterWidth = getEffectiveFilterSize(filterWidth, dilationWidth);
      var _g = getPadAndOutInfo(pad2, inHeight, inWidth, strideHeight, strideWidth, effectiveFilterHeight, effectiveFilterWidth, roundingMode, dataFormat), padInfo = _g.padInfo, outHeight = _g.outHeight, outWidth = _g.outWidth;
      var outChannels = depthwise ? filterChannels * inChannels : filterChannels;
      var outShape;
      if (dataFormat === "channelsFirst") {
        outShape = [batchSize, outChannels, outHeight, outWidth];
      } else if (dataFormat === "channelsLast") {
        outShape = [batchSize, outHeight, outWidth, outChannels];
      }
      return {
        batchSize,
        dataFormat,
        inHeight,
        inWidth,
        inChannels,
        outHeight,
        outWidth,
        outChannels,
        padInfo,
        strideHeight,
        strideWidth,
        filterHeight,
        filterWidth,
        effectiveFilterHeight,
        effectiveFilterWidth,
        dilationHeight,
        dilationWidth,
        inShape,
        outShape,
        filterShape
      };
    }
    function computeConv3DInfo(inShape, filterShape, strides, dilations, pad2, depthwise, dataFormat, roundingMode) {
      var _a, _b;
      if (depthwise === void 0) {
        depthwise = false;
      }
      if (dataFormat === void 0) {
        dataFormat = "channelsLast";
      }
      var _c = __read([-1, -1, -1, -1, -1], 5), batchSize = _c[0], inDepth = _c[1], inHeight = _c[2], inWidth = _c[3], inChannels = _c[4];
      if (dataFormat === "channelsLast") {
        _a = __read(inShape, 5), batchSize = _a[0], inDepth = _a[1], inHeight = _a[2], inWidth = _a[3], inChannels = _a[4];
      } else if (dataFormat === "channelsFirst") {
        _b = __read(inShape, 5), batchSize = _b[0], inChannels = _b[1], inDepth = _b[2], inHeight = _b[3], inWidth = _b[4];
      } else {
        throw new Error("Unknown dataFormat ".concat(dataFormat));
      }
      var _d = __read(filterShape, 5), filterDepth = _d[0], filterHeight = _d[1], filterWidth = _d[2], filterChannels = _d[4];
      var _e = __read(parse3TupleParam(strides), 3), strideDepth = _e[0], strideHeight = _e[1], strideWidth = _e[2];
      var _f = __read(parse3TupleParam(dilations), 3), dilationDepth = _f[0], dilationHeight = _f[1], dilationWidth = _f[2];
      var effectiveFilterDepth = getEffectiveFilterSize(filterDepth, dilationDepth);
      var effectiveFilterHeight = getEffectiveFilterSize(filterHeight, dilationHeight);
      var effectiveFilterWidth = getEffectiveFilterSize(filterWidth, dilationWidth);
      var _g = get3DPadAndOutInfo(pad2, inDepth, inHeight, inWidth, strideDepth, strideHeight, strideWidth, effectiveFilterDepth, effectiveFilterHeight, effectiveFilterWidth, roundingMode), padInfo = _g.padInfo, outDepth = _g.outDepth, outHeight = _g.outHeight, outWidth = _g.outWidth;
      var outChannels = depthwise ? filterChannels * inChannels : filterChannels;
      var outShape;
      if (dataFormat === "channelsFirst") {
        outShape = [batchSize, outChannels, outDepth, outHeight, outWidth];
      } else if (dataFormat === "channelsLast") {
        outShape = [batchSize, outDepth, outHeight, outWidth, outChannels];
      }
      return {
        batchSize,
        dataFormat,
        inDepth,
        inHeight,
        inWidth,
        inChannels,
        outDepth,
        outHeight,
        outWidth,
        outChannels,
        padInfo,
        strideDepth,
        strideHeight,
        strideWidth,
        filterDepth,
        filterHeight,
        filterWidth,
        effectiveFilterDepth,
        effectiveFilterHeight,
        effectiveFilterWidth,
        dilationDepth,
        dilationHeight,
        dilationWidth,
        inShape,
        outShape,
        filterShape
      };
    }
    function computeOutputShape2D(inShape, fieldSize, stride, zeroPad, roundingMode) {
      if (zeroPad == null) {
        zeroPad = computeDefaultPad(inShape, fieldSize, stride);
      }
      var inputRows = inShape[0];
      var inputCols = inShape[1];
      var outputRows = round$1((inputRows - fieldSize + 2 * zeroPad) / stride + 1, roundingMode);
      var outputCols = round$1((inputCols - fieldSize + 2 * zeroPad) / stride + 1, roundingMode);
      return [outputRows, outputCols];
    }
    function computeOutputShape4D(inShape, filterShape, outChannels, strides, zeroPad, roundingMode) {
      if (zeroPad == null) {
        zeroPad = computeDefaultPad(inShape, filterShape[0], strides[0]);
      }
      var outShape = [0, 0, 0, outChannels];
      for (var index = 0; index < 3; index++) {
        if (inShape[index] + 2 * zeroPad >= filterShape[index]) {
          outShape[index] = round$1((inShape[index] - filterShape[index] + 2 * zeroPad) / strides[index] + 1, roundingMode);
        }
      }
      return outShape;
    }
    function computeDefaultPad(inputShape, fieldSize, stride, dilation) {
      if (dilation === void 0) {
        dilation = 1;
      }
      var effectiveFieldSize = getEffectiveFilterSize(fieldSize, dilation);
      return Math.floor((inputShape[0] * (stride - 1) - stride + effectiveFieldSize) / 2);
    }
    function parseTupleParam(param) {
      if (typeof param === "number") {
        return [param, param, param];
      }
      if (param.length === 2) {
        return [param[0], param[1], 1];
      }
      return param;
    }
    function parse3TupleParam(param) {
      return typeof param === "number" ? [param, param, param] : param;
    }
    function getEffectiveFilterSize(filterSize, dilation) {
      if (dilation <= 1) {
        return filterSize;
      }
      return filterSize + (filterSize - 1) * (dilation - 1);
    }
    function getPadAndOutInfo(pad2, inHeight, inWidth, strideHeight, strideWidth, filterHeight, filterWidth, roundingMode, dataFormat) {
      var padInfo;
      var outHeight;
      var outWidth;
      if (typeof pad2 === "number") {
        var padType = pad2 === 0 ? "VALID" : "NUMBER";
        padInfo = { top: pad2, bottom: pad2, left: pad2, right: pad2, type: padType };
        var outShape = computeOutputShape2D([inHeight, inWidth], filterHeight, strideHeight, pad2, roundingMode);
        outHeight = outShape[0];
        outWidth = outShape[1];
      } else if (pad2 === "same") {
        outHeight = Math.ceil(inHeight / strideHeight);
        outWidth = Math.ceil(inWidth / strideWidth);
        var padAlongHeight = Math.max(0, (outHeight - 1) * strideHeight + filterHeight - inHeight);
        var padAlongWidth = Math.max(0, (outWidth - 1) * strideWidth + filterWidth - inWidth);
        var top = Math.floor(padAlongHeight / 2);
        var bottom = padAlongHeight - top;
        var left = Math.floor(padAlongWidth / 2);
        var right = padAlongWidth - left;
        padInfo = { top, bottom, left, right, type: "SAME" };
      } else if (pad2 === "valid") {
        padInfo = { top: 0, bottom: 0, left: 0, right: 0, type: "VALID" };
        outHeight = Math.ceil((inHeight - filterHeight + 1) / strideHeight);
        outWidth = Math.ceil((inWidth - filterWidth + 1) / strideWidth);
      } else if (typeof pad2 === "object") {
        var top = dataFormat === "channelsLast" ? pad2[1][0] : pad2[2][0];
        var bottom = dataFormat === "channelsLast" ? pad2[1][1] : pad2[2][1];
        var left = dataFormat === "channelsLast" ? pad2[2][0] : pad2[3][0];
        var right = dataFormat === "channelsLast" ? pad2[2][1] : pad2[3][1];
        var padType = top === 0 && bottom === 0 && left === 0 && right === 0 ? "VALID" : "EXPLICIT";
        padInfo = { top, bottom, left, right, type: padType };
        outHeight = round$1((inHeight - filterHeight + top + bottom) / strideHeight + 1, roundingMode);
        outWidth = round$1((inWidth - filterWidth + left + right) / strideWidth + 1, roundingMode);
      } else {
        throw Error("Unknown padding parameter: ".concat(pad2));
      }
      return { padInfo, outHeight, outWidth };
    }
    function get3DPadAndOutInfo(pad2, inDepth, inHeight, inWidth, strideDepth, strideHeight, strideWidth, filterDepth, filterHeight, filterWidth, roundingMode) {
      var padInfo;
      var outDepth;
      var outHeight;
      var outWidth;
      if (pad2 === "valid") {
        pad2 = 0;
      }
      if (typeof pad2 === "number") {
        var padType = pad2 === 0 ? "VALID" : "NUMBER";
        padInfo = {
          top: pad2,
          bottom: pad2,
          left: pad2,
          right: pad2,
          front: pad2,
          back: pad2,
          type: padType
        };
        var outShape = computeOutputShape4D([inDepth, inHeight, inWidth, 1], [filterDepth, filterHeight, filterWidth], 1, [strideDepth, strideHeight, strideWidth], pad2, roundingMode);
        outDepth = outShape[0];
        outHeight = outShape[1];
        outWidth = outShape[2];
      } else if (pad2 === "same") {
        outDepth = Math.ceil(inDepth / strideDepth);
        outHeight = Math.ceil(inHeight / strideHeight);
        outWidth = Math.ceil(inWidth / strideWidth);
        var padAlongDepth = (outDepth - 1) * strideDepth + filterDepth - inDepth;
        var padAlongHeight = (outHeight - 1) * strideHeight + filterHeight - inHeight;
        var padAlongWidth = (outWidth - 1) * strideWidth + filterWidth - inWidth;
        var front = Math.floor(padAlongDepth / 2);
        var back = padAlongDepth - front;
        var top = Math.floor(padAlongHeight / 2);
        var bottom = padAlongHeight - top;
        var left = Math.floor(padAlongWidth / 2);
        var right = padAlongWidth - left;
        padInfo = { top, bottom, left, right, front, back, type: "SAME" };
      } else {
        throw Error("Unknown padding parameter: ".concat(pad2));
      }
      return { padInfo, outDepth, outHeight, outWidth };
    }
    function round$1(value, roundingMode) {
      if (!roundingMode) {
        return Math.trunc(value);
      }
      switch (roundingMode) {
        case "round":
          return Math.round(value);
        case "ceil":
          return Math.ceil(value);
        case "floor":
          return Math.floor(value);
        default:
          throw new Error("Unknown roundingMode ".concat(roundingMode));
      }
    }
    function tupleValuesAreOne(param) {
      var _a = __read(parseTupleParam(param), 3), dimA = _a[0], dimB = _a[1], dimC = _a[2];
      return dimA === 1 && dimB === 1 && dimC === 1;
    }
    function eitherStridesOrDilationsAreOne(strides, dilations) {
      return tupleValuesAreOne(strides) || tupleValuesAreOne(dilations);
    }
    function stridesOrDilationsArePositive(values) {
      return parseTupleParam(values).every(function(value) {
        return value > 0;
      });
    }
    function convertConv2DDataFormat(dataFormat) {
      if (dataFormat === "NHWC") {
        return "channelsLast";
      } else if (dataFormat === "NCHW") {
        return "channelsFirst";
      } else {
        throw new Error("Unknown dataFormat ".concat(dataFormat));
      }
    }
    function checkPadOnDimRoundingMode(opDesc, pad2, dimRoundingMode) {
      if (dimRoundingMode != null) {
        if (typeof pad2 === "string") {
          throw Error("Error in ".concat(opDesc, ": pad must be an integer when using ") + "dimRoundingMode ".concat(dimRoundingMode, " but got pad ").concat(pad2, "."));
        } else if (typeof pad2 === "number") {
          assert(isInt(pad2), function() {
            return "Error in ".concat(opDesc, ": pad must be an integer when using ") + "dimRoundingMode ".concat(dimRoundingMode, " but got pad ").concat(pad2, ".");
          });
        } else if (typeof pad2 === "object") {
          pad2.forEach(function(p) {
            p.forEach(function(v) {
              assert(isInt(v), function() {
                return "Error in ".concat(opDesc, ": pad must be an integer when using ") + "dimRoundingMode ".concat(dimRoundingMode, " but got pad ").concat(v, ".");
              });
            });
          });
        } else {
          throw Error("Error in ".concat(opDesc, ": Unknown padding parameter: ").concat(pad2));
        }
      }
    }
    function reshape_(x, shape) {
      var $x = convertToTensor(x, "x", "reshape", "string_or_numeric");
      var inputs = { x: $x };
      var attrs = { shape };
      return ENGINE.runKernel(Reshape, inputs, attrs);
    }
    var reshape = /* @__PURE__ */ op({ reshape_ });
    function avgPool_(x, filterSize, strides, pad2, dimRoundingMode) {
      var $x = convertToTensor(x, "x", "avgPool", "float32");
      var dilations = 1;
      assert(eitherStridesOrDilationsAreOne(strides, dilations), function() {
        return "Error in avgPool: Either strides or dilations must be 1. " + "Got strides ".concat(strides, " and dilations '").concat(dilations, "'");
      });
      var x4D = $x;
      var reshapedTo4D = false;
      if ($x.rank === 3) {
        reshapedTo4D = true;
        x4D = reshape($x, [1, $x.shape[0], $x.shape[1], $x.shape[2]]);
      }
      assert(x4D.rank === 4, function() {
        return "Error in avgPool: x must be rank 4 but got rank ".concat(x4D.rank, ".");
      });
      checkPadOnDimRoundingMode("avgPool", pad2, dimRoundingMode);
      var inputs = { x: x4D };
      var attrs = { filterSize, strides, pad: pad2, dimRoundingMode };
      var res = ENGINE.runKernel(AvgPool, inputs, attrs);
      res = cast(res, $x.dtype);
      if (reshapedTo4D) {
        return reshape(res, [res.shape[1], res.shape[2], res.shape[3]]);
      }
      return res;
    }
    var avgPool = /* @__PURE__ */ op({ avgPool_ });
    function avgPool3d_(x, filterSize, strides, pad2, dimRoundingMode, dataFormat) {
      if (dataFormat === void 0) {
        dataFormat = "NDHWC";
      }
      var $x = convertToTensor(x, "x", "avgPool3d", "float32");
      var x5D = $x;
      var reshapedTo5D = false;
      if ($x.rank === 4) {
        reshapedTo5D = true;
        x5D = reshape($x, [1, $x.shape[0], $x.shape[1], $x.shape[2], $x.shape[3]]);
      }
      assert(x5D.rank === 5, function() {
        return "Error in avgPool3d: x must be rank 5 but got rank ".concat(x5D.rank, ".");
      });
      assert(dataFormat === "NDHWC", function() {
        return "Error in avgPool3d: Only NDHWC is currently supported, " + "but got dataFormat of ".concat(dataFormat);
      });
      assert(typeof strides === "number" && strides > 0 || Array.isArray(strides) && strides[0] > 0 && strides[1] > 0 && strides[2] > 0, function() {
        return "Error in avgPool3d: Stride must be > 0, but got '".concat(strides, "'");
      });
      checkPadOnDimRoundingMode("avgPool3d", pad2, dimRoundingMode);
      var inputs = { x: x5D };
      var attrs = { filterSize, strides, pad: pad2, dimRoundingMode, dataFormat };
      var res = ENGINE.runKernel(AvgPool3D, inputs, attrs);
      res = cast(res, x5D.dtype);
      if (reshapedTo5D) {
        return reshape(res, [res.shape[1], res.shape[2], res.shape[3], res.shape[4]]);
      }
      return res;
    }
    var avgPool3d = /* @__PURE__ */ op({ avgPool3d_ });
    function concat_(tensors, axis) {
      if (axis === void 0) {
        axis = 0;
      }
      assert(tensors.length >= 1, function() {
        return "Pass at least one tensor to concat";
      });
      var $tensors = convertToTensorArray(tensors, "tensors", "concat", "string_or_numeric");
      if ($tensors[0].dtype === "complex64") {
        $tensors.forEach(function(tensor2) {
          if (tensor2.dtype !== "complex64") {
            throw new Error("Cannot concatenate complex64 tensors with a tensor\n          with dtype ".concat(tensor2.dtype, ". "));
          }
        });
      }
      if ($tensors.length === 1) {
        return clone($tensors[0]);
      }
      var inputs = $tensors;
      var attr = { axis };
      return ENGINE.runKernel(Concat, inputs, attr);
    }
    var concat = /* @__PURE__ */ op({ concat_ });
    function matMul_(a, b, transposeA, transposeB) {
      var _a;
      if (transposeA === void 0) {
        transposeA = false;
      }
      if (transposeB === void 0) {
        transposeB = false;
      }
      var $a = convertToTensor(a, "a", "matMul");
      var $b = convertToTensor(b, "b", "matMul");
      _a = __read(makeTypesMatch($a, $b), 2), $a = _a[0], $b = _a[1];
      var inputs = { a: $a, b: $b };
      var attrs = { transposeA, transposeB };
      return ENGINE.runKernel(BatchMatMul, inputs, attrs);
    }
    var matMul$1 = /* @__PURE__ */ op({ matMul_ });
    function sigmoid_(x) {
      var $x = convertToTensor(x, "x", "sigmoid", "float32");
      var inputs = { x: $x };
      return ENGINE.runKernel(Sigmoid, inputs);
    }
    var sigmoid = /* @__PURE__ */ op({ sigmoid_ });
    function slice_(x, begin, size) {
      var $x = convertToTensor(x, "x", "slice", "string_or_numeric");
      if ($x.rank === 0) {
        throw new Error("Slicing scalar is not possible");
      }
      var inputs = { x: $x };
      var attrs = { begin, size };
      return ENGINE.runKernel(Slice, inputs, attrs);
    }
    var slice = /* @__PURE__ */ op({ slice_ });
    function tanh_(x) {
      var $x = convertToTensor(x, "x", "tanh", "float32");
      var inputs = { x: $x };
      return ENGINE.runKernel(Tanh, inputs);
    }
    var tanh = /* @__PURE__ */ op({ tanh_ });
    function basicLSTMCell_(forgetBias, lstmKernel, lstmBias, data, c, h) {
      var $forgetBias = convertToTensor(forgetBias, "forgetBias", "basicLSTMCell");
      var $lstmKernel = convertToTensor(lstmKernel, "lstmKernel", "basicLSTMCell");
      var $lstmBias = convertToTensor(lstmBias, "lstmBias", "basicLSTMCell");
      var $data = convertToTensor(data, "data", "basicLSTMCell");
      var $c = convertToTensor(c, "c", "basicLSTMCell");
      var $h = convertToTensor(h, "h", "basicLSTMCell");
      var combined = concat([$data, $h], 1);
      var weighted = matMul$1(combined, $lstmKernel);
      var res = add(weighted, $lstmBias);
      var batchSize = res.shape[0];
      var sliceCols = res.shape[1] / 4;
      var sliceSize = [batchSize, sliceCols];
      var i = slice(res, [0, 0], sliceSize);
      var j = slice(res, [0, sliceCols], sliceSize);
      var f = slice(res, [0, sliceCols * 2], sliceSize);
      var o = slice(res, [0, sliceCols * 3], sliceSize);
      var newC = add(mul(sigmoid(i), tanh(j)), mul($c, sigmoid(add($forgetBias, f))));
      var newH = mul(tanh(newC), sigmoid(o));
      return [newC, newH];
    }
    var basicLSTMCell = /* @__PURE__ */ op({ basicLSTMCell_ });
    function batchToSpaceND_(x, blockShape, crops) {
      var $x = convertToTensor(x, "x", "batchToSpaceND");
      var prod2 = blockShape.reduce(function(a, b) {
        return a * b;
      });
      assert($x.rank >= 1 + blockShape.length, function() {
        return "input rank is ".concat($x.rank, " but should be > than blockShape.length ").concat(blockShape.length);
      });
      assert(crops.length === blockShape.length, function() {
        return "crops.length is ".concat(crops.length, " but should be equal to blockShape.length  ").concat(blockShape.length);
      });
      assert($x.shape[0] % prod2 === 0, function() {
        return "input tensor batch is ".concat($x.shape[0], " but is not divisible by the product of ") + "the elements of blockShape ".concat(blockShape.join(" * "), " === ").concat(prod2);
      });
      var inputs = { x: $x };
      var attrs = { blockShape, crops };
      return ENGINE.runKernel(BatchToSpaceND, inputs, attrs);
    }
    var batchToSpaceND = /* @__PURE__ */ op({ batchToSpaceND_ });
    function xAs4D(x) {
      var x4D;
      if (x.rank === 0 || x.rank === 1) {
        x4D = reshape(x, [1, 1, 1, x.size]);
      } else if (x.rank === 2) {
        x4D = reshape(x, [1, 1, x.shape[0], x.shape[1]]);
      } else if (x.rank === 3) {
        x4D = reshape(x, [1, x.shape[0], x.shape[1], x.shape[2]]);
      } else {
        x4D = x;
      }
      return x4D;
    }
    function batchNorm_(x, mean2, variance, offset, scale, varianceEpsilon) {
      if (varianceEpsilon == null) {
        varianceEpsilon = 1e-3;
      }
      var $x = convertToTensor(x, "x", "batchNorm");
      var $mean = convertToTensor(mean2, "mean", "batchNorm");
      var $variance = convertToTensor(variance, "variance", "batchNorm");
      var $scale;
      if (scale != null) {
        $scale = convertToTensor(scale, "scale", "batchNorm");
      }
      var $offset;
      if (offset != null) {
        $offset = convertToTensor(offset, "offset", "batchNorm");
      }
      assert($mean.rank === $variance.rank, function() {
        return "Batch normalization gradient requires mean and variance to have equal ranks.";
      });
      assert($offset == null || $mean.rank === $offset.rank, function() {
        return "Batch normalization gradient requires mean and offset to have equal ranks.";
      });
      assert($scale == null || $mean.rank === $scale.rank, function() {
        return "Batch normalization gradient requires mean and scale to have equal ranks.";
      });
      var x4D = xAs4D($x);
      var inputs = {
        x: x4D,
        scale: $scale,
        offset: $offset,
        mean: $mean,
        variance: $variance
      };
      var attrs = { varianceEpsilon };
      var res = ENGINE.runKernel(FusedBatchNorm, inputs, attrs);
      return reshape(res, $x.shape);
    }
    var batchNorm = /* @__PURE__ */ op({ batchNorm_ });
    function batchNorm2d_(x, mean2, variance, offset, scale, varianceEpsilon) {
      var $x = convertToTensor(x, "x", "batchNorm");
      var $mean = convertToTensor(mean2, "mean", "batchNorm");
      var $variance = convertToTensor(variance, "variance", "batchNorm");
      var $scale;
      if (scale != null) {
        $scale = convertToTensor(scale, "scale", "batchNorm");
      }
      var $offset;
      if (offset != null) {
        $offset = convertToTensor(offset, "offset", "batchNorm");
      }
      assert($x.rank === 2, function() {
        return "Error in batchNorm2D: x must be rank 2 but got rank " + "".concat($x.rank, ".");
      });
      assert($mean.rank === 2 || $mean.rank === 1, function() {
        return "Error in batchNorm2D: mean must be rank 2 or rank 1 but " + "got rank ".concat($mean.rank, ".");
      });
      assert($variance.rank === 2 || $variance.rank === 1, function() {
        return "Error in batchNorm2D: variance must be rank 2 or rank 1 " + "but got rank ".concat($variance.rank, ".");
      });
      if ($scale != null) {
        assert($scale.rank === 2 || $scale.rank === 1, function() {
          return "Error in batchNorm2D: scale must be rank 2 or rank 1 " + "but got rank ".concat($scale.rank, ".");
        });
      }
      if ($offset != null) {
        assert($offset.rank === 2 || $offset.rank === 1, function() {
          return "Error in batchNorm2D: offset must be rank 2 or rank 1 " + "but got rank ".concat($offset.rank, ".");
        });
      }
      return batchNorm($x, $mean, $variance, $offset, $scale, varianceEpsilon);
    }
    var batchNorm2d = /* @__PURE__ */ op({ batchNorm2d_ });
    function batchNorm3d_(x, mean2, variance, offset, scale, varianceEpsilon) {
      var $x = convertToTensor(x, "x", "batchNorm");
      var $mean = convertToTensor(mean2, "mean", "batchNorm");
      var $variance = convertToTensor(variance, "variance", "batchNorm");
      var $scale;
      if (scale != null) {
        $scale = convertToTensor(scale, "scale", "batchNorm");
      }
      var $offset;
      if (offset != null) {
        $offset = convertToTensor(offset, "offset", "batchNorm");
      }
      assert($x.rank === 3, function() {
        return "Error in batchNorm3D: x must be rank 3 but got rank " + "".concat($x.rank, ".");
      });
      assert($mean.rank === 3 || $mean.rank === 1, function() {
        return "Error in batchNorm3D: mean must be rank 3 or rank 1 but " + "got rank ".concat($mean.rank, ".");
      });
      assert($variance.rank === 3 || $variance.rank === 1, function() {
        return "Error in batchNorm3D: variance must be rank 3 or rank 1 " + "but got rank ".concat($variance.rank, ".");
      });
      if ($scale != null) {
        assert($scale.rank === 3 || $scale.rank === 1, function() {
          return "Error in batchNorm3D: scale must be rank 3 or rank 1 " + "but got rank ".concat($scale.rank, ".");
        });
      }
      if ($offset != null) {
        assert($offset.rank === 3 || $offset.rank === 1, function() {
          return "Error in batchNorm3D: offset must be rank 3 or rank 1 " + "but got rank ".concat($offset.rank, ".");
        });
      }
      return batchNorm($x, $mean, $variance, $offset, $scale, varianceEpsilon);
    }
    var batchNorm3d = /* @__PURE__ */ op({ batchNorm3d_ });
    function batchNorm4d_(x, mean2, variance, offset, scale, varianceEpsilon) {
      var $x = convertToTensor(x, "x", "batchNorm");
      var $mean = convertToTensor(mean2, "mean", "batchNorm");
      var $variance = convertToTensor(variance, "variance", "batchNorm");
      var $scale;
      if (scale != null) {
        $scale = convertToTensor(scale, "scale", "batchNorm");
      }
      var $offset;
      if (offset != null) {
        $offset = convertToTensor(offset, "offset", "batchNorm");
      }
      assert($x.rank === 4, function() {
        return "Error in batchNorm4D: x must be rank 4 but got rank " + "".concat($x.rank, ".");
      });
      assert($mean.rank === 4 || $mean.rank === 1, function() {
        return "Error in batchNorm4D: mean must be rank 4 or rank 1 but " + "got rank ".concat($mean.rank, ".");
      });
      assert($variance.rank === 4 || $variance.rank === 1, function() {
        return "Error in batchNorm4D: variance must be rank 4 or rank 1 " + "but got rank ".concat($variance.rank, ".");
      });
      if ($scale != null) {
        assert($scale.rank === 4 || $scale.rank === 1, function() {
          return "Error in batchNorm4D: scale must be rank 4 or rank 1 " + "but got rank ".concat($scale.rank, ".");
        });
      }
      if ($offset != null) {
        assert($offset.rank === 4 || $offset.rank === 1, function() {
          return "Error in batchNorm4D: offset must be rank 4 or rank 1 " + "but got rank ".concat($offset.rank, ".");
        });
      }
      return batchNorm($x, $mean, $variance, $offset, $scale, varianceEpsilon);
    }
    var batchNorm4d = /* @__PURE__ */ op({ batchNorm4d_ });
    function bincount_(x, weights, size) {
      var $x = convertToTensor(x, "x", "bincount");
      var $weights = convertToTensor(weights, "weights", "bincount");
      assert($x.dtype === "int32", function() {
        return "Error in bincount: input " + "dtype must be int32, but got ".concat($x.dtype);
      });
      assert(size >= 0, function() {
        return "size must be non-negative, but got ".concat(size, ".");
      });
      assert($weights.size === $x.size || $weights.size === 0, function() {
        return "Error in bincount: weights must have the same size as input or" + "0-length, but got input shape: ".concat($x.shape, ", weights shape: ") + "".concat($weights.shape, ".");
      });
      var inputs = { x: $x, weights: $weights };
      var attrs = { size };
      return ENGINE.runKernel(Bincount, inputs, attrs);
    }
    var bincount = /* @__PURE__ */ op({ bincount_ });
    function bitwiseAnd_(x, y) {
      var $x = convertToTensor(x, "x", "bitwiseAnd");
      var $y = convertToTensor(y, "y", "bitwiseAnd");
      if (!arraysEqual($x.shape, $y.shape)) {
        throw new Error("BitwiseAnd: Tensors must have the same shape. x: ".concat($x.shape, ", y: ").concat($y.shape));
      }
      if ($x.dtype !== "int32" || $y.dtype !== "int32") {
        throw new Error("BitwiseAnd: Only supports 'int32' values in tensor, found type of x: ".concat($x.dtype, " and type of y: ").concat($y.dtype));
      }
      var inputs = { a: $x, b: $y };
      return ENGINE.runKernel(BitwiseAnd, inputs);
    }
    var bitwiseAnd = /* @__PURE__ */ op({ bitwiseAnd_ });
    function broadcastArgs_(s0, s1) {
      var shape1Input = convertToTensor(s0, "s0", "broadcastArgs", "int32");
      var shape2Input = convertToTensor(s1, "s1", "broadcastArgs", "int32");
      if (shape1Input.rank !== 1) {
        throw new Error("broadcastArgs(): first input must be a vector (rank=1). " + "Has rank ".concat(shape1Input.rank));
      }
      if (shape2Input.rank !== 1) {
        throw new Error("broadcastArgs(): second input must be a vector (rank=1). " + "Has rank ".concat(shape2Input.rank));
      }
      var inputs = { s0: shape1Input, s1: shape2Input };
      return ENGINE.runKernel(BroadcastArgs, inputs);
    }
    var broadcastArgs = /* @__PURE__ */ op({ broadcastArgs_ });
    function broadcastTo_(x, shape) {
      var input = convertToTensor(x, "broadcastTo", "x");
      var xShape = input.shape;
      assertNonNegativeIntegerDimensions(shape);
      if (shape.length < input.rank) {
        throw new Error("broadcastTo(): shape.length=".concat(shape.length, " < input.rank=").concat(input.rank, "."));
      }
      if (shape.length > input.rank) {
        var newShape = input.shape.slice();
        while (newShape.length < shape.length) {
          newShape.unshift(1);
        }
        input = reshape(input, newShape);
      }
      var inputShape = input.shape;
      var reps = Array.from(shape);
      for (var i = shape.length - 1; i >= 0; i--) {
        if (inputShape[i] === shape[i]) {
          reps[i] = 1;
        } else if (input.shape[i] !== 1) {
          throw new Error("broadcastTo(): [".concat(xShape, "] cannot be broadcast to [").concat(shape, "]."));
        }
      }
      var axes = reps.map(function(n, i2) {
        return n > 1 ? i2 : -1;
      }).filter(function(i2) {
        return i2 >= 0;
      });
      if (axes.length === 0) {
        return clone(input);
      }
      var inputs = { x: input };
      var attrs = { reps };
      return ENGINE.runKernel(Tile, inputs, attrs);
    }
    var broadcastTo = /* @__PURE__ */ op({ broadcastTo_ });
    function ceil_(x) {
      var $x = convertToTensor(x, "x", "ceil", "float32");
      var inputs = { x: $x };
      return ENGINE.runKernel(Ceil, inputs);
    }
    var ceil = /* @__PURE__ */ op({ ceil_ });
    function fill(shape, value, dtype) {
      assertNonNegativeIntegerDimensions(shape);
      dtype = dtype || inferDtype(value);
      var attrs = { shape, value, dtype };
      return ENGINE.runKernel(Fill, {}, attrs);
    }
    function clipByValue_(x, clipValueMin, clipValueMax) {
      var $x = convertToTensor(x, "x", "clipByValue");
      assert(clipValueMin <= clipValueMax, function() {
        return "Error in clip: min (".concat(clipValueMin, ") must be ") + "less than or equal to max (".concat(clipValueMax, ").");
      });
      if (clipValueMin === clipValueMax) {
        return fill($x.shape, clipValueMin, $x.dtype);
      }
      var inputs = { x: $x };
      var attrs = { clipValueMin, clipValueMax };
      return ENGINE.runKernel(ClipByValue, inputs, attrs);
    }
    var clipByValue = /* @__PURE__ */ op({ clipByValue_ });
    function concat1d_(tensors) {
      return concat(
        tensors,
        0
        /* axis */
      );
    }
    var concat1d = /* @__PURE__ */ op({ concat1d_ });
    function concat2d_(tensors, axis) {
      return concat(tensors, axis);
    }
    var concat2d = /* @__PURE__ */ op({ concat2d_ });
    function concat3d_(tensors, axis) {
      return concat(tensors, axis);
    }
    var concat3d = /* @__PURE__ */ op({ concat3d_ });
    function concat4d_(tensors, axis) {
      return concat(tensors, axis);
    }
    var concat4d = /* @__PURE__ */ op({ concat4d_ });
    function conv2d_(x, filter, strides, pad2, dataFormat, dilations, dimRoundingMode) {
      if (dataFormat === void 0) {
        dataFormat = "NHWC";
      }
      if (dilations === void 0) {
        dilations = [1, 1];
      }
      var $x = convertToTensor(x, "x", "conv2d", "float32");
      var $filter = convertToTensor(filter, "filter", "conv2d", "float32");
      var x4D = $x;
      var reshapedTo4D = false;
      if ($x.rank === 3) {
        reshapedTo4D = true;
        x4D = reshape($x, [1, $x.shape[0], $x.shape[1], $x.shape[2]]);
      }
      assert(x4D.rank === 4, function() {
        return "Error in conv2d: input must be rank 4, but got rank ".concat(x4D.rank, ".");
      });
      assert($filter.rank === 4, function() {
        return "Error in conv2d: filter must be rank 4, but got rank " + "".concat($filter.rank, ".");
      });
      checkPadOnDimRoundingMode("conv2d", pad2, dimRoundingMode);
      var inDepth = dataFormat === "NHWC" ? x4D.shape[3] : x4D.shape[1];
      assert(inDepth === $filter.shape[2], function() {
        return "Error in conv2d: depth of input (".concat(inDepth, ") must match ") + "input depth for filter ".concat($filter.shape[2], ".");
      });
      assert(eitherStridesOrDilationsAreOne(strides, dilations), function() {
        return "Error in conv2D: Either strides or dilations must be 1. " + "Got strides ".concat(strides, " and dilations '").concat(dilations, "'");
      });
      assert(stridesOrDilationsArePositive(dilations), function() {
        return "Error in conv2D: Dilated rates should be larger than 0.";
      });
      assert(stridesOrDilationsArePositive(strides), function() {
        return "Error in conv2D: Strides should be larger than 0.";
      });
      var inputs = { x: x4D, filter: $filter };
      var attrs = { strides, pad: pad2, dataFormat, dilations, dimRoundingMode };
      var res = ENGINE.runKernel(Conv2D, inputs, attrs);
      if (reshapedTo4D) {
        return reshape(res, [res.shape[1], res.shape[2], res.shape[3]]);
      }
      return res;
    }
    var conv2d$1 = /* @__PURE__ */ op({ conv2d_ });
    function conv1d_(x, filter, stride, pad2, dataFormat, dilation, dimRoundingMode) {
      if (dataFormat === void 0) {
        dataFormat = "NWC";
      }
      if (dilation === void 0) {
        dilation = 1;
      }
      var $x = convertToTensor(x, "x", "conv1d");
      var $filter = convertToTensor(filter, "filter", "conv1d");
      var x3D = $x;
      var reshapedTo3D = false;
      if ($x.rank === 2) {
        reshapedTo3D = true;
        x3D = reshape($x, [1, $x.shape[0], $x.shape[1]]);
      }
      assert(x3D.rank === 3, function() {
        return "Error in conv1d: input must be rank 3, but got rank ".concat(x3D.rank, ".");
      });
      assert($filter.rank === 3, function() {
        return "Error in conv1d: filter must be rank 3, but got rank " + "".concat($filter.rank, ".");
      });
      checkPadOnDimRoundingMode("conv1d", pad2, dimRoundingMode);
      assert(x3D.shape[2] === $filter.shape[1], function() {
        return "Error in conv1d: depth of input (".concat(x3D.shape[2], ") must match ") + "input depth for filter ".concat($filter.shape[1], ".");
      });
      assert(eitherStridesOrDilationsAreOne(stride, dilation), function() {
        return "Error in conv1D: Either stride or dilation must be 1. " + "Got stride ".concat(stride, " and dilation '").concat(dilation, "'");
      });
      assert(stridesOrDilationsArePositive(dilation), function() {
        return "Error in conv1D: Dilated rates should be larger than 0.";
      });
      assert(stridesOrDilationsArePositive(stride), function() {
        return "Error in conv1D: Stride should be larger than 0.";
      });
      assert(dataFormat === "NWC", function() {
        return "Error in conv1d: got dataFormat of ".concat(dataFormat, " but only NWC is currently supported.");
      });
      var filter4D = reshape($filter, [1, $filter.shape[0], $filter.shape[1], $filter.shape[2]]);
      var input4D = reshape(x3D, [x3D.shape[0], 1, x3D.shape[1], x3D.shape[2]]);
      var strides = [1, stride];
      var dilations = [1, dilation];
      var conv2dDataFormat = "NHWC";
      var res = conv2d$1(input4D, filter4D, strides, pad2, conv2dDataFormat, dilations, dimRoundingMode);
      if (reshapedTo3D) {
        return reshape(res, [res.shape[2], res.shape[3]]);
      }
      return reshape(res, [res.shape[0], res.shape[2], res.shape[3]]);
    }
    var conv1d = /* @__PURE__ */ op({ conv1d_ });
    function conv2DBackpropInput_(xShape, dy, filter, strides, pad2, dataFormat, dimRoundingMode) {
      if (dataFormat === void 0) {
        dataFormat = "NHWC";
      }
      assert(xShape.length === dy.rank, function() {
        return "Length of inShape " + "(".concat(xShape.length, ") and rank of dy (").concat(dy.rank, ") must match");
      });
      var xShape4D = xShape;
      var dy4D = dy;
      var reshapedTo4D = false;
      if (dy.rank === 3) {
        reshapedTo4D = true;
        dy4D = reshape(dy, [1, dy.shape[0], dy.shape[1], dy.shape[2]]);
        xShape4D = [1, xShape[0], xShape[1], xShape[2]];
      }
      assert(xShape4D.length === 4, function() {
        return "Error in conv2dDerInput: inShape must be length 4, but got length " + "".concat(xShape4D.length, ".");
      });
      assert(dy4D.rank === 4, function() {
        return "Error in conv2dDerInput: dy must be rank 4, but got " + "rank ".concat(dy4D.rank);
      });
      assert(filter.rank === 4, function() {
        return "Error in conv2dDerInput: filter must be rank 4, but got " + "rank ".concat(filter.rank);
      });
      var inDepth = dataFormat === "NHWC" ? xShape4D[3] : xShape4D[1];
      var outDepth = dataFormat === "NHWC" ? dy4D.shape[3] : dy4D.shape[1];
      assert(inDepth === filter.shape[2], function() {
        return "Error in conv2dDerInput: depth of input (".concat(inDepth, ") must ") + "match input depth for filter ".concat(filter.shape[2], ".");
      });
      assert(outDepth === filter.shape[3], function() {
        return "Error in conv2dDerInput: depth of output (".concat(outDepth, ") must ") + "match output depth for filter ".concat(filter.shape[3], ".");
      });
      checkPadOnDimRoundingMode("conv2dDerInput", pad2, dimRoundingMode);
      var inputs = { dy: dy4D, filter };
      var attrs = { strides, pad: pad2, dataFormat, dimRoundingMode, inputShape: xShape4D };
      var res = ENGINE.runKernel(Conv2DBackpropInput, inputs, attrs);
      if (reshapedTo4D) {
        return reshape(res, [res.shape[1], res.shape[2], res.shape[3]]);
      }
      return res;
    }
    var conv2DBackpropInput = /* @__PURE__ */ op({ conv2DBackpropInput_ });
    function conv2dTranspose_(x, filter, outputShape, strides, pad2, dimRoundingMode) {
      var $x = convertToTensor(x, "x", "conv2dTranspose");
      var $filter = convertToTensor(filter, "filter", "conv2dTranspose");
      return conv2DBackpropInput(outputShape, $x, $filter, strides, pad2, "NHWC", dimRoundingMode);
    }
    var conv2dTranspose = /* @__PURE__ */ op({ conv2dTranspose_ });
    function conv3d_(x, filter, strides, pad2, dataFormat, dilations) {
      if (dataFormat === void 0) {
        dataFormat = "NDHWC";
      }
      if (dilations === void 0) {
        dilations = [1, 1, 1];
      }
      var $x = convertToTensor(x, "x", "conv3d");
      var $filter = convertToTensor(filter, "filter", "conv3d");
      var x5D = $x;
      var reshapedTo5D = false;
      if ($x.rank === 4) {
        reshapedTo5D = true;
        x5D = reshape($x, [1, $x.shape[0], $x.shape[1], $x.shape[2], $x.shape[3]]);
      }
      assert(x5D.rank === 5, function() {
        return "Error in conv3d: input must be rank 5, but got rank ".concat(x5D.rank, ".");
      });
      assert($filter.rank === 5, function() {
        return "Error in conv3d: filter must be rank 5, but got rank " + "".concat($filter.rank, ".");
      });
      assert(x5D.shape[4] === $filter.shape[3], function() {
        return "Error in conv3d: depth of input (".concat(x5D.shape[4], ") must match ") + "input depth for filter ".concat($filter.shape[3], ".");
      });
      assert(eitherStridesOrDilationsAreOne(strides, dilations), function() {
        return "Error in conv3D: Either strides or dilations must be 1. " + "Got strides ".concat(strides, " and dilations '").concat(dilations, "'");
      });
      assert(dataFormat === "NDHWC", function() {
        return "Error in conv3d: got dataFormat of ".concat(dataFormat, " but only NDHWC is currently supported.");
      });
      assert(stridesOrDilationsArePositive(dilations), function() {
        return "Error in conv3D: Dilated rates should be larger than 0.";
      });
      assert(stridesOrDilationsArePositive(strides), function() {
        return "Error in conv3D: Strides should be larger than 0.";
      });
      var inputs = { x: x5D, filter: $filter };
      var attrs = { strides, pad: pad2, dataFormat, dilations };
      var res = ENGINE.runKernel(Conv3D, inputs, attrs);
      if (reshapedTo5D) {
        return reshape(res, [res.shape[1], res.shape[2], res.shape[3], res.shape[4]]);
      }
      return res;
    }
    var conv3d = /* @__PURE__ */ op({ conv3d_ });
    function conv3DBackpropInput_(xShape, dy, filter, strides, pad2) {
      assert(xShape.length === dy.rank, function() {
        return "Length of inShape " + "(".concat(xShape.length, ") and rank of dy (").concat(dy.rank, ") must match");
      });
      var xShape5D = xShape;
      var dy5D = dy;
      var reshapedTo5D = false;
      if (dy.rank === 4) {
        reshapedTo5D = true;
        dy5D = reshape(dy, [1, dy.shape[0], dy.shape[1], dy.shape[2], dy.shape[3]]);
        xShape5D = [1, xShape[0], xShape[1], xShape[2], xShape[3]];
      }
      var inDepth = xShape5D[4];
      var outDepth = dy5D.shape[4];
      assert(xShape5D.length === 5, function() {
        return "Error in conv3dDerInput: inShape must be length 5, but got length " + "".concat(xShape5D.length, ".");
      });
      assert(dy5D.rank === 5, function() {
        return "Error in conv3dDerInput: dy must be rank 5, but got " + "rank ".concat(dy5D.rank);
      });
      assert(filter.rank === 5, function() {
        return "Error in conv3dDerInput: filter must be rank 5, but got " + "rank ".concat(filter.rank);
      });
      assert(inDepth === filter.shape[3], function() {
        return "Error in conv3dDerInput: depth of input (".concat(inDepth, ") must ") + "match input depth for filter ".concat(filter.shape[3], ".");
      });
      assert(outDepth === filter.shape[4], function() {
        return "Error in conv3dDerInput: depth of output (".concat(outDepth, ") must ") + "match output depth for filter ".concat(filter.shape[4], ".");
      });
      var inputs = { dy: dy5D, filter };
      var attrs = { pad: pad2, strides, inputShape: xShape5D };
      var res = ENGINE.runKernel(Conv3DBackpropInputV2, inputs, attrs);
      if (reshapedTo5D) {
        return reshape(res, [res.shape[1], res.shape[2], res.shape[3], res.shape[4]]);
      }
      return res;
    }
    var conv3DBackpropInput = /* @__PURE__ */ op({ conv3DBackpropInput_ });
    function conv3dTranspose_(x, filter, outputShape, strides, pad2) {
      var $x = convertToTensor(x, "x", "conv3dTranspose");
      var $filter = convertToTensor(filter, "filter", "conv3dTranspose");
      return conv3DBackpropInput(outputShape, $x, $filter, strides, pad2);
    }
    var conv3dTranspose = /* @__PURE__ */ op({ conv3dTranspose_ });
    function cos_(x) {
      var $x = convertToTensor(x, "x", "cos", "float32");
      var inputs = { x: $x };
      return ENGINE.runKernel(Cos, inputs);
    }
    var cos = /* @__PURE__ */ op({ cos_ });
    function cosh_(x) {
      var $x = convertToTensor(x, "x", "cosh", "float32");
      var inputs = { x: $x };
      return ENGINE.runKernel(Cosh, inputs);
    }
    var cosh = /* @__PURE__ */ op({ cosh_ });
    function cumprod_(x, axis, exclusive, reverse2) {
      if (axis === void 0) {
        axis = 0;
      }
      if (exclusive === void 0) {
        exclusive = false;
      }
      if (reverse2 === void 0) {
        reverse2 = false;
      }
      var $x = convertToTensor(x, "x", "cumprod");
      var inputs = { x: $x };
      var attrs = { axis, exclusive, reverse: reverse2 };
      return ENGINE.runKernel(Cumprod, inputs, attrs);
    }
    var cumprod = /* @__PURE__ */ op({ cumprod_ });
    function cumsum_(x, axis, exclusive, reverse2) {
      if (axis === void 0) {
        axis = 0;
      }
      if (exclusive === void 0) {
        exclusive = false;
      }
      if (reverse2 === void 0) {
        reverse2 = false;
      }
      var $x = convertToTensor(x, "x", "cumsum");
      var inputs = { x: $x };
      var attrs = { axis, exclusive, reverse: reverse2 };
      return ENGINE.runKernel(Cumsum, inputs, attrs);
    }
    var cumsum = /* @__PURE__ */ op({ cumsum_ });
    function denseBincount_(x, weights, size, binaryOutput) {
      if (binaryOutput === void 0) {
        binaryOutput = false;
      }
      var $x = convertToTensor(x, "x", "denseBincount");
      var $weights = convertToTensor(weights, "weights", "denseBincount");
      assert($x.dtype === "int32", function() {
        return "Error in denseBincount: input " + "dtype must be int32, but got ".concat($x.dtype);
      });
      assert($x.rank <= 2, function() {
        return "Error in denseBincount: input must be at most rank 2, but got " + "rank ".concat($x.rank, ".");
      });
      assert(size >= 0, function() {
        return "size must be non-negative, but got ".concat(size, ".");
      });
      assert($weights.size === $x.size || $weights.size === 0, function() {
        return "Error in denseBincount: weights must have the same shape as x or " + "0-length, but got x shape: ".concat($x.shape, ", weights shape: ") + "".concat($weights.shape, ".");
      });
      var inputs = { x: $x, weights: $weights };
      var attrs = { size, binaryOutput };
      return ENGINE.runKernel(DenseBincount, inputs, attrs);
    }
    var denseBincount = /* @__PURE__ */ op({ denseBincount_ });
    function depthToSpace_(x, blockSize, dataFormat) {
      if (dataFormat === void 0) {
        dataFormat = "NHWC";
      }
      var $x = convertToTensor(x, "x", "depthToSpace", "float32");
      var inputHeight = dataFormat === "NHWC" ? $x.shape[1] : $x.shape[2];
      var inputWidth = dataFormat === "NHWC" ? $x.shape[2] : $x.shape[3];
      var inputDepth = dataFormat === "NHWC" ? $x.shape[3] : $x.shape[1];
      assert(blockSize > 1, function() {
        return "blockSize should be > 1 for depthToSpace, but was: ".concat(blockSize);
      });
      assert(inputHeight * blockSize >= 0, function() {
        return "Negative dimension size caused by overflow when multiplying\n    ".concat(inputHeight, " and ").concat(blockSize, "  for depthToSpace with input shape\n    ").concat($x.shape);
      });
      assert(inputWidth * blockSize >= 0, function() {
        return "Negative dimension size caused by overflow when multiplying\n    ".concat(inputWidth, " and ").concat(blockSize, " for depthToSpace with input shape\n        ").concat($x.shape);
      });
      assert(inputDepth % (blockSize * blockSize) === 0, function() {
        return "Dimension size must be evenly divisible by ".concat(blockSize * blockSize, " but is ").concat(inputDepth, " for depthToSpace with input shape ").concat($x.shape);
      });
      var inputs = { x: $x };
      var attrs = { blockSize, dataFormat };
      return ENGINE.runKernel(DepthToSpace, inputs, attrs);
    }
    var depthToSpace = /* @__PURE__ */ op({ depthToSpace_ });
    function depthwiseConv2d_(x, filter, strides, pad2, dataFormat, dilations, dimRoundingMode) {
      if (dataFormat === void 0) {
        dataFormat = "NHWC";
      }
      if (dilations === void 0) {
        dilations = [1, 1];
      }
      var $x = convertToTensor(x, "x", "depthwiseConv2d", "float32");
      var $filter = convertToTensor(filter, "filter", "depthwiseConv2d", "float32");
      var x4D = $x;
      var reshapedTo4D = false;
      if ($x.rank === 3) {
        reshapedTo4D = true;
        x4D = reshape($x, [1, $x.shape[0], $x.shape[1], $x.shape[2]]);
      }
      assert(x4D.rank === 4, function() {
        return "Error in depthwiseConv2d: input must be rank 4, but got " + "rank ".concat(x4D.rank, ".");
      });
      assert($filter.rank === 4, function() {
        return "Error in depthwiseConv2d: filter must be rank 4, but got rank " + "".concat($filter.rank, ".");
      });
      var inChannels = dataFormat === "NHWC" ? x4D.shape[3] : x4D.shape[1];
      assert(inChannels === $filter.shape[2], function() {
        return "Error in depthwiseConv2d: number of input channels " + "(".concat(inChannels, ") must match the inChannels dimension in ") + "filter ".concat($filter.shape[2], ".");
      });
      checkPadOnDimRoundingMode("depthwiseConv2d", pad2, dimRoundingMode);
      var inputs = { x: x4D, filter: $filter };
      var attrs = { strides, pad: pad2, dataFormat, dilations, dimRoundingMode };
      var res = ENGINE.runKernel(DepthwiseConv2dNative, inputs, attrs);
      if (reshapedTo4D) {
        return reshape(res, [res.shape[1], res.shape[2], res.shape[3]]);
      }
      return res;
    }
    var depthwiseConv2d$1 = /* @__PURE__ */ op({ depthwiseConv2d_ });
    function diag_(x) {
      var $x = convertToTensor(x, "x", "diag");
      var inputs = { x: $x };
      return ENGINE.runKernel(Diag, inputs);
    }
    var diag = /* @__PURE__ */ op({ diag_ });
    function dilation2d_(x, filter, strides, pad2, dilations, dataFormat) {
      if (dilations === void 0) {
        dilations = [1, 1];
      }
      if (dataFormat === void 0) {
        dataFormat = "NHWC";
      }
      var $x = convertToTensor(x, "x", "dilation2d");
      var $filter = convertToTensor(filter, "filter", "dilation2d");
      assert($x.rank === 3 || $x.rank === 4, function() {
        return "Error in dilation2d: input must be rank 3 or 4, but got rank " + "".concat($x.rank, ".");
      });
      assert($filter.rank === 3, function() {
        return "Error in dilation2d: filter must be rank 3, but got rank " + "".concat($filter.rank, ".");
      });
      assert(dataFormat === "NHWC", function() {
        return "Error in dilation2d: Only NHWC is currently supported, " + "but got dataFormat of ".concat(dataFormat);
      });
      var x4D = $x;
      var reshapedTo4D = false;
      if ($x.rank === 3) {
        x4D = reshape($x, [1, $x.shape[0], $x.shape[1], $x.shape[2]]);
        reshapedTo4D = true;
      }
      assert(x4D.shape[3] === $filter.shape[2], function() {
        return "Error in dilation2d:  input and filter must have the same depth: ".concat(x4D.shape[3], " vs ").concat($filter.shape[2]);
      });
      var inputs = { x: x4D, filter: $filter };
      var attrs = { strides, pad: pad2, dilations };
      var res = ENGINE.runKernel(Dilation2D, inputs, attrs);
      if (reshapedTo4D) {
        return reshape(res, [res.shape[1], res.shape[2], res.shape[3]]);
      }
      return res;
    }
    var dilation2d = /* @__PURE__ */ op({ dilation2d_ });
    function getBroadcastDims(inShape, outShape) {
      var inRank = inShape.length;
      var dims = [];
      for (var i = 0; i < inRank; i++) {
        var dim = inRank - 1 - i;
        var a = inShape[dim] || 1;
        var b = outShape[outShape.length - 1 - i] || 1;
        if (b > 1 && a === 1) {
          dims.unshift(dim);
        }
      }
      return dims;
    }
    function getReductionAxes(inShape, outShape) {
      var result = [];
      for (var i = 0; i < outShape.length; i++) {
        var inDim = inShape[inShape.length - i - 1];
        var outAxis = outShape.length - i - 1;
        var outDim = outShape[outAxis];
        if (inDim == null || inDim === 1 && outDim > 1) {
          result.unshift(outAxis);
        }
      }
      return result;
    }
    function assertAndGetBroadcastShape(shapeA, shapeB) {
      var l = Math.max(shapeA.length, shapeB.length);
      var result = new Array(l);
      for (var i = 0; i < l; i++) {
        var a = shapeA[shapeA.length - i - 1];
        if (a == null) {
          a = 1;
        }
        var b = shapeB[shapeB.length - i - 1];
        if (b == null) {
          b = 1;
        }
        if (a === 1) {
          result[l - i - 1] = b;
        } else if (b === 1) {
          result[l - i - 1] = a;
        } else if (a !== b) {
          var errMsg = "Operands could not be broadcast together with shapes " + "".concat(shapeA, " and ").concat(shapeB, ".");
          throw Error(errMsg);
        } else {
          result[l - i - 1] = a;
        }
      }
      return result;
    }
    var broadcast_util = {
      __proto__: null,
      assertAndGetBroadcastShape,
      getBroadcastDims,
      getReductionAxes
    };
    function equal_(a, b) {
      var _a;
      var $a = convertToTensor(a, "a", "equal", "string_or_numeric");
      var $b = convertToTensor(b, "b", "equal", "string_or_numeric");
      _a = __read(makeTypesMatch($a, $b), 2), $a = _a[0], $b = _a[1];
      assertAndGetBroadcastShape($a.shape, $b.shape);
      var inputs = { a: $a, b: $b };
      return ENGINE.runKernel(Equal, inputs);
    }
    var equal = /* @__PURE__ */ op({ equal_ });
    function where_(condition, a, b) {
      var $a = convertToTensor(a, "a", "where");
      var $b = convertToTensor(b, "b", "where");
      var $condition = convertToTensor(condition, "condition", "where", "bool");
      var broadcastShape = assertAndGetBroadcastShape(assertAndGetBroadcastShape($condition.shape, $a.shape), $b.shape);
      var $broadcastedCondition = broadcastTo($condition, broadcastShape);
      var $broadcastedA = broadcastTo($a, broadcastShape);
      var $broadcastedB = broadcastTo($b, broadcastShape);
      var inputs = {
        condition: $broadcastedCondition,
        t: $broadcastedA,
        e: $broadcastedB
      };
      return ENGINE.runKernel(Select, inputs);
    }
    var where = /* @__PURE__ */ op({ where_ });
    function zerosLike_(x) {
      var $x = convertToTensor(x, "x", "zerosLike");
      var inputs = { x: $x };
      return ENGINE.runKernel(ZerosLike, inputs);
    }
    var zerosLike = /* @__PURE__ */ op({ zerosLike_ });
    function divNoNan_(a, b) {
      var _a;
      var $a = convertToTensor(a, "a", "div");
      var $b = convertToTensor(b, "b", "div");
      _a = __read(makeTypesMatch($a, $b), 2), $a = _a[0], $b = _a[1];
      var divResult = div($a, $b);
      var zeros2 = zerosLike(divResult);
      var bEqualsZero = equal($b, zeros2);
      return where(bEqualsZero, zeros2, divResult);
    }
    var divNoNan = /* @__PURE__ */ op({ divNoNan_ });
    function dot_(t1, t2) {
      var $t1 = convertToTensor(t1, "t1", "dot");
      var $t2 = convertToTensor(t2, "t2", "dot");
      assert(($t1.rank === 1 || $t1.rank === 2) && ($t2.rank === 1 || $t2.rank === 2), function() {
        return "Error in dot: inputs must all be rank 1 or 2, but got ranks " + "".concat($t1.rank, " and ").concat($t2.rank, ".");
      });
      var t1Inner = $t1.rank === 1 ? $t1.size : $t1.shape[1];
      var t2Inner = $t2.rank === 1 ? $t2.size : $t2.shape[0];
      assert(t1Inner === t2Inner, function() {
        return "Error in dot: inner dimensions of inputs must match, but got " + "".concat(t1Inner, " and ").concat(t2Inner, ".");
      });
      if ($t1.rank === 1 && $t2.rank === 1) {
        var t12D = reshape($t1, [1, -1]);
        var t22D = reshape($t2, [-1, 1]);
        var t1t2 = matMul$1(t12D, t22D);
        return reshape(t1t2, []);
      } else if ($t1.rank === 1 && $t2.rank === 2) {
        var t12D = reshape($t1, [1, -1]);
        var t22D = reshape($t2, [$t2.shape[0], $t2.shape[1]]);
        var t1t2 = matMul$1(t12D, t22D);
        return reshape(t1t2, [t1t2.size]);
      } else if ($t1.rank === 2 && $t2.rank === 1) {
        var t22D = reshape($t2, [-1, 1]);
        var t1t2 = matMul$1($t1, t22D);
        return reshape(t1t2, [t1t2.size]);
      } else {
        var t22D = reshape($t2, [$t2.shape[0], $t2.shape[1]]);
        var t1t2 = matMul$1($t1, t22D);
        return t1t2;
      }
    }
    var dot = /* @__PURE__ */ op({ dot_ });
    function einsum_(equation) {
      var tensors = [];
      for (var _i = 1; _i < arguments.length; _i++) {
        tensors[_i - 1] = arguments[_i];
      }
      var $tensors = tensors.map(function(t, i) {
        return convertToTensor(t, "tensors".concat(i), "einsum");
      });
      var attrs = { equation };
      return ENGINE.runKernel(Einsum, $tensors, attrs);
    }
    var einsum = /* @__PURE__ */ op({ einsum_ });
    function elu_(x) {
      var $x = convertToTensor(x, "x", "elu", "float32");
      var inputs = { x: $x };
      return ENGINE.runKernel(Elu, inputs);
    }
    var elu = /* @__PURE__ */ op({ elu_ });
    function ensureShape_(x, shape) {
      var $x = convertToTensor(x, "x", "ensureShape", "string_or_numeric");
      if (!arraysEqualWithNull($x.shape, shape)) {
        throw new Error("EnsureShape: Shape of tensor ".concat($x.shape, " is not compatible with expected shape ").concat(shape));
      }
      return x;
    }
    var ensureShape = /* @__PURE__ */ op({ ensureShape_ });
    function erf_(x) {
      var $x = convertToTensor(x, "x", "erf");
      assert($x.dtype === "int32" || $x.dtype === "float32", function() {
        return "Input dtype must be `int32` or `float32`.";
      });
      if ($x.dtype === "int32") {
        $x = cast($x, "float32");
      }
      var inputs = { x: $x };
      return ENGINE.runKernel(Erf, inputs);
    }
    var erf = /* @__PURE__ */ op({ erf_ });
    function axesAreInnerMostDims(axes, rank) {
      for (var i = 0; i < axes.length; ++i) {
        if (axes[axes.length - i - 1] !== rank - 1 - i) {
          return false;
        }
      }
      return true;
    }
    function combineLocations(outputLoc, reduceLoc, axes) {
      var rank = outputLoc.length + reduceLoc.length;
      var loc = [];
      var outIdx = 0;
      var reduceIdx = 0;
      for (var dim = 0; dim < rank; dim++) {
        if (axes.indexOf(dim) === -1) {
          loc.push(outputLoc[outIdx++]);
        } else {
          loc.push(reduceLoc[reduceIdx++]);
        }
      }
      return loc;
    }
    function computeOutAndReduceShapes(aShape, axes) {
      var outShape = [];
      var rank = aShape.length;
      for (var dim = 0; dim < rank; dim++) {
        if (axes.indexOf(dim) === -1) {
          outShape.push(aShape[dim]);
        }
      }
      var reduceShape = axes.map(function(dim2) {
        return aShape[dim2];
      });
      return [outShape, reduceShape];
    }
    function expandShapeToKeepDim(shape, axes) {
      var reduceSubShape = axes.map(function(x) {
        return 1;
      });
      return combineLocations(shape, reduceSubShape, axes);
    }
    function assertAxesAreInnerMostDims(msg, axes, rank) {
      assert(axesAreInnerMostDims(axes, rank), function() {
        return "".concat(msg, " supports only inner-most axes for now. ") + "Got axes ".concat(axes, " and rank-").concat(rank, " input.");
      });
    }
    function getAxesPermutation(axes, rank) {
      if (axesAreInnerMostDims(axes, rank)) {
        return null;
      }
      var result = [];
      for (var i = 0; i < rank; ++i) {
        if (axes.indexOf(i) === -1) {
          result.push(i);
        }
      }
      axes.forEach(function(axis) {
        return result.push(axis);
      });
      return result;
    }
    function getUndoAxesPermutation(axes) {
      return axes.map(function(axis, i) {
        return [i, axis];
      }).sort(function(a, b) {
        return a[1] - b[1];
      }).map(function(x) {
        return x[0];
      });
    }
    function getInnerMostAxes(numAxes, rank) {
      var res = [];
      for (var i = rank - numAxes; i < rank; ++i) {
        res.push(i);
      }
      return res;
    }
    function max_(x, axis, keepDims) {
      if (axis === void 0) {
        axis = null;
      }
      if (keepDims === void 0) {
        keepDims = false;
      }
      var $x = convertToTensor(x, "x", "max");
      var inputs = { x: $x };
      var attrs = { reductionIndices: axis, keepDims };
      return ENGINE.runKernel(Max, inputs, attrs);
    }
    var max = /* @__PURE__ */ op({ max_ });
    function min_(x, axis, keepDims) {
      if (axis === void 0) {
        axis = null;
      }
      if (keepDims === void 0) {
        keepDims = false;
      }
      var $x = convertToTensor(x, "x", "min");
      var inputs = { x: $x };
      var attrs = { axis, keepDims };
      return ENGINE.runKernel(Min, inputs, attrs);
    }
    var min = /* @__PURE__ */ op({ min_ });
    function pow_(base, exp2) {
      var _a;
      var $base = convertToTensor(base, "base", "pow");
      var $exp = convertToTensor(exp2, "exp", "pow");
      _a = __read(makeTypesMatch($base, $exp), 2), $base = _a[0], $exp = _a[1];
      var inputs = { a: $base, b: $exp };
      return ENGINE.runKernel(Pow, inputs);
    }
    var pow = /* @__PURE__ */ op({ pow_ });
    function scalar(value, dtype) {
      if ((isTypedArray(value) && dtype !== "string" || Array.isArray(value)) && dtype !== "complex64") {
        throw new Error("Error creating a new Scalar: value must be a primitive (number|boolean|string)");
      }
      if (dtype === "string" && isTypedArray(value) && !(value instanceof Uint8Array)) {
        throw new Error("When making a scalar from encoded string, the value must be `Uint8Array`.");
      }
      var shape = [];
      var inferredShape = [];
      return makeTensor(value, shape, inferredShape, dtype);
    }
    function sqrt_(x) {
      var $x = convertToTensor(x, "x", "sqrt", "float32");
      var inputs = { x: $x };
      return ENGINE.runKernel(Sqrt, inputs);
    }
    var sqrt = /* @__PURE__ */ op({ sqrt_ });
    function square_(x) {
      var $x = convertToTensor(x, "x", "square");
      var attrs = {};
      return ENGINE.runKernel("Square", { x: $x }, attrs);
    }
    var square = /* @__PURE__ */ op({ square_ });
    function sum_(x, axis, keepDims) {
      if (axis === void 0) {
        axis = null;
      }
      if (keepDims === void 0) {
        keepDims = false;
      }
      var $x = convertToTensor(x, "x", "sum");
      if ($x.dtype === "bool") {
        $x = cast($x, "int32");
      }
      var inputs = { x: $x };
      var attrs = { axis, keepDims };
      return ENGINE.runKernel(Sum, inputs, attrs);
    }
    var sum = /* @__PURE__ */ op({ sum_ });
    function norm_(x, ord, axis, keepDims) {
      if (ord === void 0) {
        ord = "euclidean";
      }
      if (axis === void 0) {
        axis = null;
      }
      if (keepDims === void 0) {
        keepDims = false;
      }
      x = convertToTensor(x, "x", "norm");
      var norm2 = normImpl(x, ord, axis);
      var keepDimsShape = norm2.shape;
      if (keepDims) {
        var axes = parseAxisParam(axis, x.shape);
        keepDimsShape = expandShapeToKeepDim(norm2.shape, axes);
      }
      return reshape(norm2, keepDimsShape);
    }
    function normImpl(x, p, axis) {
      if (axis === void 0) {
        axis = null;
      }
      if (x.rank === 0) {
        return abs(x);
      }
      if (x.rank !== 1 && axis === null) {
        return normImpl(reshape(x, [-1]), p, axis);
      }
      if (x.rank === 1 || typeof axis === "number" || Array.isArray(axis) && axis.length === 1) {
        if (p === 1) {
          return sum(abs(x), axis);
        }
        if (p === Infinity) {
          return max(abs(x), axis);
        }
        if (p === -Infinity) {
          return min(abs(x), axis);
        }
        if (p === "euclidean" || p === 2) {
          return sqrt(sum(pow(abs(x), scalar(2, "int32")), axis));
        }
        throw new Error("Error in norm: invalid ord value: ".concat(p));
      }
      if (Array.isArray(axis) && axis.length === 2) {
        if (p === 1) {
          return max(sum(abs(x), axis[0]), axis[1] - 1);
        }
        if (p === Infinity) {
          return max(sum(abs(x), axis[1]), axis[0]);
        }
        if (p === -Infinity) {
          return min(sum(abs(x), axis[1]), axis[0]);
        }
        if (p === "fro" || p === "euclidean") {
          return sqrt(sum(square(x), axis));
        }
        throw new Error("Error in norm: invalid ord value: ".concat(p));
      }
      throw new Error("Error in norm: invalid axis: ".concat(axis));
    }
    var norm = /* @__PURE__ */ op({ norm_ });
    function euclideanNorm_(x, axis, keepDims) {
      if (axis === void 0) {
        axis = null;
      }
      if (keepDims === void 0) {
        keepDims = false;
      }
      return norm(x, "euclidean", axis, keepDims);
    }
    var euclideanNorm = /* @__PURE__ */ op({ euclideanNorm_ });
    function exp_(x) {
      var $x = convertToTensor(x, "x", "exp");
      var inputs = { x: $x };
      return ENGINE.runKernel(Exp, inputs);
    }
    var exp = /* @__PURE__ */ op({ exp_ });
    function expandDims_(x, axis) {
      if (axis === void 0) {
        axis = 0;
      }
      var $x = convertToTensor(x, "x", "expandDims", "string_or_numeric");
      assert(axis <= $x.rank, function() {
        return "Axis must be <= rank of the tensor";
      });
      var inputs = { input: $x };
      var attrs = { dim: axis };
      return ENGINE.runKernel(ExpandDims, inputs, attrs);
    }
    var expandDims = /* @__PURE__ */ op({ expandDims_ });
    function expm1_(x) {
      var $x = convertToTensor(x, "x", "expm1");
      var inputs = { x: $x };
      return ENGINE.runKernel(Expm1, inputs);
    }
    var expm1 = /* @__PURE__ */ op({ expm1_ });
    function tile_(x, reps) {
      var $x = convertToTensor(x, "x", "tile", "string_or_numeric");
      assert($x.rank === reps.length, function() {
        return "Error in transpose: rank of input ".concat($x.rank, " ") + "must match length of reps ".concat(reps, ".");
      });
      var inputs = { x: $x };
      var attrs = { reps };
      return ENGINE.runKernel(Tile, inputs, attrs);
    }
    var tile = /* @__PURE__ */ op({ tile_ });
    function eye_(numRows, numColumns, batchShape, dtype) {
      if (dtype === void 0) {
        dtype = "float32";
      }
      if (numColumns == null) {
        numColumns = numRows;
      }
      var buff = buffer([numRows, numColumns], dtype);
      var n = numRows <= numColumns ? numRows : numColumns;
      for (var i = 0; i < n; ++i) {
        buff.set(1, i, i);
      }
      var out = reshape(buff.toTensor(), [numRows, numColumns]);
      if (batchShape == null) {
        return out;
      } else {
        if (batchShape.length === 1) {
          return tile(expandDims(out, 0), [batchShape[0], 1, 1]);
        } else if (batchShape.length === 2) {
          return tile(expandDims(expandDims(out, 0), 0), [batchShape[0], batchShape[1], 1, 1]);
        } else if (batchShape.length === 3) {
          return tile(expandDims(expandDims(expandDims(out, 0), 0), 0), [
            batchShape[0],
            batchShape[1],
            batchShape[2],
            1,
            1
          ]);
        } else {
          throw new Error("eye() currently supports only 1D and 2D " + // tslint:disable-next-line:no-any
          "batchShapes, but received ".concat(batchShape.length, "D."));
        }
      }
    }
    var eye = /* @__PURE__ */ op({ eye_ });
    function floor_(x) {
      var $x = convertToTensor(x, "x", "floor", "float32");
      var inputs = { x: $x };
      return ENGINE.runKernel(Floor, inputs);
    }
    var floor = /* @__PURE__ */ op({ floor_ });
    function gather_(x, indices, axis, batchDims) {
      if (axis === void 0) {
        axis = 0;
      }
      if (batchDims === void 0) {
        batchDims = 0;
      }
      var $x = convertToTensor(x, "x", "gather");
      var $indices = convertToTensor(indices, "indices", "gather", "int32");
      var inputs = { x: $x, indices: $indices };
      var attrs = { axis, batchDims };
      return ENGINE.runKernel(GatherV2, inputs, attrs);
    }
    var gather = /* @__PURE__ */ op({ gather_ });
    function greater_(a, b) {
      var _a;
      var $a = convertToTensor(a, "a", "greater", "string_or_numeric");
      var $b = convertToTensor(b, "b", "greater", "string_or_numeric");
      _a = __read(makeTypesMatch($a, $b), 2), $a = _a[0], $b = _a[1];
      assertAndGetBroadcastShape($a.shape, $b.shape);
      var inputs = { a: $a, b: $b };
      return ENGINE.runKernel(Greater, inputs);
    }
    var greater = /* @__PURE__ */ op({ greater_ });
    function greaterEqual_(a, b) {
      var _a;
      var $a = convertToTensor(a, "a", "greaterEqual", "string_or_numeric");
      var $b = convertToTensor(b, "b", "greaterEqual", "string_or_numeric");
      _a = __read(makeTypesMatch($a, $b), 2), $a = _a[0], $b = _a[1];
      assertAndGetBroadcastShape($a.shape, $b.shape);
      var inputs = { a: $a, b: $b };
      return ENGINE.runKernel(GreaterEqual, inputs);
    }
    var greaterEqual = /* @__PURE__ */ op({ greaterEqual_ });
    function imag_(input) {
      var $input = convertToTensor(input, "input", "imag");
      var inputs = { input: $input };
      return ENGINE.runKernel(Imag, inputs);
    }
    var imag = /* @__PURE__ */ op({ imag_ });
    function isFinite_(x) {
      var $x = convertToTensor(x, "x", "isFinite");
      var inputs = { x: $x };
      return ENGINE.runKernel(IsFinite, inputs);
    }
    var isFinite$1 = /* @__PURE__ */ op({ isFinite_ });
    function isInf_(x) {
      var $x = convertToTensor(x, "x", "isInf");
      var inputs = { x: $x };
      return ENGINE.runKernel(IsInf, inputs);
    }
    var isInf = /* @__PURE__ */ op({ isInf_ });
    function isNaN_(x) {
      var $x = convertToTensor(x, "x", "isNaN");
      var inputs = { x: $x };
      return ENGINE.runKernel(IsNan, inputs);
    }
    var isNaN$1 = /* @__PURE__ */ op({ isNaN_ });
    function leakyRelu_(x, alpha) {
      if (alpha === void 0) {
        alpha = 0.2;
      }
      var $x = convertToTensor(x, "x", "leakyRelu");
      var inputs = { x: $x };
      var attrs = { alpha };
      return ENGINE.runKernel(LeakyRelu, inputs, attrs);
    }
    var leakyRelu = /* @__PURE__ */ op({ leakyRelu_ });
    function less_(a, b) {
      var _a;
      var $a = convertToTensor(a, "a", "less", "string_or_numeric");
      var $b = convertToTensor(b, "b", "less", "string_or_numeric");
      _a = __read(makeTypesMatch($a, $b), 2), $a = _a[0], $b = _a[1];
      assertAndGetBroadcastShape($a.shape, $b.shape);
      var inputs = { a: $a, b: $b };
      return ENGINE.runKernel(Less, inputs);
    }
    var less = /* @__PURE__ */ op({ less_ });
    function lessEqual_(a, b) {
      var _a;
      var $a = convertToTensor(a, "a", "lessEqual", "string_or_numeric");
      var $b = convertToTensor(b, "b", "lessEqual", "string_or_numeric");
      _a = __read(makeTypesMatch($a, $b), 2), $a = _a[0], $b = _a[1];
      assertAndGetBroadcastShape($a.shape, $b.shape);
      var inputs = { a: $a, b: $b };
      return ENGINE.runKernel(LessEqual, inputs);
    }
    var lessEqual = /* @__PURE__ */ op({ lessEqual_ });
    function linspace(start, stop, num) {
      if (num <= 0) {
        throw new Error("The number of values should be positive.");
      }
      var attrs = { start, stop, num };
      return ENGINE.runKernel(LinSpace, {}, attrs);
    }
    function localResponseNormalization_(x, depthRadius, bias, alpha, beta) {
      if (depthRadius === void 0) {
        depthRadius = 5;
      }
      if (bias === void 0) {
        bias = 1;
      }
      if (alpha === void 0) {
        alpha = 1;
      }
      if (beta === void 0) {
        beta = 0.5;
      }
      var $x = convertToTensor(x, "x", "localResponseNormalization");
      assert($x.rank === 4 || $x.rank === 3, function() {
        return "Error in localResponseNormalization: x must be rank 3 or 4 but got\n               rank ".concat($x.rank, ".");
      });
      assert(isInt(depthRadius), function() {
        return "Error in localResponseNormalization: depthRadius must be an " + "integer but got depthRadius ".concat(depthRadius, ".");
      });
      var x4D = $x;
      var reshapedTo4D = false;
      if ($x.rank === 3) {
        reshapedTo4D = true;
        x4D = reshape($x, [1, $x.shape[0], $x.shape[1], $x.shape[2]]);
      }
      var inputs = { x: x4D };
      var attrs = { depthRadius, bias, alpha, beta };
      var res = ENGINE.runKernel(LRN, inputs, attrs);
      if (reshapedTo4D) {
        return reshape(res, [res.shape[1], res.shape[2], res.shape[3]]);
      } else {
        return res;
      }
    }
    var localResponseNormalization = /* @__PURE__ */ op({ localResponseNormalization_ });
    function log_(x) {
      var $x = convertToTensor(x, "x", "log", "float32");
      var inputs = { x: $x };
      return ENGINE.runKernel(Log, inputs);
    }
    var log = /* @__PURE__ */ op({ log_ });
    function log1p_(x) {
      var $x = convertToTensor(x, "x", "log1p");
      var inputs = { x: $x };
      return ENGINE.runKernel(Log1p, inputs);
    }
    var log1p = /* @__PURE__ */ op({ log1p_ });
    function grad(f) {
      assert(isFunction(f), function() {
        return "The f passed in grad(f) must be a function";
      });
      return function(x, dy) {
        var $x = convertToTensor(x, "x", "tf.grad", "string_or_numeric");
        var $dy = dy != null ? convertToTensor(dy, "dy", "tf.grad") : null;
        return ENGINE.tidy(function() {
          var _a = ENGINE.gradients(function() {
            return f($x);
          }, [$x], $dy), value = _a.value, grads2 = _a.grads;
          if ($dy != null) {
            assertShapesMatch(value.shape, $dy.shape, "The shape of dy passed in grad(f)(x, dy) must match the shape returned by f(x)");
          }
          checkGrads(grads2);
          return grads2[0];
        });
      };
    }
    function grads(f) {
      assert(isFunction(f), function() {
        return "The f passed in grads(f) must be a function";
      });
      return function(args, dy) {
        assert(Array.isArray(args), function() {
          return "The args passed in grads(f)(args) must be an array of `Tensor`s or `TensorLike`s";
        });
        var $args = convertToTensorArray(args, "args", "tf.grads", "string_or_numeric");
        var $dy = dy != null ? convertToTensor(dy, "dy", "tf.grads") : null;
        return ENGINE.tidy(function() {
          var _a = ENGINE.gradients(function() {
            return f.apply(void 0, __spreadArray([], __read($args), false));
          }, $args, $dy), value = _a.value, grads2 = _a.grads;
          if ($dy != null) {
            assertShapesMatch(value.shape, $dy.shape, "The shape of dy passed in grads(f)([x1,...], dy) must match the shape returned by f([x1,...])");
          }
          checkGrads(grads2);
          return grads2;
        });
      };
    }
    function valueAndGrad(f) {
      assert(isFunction(f), function() {
        return "The f passed in valueAndGrad(f) must be a function";
      });
      return function(x, dy) {
        assert(x instanceof Tensor, function() {
          return "The x passed in valueAndGrad(f)(x) must be a tensor";
        });
        assert(dy == null || dy instanceof Tensor, function() {
          return "The dy passed in valueAndGrad(f)(x, dy) must be a tensor";
        });
        var _a = ENGINE.gradients(function() {
          return f(x);
        }, [x], dy), grads2 = _a.grads, value = _a.value;
        checkGrads(grads2);
        return { grad: grads2[0], value };
      };
    }
    function valueAndGrads(f) {
      assert(isFunction(f), function() {
        return "The f passed in valueAndGrads(f) must be a function";
      });
      return function(args, dy) {
        assert(Array.isArray(args) && args.every(function(arg) {
          return arg instanceof Tensor;
        }), function() {
          return "The args passed in valueAndGrads(f)(args) must be array of tensors";
        });
        assert(dy == null || dy instanceof Tensor, function() {
          return "The dy passed in valueAndGrads(f)(args, dy) must be a tensor";
        });
        var res = ENGINE.gradients(function() {
          return f.apply(void 0, __spreadArray([], __read(args), false));
        }, args, dy);
        if (dy != null) {
          assertShapesMatch(res.value.shape, dy.shape, "The shape of dy passed in valueAndGrads(f)([x1,...], dy) must match the shape returned by f([x1,...])");
        }
        checkGrads(res.grads);
        return res;
      };
    }
    function variableGrads(f, varList) {
      assert(isFunction(f), function() {
        return "The f passed in variableGrads(f) must be a function";
      });
      assert(varList == null || Array.isArray(varList) && varList.every(function(v) {
        return v instanceof Variable;
      }), function() {
        return "The varList passed in variableGrads(f, varList) must be an array of variables";
      });
      var specifiedVarList = varList != null;
      if (!specifiedVarList) {
        varList = [];
        for (var varName in ENGINE.registeredVariables) {
          varList.push(ENGINE.registeredVariables[varName]);
        }
      }
      var specifiedNonTrainable = specifiedVarList ? varList.filter(function(variable2) {
        return !variable2.trainable;
      }) : null;
      var originalVarCount = varList.length;
      varList = varList.filter(function(variable2) {
        return variable2.trainable;
      });
      assert(varList.length > 0, function() {
        return "variableGrads() expects at least one of the input variables to " + "be trainable, but none of the ".concat(originalVarCount, " variables is ") + "trainable.";
      });
      var allowNoGradients = true;
      var _a = ENGINE.gradients(f, varList, null, allowNoGradients), value = _a.value, grads2 = _a.grads;
      assert(grads2.some(function(g) {
        return g != null;
      }), function() {
        return "Cannot find a connection between any variable and the result of the loss function y=f(x). Please make sure the operations that use variables are inside the function f passed to minimize().";
      });
      assert(value.rank === 0, function() {
        return "The f passed in variableGrads(f) must return a scalar, but it " + "returned a rank-".concat(value.rank, " tensor");
      });
      var namedGrads = {};
      varList.forEach(function(v, i) {
        if (grads2[i] != null) {
          namedGrads[v.name] = grads2[i];
        }
      });
      if (specifiedNonTrainable != null) {
        specifiedNonTrainable.forEach(function(v) {
          return namedGrads[v.name] = null;
        });
      }
      return { value, grads: namedGrads };
    }
    function customGrad(f) {
      return ENGINE.customGrad(f);
    }
    function checkGrads(grads2) {
      var numNullGradients = grads2.filter(function(g) {
        return g == null;
      }).length;
      if (numNullGradients > 0) {
        throw new Error("Cannot compute gradient of y=f(x) with respect to x. Make sure that\n    the f you passed encloses all operations that lead from x to y.");
      }
    }
    function neg_(x) {
      var $x = convertToTensor(x, "x", "neg");
      var inputs = { x: $x };
      return ENGINE.runKernel(Neg, inputs);
    }
    var neg = /* @__PURE__ */ op({ neg_ });
    function softplus_(x) {
      var $x = convertToTensor(x, "x", "softplus");
      var inputs = { x: $x };
      return ENGINE.runKernel(Softplus, inputs);
    }
    var softplus = /* @__PURE__ */ op({ softplus_ });
    function logSigmoid_(x) {
      var $x = convertToTensor(x, "x", "logSigmoid");
      var customOp = customGrad(function(x2) {
        var value = neg(softplus(neg(x2)));
        var gradFunc = function(dy) {
          var derX = mul(dy, sigmoid(neg(x2)));
          return derX;
        };
        return { value, gradFunc };
      });
      return customOp($x);
    }
    var logSigmoid = /* @__PURE__ */ op({ logSigmoid_ });
    function sub_(a, b) {
      var _a;
      var $a = convertToTensor(a, "a", "sub");
      var $b = convertToTensor(b, "b", "sub");
      _a = __read(makeTypesMatch($a, $b), 2), $a = _a[0], $b = _a[1];
      var inputs = { a: $a, b: $b };
      return ENGINE.runKernel(Sub, inputs);
    }
    var sub = /* @__PURE__ */ op({ sub_ });
    function logSoftmax_(logits, axis) {
      if (axis === void 0) {
        axis = -1;
      }
      var $logits = convertToTensor(logits, "logits", "logSoftmax");
      if (axis === -1) {
        axis = $logits.rank - 1;
      }
      if (axis !== $logits.rank - 1) {
        throw Error("Log Softmax along a non-last dimension is not yet supported. " + "Logits was rank ".concat($logits.rank, " and axis was ").concat(axis));
      }
      var customOp = customGrad(function(logits2, save) {
        var keepDims = true;
        var xMax = max(logits2, axis, true);
        var shifted = sub(logits2, xMax);
        var value = sub(cast(shifted, "float32"), log(sum(exp(shifted), axis, keepDims)));
        save([value]);
        var gradFunc = function(dy, saved) {
          var _a = __read(saved, 1), value2 = _a[0];
          var keepDims2 = true;
          var softmax2 = exp(value2);
          return sub(dy, mul(sum(dy, axis, keepDims2), softmax2));
        };
        return { value, gradFunc };
      });
      return customOp($logits);
    }
    var logSoftmax = /* @__PURE__ */ op({ logSoftmax_ });
    function logSumExp_(x, axis, keepDims) {
      if (axis === void 0) {
        axis = null;
      }
      if (keepDims === void 0) {
        keepDims = false;
      }
      var $x = convertToTensor(x, "x", "logSumExp");
      var axes = parseAxisParam(axis, $x.shape);
      var xMax = max(
        $x,
        axes,
        true
        /* keepDims */
      );
      var a = sub($x, xMax);
      var b = exp(a);
      var c = sum(b, axes);
      var d = log(c);
      var res = add(reshape(xMax, d.shape), d);
      if (keepDims) {
        var newShape = expandShapeToKeepDim(res.shape, axes);
        return reshape(res, newShape);
      }
      return res;
    }
    var logSumExp = /* @__PURE__ */ op({ logSumExp_ });
    function logicalAnd_(a, b) {
      var $a = convertToTensor(a, "a", "logicalAnd", "bool");
      var $b = convertToTensor(b, "b", "logicalAnd", "bool");
      assertAndGetBroadcastShape($a.shape, $b.shape);
      var inputs = { a: $a, b: $b };
      return ENGINE.runKernel(LogicalAnd, inputs);
    }
    var logicalAnd = /* @__PURE__ */ op({ logicalAnd_ });
    function logicalNot_(x) {
      var $x = convertToTensor(x, "x", "logicalNot", "bool");
      var inputs = { x: $x };
      return ENGINE.runKernel(LogicalNot, inputs);
    }
    var logicalNot = /* @__PURE__ */ op({ logicalNot_ });
    function logicalOr_(a, b) {
      var $a = convertToTensor(a, "a", "logicalOr", "bool");
      var $b = convertToTensor(b, "b", "logicalOr", "bool");
      assertAndGetBroadcastShape($a.shape, $b.shape);
      var inputs = { a: $a, b: $b };
      return ENGINE.runKernel(LogicalOr, inputs);
    }
    var logicalOr = /* @__PURE__ */ op({ logicalOr_ });
    function logicalXor_(a, b) {
      var $a = convertToTensor(a, "a", "logicalXor", "bool");
      var $b = convertToTensor(b, "b", "logicalXor", "bool");
      assertAndGetBroadcastShape($a.shape, $b.shape);
      return logicalAnd(logicalOr(a, b), logicalNot(logicalAnd(a, b)));
    }
    var logicalXor = /* @__PURE__ */ op({ logicalXor_ });
    var INT32_MAX = 2147483648;
    function searchSorted_(sortedSequence, values, side) {
      if (side === void 0) {
        side = "left";
      }
      var $sortedSequence = convertToTensor(sortedSequence, "sortedSequence", "searchSorted");
      var $values = convertToTensor(values, "values", "searchSorted");
      var sequenceSize = $sortedSequence.shape[$sortedSequence.shape.length - 1];
      var valuesSize = $values.shape[$values.shape.length - 1];
      var $sortedSequence2D = reshape($sortedSequence, [-1, sequenceSize]);
      var $values2D = reshape($values, [-1, valuesSize]);
      if ($sortedSequence2D.rank < 2) {
        throw new Error("Sorted input argument must be at least 2-dimensional");
      }
      if ($sortedSequence2D.shape[0] !== $values2D.shape[0]) {
        throw new Error("Leading dimension of 'sortedSequence' and 'values' must match.");
      }
      if (sizeFromShape($values2D.shape) >= INT32_MAX) {
        throw new Error("values tensor size must less than ".concat(INT32_MAX));
      }
      if ($sortedSequence2D.shape[1] >= INT32_MAX) {
        throw new Error("trailing dim_size must less than ".concat(INT32_MAX, " for int32 output type, was ").concat($sortedSequence2D.shape[1]));
      }
      var inputs = {
        sortedSequence: $sortedSequence2D,
        values: $values2D
      };
      var attrs = { side };
      return ENGINE.runKernel(SearchSorted, inputs, attrs);
    }
    var searchSorted = /* @__PURE__ */ op({ searchSorted_ });
    function lowerBound(sortedSequence, values) {
      return searchSorted(sortedSequence, values, "left");
    }
    function maxPool_(x, filterSize, strides, pad2, dimRoundingMode) {
      var $x = convertToTensor(x, "x", "maxPool");
      var dilations = 1;
      var x4D = $x;
      var reshapedTo4D = false;
      if ($x.rank === 3) {
        reshapedTo4D = true;
        x4D = reshape($x, [1, $x.shape[0], $x.shape[1], $x.shape[2]]);
      }
      assert(x4D.rank === 4, function() {
        return "Error in maxPool: input must be rank 4 but got rank ".concat(x4D.rank, ".");
      });
      assert(eitherStridesOrDilationsAreOne(strides, dilations), function() {
        return "Error in maxPool: Either strides or dilations must be 1. " + "Got strides ".concat(strides, " and dilations '").concat(dilations, "'");
      });
      checkPadOnDimRoundingMode("maxPool", pad2, dimRoundingMode);
      var inputs = { x: x4D };
      var attrs = { filterSize, strides, pad: pad2, dimRoundingMode };
      var res = ENGINE.runKernel(MaxPool, inputs, attrs);
      if (reshapedTo4D) {
        return reshape(res, [res.shape[1], res.shape[2], res.shape[3]]);
      }
      return res;
    }
    var maxPool = /* @__PURE__ */ op({ maxPool_ });
    function maxPool3d_(x, filterSize, strides, pad2, dimRoundingMode, dataFormat) {
      if (filterSize === void 0) {
        filterSize = [1, 1, 1];
      }
      if (dataFormat === void 0) {
        dataFormat = "NDHWC";
      }
      var $x = convertToTensor(x, "x", "maxPool3d");
      var x5D = $x;
      var reshapedTo5D = false;
      if ($x.rank === 4) {
        reshapedTo5D = true;
        x5D = reshape($x, [1, $x.shape[0], $x.shape[1], $x.shape[2], $x.shape[3]]);
      }
      assert(x5D.rank === 5, function() {
        return "Error in maxPool3d: x must be rank 5 but got rank ".concat(x5D.rank, ".");
      });
      assert(dataFormat === "NDHWC", function() {
        return "Error in maxPool3d: Only NDHWC is currently supported, " + "but got dataFormat of ".concat(dataFormat);
      });
      checkPadOnDimRoundingMode("maxPool3d", pad2, dimRoundingMode);
      var inputs = { x: x5D };
      var attrs = { filterSize, strides, pad: pad2, dimRoundingMode, dataFormat };
      var res = ENGINE.runKernel(MaxPool3D, inputs, attrs);
      if (reshapedTo5D) {
        return reshape(res, [res.shape[1], res.shape[2], res.shape[3], res.shape[4]]);
      }
      return res;
    }
    var maxPool3d = /* @__PURE__ */ op({ maxPool3d_ });
    function maxPoolWithArgmax_(x, filterSize, strides, pad2, includeBatchInIndex) {
      if (includeBatchInIndex === void 0) {
        includeBatchInIndex = false;
      }
      var $x = convertToTensor(x, "x", "maxPoolWithArgmax");
      var inputs = { x: $x };
      var attrs = { filterSize, strides, pad: pad2, includeBatchInIndex };
      var result = ENGINE.runKernel(MaxPoolWithArgmax, inputs, attrs);
      return { result: result[0], indexes: result[1] };
    }
    var maxPoolWithArgmax = /* @__PURE__ */ op({ maxPoolWithArgmax_ });
    function maximum_(a, b) {
      var _a;
      var $a = convertToTensor(a, "a", "maximum");
      var $b = convertToTensor(b, "b", "maximum");
      _a = __read(makeTypesMatch($a, $b), 2), $a = _a[0], $b = _a[1];
      if ($a.dtype === "bool") {
        $a = cast($a, "int32");
        $b = cast($b, "int32");
      }
      assertAndGetBroadcastShape($a.shape, $b.shape);
      var inputs = { a: $a, b: $b };
      return ENGINE.runKernel(Maximum, inputs);
    }
    var maximum = /* @__PURE__ */ op({ maximum_ });
    function mean_(x, axis, keepDims) {
      if (axis === void 0) {
        axis = null;
      }
      if (keepDims === void 0) {
        keepDims = false;
      }
      var $x = convertToTensor(x, "x", "mean");
      var inputs = { x: $x };
      var attrs = { axis, keepDims };
      return ENGINE.runKernel(Mean, inputs, attrs);
    }
    var mean = /* @__PURE__ */ op({ mean_ });
    function zeros(shape, dtype) {
      if (dtype === void 0) {
        dtype = "float32";
      }
      assertNonNegativeIntegerDimensions(shape);
      if (dtype === "complex64") {
        var real2 = zeros(shape, "float32");
        var imag2 = zeros(shape, "float32");
        return complex(real2, imag2);
      }
      var values = makeZerosTypedArray(sizeFromShape(shape), dtype);
      return ENGINE.makeTensor(values, shape, dtype);
    }
    function ones(shape, dtype) {
      if (dtype === void 0) {
        dtype = "float32";
      }
      assertNonNegativeIntegerDimensions(shape);
      if (dtype === "complex64") {
        var real2 = ones(shape, "float32");
        var imag2 = zeros(shape, "float32");
        return complex(real2, imag2);
      }
      var values = makeOnesTypedArray(sizeFromShape(shape), dtype);
      return ENGINE.makeTensor(values, shape, dtype);
    }
    function meshgrid(x, y, _a) {
      var _b = _a === void 0 ? {} : _a, _c = _b.indexing, indexing = _c === void 0 ? "xy" : _c;
      if (indexing !== "xy" && indexing !== "ij") {
        throw new TypeError("".concat(indexing, " is not a valid third argument to meshgrid"));
      }
      if (x === void 0) {
        return [];
      }
      var $x = convertToTensor(x, "x", "meshgrid", x instanceof Tensor ? x.dtype : "float32");
      if (y === void 0) {
        return [$x];
      }
      var $y = convertToTensor(y, "y", "meshgrid", y instanceof Tensor ? y.dtype : "float32");
      var w = sizeFromShape($x.shape);
      var h = sizeFromShape($y.shape);
      if (indexing === "xy") {
        $x = reshape($x, [1, -1]);
        $y = reshape($y, [-1, 1]);
        return [
          matMul$1(ones([h, 1], $x.dtype), $x),
          matMul$1($y, ones([1, w], $y.dtype))
        ];
      }
      $x = reshape($x, [-1, 1]);
      $y = reshape($y, [1, -1]);
      return [
        matMul$1($x, ones([1, h], $x.dtype)),
        matMul$1(ones([w, 1], $y.dtype), $y)
      ];
    }
    function minimum_(a, b) {
      var _a;
      var $a = convertToTensor(a, "a", "minimum");
      var $b = convertToTensor(b, "b", "minimum");
      _a = __read(makeTypesMatch($a, $b), 2), $a = _a[0], $b = _a[1];
      if ($a.dtype === "bool") {
        $a = cast($a, "int32");
        $b = cast($b, "int32");
      }
      assertAndGetBroadcastShape($a.shape, $b.shape);
      var inputs = { a: $a, b: $b };
      return ENGINE.runKernel(Minimum, inputs);
    }
    var minimum = /* @__PURE__ */ op({ minimum_ });
    function mirrorPad_(x, paddings, mode) {
      assert(mode === "reflect" || mode === "symmetric", function() {
        return "Invalid mode. Mode must be either reflect or symmetric. " + "Got ".concat(mode, ".");
      });
      var $x = convertToTensor(x, "x", "mirrorPad");
      if ($x.rank === 0) {
        throw new Error("mirrorPad(scalar) is not defined. Pass non-scalar to mirrorPad");
      }
      assert(paddings.length === $x.rank, function() {
        return "Padding doesn't match input. Must be ".concat($x.rank, ". ") + "Got ".concat(paddings.length, ".");
      });
      var shapeOffset = mode === "reflect" ? 1 : 0;
      var _loop_1 = function(i2) {
        assert(paddings[i2].length === 2, function() {
          return "Invalid number of paddings. Must be length of 2 each.";
        });
        assert(paddings[i2][0] >= 0 && paddings[i2][0] <= $x.shape[i2] - shapeOffset && paddings[i2][1] >= 0 && paddings[i2][1] <= $x.shape[i2] - shapeOffset, function() {
          return "Padding in dimension ".concat(i2, " cannot be greater than or equal ") + "to ".concat($x.shape[i2] - shapeOffset, " or less than 0 for input of ") + "shape ".concat($x.shape);
        });
      };
      for (var i = 0; i < $x.rank; i++) {
        _loop_1(i);
      }
      var attrs = { paddings, mode };
      var inputs = { x: $x };
      return ENGINE.runKernel(MirrorPad, inputs, attrs);
    }
    var mirrorPad = /* @__PURE__ */ op({ mirrorPad_ });
    function mod_(a, b) {
      var _a;
      var $a = convertToTensor(a, "a", "mod");
      var $b = convertToTensor(b, "b", "mod");
      _a = __read(makeTypesMatch($a, $b), 2), $a = _a[0], $b = _a[1];
      var inputs = { a: $a, b: $b };
      return ENGINE.runKernel(Mod, inputs);
    }
    var mod = /* @__PURE__ */ op({ mod_ });
    function moments_(x, axis, keepDims) {
      if (axis === void 0) {
        axis = null;
      }
      if (keepDims === void 0) {
        keepDims = false;
      }
      x = convertToTensor(x, "x", "moments");
      var axes = parseAxisParam(axis, x.shape);
      var xMean = mean(x, axes, keepDims);
      var keepDimsShape = xMean.shape;
      if (!keepDims) {
        keepDimsShape = expandShapeToKeepDim(xMean.shape, axes);
      }
      var devSquared = square(sub(cast(x, "float32"), reshape(xMean, keepDimsShape)));
      var variance = mean(devSquared, axes, keepDims);
      return { mean: xMean, variance };
    }
    var moments = /* @__PURE__ */ op({ moments_ });
    function multiRNNCell_(lstmCells, data, c, h) {
      var $data = convertToTensor(data, "data", "multiRNNCell");
      var $c = convertToTensorArray(c, "c", "multiRNNCell");
      var $h = convertToTensorArray(h, "h", "multiRNNCell");
      var input = $data;
      var newStates = [];
      for (var i = 0; i < lstmCells.length; i++) {
        var output = lstmCells[i](input, $c[i], $h[i]);
        newStates.push(output[0]);
        newStates.push(output[1]);
        input = output[1];
      }
      var newC = [];
      var newH = [];
      for (var i = 0; i < newStates.length; i += 2) {
        newC.push(newStates[i]);
        newH.push(newStates[i + 1]);
      }
      return [newC, newH];
    }
    var multiRNNCell = /* @__PURE__ */ op({ multiRNNCell_ });
    function multinomial_(logits, numSamples, seed, normalized) {
      if (normalized === void 0) {
        normalized = false;
      }
      var $logits = convertToTensor(logits, "logits", "multinomial");
      var numOutcomes = $logits.size;
      var origRank = $logits.rank;
      if (numOutcomes < 2) {
        throw new Error("Error in multinomial: you need at least 2 outcomes, but got " + "".concat(numOutcomes, "."));
      }
      if (origRank > 2) {
        throw new Error("Rank of probabilities must be 1 or 2, but is ".concat(origRank));
      }
      seed = seed || Math.random();
      var logits2D = origRank === 1 ? reshape($logits, [1, -1]) : $logits;
      var inputs = { logits: logits2D };
      var attrs = { numSamples, seed, normalized };
      var res = ENGINE.runKernel(Multinomial, inputs, attrs);
      return origRank === 1 ? reshape(res, [res.size]) : res;
    }
    var multinomial = /* @__PURE__ */ op({ multinomial_ });
    function notEqual_(a, b) {
      var _a;
      var $a = convertToTensor(a, "a", "notEqual", "string_or_numeric");
      var $b = convertToTensor(b, "b", "notEqual", "string_or_numeric");
      _a = __read(makeTypesMatch($a, $b), 2), $a = _a[0], $b = _a[1];
      assertAndGetBroadcastShape($a.shape, $b.shape);
      var inputs = { a: $a, b: $b };
      return ENGINE.runKernel(NotEqual, inputs);
    }
    var notEqual = /* @__PURE__ */ op({ notEqual_ });
    function oneHot_(indices, depth, onValue, offValue, dtype) {
      if (onValue === void 0) {
        onValue = 1;
      }
      if (offValue === void 0) {
        offValue = 0;
      }
      if (dtype === void 0) {
        dtype = "int32";
      }
      if (depth < 2) {
        throw new Error("Error in oneHot: depth must be >=2, but it is ".concat(depth));
      }
      var $indices = convertToTensor(indices, "indices", "oneHot", "int32");
      var inputs = { indices: $indices };
      var attrs = { dtype, depth, onValue, offValue };
      return ENGINE.runKernel(OneHot, inputs, attrs);
    }
    var oneHot = /* @__PURE__ */ op({ oneHot_ });
    function onesLike_(x) {
      var $x = convertToTensor(x, "x", "onesLike");
      var inputs = { x: $x };
      return ENGINE.runKernel(OnesLike, inputs);
    }
    var onesLike = /* @__PURE__ */ op({ onesLike_ });
    function outerProduct_(v1, v2) {
      var $v1 = convertToTensor(v1, "v1", "outerProduct");
      var $v2 = convertToTensor(v2, "v2", "outerProduct");
      assert($v1.rank === 1 && $v2.rank === 1, function() {
        return "Error in outerProduct: inputs must be rank 1, but got ranks " + "".concat($v1.rank, " and ").concat($v2.rank, ".");
      });
      var v12D = reshape($v1, [-1, 1]);
      var v22D = reshape($v2, [1, -1]);
      return matMul$1(v12D, v22D);
    }
    var outerProduct = /* @__PURE__ */ op({ outerProduct_ });
    function pad_(x, paddings, constantValue) {
      if (constantValue === void 0) {
        constantValue = 0;
      }
      var $x = convertToTensor(x, "x", "pad");
      if ($x.rank === 0) {
        throw new Error("pad(scalar) is not defined. Pass non-scalar to pad");
      }
      var attrs = { paddings, constantValue };
      var inputs = { x: $x };
      return ENGINE.runKernel(PadV2, inputs, attrs);
    }
    var pad = /* @__PURE__ */ op({ pad_ });
    function pad1d_(x, paddings, constantValue) {
      if (constantValue === void 0) {
        constantValue = 0;
      }
      assert(paddings.length === 2, function() {
        return "Invalid number of paddings. Must be length of 2.";
      });
      return pad(x, [paddings], constantValue);
    }
    var pad1d = /* @__PURE__ */ op({ pad1d_ });
    function pad2d_(x, paddings, constantValue) {
      if (constantValue === void 0) {
        constantValue = 0;
      }
      assert(paddings.length === 2 && paddings[0].length === 2 && paddings[1].length === 2, function() {
        return "Invalid number of paddings. Must be length of 2 each.";
      });
      return pad(x, paddings, constantValue);
    }
    var pad2d = /* @__PURE__ */ op({ pad2d_ });
    function pad3d_(x, paddings, constantValue) {
      if (constantValue === void 0) {
        constantValue = 0;
      }
      assert(paddings.length === 3 && paddings[0].length === 2 && paddings[1].length === 2 && paddings[2].length === 2, function() {
        return "Invalid number of paddings. Must be length of 2 each.";
      });
      return pad(x, paddings, constantValue);
    }
    var pad3d = /* @__PURE__ */ op({ pad3d_ });
    function pad4d_(x, paddings, constantValue) {
      if (constantValue === void 0) {
        constantValue = 0;
      }
      assert(paddings.length === 4 && paddings[0].length === 2 && paddings[1].length === 2 && paddings[2].length === 2 && paddings[3].length === 2, function() {
        return "Invalid number of paddings. Must be length of 2 each.";
      });
      return pad(x, paddings, constantValue);
    }
    var pad4d = /* @__PURE__ */ op({ pad4d_ });
    function spaceToBatchND_(x, blockShape, paddings) {
      var $x = convertToTensor(x, "x", "spaceToBatchND");
      assert($x.rank >= 1 + blockShape.length, function() {
        return "input rank ".concat($x.rank, " should be > than [blockShape] ").concat(blockShape.length);
      });
      assert(paddings.length === blockShape.length, function() {
        return "paddings.shape[0] ".concat(paddings.length, " must be equal to [blockShape] ").concat(blockShape.length);
      });
      assert($x.shape.reduce(function(a, b, i) {
        if (i > 0 && i <= blockShape.length) {
          return a && (b + paddings[i - 1][0] + paddings[i - 1][1]) % blockShape[i - 1] === 0;
        }
        return a;
      }, true), function() {
        return "input spatial dimensions ".concat($x.shape.slice(1), " with paddings ").concat(paddings.toString(), " must be divisible by blockShapes ").concat(blockShape.toString());
      });
      var inputs = { x: $x };
      var attrs = { blockShape, paddings };
      return ENGINE.runKernel(SpaceToBatchND, inputs, attrs);
    }
    var spaceToBatchND = /* @__PURE__ */ op({ spaceToBatchND_ });
    function pool_(input, windowShape, poolingType, pad2, dilations, strides, dimRoundingMode) {
      if (dilations == null) {
        dilations = [1, 1];
      }
      if (strides == null) {
        strides = 1;
      }
      if (pad2 === 0) {
        pad2 = "valid";
      }
      var $x = convertToTensor(input, "x", "maxPool");
      var x4D = $x;
      var reshapedTo4D = false;
      if ($x.rank === 3) {
        reshapedTo4D = true;
        x4D = reshape($x, [1, $x.shape[0], $x.shape[1], $x.shape[2]]);
      }
      assert(eitherStridesOrDilationsAreOne(strides, dilations), function() {
        return "Error in pool: Either strides or dilations must be 1. " + "Got strides ".concat(strides, " and dilations '").concat(dilations, "'");
      });
      var convInfo = computePool2DInfo(x4D.shape, windowShape, strides, dilations, pad2);
      var dilation = [convInfo.dilationHeight, convInfo.dilationWidth];
      var basePadding;
      if (pad2 === "same") {
        basePadding = withSpaceToBatchBasePaddings([convInfo.filterHeight, convInfo.filterWidth], dilation);
      } else {
        basePadding = [[0, 0], [0, 0]];
      }
      var isDilationOne = dilation[0] === 1 && dilation[1] === 1;
      var _a = __read(requiredSpaceToBatchPaddings([convInfo.inHeight, convInfo.inWidth], dilation, basePadding), 2), adjustedPadding = _a[0], adjustedCrops = _a[1];
      var convertedPad = isDilationOne ? pad2 : "valid";
      var convertedX = isDilationOne ? x4D : spaceToBatchND(x4D, dilation, adjustedPadding);
      var forwardOp = poolingType === "avg" ? function() {
        return avgPool(convertedX, windowShape, strides, convertedPad, dimRoundingMode);
      } : function() {
        return maxPool(convertedX, windowShape, strides, convertedPad, dimRoundingMode);
      };
      var y = forwardOp();
      var res = isDilationOne ? y : batchToSpaceND(y, dilation, adjustedCrops);
      if (reshapedTo4D) {
        return reshape(res, [res.shape[1], res.shape[2], res.shape[3]]);
      }
      return res;
    }
    function requiredSpaceToBatchPaddings(inputShape, blockShape, basePadding) {
      var padStart = basePadding.map(function(b) {
        return b[0];
      });
      var origPadEnd = basePadding.map(function(b) {
        return b[1];
      });
      var fullInputShape = inputShape.concat(padStart, origPadEnd);
      var padEndExtra = blockShape.map(function(b, i) {
        return (b - fullInputShape[i] % b) % b;
      });
      var padEnd = origPadEnd.map(function(s, i) {
        return s + padEndExtra[i];
      });
      var paddings = blockShape.map(function(_, i) {
        return [padStart[i], padEnd[i]];
      });
      var crops = blockShape.map(function(_, i) {
        return [0, padEndExtra[i]];
      });
      return [paddings, crops];
    }
    function withSpaceToBatchBasePaddings(filterShape, dilation) {
      var dilatedFilterShape = filterShape.map(function(s, i) {
        return s + (s - 1) * (dilation[i] - 1);
      });
      var padExtraShape = dilatedFilterShape.map(function(s) {
        return s - 1;
      });
      var padExtraStart = padExtraShape.map(function(s) {
        return Math.floor(s / 2);
      });
      var padExtraEnd = padExtraShape.map(function(s, i) {
        return s - padExtraStart[i];
      });
      return padExtraShape.map(function(_, i) {
        return [padExtraStart[i], padExtraEnd[i]];
      });
    }
    var pool = /* @__PURE__ */ op({ pool_ });
    function prelu_(x, alpha) {
      var $x = convertToTensor(x, "x", "prelu");
      var $alpha = convertToTensor(alpha, "alpha", "prelu");
      var inputs = { x: $x, alpha: $alpha };
      return ENGINE.runKernel(Prelu, inputs);
    }
    var prelu = /* @__PURE__ */ op({ prelu_ });
    function prod_(x, axis, keepDims) {
      if (axis === void 0) {
        axis = null;
      }
      if (keepDims === void 0) {
        keepDims = false;
      }
      var $x = convertToTensor(x, "x", "prod");
      if ($x.dtype === "bool") {
        $x = cast($x, "int32");
      }
      var inputs = { x: $x };
      var attrs = { axis, keepDims };
      return ENGINE.runKernel(Prod, inputs, attrs);
    }
    var prod = /* @__PURE__ */ op({ prod_ });
    function raggedGather_(paramsNestedSplits, paramsDenseValues, indices, outputRaggedRank) {
      var $paramsNestedSplits = paramsNestedSplits.map(function(t, i) {
        return convertToTensor(t, "tensors".concat(i), "raggedGather", "int32");
      });
      var $paramsDenseValues = convertToTensor(paramsDenseValues, "paramsDenseValues", "raggedGather");
      var $indices = convertToTensor(indices, "indices", "raggedGather", "int32");
      var inputs = {
        paramsNestedSplits: $paramsNestedSplits,
        paramsDenseValues: $paramsDenseValues,
        indices: $indices
      };
      var attrs = { outputRaggedRank };
      var result = ENGINE.runKernel(RaggedGather, inputs, attrs);
      return {
        outputNestedSplits: result.slice(0, result.length - 1),
        outputDenseValues: result[result.length - 1]
      };
    }
    var raggedGather = /* @__PURE__ */ op({ raggedGather_ });
    function raggedRange_(starts, limits, deltas) {
      var $starts = convertToTensor(starts, "starts", "raggedRange");
      var $limits = convertToTensor(limits, "limits", "raggedRange", $starts.dtype);
      var $deltas = convertToTensor(deltas, "deltas", "raggedRange", $starts.dtype);
      var inputs = {
        starts: $starts,
        limits: $limits,
        deltas: $deltas
      };
      var result = ENGINE.runKernel(RaggedRange, inputs);
      return {
        rtNestedSplits: result[0],
        rtDenseValues: result[1]
      };
    }
    var raggedRange = /* @__PURE__ */ op({ raggedRange_ });
    function raggedTensorToTensor_(shape, values, defaultValue, rowPartitionTensors, rowPartitionTypes) {
      var $shape = convertToTensor(shape, "shape", "raggedTensorToTensor", "int32");
      var $values = convertToTensor(values, "values", "raggedTensorToTensor");
      var $defaultValue = convertToTensor(defaultValue, "defaultValue", "raggedTensorToTensor", $values.dtype);
      var $rowPartitionTensors = rowPartitionTensors.map(function(t, i) {
        return convertToTensor(t, "tensors".concat(i), "raggedTensorToTensor", "int32");
      });
      var inputs = {
        shape: $shape,
        values: $values,
        defaultValue: $defaultValue,
        rowPartitionTensors: $rowPartitionTensors
      };
      var attrs = { rowPartitionTypes };
      return ENGINE.runKernel(RaggedTensorToTensor, inputs, attrs);
    }
    var raggedTensorToTensor = /* @__PURE__ */ op({ raggedTensorToTensor_ });
    function rand_(shape, randFunction, dtype) {
      assertNonNegativeIntegerDimensions(shape);
      var size = sizeFromShape(shape);
      var values = null;
      if (dtype == null || dtype === "float32") {
        values = new Float32Array(size);
      } else if (dtype === "int32") {
        values = new Int32Array(size);
      } else if (dtype === "bool") {
        values = new Uint8Array(size);
      } else {
        throw new Error("Unknown data type ".concat(dtype));
      }
      for (var i = 0; i < size; i++) {
        values[i] = randFunction();
      }
      return ENGINE.makeTensor(values, shape, dtype);
    }
    var rand = /* @__PURE__ */ op({ rand_ });
    var alea$1 = { exports: {} };
    (function(module3) {
      (function(global2, module4, define) {
        function Alea(seed) {
          var me = this, mash = Mash();
          me.next = function() {
            var t = 2091639 * me.s0 + me.c * 23283064365386963e-26;
            me.s0 = me.s1;
            me.s1 = me.s2;
            return me.s2 = t - (me.c = t | 0);
          };
          me.c = 1;
          me.s0 = mash(" ");
          me.s1 = mash(" ");
          me.s2 = mash(" ");
          me.s0 -= mash(seed);
          if (me.s0 < 0) {
            me.s0 += 1;
          }
          me.s1 -= mash(seed);
          if (me.s1 < 0) {
            me.s1 += 1;
          }
          me.s2 -= mash(seed);
          if (me.s2 < 0) {
            me.s2 += 1;
          }
          mash = null;
        }
        function copy(f, t) {
          t.c = f.c;
          t.s0 = f.s0;
          t.s1 = f.s1;
          t.s2 = f.s2;
          return t;
        }
        function impl(seed, opts) {
          var xg = new Alea(seed), state = opts && opts.state, prng = xg.next;
          prng.int32 = function() {
            return xg.next() * 4294967296 | 0;
          };
          prng.double = function() {
            return prng() + (prng() * 2097152 | 0) * 11102230246251565e-32;
          };
          prng.quick = prng;
          if (state) {
            if (typeof state == "object")
              copy(state, xg);
            prng.state = function() {
              return copy(xg, {});
            };
          }
          return prng;
        }
        function Mash() {
          var n = 4022871197;
          var mash = function(data) {
            data = String(data);
            for (var i = 0; i < data.length; i++) {
              n += data.charCodeAt(i);
              var h = 0.02519603282416938 * n;
              n = h >>> 0;
              h -= n;
              h *= n;
              n = h >>> 0;
              h -= n;
              n += h * 4294967296;
            }
            return (n >>> 0) * 23283064365386963e-26;
          };
          return mash;
        }
        if (module4 && module4.exports) {
          module4.exports = impl;
        } else if (define && define.amd) {
          define(function() {
            return impl;
          });
        } else {
          this.alea = impl;
        }
      })(
        commonjsGlobal,
        module3,
        // present in node.js
        false
        // present with an AMD loader
      );
    })(alea$1);
    var aleaExports = alea$1.exports;
    var xor128$1 = { exports: {} };
    (function(module3) {
      (function(global2, module4, define) {
        function XorGen(seed) {
          var me = this, strseed = "";
          me.x = 0;
          me.y = 0;
          me.z = 0;
          me.w = 0;
          me.next = function() {
            var t = me.x ^ me.x << 11;
            me.x = me.y;
            me.y = me.z;
            me.z = me.w;
            return me.w ^= me.w >>> 19 ^ t ^ t >>> 8;
          };
          if (seed === (seed | 0)) {
            me.x = seed;
          } else {
            strseed += seed;
          }
          for (var k = 0; k < strseed.length + 64; k++) {
            me.x ^= strseed.charCodeAt(k) | 0;
            me.next();
          }
        }
        function copy(f, t) {
          t.x = f.x;
          t.y = f.y;
          t.z = f.z;
          t.w = f.w;
          return t;
        }
        function impl(seed, opts) {
          var xg = new XorGen(seed), state = opts && opts.state, prng = function() {
            return (xg.next() >>> 0) / 4294967296;
          };
          prng.double = function() {
            do {
              var top = xg.next() >>> 11, bot = (xg.next() >>> 0) / 4294967296, result = (top + bot) / (1 << 21);
            } while (result === 0);
            return result;
          };
          prng.int32 = xg.next;
          prng.quick = prng;
          if (state) {
            if (typeof state == "object")
              copy(state, xg);
            prng.state = function() {
              return copy(xg, {});
            };
          }
          return prng;
        }
        if (module4 && module4.exports) {
          module4.exports = impl;
        } else if (define && define.amd) {
          define(function() {
            return impl;
          });
        } else {
          this.xor128 = impl;
        }
      })(
        commonjsGlobal,
        module3,
        // present in node.js
        false
        // present with an AMD loader
      );
    })(xor128$1);
    var xor128Exports = xor128$1.exports;
    var xorwow$1 = { exports: {} };
    (function(module3) {
      (function(global2, module4, define) {
        function XorGen(seed) {
          var me = this, strseed = "";
          me.next = function() {
            var t = me.x ^ me.x >>> 2;
            me.x = me.y;
            me.y = me.z;
            me.z = me.w;
            me.w = me.v;
            return (me.d = me.d + 362437 | 0) + (me.v = me.v ^ me.v << 4 ^ (t ^ t << 1)) | 0;
          };
          me.x = 0;
          me.y = 0;
          me.z = 0;
          me.w = 0;
          me.v = 0;
          if (seed === (seed | 0)) {
            me.x = seed;
          } else {
            strseed += seed;
          }
          for (var k = 0; k < strseed.length + 64; k++) {
            me.x ^= strseed.charCodeAt(k) | 0;
            if (k == strseed.length) {
              me.d = me.x << 10 ^ me.x >>> 4;
            }
            me.next();
          }
        }
        function copy(f, t) {
          t.x = f.x;
          t.y = f.y;
          t.z = f.z;
          t.w = f.w;
          t.v = f.v;
          t.d = f.d;
          return t;
        }
        function impl(seed, opts) {
          var xg = new XorGen(seed), state = opts && opts.state, prng = function() {
            return (xg.next() >>> 0) / 4294967296;
          };
          prng.double = function() {
            do {
              var top = xg.next() >>> 11, bot = (xg.next() >>> 0) / 4294967296, result = (top + bot) / (1 << 21);
            } while (result === 0);
            return result;
          };
          prng.int32 = xg.next;
          prng.quick = prng;
          if (state) {
            if (typeof state == "object")
              copy(state, xg);
            prng.state = function() {
              return copy(xg, {});
            };
          }
          return prng;
        }
        if (module4 && module4.exports) {
          module4.exports = impl;
        } else if (define && define.amd) {
          define(function() {
            return impl;
          });
        } else {
          this.xorwow = impl;
        }
      })(
        commonjsGlobal,
        module3,
        // present in node.js
        false
        // present with an AMD loader
      );
    })(xorwow$1);
    var xorwowExports = xorwow$1.exports;
    var xorshift7$1 = { exports: {} };
    (function(module3) {
      (function(global2, module4, define) {
        function XorGen(seed) {
          var me = this;
          me.next = function() {
            var X = me.x, i = me.i, t, v;
            t = X[i];
            t ^= t >>> 7;
            v = t ^ t << 24;
            t = X[i + 1 & 7];
            v ^= t ^ t >>> 10;
            t = X[i + 3 & 7];
            v ^= t ^ t >>> 3;
            t = X[i + 4 & 7];
            v ^= t ^ t << 7;
            t = X[i + 7 & 7];
            t = t ^ t << 13;
            v ^= t ^ t << 9;
            X[i] = v;
            me.i = i + 1 & 7;
            return v;
          };
          function init(me2, seed2) {
            var j, X = [];
            if (seed2 === (seed2 | 0)) {
              X[0] = seed2;
            } else {
              seed2 = "" + seed2;
              for (j = 0; j < seed2.length; ++j) {
                X[j & 7] = X[j & 7] << 15 ^ seed2.charCodeAt(j) + X[j + 1 & 7] << 13;
              }
            }
            while (X.length < 8)
              X.push(0);
            for (j = 0; j < 8 && X[j] === 0; ++j)
              ;
            if (j == 8)
              X[7] = -1;
            else
              X[j];
            me2.x = X;
            me2.i = 0;
            for (j = 256; j > 0; --j) {
              me2.next();
            }
          }
          init(me, seed);
        }
        function copy(f, t) {
          t.x = f.x.slice();
          t.i = f.i;
          return t;
        }
        function impl(seed, opts) {
          if (seed == null)
            seed = +/* @__PURE__ */ new Date();
          var xg = new XorGen(seed), state = opts && opts.state, prng = function() {
            return (xg.next() >>> 0) / 4294967296;
          };
          prng.double = function() {
            do {
              var top = xg.next() >>> 11, bot = (xg.next() >>> 0) / 4294967296, result = (top + bot) / (1 << 21);
            } while (result === 0);
            return result;
          };
          prng.int32 = xg.next;
          prng.quick = prng;
          if (state) {
            if (state.x)
              copy(state, xg);
            prng.state = function() {
              return copy(xg, {});
            };
          }
          return prng;
        }
        if (module4 && module4.exports) {
          module4.exports = impl;
        } else if (define && define.amd) {
          define(function() {
            return impl;
          });
        } else {
          this.xorshift7 = impl;
        }
      })(
        commonjsGlobal,
        module3,
        // present in node.js
        false
        // present with an AMD loader
      );
    })(xorshift7$1);
    var xorshift7Exports = xorshift7$1.exports;
    var xor4096$1 = { exports: {} };
    (function(module3) {
      (function(global2, module4, define) {
        function XorGen(seed) {
          var me = this;
          me.next = function() {
            var w = me.w, X = me.X, i = me.i, t, v;
            me.w = w = w + 1640531527 | 0;
            v = X[i + 34 & 127];
            t = X[i = i + 1 & 127];
            v ^= v << 13;
            t ^= t << 17;
            v ^= v >>> 15;
            t ^= t >>> 12;
            v = X[i] = v ^ t;
            me.i = i;
            return v + (w ^ w >>> 16) | 0;
          };
          function init(me2, seed2) {
            var t, v, i, j, w, X = [], limit = 128;
            if (seed2 === (seed2 | 0)) {
              v = seed2;
              seed2 = null;
            } else {
              seed2 = seed2 + "\0";
              v = 0;
              limit = Math.max(limit, seed2.length);
            }
            for (i = 0, j = -32; j < limit; ++j) {
              if (seed2)
                v ^= seed2.charCodeAt((j + 32) % seed2.length);
              if (j === 0)
                w = v;
              v ^= v << 10;
              v ^= v >>> 15;
              v ^= v << 4;
              v ^= v >>> 13;
              if (j >= 0) {
                w = w + 1640531527 | 0;
                t = X[j & 127] ^= v + w;
                i = 0 == t ? i + 1 : 0;
              }
            }
            if (i >= 128) {
              X[(seed2 && seed2.length || 0) & 127] = -1;
            }
            i = 127;
            for (j = 4 * 128; j > 0; --j) {
              v = X[i + 34 & 127];
              t = X[i = i + 1 & 127];
              v ^= v << 13;
              t ^= t << 17;
              v ^= v >>> 15;
              t ^= t >>> 12;
              X[i] = v ^ t;
            }
            me2.w = w;
            me2.X = X;
            me2.i = i;
          }
          init(me, seed);
        }
        function copy(f, t) {
          t.i = f.i;
          t.w = f.w;
          t.X = f.X.slice();
          return t;
        }
        function impl(seed, opts) {
          if (seed == null)
            seed = +/* @__PURE__ */ new Date();
          var xg = new XorGen(seed), state = opts && opts.state, prng = function() {
            return (xg.next() >>> 0) / 4294967296;
          };
          prng.double = function() {
            do {
              var top = xg.next() >>> 11, bot = (xg.next() >>> 0) / 4294967296, result = (top + bot) / (1 << 21);
            } while (result === 0);
            return result;
          };
          prng.int32 = xg.next;
          prng.quick = prng;
          if (state) {
            if (state.X)
              copy(state, xg);
            prng.state = function() {
              return copy(xg, {});
            };
          }
          return prng;
        }
        if (module4 && module4.exports) {
          module4.exports = impl;
        } else if (define && define.amd) {
          define(function() {
            return impl;
          });
        } else {
          this.xor4096 = impl;
        }
      })(
        commonjsGlobal,
        // window object or global
        module3,
        // present in node.js
        false
        // present with an AMD loader
      );
    })(xor4096$1);
    var xor4096Exports = xor4096$1.exports;
    var tychei$1 = { exports: {} };
    (function(module3) {
      (function(global2, module4, define) {
        function XorGen(seed) {
          var me = this, strseed = "";
          me.next = function() {
            var b = me.b, c = me.c, d = me.d, a = me.a;
            b = b << 25 ^ b >>> 7 ^ c;
            c = c - d | 0;
            d = d << 24 ^ d >>> 8 ^ a;
            a = a - b | 0;
            me.b = b = b << 20 ^ b >>> 12 ^ c;
            me.c = c = c - d | 0;
            me.d = d << 16 ^ c >>> 16 ^ a;
            return me.a = a - b | 0;
          };
          me.a = 0;
          me.b = 0;
          me.c = 2654435769 | 0;
          me.d = 1367130551;
          if (seed === Math.floor(seed)) {
            me.a = seed / 4294967296 | 0;
            me.b = seed | 0;
          } else {
            strseed += seed;
          }
          for (var k = 0; k < strseed.length + 20; k++) {
            me.b ^= strseed.charCodeAt(k) | 0;
            me.next();
          }
        }
        function copy(f, t) {
          t.a = f.a;
          t.b = f.b;
          t.c = f.c;
          t.d = f.d;
          return t;
        }
        function impl(seed, opts) {
          var xg = new XorGen(seed), state = opts && opts.state, prng = function() {
            return (xg.next() >>> 0) / 4294967296;
          };
          prng.double = function() {
            do {
              var top = xg.next() >>> 11, bot = (xg.next() >>> 0) / 4294967296, result = (top + bot) / (1 << 21);
            } while (result === 0);
            return result;
          };
          prng.int32 = xg.next;
          prng.quick = prng;
          if (state) {
            if (typeof state == "object")
              copy(state, xg);
            prng.state = function() {
              return copy(xg, {});
            };
          }
          return prng;
        }
        if (module4 && module4.exports) {
          module4.exports = impl;
        } else if (define && define.amd) {
          define(function() {
            return impl;
          });
        } else {
          this.tychei = impl;
        }
      })(
        commonjsGlobal,
        module3,
        // present in node.js
        false
        // present with an AMD loader
      );
    })(tychei$1);
    var tycheiExports = tychei$1.exports;
    var seedrandom$1 = { exports: {} };
    (function(module3) {
      (function(global2, pool2, math2) {
        var width = 256, chunks = 6, digits = 52, rngname = "random", startdenom = math2.pow(width, chunks), significance = math2.pow(2, digits), overflow = significance * 2, mask = width - 1, nodecrypto;
        function seedrandom2(seed, options, callback) {
          var key = [];
          options = options == true ? { entropy: true } : options || {};
          var shortseed = mixkey(flatten2(options.entropy ? [seed, tostring(pool2)] : seed == null ? autoseed() : seed, 3), key);
          var arc4 = new ARC4(key);
          var prng = function() {
            var n = arc4.g(chunks), d = startdenom, x = 0;
            while (n < significance) {
              n = (n + x) * width;
              d *= width;
              x = arc4.g(1);
            }
            while (n >= overflow) {
              n /= 2;
              d /= 2;
              x >>>= 1;
            }
            return (n + x) / d;
          };
          prng.int32 = function() {
            return arc4.g(4) | 0;
          };
          prng.quick = function() {
            return arc4.g(4) / 4294967296;
          };
          prng.double = prng;
          mixkey(tostring(arc4.S), pool2);
          return (options.pass || callback || function(prng2, seed2, is_math_call, state) {
            if (state) {
              if (state.S) {
                copy(state, arc4);
              }
              prng2.state = function() {
                return copy(arc4, {});
              };
            }
            if (is_math_call) {
              math2[rngname] = prng2;
              return seed2;
            } else
              return prng2;
          })(prng, shortseed, "global" in options ? options.global : this == math2, options.state);
        }
        function ARC4(key) {
          var t, keylen = key.length, me = this, i = 0, j = me.i = me.j = 0, s = me.S = [];
          if (!keylen) {
            key = [keylen++];
          }
          while (i < width) {
            s[i] = i++;
          }
          for (i = 0; i < width; i++) {
            s[i] = s[j = mask & j + key[i % keylen] + (t = s[i])];
            s[j] = t;
          }
          (me.g = function(count) {
            var t2, r = 0, i2 = me.i, j2 = me.j, s2 = me.S;
            while (count--) {
              t2 = s2[i2 = mask & i2 + 1];
              r = r * width + s2[mask & (s2[i2] = s2[j2 = mask & j2 + t2]) + (s2[j2] = t2)];
            }
            me.i = i2;
            me.j = j2;
            return r;
          })(width);
        }
        function copy(f, t) {
          t.i = f.i;
          t.j = f.j;
          t.S = f.S.slice();
          return t;
        }
        function flatten2(obj, depth) {
          var result = [], typ = typeof obj, prop;
          if (depth && typ == "object") {
            for (prop in obj) {
              try {
                result.push(flatten2(obj[prop], depth - 1));
              } catch (e) {
              }
            }
          }
          return result.length ? result : typ == "string" ? obj : obj + "\0";
        }
        function mixkey(seed, key) {
          var stringseed = seed + "", smear, j = 0;
          while (j < stringseed.length) {
            key[mask & j] = mask & (smear ^= key[mask & j] * 19) + stringseed.charCodeAt(j++);
          }
          return tostring(key);
        }
        function autoseed() {
          try {
            var out;
            if (nodecrypto && (out = nodecrypto.randomBytes)) {
              out = out(width);
            } else {
              out = new Uint8Array(width);
              (global2.crypto || global2.msCrypto).getRandomValues(out);
            }
            return tostring(out);
          } catch (e) {
            var browser2 = global2.navigator, plugins = browser2 && browser2.plugins;
            return [+/* @__PURE__ */ new Date(), global2, plugins, global2.screen, tostring(pool2)];
          }
        }
        function tostring(a) {
          return String.fromCharCode.apply(0, a);
        }
        mixkey(math2.random(), pool2);
        if (module3.exports) {
          module3.exports = seedrandom2;
          try {
            nodecrypto = require("crypto");
          } catch (ex) {
          }
        } else {
          math2["seed" + rngname] = seedrandom2;
        }
      })(
        // global: `self` in browsers (including strict mode and web workers),
        // otherwise `this` in Node and other environments
        typeof self !== "undefined" ? self : commonjsGlobal,
        [],
        // pool: entropy pool starts empty
        Math
        // math: package containing random, pow, and seedrandom
      );
    })(seedrandom$1);
    var seedrandomExports = seedrandom$1.exports;
    var alea = aleaExports;
    var xor128 = xor128Exports;
    var xorwow = xorwowExports;
    var xorshift7 = xorshift7Exports;
    var xor4096 = xor4096Exports;
    var tychei = tycheiExports;
    var sr = seedrandomExports;
    sr.alea = alea;
    sr.xor128 = xor128;
    sr.xorwow = xorwow;
    sr.xorshift7 = xorshift7;
    sr.xor4096 = xor4096;
    sr.tychei = tychei;
    var seedrandom = sr;
    var TEST_EPSILON_FLOAT32 = 1e-3;
    var TEST_EPSILON_FLOAT16 = 0.1;
    function expectArraysClose(actual, expected, epsilon) {
      if (epsilon == null) {
        epsilon = testEpsilon();
      }
      return expectArraysPredicate(actual, expected, function(a, b) {
        return areClose(a, b, epsilon);
      });
    }
    function testEpsilon() {
      return ENGINE.backend.floatPrecision() === 32 ? TEST_EPSILON_FLOAT32 : TEST_EPSILON_FLOAT16;
    }
    function expectArraysPredicate(actual, expected, predicate) {
      var checkClassType = true;
      if (isTypedArray(actual) || isTypedArray(expected)) {
        checkClassType = false;
      }
      if (isTypedArray(actual) && isTypedArray(expected)) {
        checkClassType = true;
      }
      if (checkClassType) {
        var aType = actual.constructor.name;
        var bType = expected.constructor.name;
        if (aType !== bType) {
          throw new Error("Arrays are of different type. Actual: ".concat(aType, ". ") + "Expected: ".concat(bType));
        }
      }
      if (Array.isArray(actual) && Array.isArray(expected)) {
        var actualShape = inferShape(actual);
        var expectedShape = inferShape(expected);
        if (!arraysEqual(actualShape, expectedShape)) {
          throw new Error("Arrays have different shapes. " + "Actual: [".concat(actualShape, "]. Expected: [").concat(expectedShape, "]"));
        }
      }
      var actualFlat = isTypedArray(actual) ? actual : flatten(actual);
      var expectedFlat = isTypedArray(expected) ? expected : flatten(expected);
      if (actualFlat.length !== expectedFlat.length) {
        throw new Error("Arrays have different lengths actual: ".concat(actualFlat.length, " vs ") + "expected: ".concat(expectedFlat.length, ".\n") + "Actual:   ".concat(actualFlat, ".\n") + "Expected: ".concat(expectedFlat, "."));
      }
      for (var i = 0; i < expectedFlat.length; ++i) {
        var a = actualFlat[i];
        var e = expectedFlat[i];
        if (!predicate(a, e)) {
          throw new Error("Arrays differ: actual[".concat(i, "] = ").concat(a, ", expected[").concat(i, "] = ").concat(e, ".\n") + "Actual:   ".concat(actualFlat, ".\n") + "Expected: ".concat(expectedFlat, "."));
        }
      }
      if (typeof expect !== "undefined") {
        expect().nothing();
      }
    }
    function expectPromiseToFail(fn, done) {
      fn().then(function() {
        return done.fail();
      }, function() {
        return done();
      });
      if (typeof expect !== "undefined") {
        expect().nothing();
      }
    }
    function expectArraysEqual(actual, expected) {
      var exp2 = typeof expected === "string" || typeof expected === "number" || typeof expected === "boolean" ? [expected] : expected;
      if (isString(actual) || isString(actual[0]) || isString(expected) || isString(expected[0])) {
        return expectArraysPredicate(actual, exp2, function(a, b) {
          return a == b;
        });
      }
      return expectArraysPredicate(actual, expected, function(a, b) {
        return areClose(a, b, 0);
      });
    }
    function expectNumbersClose(a, e, epsilon) {
      if (epsilon == null) {
        epsilon = testEpsilon();
      }
      if (!areClose(a, e, epsilon)) {
        throw new Error("Numbers differ: actual === ".concat(a, ", expected === ").concat(e));
      }
      if (typeof expect !== "undefined") {
        expect().nothing();
      }
    }
    function areClose(a, e, epsilon) {
      if (!isFinite(a) && !isFinite(e)) {
        return true;
      }
      if (isNaN(a) || isNaN(e) || Math.abs(a - e) > epsilon) {
        return false;
      }
      return true;
    }
    function expectValuesInRange(actual, low, high) {
      for (var i = 0; i < actual.length; i++) {
        if (actual[i] < low || actual[i] > high) {
          throw new Error("Value out of range:".concat(actual[i], " low: ").concat(low, ", high: ").concat(high));
        }
      }
    }
    function expectArrayBuffersEqual(actual, expected) {
      var actualArray = new Float32Array(actual);
      var expectedArray = new Float32Array(expected);
      if (actualArray.length !== expectedArray.length) {
        throw new Error("Expected ArrayBuffer to be of length " + "".concat(expectedArray.length, ", but it was ").concat(actualArray.length));
      }
      for (var i = 0; i < expectedArray.length; i++) {
        if (actualArray[i] !== expectedArray[i]) {
          throw new Error("Expected ArrayBuffer value at ".concat(i, " to be ") + "".concat(expectedArray[i], " but got ").concat(actualArray[i], " instead"));
        }
      }
    }
    function encodeStrings(a) {
      for (var i = 0; i < a.length; i++) {
        var val = a[i];
        if (Array.isArray(val)) {
          encodeStrings(val);
        } else {
          a[i] = encodeString(val);
        }
      }
      return a;
    }
    function createVideoElement(source) {
      var video = document.createElement("video");
      if ("playsInline" in video) {
        video.playsInline = true;
      }
      video.muted = true;
      video.loop = true;
      video.style.position = "fixed";
      video.style.left = "0px";
      video.style.top = "0px";
      video.preload = "auto";
      video.appendChild(source);
      return new Promise(function(resolve2) {
        video.addEventListener("loadeddata", function(_) {
          return resolve2(video);
        });
        video.load();
      });
    }
    function play(video) {
      return __awaiter(this, void 0, void 0, function() {
        return __generator(this, function(_a) {
          switch (_a.label) {
            case 0:
              return [4, video.play()];
            case 1:
              _a.sent();
              if (!("requestVideoFrameCallback" in video))
                return [3, 3];
              return [4, new Promise(function(resolve2) {
                video.requestVideoFrameCallback(resolve2);
              })];
            case 2:
              _a.sent();
              _a.label = 3;
            case 3:
              return [
                2
                /*return*/
              ];
          }
        });
      });
    }
    var test_util = {
      __proto__: null,
      TEST_EPSILON_FLOAT16,
      createVideoElement,
      encodeStrings,
      expectArrayBuffersEqual,
      expectArraysClose,
      expectArraysEqual,
      expectNumbersClose,
      expectPromiseToFail,
      expectValuesInRange,
      play,
      testEpsilon
    };
    var MPRandGauss = (
      /** @class */
      function() {
        function MPRandGauss2(mean2, stdDeviation, dtype, truncated, seed) {
          this.mean = mean2;
          this.stdDev = stdDeviation;
          this.dtype = dtype;
          this.nextVal = NaN;
          this.truncated = truncated;
          if (this.truncated) {
            this.upper = this.mean + this.stdDev * 2;
            this.lower = this.mean - this.stdDev * 2;
          }
          var seedValue = seed ? seed : Math.random();
          this.random = seedrandom.alea(seedValue.toString());
        }
        MPRandGauss2.prototype.nextValue = function() {
          if (!isNaN(this.nextVal)) {
            var value = this.nextVal;
            this.nextVal = NaN;
            return value;
          }
          var resultX, resultY;
          var isValid = false;
          while (!isValid) {
            var v1 = void 0, v2 = void 0, s = void 0;
            do {
              v1 = 2 * this.random() - 1;
              v2 = 2 * this.random() - 1;
              s = v1 * v1 + v2 * v2;
            } while (s >= 1 || s === 0);
            var mul2 = Math.sqrt(-2 * Math.log(s) / s);
            resultX = this.mean + this.stdDev * v1 * mul2;
            resultY = this.mean + this.stdDev * v2 * mul2;
            if (!this.truncated || this.isValidTruncated(resultX)) {
              isValid = true;
            }
          }
          if (!this.truncated || this.isValidTruncated(resultY)) {
            this.nextVal = this.convertValue(resultY);
          }
          return this.convertValue(resultX);
        };
        MPRandGauss2.prototype.convertValue = function(value) {
          if (this.dtype == null || this.dtype === "float32") {
            return value;
          }
          return Math.round(value);
        };
        MPRandGauss2.prototype.isValidTruncated = function(value) {
          return value <= this.upper && value >= this.lower;
        };
        return MPRandGauss2;
      }()
    );
    var RandGamma = (
      /** @class */
      function() {
        function RandGamma2(alpha, beta, dtype, seed) {
          this.alpha = alpha;
          this.beta = 1 / beta;
          this.dtype = dtype;
          var seedValue = seed ? seed : Math.random();
          this.randu = seedrandom.alea(seedValue.toString());
          this.randn = new MPRandGauss(0, 1, dtype, false, this.randu());
          if (alpha < 1) {
            this.d = alpha + 2 / 3;
          } else {
            this.d = alpha - 1 / 3;
          }
          this.c = 1 / Math.sqrt(9 * this.d);
        }
        RandGamma2.prototype.nextValue = function() {
          var x2, v0, v1, x, u, v;
          while (true) {
            do {
              x = this.randn.nextValue();
              v = 1 + this.c * x;
            } while (v <= 0);
            v *= v * v;
            x2 = x * x;
            v0 = 1 - 0.331 * x2 * x2;
            v1 = 0.5 * x2 + this.d * (1 - v + Math.log(v));
            u = this.randu();
            if (u < v0 || Math.log(u) < v1) {
              break;
            }
          }
          v = 1 / this.beta * this.d * v;
          if (this.alpha < 1) {
            v *= Math.pow(this.randu(), 1 / this.alpha);
          }
          return this.convertValue(v);
        };
        RandGamma2.prototype.convertValue = function(value) {
          if (this.dtype === "float32") {
            return value;
          }
          return Math.round(value);
        };
        return RandGamma2;
      }()
    );
    var UniformRandom = (
      /** @class */
      function() {
        function UniformRandom2(min2, max2, dtype, seed) {
          if (min2 === void 0) {
            min2 = 0;
          }
          if (max2 === void 0) {
            max2 = 1;
          }
          var _this = this;
          this.canReturnFloat = function() {
            return _this.dtype == null || _this.dtype === "float32";
          };
          this.min = min2;
          this.range = max2 - min2;
          this.dtype = dtype;
          if (seed == null) {
            seed = Math.random();
          }
          if (typeof seed === "number") {
            seed = seed.toString();
          }
          if (!this.canReturnFloat() && this.range <= 1) {
            throw new Error("The difference between ".concat(min2, " - ").concat(max2, " <= 1 and dtype is not float"));
          }
          this.random = seedrandom.alea(seed);
        }
        UniformRandom2.prototype.convertValue = function(value) {
          if (this.canReturnFloat()) {
            return value;
          }
          return Math.round(value);
        };
        UniformRandom2.prototype.nextValue = function() {
          return this.convertValue(this.min + this.range * this.random());
        };
        return UniformRandom2;
      }()
    );
    function randomGamma_(shape, alpha, beta, dtype, seed) {
      if (beta === void 0) {
        beta = 1;
      }
      if (dtype === void 0) {
        dtype = "float32";
      }
      assertNonNegativeIntegerDimensions(shape);
      if (beta == null) {
        beta = 1;
      }
      if (dtype == null) {
        dtype = "float32";
      }
      if (dtype !== "float32" && dtype !== "int32") {
        throw new Error("Unsupported data type ".concat(dtype));
      }
      var rgamma = new RandGamma(alpha, beta, dtype, seed);
      var res = buffer(shape, dtype);
      for (var i = 0; i < res.values.length; i++) {
        res.values[i] = rgamma.nextValue();
      }
      return res.toTensor();
    }
    var randomGamma = /* @__PURE__ */ op({ randomGamma_ });
    function randomNormal_(shape, mean2, stdDev, dtype, seed) {
      if (mean2 === void 0) {
        mean2 = 0;
      }
      if (stdDev === void 0) {
        stdDev = 1;
      }
      assertNonNegativeIntegerDimensions(shape);
      if (dtype != null && dtype === "bool") {
        throw new Error("Unsupported data type ".concat(dtype));
      }
      var randGauss = new MPRandGauss(mean2, stdDev, dtype, false, seed);
      var res = buffer(shape, dtype);
      for (var i = 0; i < res.values.length; i++) {
        res.values[i] = randGauss.nextValue();
      }
      return res.toTensor();
    }
    var randomNormal = /* @__PURE__ */ op({ randomNormal_ });
    function randomStandardNormal_(shape, dtype, seed) {
      if (dtype != null && dtype === "bool") {
        throw new Error("Unsupported data type ".concat(dtype));
      }
      return randomNormal(shape, 0, 1, dtype, seed);
    }
    var randomStandardNormal = /* @__PURE__ */ op({ randomStandardNormal_ });
    function randomUniform_(shape, minval, maxval, dtype, seed) {
      if (minval === void 0) {
        minval = 0;
      }
      if (maxval === void 0) {
        maxval = 1;
      }
      if (dtype === void 0) {
        dtype = "float32";
      }
      assertNonNegativeIntegerDimensions(shape);
      var res = buffer(shape, dtype);
      var random = new UniformRandom(minval, maxval, null, seed);
      for (var i = 0; i < res.values.length; i++) {
        res.values[i] = random.nextValue();
      }
      return res.toTensor();
    }
    var randomUniform = /* @__PURE__ */ op({ randomUniform_ });
    function randomUniformInt_(shape, minval, maxval, seed) {
      return randomUniform(shape, minval, maxval, "int32", seed);
    }
    var randomUniformInt = /* @__PURE__ */ op({ randomUniformInt_ });
    function range(start, stop, step2, dtype) {
      if (step2 === void 0) {
        step2 = 1;
      }
      if (dtype === void 0) {
        dtype = "float32";
      }
      if (step2 === 0) {
        throw new Error("Cannot have a step of zero");
      }
      var attrs = { start, stop, step: step2, dtype };
      return ENGINE.runKernel(Range, {}, attrs);
    }
    function real_(input) {
      var $input = convertToTensor(input, "input", "real");
      var inputs = { input: $input };
      return ENGINE.runKernel(Real, inputs);
    }
    var real = /* @__PURE__ */ op({ real_ });
    function reciprocal_(x) {
      var $x = convertToTensor(x, "x", "reciprocal");
      var inputs = { x: $x };
      return ENGINE.runKernel(Reciprocal, inputs);
    }
    var reciprocal = /* @__PURE__ */ op({ reciprocal_ });
    function relu_(x) {
      var $x = convertToTensor(x, "x", "relu");
      var inputs = { x: $x };
      return ENGINE.runKernel(Relu, inputs);
    }
    var relu = /* @__PURE__ */ op({ relu_ });
    function relu6_(x) {
      var $x = convertToTensor(x, "x", "relu6");
      var inputs = { x: $x };
      return ENGINE.runKernel(Relu6, inputs);
    }
    var relu6 = /* @__PURE__ */ op({ relu6_ });
    function reverse_(x, axis) {
      var $x = convertToTensor(x, "x", "reverse");
      var inputs = { x: $x };
      var attrs = { dims: axis };
      return ENGINE.runKernel(Reverse, inputs, attrs);
    }
    var reverse = /* @__PURE__ */ op({ reverse_ });
    function reverse1d_(x) {
      var $x = convertToTensor(x, "x", "reverse");
      assert($x.rank === 1, function() {
        return "Error in reverse1D: x must be rank 1 but got rank ".concat($x.rank, ".");
      });
      return reverse($x, 0);
    }
    var reverse1d = /* @__PURE__ */ op({ reverse1d_ });
    function reverse2d_(x, axis) {
      var $x = convertToTensor(x, "x", "reverse");
      assert($x.rank === 2, function() {
        return "Error in reverse2D: x must be rank 2 but got rank ".concat($x.rank, ".");
      });
      return reverse($x, axis);
    }
    var reverse2d = /* @__PURE__ */ op({ reverse2d_ });
    function reverse3d_(x, axis) {
      var $x = convertToTensor(x, "x", "reverse");
      assert($x.rank === 3, function() {
        return "Error in reverse3D: x must be rank 3 but got rank ".concat($x.rank, ".");
      });
      return reverse($x, axis);
    }
    var reverse3d = /* @__PURE__ */ op({ reverse3d_ });
    function reverse4d_(x, axis) {
      var $x = convertToTensor(x, "x", "reverse");
      assert($x.rank === 4, function() {
        return "Error in reverse4D: x must be rank 4 but got rank ".concat($x.rank, ".");
      });
      return reverse($x, axis);
    }
    var reverse4d = /* @__PURE__ */ op({ reverse4d_ });
    function round_(x) {
      var $x = convertToTensor(x, "x", "round");
      var inputs = { x: $x };
      return ENGINE.runKernel(Round, inputs);
    }
    var round = /* @__PURE__ */ op({ round_ });
    function rsqrt_(x) {
      var $x = convertToTensor(x, "x", "rsqrt", "float32");
      var inputs = { x: $x };
      return ENGINE.runKernel(Rsqrt, inputs);
    }
    var rsqrt = /* @__PURE__ */ op({ rsqrt_ });
    function selu_(x) {
      var $x = convertToTensor(x, "x", "selu");
      var inputs = { x: $x };
      return ENGINE.runKernel(Selu, inputs);
    }
    var selu = /* @__PURE__ */ op({ selu_ });
    function separableConv2d_(x, depthwiseFilter, pointwiseFilter, strides, pad2, dilation, dataFormat) {
      if (dilation === void 0) {
        dilation = [1, 1];
      }
      if (dataFormat === void 0) {
        dataFormat = "NHWC";
      }
      var $x = convertToTensor(x, "x", "separableConv2d");
      var $depthwiseFilter = convertToTensor(depthwiseFilter, "depthwiseFilter", "separableConv2d");
      var $pointwiseFilter = convertToTensor(pointwiseFilter, "pointwiseFilter", "separableConv2d");
      var x4D = $x;
      var reshapedTo4D = false;
      if ($x.rank === 3) {
        reshapedTo4D = true;
        x4D = reshape($x, [1, $x.shape[0], $x.shape[1], $x.shape[2]]);
      }
      if (dataFormat === "NCHW") {
        throw new Error("separableConv2d currently does not support dataFormat NCHW; only NHWC is supported");
      }
      assert(x4D.rank === 4, function() {
        return "Error in separableConv2d: input must be rank 4, but got " + "rank ".concat(x4D.rank, ".");
      });
      assert($depthwiseFilter.rank === 4, function() {
        return "Error in separableConv2d: depthwise filter must be rank 4, but " + "got rank ".concat($depthwiseFilter.rank, ".");
      });
      assert($pointwiseFilter.rank === 4, function() {
        return "Error in separableConv2d: pointwise filter must be rank 4, but " + "got rank ".concat($depthwiseFilter.rank, ".");
      });
      assert($pointwiseFilter.shape[0] === 1, function() {
        return "Error in separableConv2d: the first dimension of pointwise filter " + " must be 1, but got ".concat($pointwiseFilter.shape[0], ".");
      });
      assert($pointwiseFilter.shape[1] === 1, function() {
        return "Error in separableConv2d: the second dimension of pointwise " + "filter must be 1, but got ".concat($pointwiseFilter.shape[1], ".");
      });
      var inChannels = $depthwiseFilter.shape[2];
      var channelMultiplier = $depthwiseFilter.shape[3];
      assert($pointwiseFilter.shape[2] === inChannels * channelMultiplier, function() {
        return "Error in separableConv2d: the third dimension of pointwise filter " + "must be ".concat(inChannels * channelMultiplier, ", ") + "but got ".concat($pointwiseFilter.shape[2], ".");
      });
      var depthwise = depthwiseConv2d$1(x4D, $depthwiseFilter, strides, pad2, dataFormat, dilation);
      var pointwiseStride = 1;
      var res = conv2d$1(depthwise, $pointwiseFilter, pointwiseStride, "valid", dataFormat);
      if (reshapedTo4D) {
        return reshape(res, [res.shape[1], res.shape[2], res.shape[3]]);
      }
      return res;
    }
    var separableConv2d = /* @__PURE__ */ op({ separableConv2d_ });
    function setdiff1dAsync_(x, y) {
      return __awaiter(this, void 0, void 0, function() {
        var $x, $y, xVals, yVals, ySet, outputSize, i, buffer2, indices, i, p;
        return __generator(this, function(_a) {
          switch (_a.label) {
            case 0:
              $x = convertToTensor(x, "x", "setdiff1d");
              $y = convertToTensor(y, "y", "setdiff1d");
              assert($x.dtype === $y.dtype, function() {
                return "x and y should have the same dtype, but got x (".concat($x.dtype, ") and y (").concat($y.dtype, ").");
              });
              assert($x.rank === 1, function() {
                return "x should be 1D tensor, but got x (".concat($x.shape, ").");
              });
              assert($y.rank === 1, function() {
                return "y should be 1D tensor, but got y (".concat($y.shape, ").");
              });
              return [4, $x.data()];
            case 1:
              xVals = _a.sent();
              return [4, $y.data()];
            case 2:
              yVals = _a.sent();
              ySet = new Set(yVals);
              outputSize = 0;
              for (i = 0; i < xVals.length; i++) {
                if (!ySet.has(xVals[i])) {
                  outputSize++;
                }
              }
              buffer2 = new TensorBuffer([outputSize], $x.dtype);
              indices = new TensorBuffer([outputSize], "int32");
              for (i = 0, p = 0; i < xVals.length; i++) {
                if (!ySet.has(xVals[i])) {
                  buffer2.values[p] = xVals[i];
                  indices.values[p] = i;
                  p++;
                }
              }
              return [2, [buffer2.toTensor(), indices.toTensor()]];
          }
        });
      });
    }
    var setdiff1dAsync = setdiff1dAsync_;
    function sign_(x) {
      var $x = convertToTensor(x, "x", "sign");
      var inputs = { x: $x };
      return ENGINE.runKernel(Sign, inputs);
    }
    var sign = /* @__PURE__ */ op({ sign_ });
    function sin_(x) {
      var $x = convertToTensor(x, "x", "sin", "float32");
      var inputs = { x: $x };
      return ENGINE.runKernel(Sin, inputs);
    }
    var sin = /* @__PURE__ */ op({ sin_ });
    function sinh_(x) {
      var $x = convertToTensor(x, "x", "sinh");
      var inputs = { x: $x };
      return ENGINE.runKernel(Sinh, inputs);
    }
    var sinh = /* @__PURE__ */ op({ sinh_ });
    function slice1d_(x, begin, size) {
      var $x = convertToTensor(x, "x", "slice1d");
      assert($x.rank === 1, function() {
        return "slice1d expects a rank-1 tensor, but got a rank-".concat($x.rank, " tensor");
      });
      return slice($x, [begin], [size]);
    }
    var slice1d = /* @__PURE__ */ op({ slice1d_ });
    function slice2d_(x, begin, size) {
      var $x = convertToTensor(x, "x", "slice2d");
      assert($x.rank === 2, function() {
        return "slice2d expects a rank-2 tensor, but got a rank-".concat($x.rank, " tensor");
      });
      return slice($x, begin, size);
    }
    var slice2d = /* @__PURE__ */ op({ slice2d_ });
    function slice3d_(x, begin, size) {
      var $x = convertToTensor(x, "x", "slice3d");
      assert($x.rank === 3, function() {
        return "slice3d expects a rank-3 tensor, but got a rank-".concat($x.rank, " tensor");
      });
      return slice($x, begin, size);
    }
    var slice3d = /* @__PURE__ */ op({ slice3d_ });
    function slice4d_(x, begin, size) {
      var $x = convertToTensor(x, "x", "slice4d");
      assert($x.rank === 4, function() {
        return "slice4d expects a rank-4 tensor, but got a rank-".concat($x.rank, " tensor");
      });
      return slice($x, begin, size);
    }
    var slice4d = /* @__PURE__ */ op({ slice4d_ });
    function softmax_(logits, dim) {
      if (dim === void 0) {
        dim = -1;
      }
      var $logits = convertToTensor(logits, "logits", "softmax", "float32");
      if (dim === -1) {
        dim = $logits.rank - 1;
      }
      if (dim !== $logits.rank - 1) {
        throw Error("Softmax along a non-last dimension is not yet supported. " + "Logits was rank ".concat($logits.rank, " and dim was ").concat(dim));
      }
      var inputs = { logits: $logits };
      var attrs = { dim };
      return ENGINE.runKernel(Softmax, inputs, attrs);
    }
    var softmax = /* @__PURE__ */ op({ softmax_ });
    function fft_(input) {
      assert(input.dtype === "complex64", function() {
        return "The dtype for tf.spectral.fft() must be complex64 " + "but got ".concat(input.dtype, ".");
      });
      var inputs = { input };
      return ENGINE.runKernel(FFT, inputs);
    }
    var fft = /* @__PURE__ */ op({ fft_ });
    function ifft_(input) {
      assert(input.dtype === "complex64", function() {
        return "The dtype for tf.spectral.ifft() must be complex64 " + "but got ".concat(input.dtype, ".");
      });
      var inputs = { input };
      return ENGINE.runKernel(IFFT, inputs);
    }
    var ifft = /* @__PURE__ */ op({ ifft_ });
    function irfft_(input) {
      var innerDimensionSize = input.shape[input.shape.length - 1];
      var batch = input.size / innerDimensionSize;
      var ret;
      if (innerDimensionSize <= 2) {
        var complexInput = reshape(input, [batch, innerDimensionSize]);
        ret = ifft(complexInput);
      } else {
        var outputShape = [batch, 2 * (innerDimensionSize - 1)];
        var realInput = reshape(real(input), [batch, innerDimensionSize]);
        var imagInput = reshape(imag(input), [batch, innerDimensionSize]);
        var realConjugate = reverse(slice(realInput, [0, 1], [batch, innerDimensionSize - 2]), 1);
        var imagConjugate = mul(reverse(slice(imagInput, [0, 1], [batch, innerDimensionSize - 2]), 1), scalar(-1));
        var r = concat([realInput, realConjugate], 1);
        var i = concat([imagInput, imagConjugate], 1);
        var complexInput = reshape(complex(r, i), [outputShape[0], outputShape[1]]);
        ret = ifft(complexInput);
      }
      ret = real(ret);
      if (input.rank === 3 && input.shape[0] !== 0) {
        var temp = ret;
        var batch_1 = input.shape[0];
        ret = reshape(ret, [batch_1, ret.shape[0] / batch_1, ret.shape[1]]);
        temp.dispose();
      }
      return ret;
    }
    var irfft = /* @__PURE__ */ op({ irfft_ });
    function split_(x, numOrSizeSplits, axis) {
      if (axis === void 0) {
        axis = 0;
      }
      var $x = convertToTensor(x, "x", "split");
      var inputs = { x: $x };
      var attr = { numOrSizeSplits, axis };
      return ENGINE.runKernel(SplitV, inputs, attr);
    }
    var split = /* @__PURE__ */ op({ split_ });
    function rfft_(input, fftLength) {
      assert(input.dtype === "float32", function() {
        return "The dtype for rfft() must be real value but got ".concat(input.dtype);
      });
      var innerDimensionSize = input.shape[input.shape.length - 1];
      var batch = input.size / innerDimensionSize;
      var adjustedInput;
      if (fftLength != null && fftLength < innerDimensionSize) {
        var begin = input.shape.map(function(v) {
          return 0;
        });
        var size = input.shape.map(function(v) {
          return v;
        });
        size[input.shape.length - 1] = fftLength;
        adjustedInput = slice(input, begin, size);
        innerDimensionSize = fftLength;
      } else if (fftLength != null && fftLength > innerDimensionSize) {
        var zerosShape = input.shape.map(function(v) {
          return v;
        });
        zerosShape[input.shape.length - 1] = fftLength - innerDimensionSize;
        adjustedInput = concat([input, zeros(zerosShape)], input.shape.length - 1);
        innerDimensionSize = fftLength;
      } else {
        adjustedInput = input;
      }
      var zerosInput = zerosLike(adjustedInput);
      var complexInput = reshape(complex(adjustedInput, zerosInput), [batch, innerDimensionSize]);
      var ret = fft(complexInput);
      var half = Math.floor(innerDimensionSize / 2) + 1;
      var realValues = real(ret);
      var imagValues = imag(ret);
      var realComplexConjugate = split(realValues, [half, innerDimensionSize - half], realValues.shape.length - 1);
      var imagComplexConjugate = split(imagValues, [half, innerDimensionSize - half], imagValues.shape.length - 1);
      var outputShape = adjustedInput.shape.slice();
      outputShape[adjustedInput.shape.length - 1] = half;
      return reshape(complex(realComplexConjugate[0], imagComplexConjugate[0]), outputShape);
    }
    var rfft = /* @__PURE__ */ op({ rfft_ });
    function squaredDifference_(a, b) {
      var _a;
      var $a = convertToTensor(a, "a", "squaredDifference");
      var $b = convertToTensor(b, "b", "squaredDifference");
      _a = __read(makeTypesMatch($a, $b), 2), $a = _a[0], $b = _a[1];
      assertAndGetBroadcastShape($a.shape, $b.shape);
      var inputs = { a: $a, b: $b };
      var attrs = {};
      return ENGINE.runKernel(SquaredDifference, inputs, attrs);
    }
    var squaredDifference = /* @__PURE__ */ op({ squaredDifference_ });
    function squeeze_(x, axis) {
      var $x = convertToTensor(x, "x", "squeeze", "string_or_numeric");
      return reshape($x, squeezeShape($x.shape, axis).newShape);
    }
    var squeeze = /* @__PURE__ */ op({ squeeze_ });
    function stack_(tensors, axis) {
      if (axis === void 0) {
        axis = 0;
      }
      var $tensors = convertToTensorArray(tensors, "tensors", "stack", "string_or_numeric");
      assert($tensors.length >= 1, function() {
        return "Pass at least one tensor to tf.stack";
      });
      if ($tensors.length > 0) {
        assert(axis <= $tensors[0].rank, function() {
          return "Axis must be <= rank of the tensor";
        });
      }
      var inputs = $tensors;
      var attrs = { axis };
      return ENGINE.runKernel(Pack, inputs, attrs);
    }
    var stack = /* @__PURE__ */ op({ stack_ });
    function step_(x, alpha) {
      if (alpha === void 0) {
        alpha = 0;
      }
      var $x = convertToTensor(x, "x", "step");
      var inputs = { x: $x };
      var attrs = { alpha };
      return ENGINE.runKernel(Step, inputs, attrs);
    }
    var step = /* @__PURE__ */ op({ step_ });
    function stridedSlice_(x, begin, end, strides, beginMask, endMask, ellipsisMask, newAxisMask, shrinkAxisMask) {
      if (beginMask === void 0) {
        beginMask = 0;
      }
      if (endMask === void 0) {
        endMask = 0;
      }
      if (ellipsisMask === void 0) {
        ellipsisMask = 0;
      }
      if (newAxisMask === void 0) {
        newAxisMask = 0;
      }
      if (shrinkAxisMask === void 0) {
        shrinkAxisMask = 0;
      }
      var $x = convertToTensor(x, "x", "stridedSlice", "string_or_numeric");
      var inputs = { x: $x };
      var attrs = {
        begin,
        end,
        strides,
        beginMask,
        endMask,
        ellipsisMask,
        newAxisMask,
        shrinkAxisMask
      };
      return ENGINE.runKernel(StridedSlice, inputs, attrs);
    }
    var stridedSlice = /* @__PURE__ */ op({ stridedSlice_ });
    function tan_(x) {
      var $x = convertToTensor(x, "x", "tan", "float32");
      var inputs = { x: $x };
      return ENGINE.runKernel(Tan, inputs);
    }
    var tan = /* @__PURE__ */ op({ tan_ });
    function tensor1d(values, dtype) {
      assertNonNull(values);
      var inferredShape = inferShape(values, dtype);
      if (inferredShape.length !== 1) {
        throw new Error("tensor1d() requires values to be a flat/TypedArray");
      }
      var shape = null;
      return makeTensor(values, shape, inferredShape, dtype);
    }
    function tensor2d(values, shape, dtype) {
      assertNonNull(values);
      if (shape != null && shape.length !== 2) {
        throw new Error("tensor2d() requires shape to have two numbers");
      }
      var inferredShape = inferShape(values, dtype);
      if (inferredShape.length !== 2 && inferredShape.length !== 1) {
        throw new Error("tensor2d() requires values to be number[][] or flat/TypedArray");
      }
      if (inferredShape.length === 1 && shape == null) {
        throw new Error("tensor2d() requires shape to be provided when `values` are a flat/TypedArray");
      }
      return makeTensor(values, shape, inferredShape, dtype);
    }
    function tensor3d(values, shape, dtype) {
      assertNonNull(values);
      if (shape != null && shape.length !== 3) {
        throw new Error("tensor3d() requires shape to have three numbers");
      }
      var inferredShape = inferShape(values, dtype);
      if (inferredShape.length !== 3 && inferredShape.length !== 1) {
        throw new Error("tensor3d() requires values to be number[][][] or flat/TypedArray");
      }
      if (inferredShape.length === 1 && shape == null) {
        throw new Error("tensor3d() requires shape to be provided when `values` are a flat array");
      }
      return makeTensor(values, shape, inferredShape, dtype);
    }
    function tensor4d(values, shape, dtype) {
      assertNonNull(values);
      if (shape != null && shape.length !== 4) {
        throw new Error("tensor4d() requires shape to have four numbers");
      }
      var inferredShape = inferShape(values, dtype);
      if (inferredShape.length !== 4 && inferredShape.length !== 1) {
        throw new Error("tensor4d() requires values to be number[][][][] or flat/TypedArray");
      }
      if (inferredShape.length === 1 && shape == null) {
        throw new Error("tensor4d() requires shape to be provided when `values` are a flat array");
      }
      return makeTensor(values, shape, inferredShape, dtype);
    }
    function tensor5d(values, shape, dtype) {
      assertNonNull(values);
      if (shape != null && shape.length !== 5) {
        throw new Error("tensor5d() requires shape to have five numbers");
      }
      var inferredShape = inferShape(values, dtype);
      if (inferredShape.length !== 5 && inferredShape.length !== 1) {
        throw new Error("tensor5d() requires values to be number[][][][][] or flat/TypedArray");
      }
      if (inferredShape.length === 1 && shape == null) {
        throw new Error("tensor5d() requires shape to be provided when `values` are a flat array");
      }
      return makeTensor(values, shape, inferredShape, dtype);
    }
    function tensor6d(values, shape, dtype) {
      assertNonNull(values);
      if (shape != null && shape.length !== 6) {
        throw new Error("tensor6d() requires shape to have six numbers");
      }
      var inferredShape = inferShape(values, dtype);
      if (inferredShape.length !== 6 && inferredShape.length !== 1) {
        throw new Error("tensor6d() requires values to be number[][][][][][] or flat/TypedArray");
      }
      if (inferredShape.length === 1 && shape == null) {
        throw new Error("tensor6d() requires shape to be provided when `values` are a flat array");
      }
      shape = shape || inferredShape;
      return makeTensor(values, shape, inferredShape, dtype);
    }
    function validateUpdateShape(shape, indices, updates) {
      var sliceDim = indices.rank > 1 ? indices.shape[indices.rank - 1] : 1;
      var batchDim = indices.rank > 1 ? indices.rank - 1 : 1;
      var shapeError = "Must have updates.shape = indices.shape[:batchDim] + " + "shape[sliceDim:], got updates.shape: ".concat(updates.shape) + ", indices.shape: ".concat(indices.shape, ", shape: ").concat(shape) + ", sliceDim: ".concat(sliceDim, ", and batchDim: ").concat(batchDim, ".");
      if (updates.rank < batchDim) {
        throw new Error(shapeError + " update.rank < ".concat(batchDim, ". "));
      }
      if (shape.length < sliceDim + (updates.rank - batchDim)) {
        throw new Error(shapeError + " Output shape length < ".concat(sliceDim + (updates.rank - batchDim)));
      }
      if (updates.rank !== batchDim + shape.length - sliceDim) {
        throw new Error(shapeError + " update.rank != ".concat(batchDim + shape.length - sliceDim));
      }
      for (var d = 0; d < batchDim; ++d) {
        if (updates.shape[d] !== indices.shape[d]) {
          throw new Error(shapeError + " updates.shape[".concat(d, "] (").concat(updates.shape[d], ") != indices.shape[").concat(d, "] (").concat(indices.shape[d], ")."));
        }
      }
      for (var d = 0; d < updates.rank - batchDim; ++d) {
        if (updates.shape[d + batchDim] !== shape[d + sliceDim]) {
          throw new Error(shapeError + " updates.shape[".concat(d + batchDim, "] (").concat(updates.shape[d + batchDim], ") != shape[").concat(d + batchDim, "] (").concat(shape[d + batchDim], ")"));
        }
      }
    }
    function validateInput$1(updates, indices, shape) {
      if (indices.rank < 1) {
        throw new Error("tf.scatterND() expects the indices to be rank 1 or higher," + " but the rank was ".concat(indices.rank, "."));
      }
      if (updates.rank < 1) {
        throw new Error("tf.scatterND() expects the updates to be rank 1 or higher," + " but the rank was ".concat(updates.rank, "."));
      }
      if (indices.dtype !== "int32") {
        throw new Error("The dtype of 'indices' should be int32, but got dtype: ".concat(indices.dtype));
      }
      if (shape.length < 1) {
        throw new Error("Output rank must be greater or equal to 1, but got shape: ".concat(shape));
      }
      if (shape.length === 0) {
        if (indices.size === 0) {
          throw new Error("Indices specified for empty output. indices shape: ".concat(indices.shape));
        }
        if (updates.size === 0) {
          throw new Error("Updates specified for empty output. updates shape: ".concat(updates.shape));
        }
      }
      validateUpdateShape(shape, indices, updates);
    }
    function calculateShapes(updates, indices, shape) {
      var indicesRank = indices.shape.length;
      var sliceRank = indicesRank > 1 ? indices.shape[indicesRank - 1] : 1;
      var totalNd = shape.length;
      var sliceSize = 1;
      for (var i = sliceRank; i < totalNd; ++i) {
        sliceSize *= shape[i];
      }
      var safeSliceDim = sliceRank < 1 ? 1 : sliceRank;
      var numUpdates = sizeFromShape(indices.shape) / safeSliceDim;
      var strides = __spreadArray(__spreadArray([], __read(computeStrides(shape.slice(0, sliceRank))), false), [1], false);
      var outputSize = sizeFromShape(shape);
      return { sliceRank, numUpdates, sliceSize, strides, outputSize };
    }
    var scatter_nd_util = {
      __proto__: null,
      calculateShapes,
      validateInput: validateInput$1,
      validateUpdateShape
    };
    function tensorScatterUpdate_(tensor2, indices, updates) {
      var $tensor = convertToTensor(tensor2, "tensor", "tensorScatterupdate");
      var $indices = convertToTensor(indices, "indices", "tensorScatterupdate", "int32");
      var $updates = convertToTensor(updates, "updates", "tensorScatterupdate");
      validateInput$1($updates, $indices, $tensor.shape);
      if ($tensor.dtype !== $updates.dtype) {
        throw new Error("tensor and updates must have the same dtype, instead they are ".concat($tensor.dtype, " and ").concat($updates.dtype, "."));
      }
      var inputs = {
        tensor: $tensor,
        indices: $indices,
        updates: $updates
      };
      var attrs = {};
      return ENGINE.runKernel(TensorScatterUpdate, inputs, attrs);
    }
    var tensorScatterUpdate = op({ tensorScatterUpdate_ });
    function topk_(x, k, sorted) {
      if (k === void 0) {
        k = 1;
      }
      if (sorted === void 0) {
        sorted = true;
      }
      var $x = convertToTensor(x, "x", "topk");
      if ($x.rank === 0) {
        throw new Error("topk() expects the input to be of rank 1 or higher");
      }
      var lastDim = $x.shape[$x.shape.length - 1];
      if (k < 0) {
        throw new Error("'k' passed to topk() must be >= 0 but got ".concat(k));
      }
      if (k > lastDim) {
        throw new Error("'k' passed to topk() must be <= the last dimension (".concat(lastDim, ") ") + "but got ".concat(k));
      }
      var inputs = { x: $x };
      var attrs = { k, sorted };
      var _a = __read(ENGINE.runKernel(TopK, inputs, attrs), 2), values = _a[0], indices = _a[1];
      return { values, indices };
    }
    var topk = /* @__PURE__ */ op({ topk_ });
    function truncatedNormal_(shape, mean2, stdDev, dtype, seed) {
      if (mean2 === void 0) {
        mean2 = 0;
      }
      if (stdDev === void 0) {
        stdDev = 1;
      }
      assertNonNegativeIntegerDimensions(shape);
      if (dtype != null && dtype === "bool") {
        throw new Error("Unsupported data type $ { dtype }");
      }
      var randGauss = new MPRandGauss(mean2, stdDev, dtype, true, seed);
      var res = buffer(shape, dtype);
      for (var i = 0; i < res.values.length; i++) {
        res.values[i] = randGauss.nextValue();
      }
      return res.toTensor();
    }
    var truncatedNormal = /* @__PURE__ */ op({ truncatedNormal_ });
    function unique_(x, axis) {
      if (axis === void 0) {
        axis = 0;
      }
      var $x = convertToTensor(x, "x", "unique", "string_or_numeric");
      assert($x.rank > 0, function() {
        return "The input tensor must be at least 1D";
      });
      var inputs = { x: $x };
      var attrs = { axis };
      var _a = __read(ENGINE.runKernel(Unique, inputs, attrs), 2), values = _a[0], indices = _a[1];
      return { values, indices };
    }
    var unique = /* @__PURE__ */ op({ unique_ });
    function unsortedSegmentSum_(x, segmentIds, numSegments) {
      var $x = convertToTensor(x, "x", "unsortedSegmentSum");
      var $segmentIds = convertToTensor(segmentIds, "segmentIds", "unsortedSegmentSum", "int32");
      assert(isInt(numSegments), function() {
        return "numSegments must be of dtype int";
      });
      var inputs = { x: $x, segmentIds: $segmentIds };
      var attrs = { numSegments };
      return ENGINE.runKernel(UnsortedSegmentSum, inputs, attrs);
    }
    var unsortedSegmentSum = /* @__PURE__ */ op({ unsortedSegmentSum_ });
    function unstack_(x, axis) {
      if (axis === void 0) {
        axis = 0;
      }
      var $x = convertToTensor(x, "x", "unstack", "string_or_numeric");
      assert(axis >= -$x.shape.length && axis < $x.shape.length, function() {
        return "Axis = ".concat(axis, " is not in [-").concat($x.shape.length, ", ").concat($x.shape.length, ")");
      });
      var inputs = { value: $x };
      var attrs = { axis };
      return ENGINE.runKernel(Unpack, inputs, attrs);
    }
    var unstack = /* @__PURE__ */ op({ unstack_ });
    function upperBound(sortedSequence, values) {
      return searchSorted(sortedSequence, values, "right");
    }
    function variable(initialValue, trainable, name, dtype) {
      if (trainable === void 0) {
        trainable = true;
      }
      return ENGINE.makeVariable(initialValue, trainable, name, dtype);
    }
    function whereImpl(condShape, condVals) {
      var indices = [];
      for (var i = 0; i < condVals.length; i++) {
        if (condVals[i]) {
          indices.push(i);
        }
      }
      var inBuffer = buffer(condShape, "int32");
      var out = buffer([indices.length, condShape.length], "int32");
      for (var i = 0; i < indices.length; i++) {
        var loc = inBuffer.indexToLoc(indices[i]);
        var offset = i * condShape.length;
        out.values.set(loc, offset);
      }
      return out.toTensor();
    }
    function whereAsync_(condition) {
      return __awaiter(this, void 0, void 0, function() {
        var $condition, vals, res;
        return __generator(this, function(_a) {
          switch (_a.label) {
            case 0:
              $condition = convertToTensor(condition, "condition", "whereAsync", "bool");
              return [4, $condition.data()];
            case 1:
              vals = _a.sent();
              res = whereImpl($condition.shape, vals);
              if (condition !== $condition) {
                $condition.dispose();
              }
              return [2, res];
          }
        });
      });
    }
    var whereAsync = whereAsync_;
    function booleanMaskAsync_(tensor2, mask, axis) {
      return __awaiter(this, void 0, void 0, function() {
        var $tensor, $mask, axisFrom, maskDim, tensorShape, leadingSize, i, targetTensorShape, reshapedTensor, reshapedMask, positivePositions, indices, res;
        return __generator(this, function(_a) {
          switch (_a.label) {
            case 0:
              $tensor = convertToTensor(tensor2, "tensor", "boolMask");
              $mask = convertToTensor(mask, "mask", "boolMask", "bool");
              axisFrom = axis == null ? 0 : axis;
              maskDim = $mask.rank;
              tensorShape = $tensor.shape;
              assert(maskDim > 0, function() {
                return "mask cannot be scalar";
              });
              assertShapesMatch(tensorShape.slice(axisFrom, axisFrom + maskDim), $mask.shape, "mask's shape must match the first K dimensions of tensor's shape,");
              leadingSize = 1;
              for (i = axisFrom; i < axisFrom + maskDim; i++) {
                leadingSize *= tensorShape[i];
              }
              targetTensorShape = tensorShape.slice(0, axisFrom).concat([leadingSize], tensorShape.slice(axisFrom + maskDim));
              reshapedTensor = reshape($tensor, targetTensorShape);
              reshapedMask = reshape($mask, [-1]);
              return [4, whereAsync(reshapedMask)];
            case 1:
              positivePositions = _a.sent();
              indices = squeeze(positivePositions, [1]);
              res = gather(reshapedTensor, indices, axisFrom);
              if (tensor2 !== $tensor) {
                $tensor.dispose();
              }
              if (mask !== $mask) {
                $mask.dispose();
              }
              indices.dispose();
              reshapedTensor.dispose();
              reshapedMask.dispose();
              positivePositions.dispose();
              return [2, res];
          }
        });
      });
    }
    var booleanMaskAsync = booleanMaskAsync_;
    function transpose_(x, perm, conjugate) {
      var $x = convertToTensor(x, "x", "transpose");
      if (perm == null) {
        perm = $x.shape.map(function(s, i) {
          return i;
        }).reverse();
      }
      assert($x.rank === perm.length, function() {
        return "Error in transpose: rank of input ".concat($x.rank, " ") + "must match length of perm ".concat(perm, ".");
      });
      perm.forEach(function(axis) {
        assert(axis >= 0 && axis < $x.rank, function() {
          return "All entries in 'perm' must be between 0 and ".concat($x.rank - 1) + " but got ".concat(perm);
        });
      });
      if ($x.rank <= 1) {
        return $x.clone();
      }
      var inputs = { x: $x };
      var attrs = { perm };
      if ($x.dtype === "complex64") {
        return tidy(function() {
          var $real = real($x);
          var $imag = imag($x);
          $real = ENGINE.runKernel(Transpose, { x: $real }, attrs);
          $imag = ENGINE.runKernel(Transpose, { x: $imag }, attrs);
          if (conjugate) {
            $imag = neg($imag);
          }
          return complex($real, $imag);
        });
      }
      return ENGINE.runKernel(Transpose, inputs, attrs);
    }
    var transpose = /* @__PURE__ */ op({ transpose_ });
    function movingAverage_(v, x, decay, step2, zeroDebias) {
      if (zeroDebias === void 0) {
        zeroDebias = true;
      }
      var $v = convertToTensor(v, "v", "movingAverage");
      var $x = convertToTensor(x, "x", "movingAverage");
      var $decay = convertToTensor(decay, "decay", "movingAverage");
      assertTypesMatch($v, $x);
      assert(arraysEqual($v.shape, $x.shape), function() {
        return "Shape mismatch in v and x";
      });
      var one = scalar(1);
      var oneMinusDecay = sub(one, $decay);
      var update = mul(sub($x, $v), oneMinusDecay);
      if (zeroDebias) {
        assert(step2 != null, function() {
          return "When using zeroDebias: true, step is required.";
        });
        var $step = convertToTensor(step2, "step", "movingAverage");
        update = div(update, sub(one, pow($decay, $step)));
      }
      return add($v, update);
    }
    var movingAverage = /* @__PURE__ */ op({ movingAverage_ });
    function scatterND_(indices, updates, shape) {
      assertNonNegativeIntegerDimensions(shape);
      var $indices = convertToTensor(indices, "indices", "scatterND", "int32");
      var $updates = convertToTensor(updates, "updates", "scatterND");
      validateInput$1($updates, $indices, shape);
      var inputs = { indices: $indices, updates: $updates };
      var attrs = { shape };
      return ENGINE.runKernel(ScatterNd, inputs, attrs);
    }
    var scatterND = /* @__PURE__ */ op({ scatterND_ });
    function validateInput(sparseIndices, sparseValues, outputShape, defaultValues) {
      if (sparseIndices.dtype !== "int32") {
        throw new Error("tf.sparseToDense() expects the indices to be int32 type," + " but the dtype was ".concat(sparseIndices.dtype, "."));
      }
      if (sparseIndices.rank > 2) {
        throw new Error("sparseIndices should be a scalar, vector, or matrix," + " but got shape ".concat(sparseIndices.shape, "."));
      }
      var numElems = sparseIndices.rank > 0 ? sparseIndices.shape[0] : 1;
      var numDims = sparseIndices.rank > 1 ? sparseIndices.shape[1] : 1;
      if (outputShape.length !== numDims) {
        throw new Error("outputShape has incorrect number of elements:," + " ".concat(outputShape.length, ", should be: ").concat(numDims, "."));
      }
      var numValues = sparseValues.size;
      if (!(sparseValues.rank === 0 || sparseValues.rank === 1 && numValues === numElems)) {
        throw new Error("sparseValues has incorrect shape " + "".concat(sparseValues.shape, ", should be [] or [").concat(numElems, "]"));
      }
      if (sparseValues.dtype !== defaultValues.dtype) {
        throw new Error("sparseValues.dtype must match defaultValues.dtype");
      }
    }
    function sparseToDense_(sparseIndices, sparseValues, outputShape, defaultValue) {
      if (defaultValue === void 0) {
        defaultValue = 0;
      }
      assertNonNegativeIntegerDimensions(outputShape);
      var $sparseIndices = convertToTensor(sparseIndices, "sparseIndices", "sparseToDense", "int32");
      var $sparseValues = convertToTensor(sparseValues, "sparseValues", "sparseToDense", "string_or_numeric");
      var $defaultValue = convertToTensor(defaultValue, "defaultValue", "sparseToDense", $sparseValues.dtype);
      validateInput($sparseIndices, $sparseValues, outputShape, $defaultValue);
      var inputs = {
        sparseIndices: $sparseIndices,
        sparseValues: $sparseValues,
        defaultValue: $defaultValue
      };
      var attrs = { outputShape };
      return ENGINE.runKernel(SparseToDense, inputs, attrs);
    }
    var sparseToDense = /* @__PURE__ */ op({ sparseToDense_ });
    function gatherND_(x, indices) {
      var $indices = convertToTensor(indices, "indices", "gatherND", "int32");
      var $x = convertToTensor(x, "x", "gatherND", "string_or_numeric");
      var inputs = { params: $x, indices: $indices };
      return ENGINE.runKernel(GatherNd, inputs);
    }
    var gatherND = /* @__PURE__ */ op({ gatherND_ });
    function getNoiseShape(x, noiseShape) {
      if (noiseShape == null) {
        return x.shape.slice();
      }
      if (arraysEqual(x.shape, noiseShape)) {
        return noiseShape;
      }
      if (x.shape.length === noiseShape.length) {
        var newDimension = [];
        for (var i = 0; i < x.shape.length; i++) {
          if (noiseShape[i] == null && x.shape[i] != null) {
            newDimension.push(x.shape[i]);
          } else {
            newDimension.push(noiseShape[i]);
          }
        }
        return newDimension;
      }
      return noiseShape;
    }
    function dropout_(x, rate, noiseShape, seed) {
      var $x = convertToTensor(x, "x", "dropout");
      assert($x.dtype === "float32", function() {
        return "x has to be a floating point tensor since it's going to be " + "scaled, but got a ".concat($x.dtype, " tensor instead.");
      });
      assert(rate >= 0 && rate < 1, function() {
        return "rate must be a float in the range [0, 1), but got ".concat(rate, ".");
      });
      if (rate === 0) {
        return x instanceof Tensor ? $x.clone() : $x;
      }
      var $noiseShape = getNoiseShape($x, noiseShape);
      var keepProb = 1 - rate;
      var multiplier = div(floor(add(randomUniform($noiseShape, 0, 1, "float32", seed), keepProb)), keepProb);
      return mul($x, multiplier);
    }
    var dropout = /* @__PURE__ */ op({ dropout_ });
    function enclosingPowerOfTwo(value) {
      return Math.floor(Math.pow(2, Math.ceil(Math.log(value) / Math.log(2))));
    }
    function cosineWindow(windowLength, a, b) {
      var even = 1 - windowLength % 2;
      var newValues = new Float32Array(windowLength);
      for (var i = 0; i < windowLength; ++i) {
        var cosArg = 2 * Math.PI * i / (windowLength + even - 1);
        newValues[i] = a - b * Math.cos(cosArg);
      }
      return tensor1d(newValues, "float32");
    }
    function inTopKAsync_(predictions, targets, k) {
      if (k === void 0) {
        k = 1;
      }
      return __awaiter(this, void 0, void 0, function() {
        var $predictions, $targets, lastDim, predictionsVals, targetsVals, _a, batch, size, precision, b, offset, vals, valAndInd, i, i;
        return __generator(this, function(_b) {
          switch (_b.label) {
            case 0:
              $predictions = convertToTensor(predictions, "predictions", "inTopK");
              $targets = convertToTensor(targets, "targets", "inTopK");
              assert($predictions.rank > 1, function() {
                return "inTopK() expects the predictions to be of rank 2 or higher, " + "but got ".concat($predictions.rank);
              });
              assert($predictions.rank - 1 === $targets.rank, function() {
                return "predictions rank should be 1 larger than targets rank, but got predictions rank " + "".concat($predictions.rank, " and targets rank ").concat($targets.rank);
              });
              assertShapesMatch($predictions.shape.slice(0, $predictions.shape.length - 1), $targets.shape, "predictions's shape should be align with the targets' shape, except the last dimension.");
              lastDim = $predictions.shape[$predictions.shape.length - 1];
              assert(k > 0 && k <= lastDim, function() {
                return "'k' passed to inTopK() must be > 0 && <= the predictions last " + "dimension (".concat(lastDim, "), but got ").concat(k);
              });
              return [4, $predictions.data()];
            case 1:
              predictionsVals = _b.sent();
              return [4, $targets.data()];
            case 2:
              targetsVals = _b.sent();
              _a = __read([predictionsVals.length / lastDim, lastDim], 2), batch = _a[0], size = _a[1];
              precision = getTypedArrayFromDType("bool", batch);
              for (b = 0; b < batch; b++) {
                offset = b * size;
                vals = predictionsVals.subarray(offset, offset + size);
                valAndInd = [];
                for (i = 0; i < vals.length; i++) {
                  valAndInd.push({ value: vals[i], index: i });
                }
                valAndInd.sort(function(a, b2) {
                  return b2.value - a.value;
                });
                precision[b] = 0;
                for (i = 0; i < k; i++) {
                  if (valAndInd[i].index === targetsVals[b]) {
                    precision[b] = 1;
                    break;
                  }
                }
              }
              if (predictions !== $predictions) {
                $predictions.dispose();
              }
              if (targets !== $targets) {
                $targets.dispose();
              }
              return [2, tensor(precision, $targets.shape, "bool")];
          }
        });
      });
    }
    var inTopKAsync = inTopKAsync_;
    function conv2DBackpropFilter_(x, dy, filterShape, strides, pad2, dataFormat, dimRoundingMode) {
      if (dataFormat === void 0) {
        dataFormat = "NHWC";
      }
      var x4D = x;
      if (x.rank === 3) {
        x4D = reshape(x, [1, x.shape[0], x.shape[1], x.shape[2]]);
      }
      var dy4D = dy;
      if (dy4D.rank === 3) {
        dy4D = reshape(dy, [1, dy.shape[0], dy.shape[1], dy.shape[2]]);
      }
      assert(x4D.rank === 4, function() {
        return "Error in conv2dDerFilter: input must be rank 4, but got shape " + "".concat(x4D.shape, ".");
      });
      assert(dy4D.rank === 4, function() {
        return "Error in conv2dDerFilter: dy must be rank 4, but got shape " + "".concat(dy4D.shape, ".");
      });
      assert(filterShape.length === 4, function() {
        return "Error in conv2dDerFilter: filterShape must be length 4, but got " + "".concat(filterShape, ".");
      });
      var inDepth = dataFormat === "NHWC" ? x4D.shape[3] : x4D.shape[1];
      var outDepth = dataFormat === "NHWC" ? dy4D.shape[3] : dy4D.shape[1];
      assert(inDepth === filterShape[2], function() {
        return "Error in conv2dDerFilter: depth of input ".concat(inDepth, ") must ") + "match input depth in filter (".concat(filterShape[2], ".");
      });
      assert(outDepth === filterShape[3], function() {
        return "Error in conv2dDerFilter: depth of dy (".concat(outDepth, ") must ") + "match output depth for filter (".concat(filterShape[3], ").");
      });
      checkPadOnDimRoundingMode("conv2dDerFilter", pad2, dimRoundingMode);
      var inputs = { x: x4D, dy: dy4D };
      var attrs = { strides, pad: pad2, dataFormat, dimRoundingMode, filterShape };
      return ENGINE.runKernel(Conv2DBackpropFilter, inputs, attrs);
    }
    var conv2DBackpropFilter = /* @__PURE__ */ op({ conv2DBackpropFilter_ });
    function getFusedDyActivation(dy, y, activation) {
      if (activation == null || activation === "linear") {
        return dy;
      }
      if (activation === "relu") {
        return mul(dy, step(y));
      }
      throw new Error("Cannot compute gradient for fused activation ".concat(activation, "."));
    }
    function getFusedBiasGradient(bias, dyActivation) {
      var res = dyActivation;
      var reduceAxes = getReductionAxes(bias.shape, dyActivation.shape);
      if (reduceAxes.length > 0) {
        res = sum(res, reduceAxes);
      }
      return reshape(res, bias.shape);
    }
    function applyActivation(x, activation, preluActivationWeights, leakyreluAlpha) {
      if (activation === "linear") {
        return x;
      } else if (activation === "relu") {
        return relu(x);
      } else if (activation === "elu") {
        return elu(x);
      } else if (activation === "relu6") {
        return relu6(x);
      } else if (activation === "prelu") {
        return prelu(x, preluActivationWeights);
      } else if (activation === "leakyrelu") {
        return leakyRelu(x, leakyreluAlpha);
      } else if (activation === "sigmoid") {
        return sigmoid(x);
      }
      throw new Error("Unknown fused activation ".concat(activation, "."));
    }
    var shouldFuse = function(gradientDepth, activation) {
      var gradientMode = gradientDepth > 0;
      return !gradientMode || activation === "linear";
    };
    function fusedConv2d_(_a) {
      var _b;
      var x = _a.x, filter = _a.filter, strides = _a.strides, pad2 = _a.pad, _c = _a.dataFormat, dataFormat = _c === void 0 ? "NHWC" : _c, _d = _a.dilations, dilations = _d === void 0 ? [1, 1] : _d, dimRoundingMode = _a.dimRoundingMode, bias = _a.bias, _e = _a.activation, activation = _e === void 0 ? "linear" : _e, preluActivationWeights = _a.preluActivationWeights, leakyreluAlpha = _a.leakyreluAlpha;
      activation = activation || "linear";
      if (shouldFuse(ENGINE.state.gradientDepth, activation) === false) {
        assert(dataFormat === "NHWC", function() {
          return "Error in fused conv2d: got dataFormat of ".concat(dataFormat, " but ") + "only NHWC is currently supported for the case of gradient depth is 0 and the activation is not linear.";
        });
        var result = conv2d$1(x, filter, strides, pad2, dataFormat, dilations, dimRoundingMode);
        if (bias != null) {
          result = add(result, bias);
        }
        return applyActivation(result, activation, preluActivationWeights, leakyreluAlpha);
      }
      var $x = convertToTensor(x, "x", "conv2d", "float32");
      var $filter = convertToTensor(filter, "filter", "conv2d", "float32");
      var x4D = $x;
      var reshapedTo4D = false;
      if ($x.rank === 3) {
        reshapedTo4D = true;
        x4D = reshape($x, [1, $x.shape[0], $x.shape[1], $x.shape[2]]);
      }
      assert(x4D.rank === 4, function() {
        return "Error in fused conv2d: input must be rank 4, but got rank " + "".concat(x4D.rank, ".");
      });
      assert($filter.rank === 4, function() {
        return "Error in fused conv2d: filter must be rank 4, but got rank " + "".concat($filter.rank, ".");
      });
      checkPadOnDimRoundingMode("fused conv2d", pad2, dimRoundingMode);
      var inputChannels = dataFormat === "NHWC" ? x4D.shape[3] : x4D.shape[1];
      assert($filter.shape[2] === inputChannels, function() {
        return "Error in conv2d: depth of input (".concat(inputChannels, ") must match ") + "input depth for filter ".concat($filter.shape[2], ".");
      });
      assert(eitherStridesOrDilationsAreOne(strides, dilations), function() {
        return "Error in conv2D: Either strides or dilations must be 1. " + "Got strides ".concat(strides, " and dilations '").concat(dilations, "'");
      });
      var convInfo = computeConv2DInfo(x4D.shape, $filter.shape, strides, dilations, pad2, dimRoundingMode);
      var $bias;
      if (bias != null) {
        $bias = convertToTensor(bias, "bias", "fused conv2d");
        _b = __read(makeTypesMatch($bias, $x), 1), $bias = _b[0];
        if (dataFormat === "NHWC") {
          assertAndGetBroadcastShape(convInfo.outShape, $bias.shape);
        } else {
          assert($bias.shape.length <= 1, function() {
            return "Error in fused conv2d: only supports scalar or 1-D Tensor bias for NCHW format but got the bias of " + "rank-".concat($bias.shape.length, ".");
          });
          assert($bias.shape.length === 0 || $bias.shape[0] === convInfo.outChannels || $bias.shape[0] === 1, function() {
            return "Error in fused conv2d: bias shape (".concat($bias.shape, ") is not ") + "compatible with the number of output channels " + "(".concat(convInfo.outChannels, ")");
          });
        }
      }
      var $preluActivationWeights;
      if (preluActivationWeights != null) {
        var alphaShape_1 = preluActivationWeights.shape;
        assert(alphaShape_1.length <= 1 || alphaShape_1.length === 3, function() {
          return "Error in fused conv2d: only supports scalar, 1-D Tensor or 3-D Tensor PReLU activation weights but got a tensor of " + "rank-".concat(alphaShape_1.length, ".");
        });
        if (alphaShape_1.length === 1) {
          assert(alphaShape_1[0] === 1 || alphaShape_1[0] === convInfo.outChannels, function() {
            return "Error in fused conv2d: PReLU activation weights " + "(".concat(alphaShape_1, ") is not compatible with the number of output ") + "channels (".concat(convInfo.outChannels, ").");
          });
        } else if (alphaShape_1.length === 3) {
          try {
            assertAndGetBroadcastShape(alphaShape_1, convInfo.outShape);
          } catch (e) {
            var errMsg = "Error in fused conv2d: PReLU activation weights (".concat(alphaShape_1, ") ") + "is not compatible with the output shape of the conv2d " + "(".concat(convInfo.outShape, ").");
            throw Error(errMsg);
          }
        }
        $preluActivationWeights = convertToTensor(preluActivationWeights, "prelu weights", "fused conv2d");
      }
      var grad2 = function(dy, saved) {
        assert(dataFormat === "NHWC", function() {
          return "Error in gradient of fused conv2D: got dataFormat of ".concat(dataFormat, " but only NHWC is currently supported.");
        });
        var _a2 = __read(saved, 4), $filter2 = _a2[0], x4D2 = _a2[1], y = _a2[2], $bias2 = _a2[3];
        var dyActivation = getFusedDyActivation(dy, y, activation);
        assert(tupleValuesAreOne(dilations), function() {
          return "Error in gradient of fused conv2D: dilation rates greater than 1 " + "are not yet supported in gradients. Got dilations '".concat(dilations, "'");
        });
        var xDer = conv2DBackpropInput(x4D2.shape, dyActivation, $filter2, strides, pad2);
        var filterDer = conv2DBackpropFilter(x4D2, dyActivation, $filter2.shape, strides, pad2);
        var der = [xDer, filterDer];
        if ($bias2 != null) {
          var biasDer = getFusedBiasGradient($bias2, dyActivation);
          der.push(biasDer);
        }
        return der;
      };
      var inputs = {
        x: x4D,
        filter: $filter,
        bias: $bias,
        preluActivationWeights: $preluActivationWeights
      };
      var attrs = {
        strides,
        pad: pad2,
        dataFormat,
        dilations,
        dimRoundingMode,
        activation,
        leakyreluAlpha
      };
      if (bias == null) {
        var customOp = customGrad(function(x4D2, filter2, save) {
          var res = (
            // tslint:disable-next-line: no-unnecessary-type-assertion
            ENGINE.runKernel(FusedConv2D, inputs, attrs)
          );
          save([filter2, x4D2, res]);
          if (reshapedTo4D) {
            res = reshape(res, [res.shape[1], res.shape[2], res.shape[3]]);
          }
          return { value: res, gradFunc: grad2 };
        });
        return customOp(x4D, $filter);
      } else {
        var customOpWithBias = customGrad(function(x4D2, filter2, bias2, save) {
          var res = ENGINE.runKernel(FusedConv2D, inputs, attrs);
          save([filter2, x4D2, res, bias2]);
          if (reshapedTo4D) {
            res = reshape(res, [res.shape[1], res.shape[2], res.shape[3]]);
          }
          return { value: res, gradFunc: grad2 };
        });
        return customOpWithBias(x4D, $filter, $bias);
      }
    }
    var conv2d = /* @__PURE__ */ op({ fusedConv2d_ });
    function depthwiseConv2dNativeBackpropFilter_(x, dy, filterShape, strides, pad2, dilations, dimRoundingMode) {
      if (dilations === void 0) {
        dilations = [1, 1];
      }
      var x4D = x;
      if (x.rank === 3) {
        x4D = reshape(x, [1, x.shape[0], x.shape[1], x.shape[2]]);
      }
      var dy4D = dy;
      if (dy4D.rank === 3) {
        dy4D = reshape(dy, [1, dy.shape[0], dy.shape[1], dy.shape[2]]);
      }
      var inputs = { x: x4D, dy: dy4D };
      var attrs = { strides, pad: pad2, dimRoundingMode, dilations, filterShape };
      return ENGINE.runKernel(DepthwiseConv2dNativeBackpropFilter, inputs, attrs);
    }
    var depthwiseConv2dNativeBackpropFilter = op({ depthwiseConv2dNativeBackpropFilter_ });
    function depthwiseConv2dNativeBackpropInput_(xShape, dy, filter, strides, pad2, dilations, dimRoundingMode) {
      if (dilations === void 0) {
        dilations = [1, 1];
      }
      var dy4D = dy;
      var reshapedTo4D = false;
      if (dy.rank === 3) {
        reshapedTo4D = true;
        dy4D = reshape(dy, [1, dy.shape[0], dy.shape[1], dy.shape[2]]);
      }
      var inputs = { dy: dy4D, filter };
      var attrs = { strides, pad: pad2, dimRoundingMode, dilations, inputShape: xShape };
      var res = (
        // tslint:disable-next-line: no-unnecessary-type-assertion
        ENGINE.runKernel(DepthwiseConv2dNativeBackpropInput, inputs, attrs)
      );
      if (reshapedTo4D) {
        return reshape(res, [res.shape[1], res.shape[2], res.shape[3]]);
      }
      return res;
    }
    var depthwiseConv2dNativeBackpropInput = op({ depthwiseConv2dNativeBackpropInput_ });
    function fusedDepthwiseConv2d_(_a) {
      var _b;
      var x = _a.x, filter = _a.filter, strides = _a.strides, pad2 = _a.pad, _c = _a.dataFormat, dataFormat = _c === void 0 ? "NHWC" : _c, _d = _a.dilations, dilations = _d === void 0 ? [1, 1] : _d, dimRoundingMode = _a.dimRoundingMode, bias = _a.bias, _e = _a.activation, activation = _e === void 0 ? "linear" : _e, preluActivationWeights = _a.preluActivationWeights, leakyreluAlpha = _a.leakyreluAlpha;
      if (shouldFuse(ENGINE.state.gradientDepth, activation) === false) {
        var result = depthwiseConv2d$1(x, filter, strides, pad2, dataFormat, dilations, dimRoundingMode);
        if (bias != null) {
          result = add(result, bias);
        }
        return applyActivation(result, activation, preluActivationWeights, leakyreluAlpha);
      }
      var $x = convertToTensor(x, "x", "depthwiseConv2d", "float32");
      var $filter = convertToTensor(filter, "filter", "depthwiseConv2d", "float32");
      var x4D = $x;
      var reshapedTo4D = false;
      if ($x.rank === 3) {
        reshapedTo4D = true;
        x4D = reshape($x, [1, $x.shape[0], $x.shape[1], $x.shape[2]]);
      }
      assert(x4D.rank === 4, function() {
        return "Error in fused depthwiseConv2d: input must be rank 4, but got " + "rank ".concat(x4D.rank, ".");
      });
      assert($filter.rank === 4, function() {
        return "Error in fused depthwiseConv2d: filter must be rank 4, " + "but got rank ".concat($filter.rank, ".");
      });
      assert(x4D.shape[3] === $filter.shape[2], function() {
        return "Error in fused depthwiseConv2d: number of input channels " + "(".concat(x4D.shape[3], ") must match the inChannels dimension in ") + "filter ".concat($filter.shape[2], ".");
      });
      if (dilations == null) {
        dilations = [1, 1];
      }
      assert(eitherStridesOrDilationsAreOne(strides, dilations), function() {
        return "Error in fused depthwiseConv2d: Either strides or dilations must " + "be 1. Got strides ".concat(strides, " and dilations '").concat(dilations, "'");
      });
      checkPadOnDimRoundingMode("fused depthwiseConv2d", pad2, dimRoundingMode);
      var convInfo = computeConv2DInfo(
        x4D.shape,
        $filter.shape,
        strides,
        dilations,
        pad2,
        dimRoundingMode,
        true
        /* depthwise */
      );
      var $bias;
      if (bias != null) {
        $bias = convertToTensor(bias, "bias", "fused conv2d");
        _b = __read(makeTypesMatch($bias, $x), 1), $bias = _b[0];
        assertAndGetBroadcastShape(convInfo.outShape, $bias.shape);
      }
      var $preluActivationWeights;
      if (preluActivationWeights != null) {
        $preluActivationWeights = convertToTensor(preluActivationWeights, "prelu weights", "fused depthwiseConv2d");
      }
      var grad2 = function(dy, saved) {
        assert(tupleValuesAreOne(dilations), function() {
          return "Error in gradient of fused depthwiseConv2d: dilation rates greater than 1 are not yet supported. Got dilations " + "'".concat(dilations, "'");
        });
        var _a2 = __read(saved, 4), $filter2 = _a2[0], x4D2 = _a2[1], y = _a2[2], bias2 = _a2[3];
        var dyActivation = getFusedDyActivation(dy, y, activation);
        var xDer = depthwiseConv2dNativeBackpropInput(x4D2.shape, dyActivation, $filter2, strides, pad2, dilations, dimRoundingMode);
        var filterDer = depthwiseConv2dNativeBackpropFilter(x4D2, dyActivation, $filter2.shape, strides, pad2, dilations, dimRoundingMode);
        if (bias2 != null) {
          var biasDer = getFusedBiasGradient($bias, dyActivation);
          return [xDer, filterDer, biasDer];
        }
        return [xDer, filterDer];
      };
      var inputs = {
        x: x4D,
        filter: $filter,
        bias: $bias,
        preluActivationWeights: $preluActivationWeights
      };
      var attrs = {
        strides,
        pad: pad2,
        dataFormat,
        dilations,
        dimRoundingMode,
        activation,
        leakyreluAlpha
      };
      if (bias == null) {
        var customOp = customGrad(function(x4D2, filter2, save) {
          var res = ENGINE.runKernel(FusedDepthwiseConv2D, inputs, attrs);
          save([filter2, x4D2, res]);
          if (reshapedTo4D) {
            res = reshape(res, [res.shape[1], res.shape[2], res.shape[3]]);
          }
          return { value: res, gradFunc: grad2 };
        });
        return customOp(x4D, $filter);
      } else {
        var customOpWithBias = customGrad(function(x4D2, filter2, bias2, save) {
          var res = ENGINE.runKernel(FusedDepthwiseConv2D, inputs, attrs);
          save([filter2, x4D2, res, bias2]);
          if (reshapedTo4D) {
            res = reshape(res, [res.shape[1], res.shape[2], res.shape[3]]);
          }
          return { value: res, gradFunc: grad2 };
        });
        return customOpWithBias(x4D, $filter, $bias);
      }
    }
    var depthwiseConv2d = /* @__PURE__ */ op({ fusedDepthwiseConv2d_ });
    function fusedMatMul_(_a) {
      var _b, _c;
      var a = _a.a, b = _a.b, _d = _a.transposeA, transposeA = _d === void 0 ? false : _d, _e = _a.transposeB, transposeB = _e === void 0 ? false : _e, bias = _a.bias, _f = _a.activation, activation = _f === void 0 ? "linear" : _f, preluActivationWeights = _a.preluActivationWeights, _g = _a.leakyreluAlpha, leakyreluAlpha = _g === void 0 ? 0.2 : _g;
      if (shouldFuse(ENGINE.state.gradientDepth, activation) === false) {
        var result = matMul$1(a, b, transposeA, transposeB);
        if (bias != null) {
          result = add(result, bias);
        }
        return applyActivation(result, activation, preluActivationWeights, leakyreluAlpha);
      }
      var $a = convertToTensor(a, "a", "fused matMul");
      var $b = convertToTensor(b, "b", "fused matMul");
      _b = __read(makeTypesMatch($a, $b), 2), $a = _b[0], $b = _b[1];
      var innerShapeA = transposeA ? $a.shape[$a.rank - 2] : $a.shape[$a.rank - 1];
      var innerShapeB = transposeB ? $b.shape[$b.rank - 1] : $b.shape[$b.rank - 2];
      var outerShapeA = transposeA ? $a.shape[$a.rank - 1] : $a.shape[$a.rank - 2];
      var outerShapeB = transposeB ? $b.shape[$b.rank - 2] : $b.shape[$b.rank - 1];
      var outerDimsA = $a.shape.slice(0, -2);
      var outerDimsB = $b.shape.slice(0, -2);
      var batchDimA = sizeFromShape(outerDimsA);
      var batchDimB = sizeFromShape(outerDimsB);
      assert(innerShapeA === innerShapeB, function() {
        return "Error in fused matMul: inner shapes (".concat(innerShapeA, ") and (") + "".concat(innerShapeB, ") of Tensors with shapes ").concat($a.shape, " and ") + "".concat($b.shape, " and transposeA=").concat(transposeA) + " and transposeB=".concat(transposeB, " must match.");
      });
      var outShapeOuterDims = assertAndGetBroadcastShape($a.shape.slice(0, -2), $b.shape.slice(0, -2));
      var outShape = outShapeOuterDims.concat([outerShapeA, outerShapeB]);
      var a3D = transposeA ? reshape($a, [batchDimA, innerShapeA, outerShapeA]) : reshape($a, [batchDimA, outerShapeA, innerShapeA]);
      var b3D = transposeB ? reshape($b, [batchDimB, outerShapeB, innerShapeB]) : reshape($b, [batchDimB, innerShapeB, outerShapeB]);
      var $bias;
      if (bias != null) {
        $bias = convertToTensor(bias, "bias", "fused matMul");
        _c = __read(makeTypesMatch($bias, $a), 1), $bias = _c[0];
        assertAndGetBroadcastShape(outShape, $bias.shape);
      }
      var $preluActivationWeights;
      if (preluActivationWeights != null) {
        $preluActivationWeights = convertToTensor(preluActivationWeights, "prelu weights", "fused matMul");
      }
      var grad2 = function(dy, saved) {
        var _a2 = __read(saved, 4), a3D2 = _a2[0], b3D2 = _a2[1], y = _a2[2], $bias2 = _a2[3];
        var dyActivation = getFusedDyActivation(reshape(dy, y.shape), y, activation);
        var aDer;
        var bDer;
        if (!transposeA && !transposeB) {
          aDer = matMul$1(dyActivation, b3D2, false, true);
          bDer = matMul$1(a3D2, dyActivation, true, false);
        } else if (!transposeA && transposeB) {
          aDer = matMul$1(dyActivation, b3D2, false, false);
          bDer = matMul$1(dyActivation, a3D2, true, false);
        } else if (transposeA && !transposeB) {
          aDer = matMul$1(b3D2, dyActivation, false, true);
          bDer = matMul$1(a3D2, dyActivation, false, false);
        } else {
          aDer = matMul$1(b3D2, dyActivation, true, true);
          bDer = matMul$1(dyActivation, a3D2, true, true);
        }
        if (bias != null) {
          var biasDer = getFusedBiasGradient($bias2, dyActivation);
          return [aDer, bDer, biasDer];
        } else {
          return [aDer, bDer];
        }
      };
      var inputs = {
        a: a3D,
        b: b3D,
        bias: $bias,
        preluActivationWeights: $preluActivationWeights
      };
      var attrs = { transposeA, transposeB, activation, leakyreluAlpha };
      if (bias == null) {
        var customOp = customGrad(function(a3D2, b3D2, save) {
          var res = (
            // tslint:disable-next-line: no-unnecessary-type-assertion
            ENGINE.runKernel(_FusedMatMul, inputs, attrs)
          );
          save([a3D2, b3D2, res]);
          return { value: reshape(res, outShape), gradFunc: grad2 };
        });
        return customOp(a3D, b3D);
      } else {
        var customOpWithBias = customGrad(function(a3D2, b3D2, $bias2, save) {
          var res = (
            // tslint:disable-next-line: no-unnecessary-type-assertion
            ENGINE.runKernel(_FusedMatMul, inputs, attrs)
          );
          save([a3D2, b3D2, res, $bias2]);
          return { value: reshape(res, outShape), gradFunc: grad2 };
        });
        return customOpWithBias(a3D, b3D, $bias);
      }
    }
    var matMul = /* @__PURE__ */ op({ fusedMatMul_ });
    var fused_ops = {
      __proto__: null,
      conv2d,
      depthwiseConv2d,
      matMul
    };
    function hammingWindow_(windowLength) {
      return cosineWindow(windowLength, 0.54, 0.46);
    }
    var hammingWindow = /* @__PURE__ */ op({ hammingWindow_ });
    function hannWindow_(windowLength) {
      return cosineWindow(windowLength, 0.5, 0.5);
    }
    var hannWindow = /* @__PURE__ */ op({ hannWindow_ });
    function frame_(signal2, frameLength, frameStep, padEnd, padValue) {
      if (padEnd === void 0) {
        padEnd = false;
      }
      if (padValue === void 0) {
        padValue = 0;
      }
      var start = 0;
      var output = [];
      while (start + frameLength <= signal2.size) {
        output.push(slice(signal2, start, frameLength));
        start += frameStep;
      }
      if (padEnd) {
        while (start < signal2.size) {
          var padLen = start + frameLength - signal2.size;
          var pad2 = concat([
            slice(signal2, start, frameLength - padLen),
            fill([padLen], padValue)
          ]);
          output.push(pad2);
          start += frameStep;
        }
      }
      if (output.length === 0) {
        return tensor2d([], [0, frameLength]);
      }
      return reshape(concat(output), [output.length, frameLength]);
    }
    var frame = /* @__PURE__ */ op({ frame_ });
    function stft_(signal2, frameLength, frameStep, fftLength, windowFn) {
      if (windowFn === void 0) {
        windowFn = hannWindow;
      }
      if (fftLength == null) {
        fftLength = enclosingPowerOfTwo(frameLength);
      }
      var framedSignal = frame(signal2, frameLength, frameStep);
      var windowedSignal = mul(framedSignal, windowFn(frameLength));
      return rfft(windowedSignal, fftLength);
    }
    var stft = /* @__PURE__ */ op({ stft_ });
    function cropAndResize_(image2, boxes, boxInd, cropSize, method, extrapolationValue) {
      if (method === void 0) {
        method = "bilinear";
      }
      if (extrapolationValue === void 0) {
        extrapolationValue = 0;
      }
      var $image = convertToTensor(image2, "image", "cropAndResize");
      var $boxes = convertToTensor(boxes, "boxes", "cropAndResize", "float32");
      var $boxInd = convertToTensor(boxInd, "boxInd", "cropAndResize", "int32");
      var numBoxes = $boxes.shape[0];
      assert($image.rank === 4, function() {
        return "Error in cropAndResize: image must be rank 4," + "but got rank ".concat($image.rank, ".");
      });
      assert($boxes.rank === 2 && $boxes.shape[1] === 4, function() {
        return "Error in cropAndResize: boxes must be have size [".concat(numBoxes, ",4] ") + "but had shape ".concat($boxes.shape, ".");
      });
      assert($boxInd.rank === 1 && $boxInd.shape[0] === numBoxes, function() {
        return "Error in cropAndResize: boxInd must be have size [".concat(numBoxes, "] ") + "but had shape ".concat($boxes.shape, ".");
      });
      assert(cropSize.length === 2, function() {
        return "Error in cropAndResize: cropSize must be of length 2, but got " + "length ".concat(cropSize.length, ".");
      });
      assert(cropSize[0] >= 1 && cropSize[1] >= 1, function() {
        return "cropSize must be atleast [1,1], but was ".concat(cropSize);
      });
      assert(method === "bilinear" || method === "nearest", function() {
        return "method must be bilinear or nearest, but was ".concat(method);
      });
      var inputs = { image: $image, boxes: $boxes, boxInd: $boxInd };
      var attrs = { method, extrapolationValue, cropSize };
      var res = ENGINE.runKernel(CropAndResize, inputs, attrs);
      return res;
    }
    var cropAndResize = /* @__PURE__ */ op({ cropAndResize_ });
    function flipLeftRight_(image2) {
      var $image = convertToTensor(image2, "image", "flipLeftRight", "float32");
      assert($image.rank === 4, function() {
        return "Error in flipLeftRight: image must be rank 4," + "but got rank ".concat($image.rank, ".");
      });
      var inputs = { image: $image };
      var res = ENGINE.runKernel(FlipLeftRight, inputs, {});
      return res;
    }
    var flipLeftRight = /* @__PURE__ */ op({ flipLeftRight_ });
    function grayscaleToRGB_(image2) {
      var $image = convertToTensor(image2, "image", "grayscaleToRGB");
      var lastDimsIdx = $image.rank - 1;
      var lastDims = $image.shape[lastDimsIdx];
      assert($image.rank >= 2, function() {
        return "Error in grayscaleToRGB: images must be at least rank 2, " + "but got rank ".concat($image.rank, ".");
      });
      assert(lastDims === 1, function() {
        return "Error in grayscaleToRGB: last dimension of a grayscale image " + "should be size 1, but got size ".concat(lastDims, ".");
      });
      var reps = new Array($image.rank);
      reps.fill(1, 0, lastDimsIdx);
      reps[lastDimsIdx] = 3;
      return tile($image, reps);
    }
    var grayscaleToRGB = /* @__PURE__ */ op({ grayscaleToRGB_ });
    function rotateWithOffset_(image2, radians, fillValue, center) {
      if (fillValue === void 0) {
        fillValue = 0;
      }
      if (center === void 0) {
        center = 0.5;
      }
      var $image = convertToTensor(image2, "image", "rotateWithOffset", "float32");
      assert($image.rank === 4, function() {
        return "Error in rotateWithOffset: image must be rank 4," + "but got rank ".concat($image.rank, ".");
      });
      var inputs = { image: $image };
      var attrs = { radians, fillValue, center };
      var res = ENGINE.runKernel(RotateWithOffset, inputs, attrs);
      return res;
    }
    var rotateWithOffset = /* @__PURE__ */ op({ rotateWithOffset_ });
    function nonMaxSuppSanityCheck(boxes, scores, maxOutputSize, iouThreshold, scoreThreshold, softNmsSigma) {
      if (iouThreshold == null) {
        iouThreshold = 0.5;
      }
      if (scoreThreshold == null) {
        scoreThreshold = Number.NEGATIVE_INFINITY;
      }
      if (softNmsSigma == null) {
        softNmsSigma = 0;
      }
      var numBoxes = boxes.shape[0];
      maxOutputSize = Math.min(maxOutputSize, numBoxes);
      assert(0 <= iouThreshold && iouThreshold <= 1, function() {
        return "iouThreshold must be in [0, 1], but was '".concat(iouThreshold, "'");
      });
      assert(boxes.rank === 2, function() {
        return "boxes must be a 2D tensor, but was of rank '".concat(boxes.rank, "'");
      });
      assert(boxes.shape[1] === 4, function() {
        return "boxes must have 4 columns, but 2nd dimension was ".concat(boxes.shape[1]);
      });
      assert(scores.rank === 1, function() {
        return "scores must be a 1D tensor";
      });
      assert(scores.shape[0] === numBoxes, function() {
        return "scores has incompatible shape with boxes. Expected ".concat(numBoxes, ", ") + "but was ".concat(scores.shape[0]);
      });
      assert(0 <= softNmsSigma && softNmsSigma <= 1, function() {
        return "softNmsSigma must be in [0, 1], but was '".concat(softNmsSigma, "'");
      });
      return { maxOutputSize, iouThreshold, scoreThreshold, softNmsSigma };
    }
    function nonMaxSuppression_(boxes, scores, maxOutputSize, iouThreshold, scoreThreshold) {
      if (iouThreshold === void 0) {
        iouThreshold = 0.5;
      }
      if (scoreThreshold === void 0) {
        scoreThreshold = Number.NEGATIVE_INFINITY;
      }
      var $boxes = convertToTensor(boxes, "boxes", "nonMaxSuppression", "float32");
      var $scores = convertToTensor(scores, "scores", "nonMaxSuppression", "float32");
      var inputs = nonMaxSuppSanityCheck($boxes, $scores, maxOutputSize, iouThreshold, scoreThreshold);
      maxOutputSize = inputs.maxOutputSize;
      iouThreshold = inputs.iouThreshold;
      scoreThreshold = inputs.scoreThreshold;
      var attrs = { maxOutputSize, iouThreshold, scoreThreshold };
      return ENGINE.runKernel(NonMaxSuppressionV3, { boxes: $boxes, scores: $scores }, attrs);
    }
    var nonMaxSuppression = /* @__PURE__ */ op({ nonMaxSuppression_ });
    function binaryInsert(arr, element, comparator) {
      var index = binarySearch(arr, element, comparator);
      var insertionPoint = index < 0 ? -(index + 1) : index;
      arr.splice(insertionPoint, 0, element);
    }
    function binarySearch(arr, target, comparator) {
      return binarySearch_(arr, target, comparator || defaultComparator);
    }
    function defaultComparator(a, b) {
      return a > b ? 1 : a < b ? -1 : 0;
    }
    function binarySearch_(arr, target, comparator) {
      var left = 0;
      var right = arr.length;
      var middle = 0;
      var found = false;
      while (left < right) {
        middle = left + (right - left >>> 1);
        var compareResult = comparator(target, arr[middle]);
        if (compareResult > 0) {
          left = middle + 1;
        } else {
          right = middle;
          found = !compareResult;
        }
      }
      return found ? left : -left - 1;
    }
    function nonMaxSuppressionV3Impl(boxes, scores, maxOutputSize, iouThreshold, scoreThreshold) {
      return nonMaxSuppressionImpl_(
        boxes,
        scores,
        maxOutputSize,
        iouThreshold,
        scoreThreshold,
        0
        /* softNmsSigma */
      );
    }
    function nonMaxSuppressionV4Impl(boxes, scores, maxOutputSize, iouThreshold, scoreThreshold, padToMaxOutputSize) {
      return nonMaxSuppressionImpl_(
        boxes,
        scores,
        maxOutputSize,
        iouThreshold,
        scoreThreshold,
        0,
        false,
        padToMaxOutputSize,
        true
        /* returnValidOutputs */
      );
    }
    function nonMaxSuppressionV5Impl(boxes, scores, maxOutputSize, iouThreshold, scoreThreshold, softNmsSigma) {
      return nonMaxSuppressionImpl_(
        boxes,
        scores,
        maxOutputSize,
        iouThreshold,
        scoreThreshold,
        softNmsSigma,
        true
        /* returnScoresTensor */
      );
    }
    function nonMaxSuppressionImpl_(boxes, scores, maxOutputSize, iouThreshold, scoreThreshold, softNmsSigma, returnScoresTensor, padToMaxOutputSize, returnValidOutputs) {
      if (returnScoresTensor === void 0) {
        returnScoresTensor = false;
      }
      if (padToMaxOutputSize === void 0) {
        padToMaxOutputSize = false;
      }
      if (returnValidOutputs === void 0) {
        returnValidOutputs = false;
      }
      var candidates = [];
      for (var i = 0; i < scores.length; i++) {
        if (scores[i] > scoreThreshold) {
          candidates.push({ score: scores[i], boxIndex: i, suppressBeginIndex: 0 });
        }
      }
      candidates.sort(ascendingComparator);
      var scale = softNmsSigma > 0 ? -0.5 / softNmsSigma : 0;
      var selectedIndices = [];
      var selectedScores = [];
      while (selectedIndices.length < maxOutputSize && candidates.length > 0) {
        var candidate = candidates.pop();
        var originalScore = candidate.score, boxIndex = candidate.boxIndex, suppressBeginIndex = candidate.suppressBeginIndex;
        if (originalScore < scoreThreshold) {
          break;
        }
        var ignoreCandidate = false;
        for (var j = selectedIndices.length - 1; j >= suppressBeginIndex; --j) {
          var iou = intersectionOverUnion(boxes, boxIndex, selectedIndices[j]);
          if (iou >= iouThreshold) {
            ignoreCandidate = true;
            break;
          }
          candidate.score = candidate.score * suppressWeight(iouThreshold, scale, iou);
          if (candidate.score <= scoreThreshold) {
            break;
          }
        }
        candidate.suppressBeginIndex = selectedIndices.length;
        if (!ignoreCandidate) {
          if (candidate.score === originalScore) {
            selectedIndices.push(boxIndex);
            selectedScores.push(candidate.score);
          } else if (candidate.score > scoreThreshold) {
            binaryInsert(candidates, candidate, ascendingComparator);
          }
        }
      }
      var validOutputs = selectedIndices.length;
      var elemsToPad = maxOutputSize - validOutputs;
      if (padToMaxOutputSize && elemsToPad > 0) {
        selectedIndices.push.apply(selectedIndices, __spreadArray([], __read(new Array(elemsToPad).fill(0)), false));
        selectedScores.push.apply(selectedScores, __spreadArray([], __read(new Array(elemsToPad).fill(0)), false));
      }
      var result = { selectedIndices };
      if (returnScoresTensor) {
        result["selectedScores"] = selectedScores;
      }
      if (returnValidOutputs) {
        result["validOutputs"] = validOutputs;
      }
      return result;
    }
    function intersectionOverUnion(boxes, i, j) {
      var iCoord = boxes.subarray(i * 4, i * 4 + 4);
      var jCoord = boxes.subarray(j * 4, j * 4 + 4);
      var yminI = Math.min(iCoord[0], iCoord[2]);
      var xminI = Math.min(iCoord[1], iCoord[3]);
      var ymaxI = Math.max(iCoord[0], iCoord[2]);
      var xmaxI = Math.max(iCoord[1], iCoord[3]);
      var yminJ = Math.min(jCoord[0], jCoord[2]);
      var xminJ = Math.min(jCoord[1], jCoord[3]);
      var ymaxJ = Math.max(jCoord[0], jCoord[2]);
      var xmaxJ = Math.max(jCoord[1], jCoord[3]);
      var areaI = (ymaxI - yminI) * (xmaxI - xminI);
      var areaJ = (ymaxJ - yminJ) * (xmaxJ - xminJ);
      if (areaI <= 0 || areaJ <= 0) {
        return 0;
      }
      var intersectionYmin = Math.max(yminI, yminJ);
      var intersectionXmin = Math.max(xminI, xminJ);
      var intersectionYmax = Math.min(ymaxI, ymaxJ);
      var intersectionXmax = Math.min(xmaxI, xmaxJ);
      var intersectionArea = Math.max(intersectionYmax - intersectionYmin, 0) * Math.max(intersectionXmax - intersectionXmin, 0);
      return intersectionArea / (areaI + areaJ - intersectionArea);
    }
    function suppressWeight(iouThreshold, scale, iou) {
      var weight = Math.exp(scale * iou * iou);
      return iou <= iouThreshold ? weight : 0;
    }
    function ascendingComparator(c1, c2) {
      return c1.score - c2.score || c1.score === c2.score && c2.boxIndex - c1.boxIndex;
    }
    function nonMaxSuppressionAsync_(boxes, scores, maxOutputSize, iouThreshold, scoreThreshold) {
      if (iouThreshold === void 0) {
        iouThreshold = 0.5;
      }
      if (scoreThreshold === void 0) {
        scoreThreshold = Number.NEGATIVE_INFINITY;
      }
      return __awaiter(this, void 0, void 0, function() {
        var $boxes, $scores, inputs, boxesAndScores, boxesVals, scoresVals, selectedIndices;
        return __generator(this, function(_a) {
          switch (_a.label) {
            case 0:
              $boxes = convertToTensor(boxes, "boxes", "nonMaxSuppressionAsync");
              $scores = convertToTensor(scores, "scores", "nonMaxSuppressionAsync");
              inputs = nonMaxSuppSanityCheck($boxes, $scores, maxOutputSize, iouThreshold, scoreThreshold);
              maxOutputSize = inputs.maxOutputSize;
              iouThreshold = inputs.iouThreshold;
              scoreThreshold = inputs.scoreThreshold;
              return [4, Promise.all([$boxes.data(), $scores.data()])];
            case 1:
              boxesAndScores = _a.sent();
              boxesVals = boxesAndScores[0];
              scoresVals = boxesAndScores[1];
              selectedIndices = nonMaxSuppressionV3Impl(boxesVals, scoresVals, maxOutputSize, iouThreshold, scoreThreshold).selectedIndices;
              if ($boxes !== boxes) {
                $boxes.dispose();
              }
              if ($scores !== scores) {
                $scores.dispose();
              }
              return [2, tensor1d(selectedIndices, "int32")];
          }
        });
      });
    }
    var nonMaxSuppressionAsync = nonMaxSuppressionAsync_;
    function nonMaxSuppressionWithScore_(boxes, scores, maxOutputSize, iouThreshold, scoreThreshold, softNmsSigma) {
      if (iouThreshold === void 0) {
        iouThreshold = 0.5;
      }
      if (scoreThreshold === void 0) {
        scoreThreshold = Number.NEGATIVE_INFINITY;
      }
      if (softNmsSigma === void 0) {
        softNmsSigma = 0;
      }
      var $boxes = convertToTensor(boxes, "boxes", "nonMaxSuppression");
      var $scores = convertToTensor(scores, "scores", "nonMaxSuppression");
      var params = nonMaxSuppSanityCheck($boxes, $scores, maxOutputSize, iouThreshold, scoreThreshold, softNmsSigma);
      maxOutputSize = params.maxOutputSize;
      iouThreshold = params.iouThreshold;
      scoreThreshold = params.scoreThreshold;
      softNmsSigma = params.softNmsSigma;
      var inputs = { boxes: $boxes, scores: $scores };
      var attrs = { maxOutputSize, iouThreshold, scoreThreshold, softNmsSigma };
      var result = ENGINE.runKernel(NonMaxSuppressionV5, inputs, attrs);
      return { selectedIndices: result[0], selectedScores: result[1] };
    }
    var nonMaxSuppressionWithScore = /* @__PURE__ */ op({ nonMaxSuppressionWithScore_ });
    function nonMaxSuppressionWithScoreAsync_(boxes, scores, maxOutputSize, iouThreshold, scoreThreshold, softNmsSigma) {
      if (iouThreshold === void 0) {
        iouThreshold = 0.5;
      }
      if (scoreThreshold === void 0) {
        scoreThreshold = Number.NEGATIVE_INFINITY;
      }
      if (softNmsSigma === void 0) {
        softNmsSigma = 0;
      }
      return __awaiter(this, void 0, void 0, function() {
        var $boxes, $scores, params, boxesAndScores, boxesVals, scoresVals, _a, selectedIndices, selectedScores;
        return __generator(this, function(_b) {
          switch (_b.label) {
            case 0:
              $boxes = convertToTensor(boxes, "boxes", "nonMaxSuppressionAsync");
              $scores = convertToTensor(scores, "scores", "nonMaxSuppressionAsync");
              params = nonMaxSuppSanityCheck($boxes, $scores, maxOutputSize, iouThreshold, scoreThreshold, softNmsSigma);
              maxOutputSize = params.maxOutputSize;
              iouThreshold = params.iouThreshold;
              scoreThreshold = params.scoreThreshold;
              softNmsSigma = params.softNmsSigma;
              return [4, Promise.all([$boxes.data(), $scores.data()])];
            case 1:
              boxesAndScores = _b.sent();
              boxesVals = boxesAndScores[0];
              scoresVals = boxesAndScores[1];
              _a = nonMaxSuppressionV5Impl(boxesVals, scoresVals, maxOutputSize, iouThreshold, scoreThreshold, softNmsSigma), selectedIndices = _a.selectedIndices, selectedScores = _a.selectedScores;
              if ($boxes !== boxes) {
                $boxes.dispose();
              }
              if ($scores !== scores) {
                $scores.dispose();
              }
              return [2, {
                selectedIndices: tensor1d(selectedIndices, "int32"),
                selectedScores: tensor1d(selectedScores)
              }];
          }
        });
      });
    }
    var nonMaxSuppressionWithScoreAsync = nonMaxSuppressionWithScoreAsync_;
    function nonMaxSuppressionPadded_(boxes, scores, maxOutputSize, iouThreshold, scoreThreshold, padToMaxOutputSize) {
      if (iouThreshold === void 0) {
        iouThreshold = 0.5;
      }
      if (scoreThreshold === void 0) {
        scoreThreshold = Number.NEGATIVE_INFINITY;
      }
      if (padToMaxOutputSize === void 0) {
        padToMaxOutputSize = false;
      }
      var $boxes = convertToTensor(boxes, "boxes", "nonMaxSuppression");
      var $scores = convertToTensor(scores, "scores", "nonMaxSuppression");
      var params = nonMaxSuppSanityCheck(
        $boxes,
        $scores,
        maxOutputSize,
        iouThreshold,
        scoreThreshold,
        null
        /* softNmsSigma */
      );
      var $maxOutputSize = params.maxOutputSize;
      var $iouThreshold = params.iouThreshold;
      var $scoreThreshold = params.scoreThreshold;
      var inputs = { boxes: $boxes, scores: $scores };
      var attrs = {
        maxOutputSize: $maxOutputSize,
        iouThreshold: $iouThreshold,
        scoreThreshold: $scoreThreshold,
        padToMaxOutputSize
      };
      var result = ENGINE.runKernel(NonMaxSuppressionV4, inputs, attrs);
      return { selectedIndices: result[0], validOutputs: result[1] };
    }
    var nonMaxSuppressionPadded = /* @__PURE__ */ op({ nonMaxSuppressionPadded_ });
    function nonMaxSuppressionPaddedAsync_(boxes, scores, maxOutputSize, iouThreshold, scoreThreshold, padToMaxOutputSize) {
      if (iouThreshold === void 0) {
        iouThreshold = 0.5;
      }
      if (scoreThreshold === void 0) {
        scoreThreshold = Number.NEGATIVE_INFINITY;
      }
      if (padToMaxOutputSize === void 0) {
        padToMaxOutputSize = false;
      }
      return __awaiter(this, void 0, void 0, function() {
        var $boxes, $scores, params, $maxOutputSize, $iouThreshold, $scoreThreshold, _a, boxesVals, scoresVals, _b, selectedIndices, validOutputs;
        return __generator(this, function(_c) {
          switch (_c.label) {
            case 0:
              $boxes = convertToTensor(boxes, "boxes", "nonMaxSuppressionAsync");
              $scores = convertToTensor(scores, "scores", "nonMaxSuppressionAsync");
              params = nonMaxSuppSanityCheck(
                $boxes,
                $scores,
                maxOutputSize,
                iouThreshold,
                scoreThreshold,
                null
                /* softNmsSigma */
              );
              $maxOutputSize = params.maxOutputSize;
              $iouThreshold = params.iouThreshold;
              $scoreThreshold = params.scoreThreshold;
              return [4, Promise.all([$boxes.data(), $scores.data()])];
            case 1:
              _a = __read.apply(void 0, [_c.sent(), 2]), boxesVals = _a[0], scoresVals = _a[1];
              _b = nonMaxSuppressionV4Impl(boxesVals, scoresVals, $maxOutputSize, $iouThreshold, $scoreThreshold, padToMaxOutputSize), selectedIndices = _b.selectedIndices, validOutputs = _b.validOutputs;
              if ($boxes !== boxes) {
                $boxes.dispose();
              }
              if ($scores !== scores) {
                $scores.dispose();
              }
              return [2, {
                selectedIndices: tensor1d(selectedIndices, "int32"),
                validOutputs: scalar(validOutputs, "int32")
              }];
          }
        });
      });
    }
    var nonMaxSuppressionPaddedAsync = nonMaxSuppressionPaddedAsync_;
    function resizeBilinear_(images, size, alignCorners, halfPixelCenters) {
      if (alignCorners === void 0) {
        alignCorners = false;
      }
      if (halfPixelCenters === void 0) {
        halfPixelCenters = false;
      }
      var $images = convertToTensor(images, "images", "resizeBilinear");
      assert($images.rank === 3 || $images.rank === 4, function() {
        return "Error in resizeBilinear: x must be rank 3 or 4, but got " + "rank ".concat($images.rank, ".");
      });
      assert(size.length === 2, function() {
        return "Error in resizeBilinear: new shape must 2D, but got shape " + "".concat(size, ".");
      });
      assert(halfPixelCenters === false || alignCorners === false, function() {
        return "Error in resizeBilinear: If halfPixelCenters is true, alignCorners must be false.";
      });
      var batchImages = $images;
      var reshapedTo4D = false;
      if ($images.rank === 3) {
        reshapedTo4D = true;
        batchImages = reshape($images, [1, $images.shape[0], $images.shape[1], $images.shape[2]]);
      }
      __read(size, 0);
      var inputs = { images: batchImages };
      var attrs = { alignCorners, halfPixelCenters, size };
      var res = ENGINE.runKernel(ResizeBilinear, inputs, attrs);
      if (reshapedTo4D) {
        return reshape(res, [res.shape[1], res.shape[2], res.shape[3]]);
      }
      return res;
    }
    var resizeBilinear = /* @__PURE__ */ op({ resizeBilinear_ });
    function resizeNearestNeighbor_(images, size, alignCorners, halfPixelCenters) {
      if (alignCorners === void 0) {
        alignCorners = false;
      }
      if (halfPixelCenters === void 0) {
        halfPixelCenters = false;
      }
      var $images = convertToTensor(images, "images", "resizeNearestNeighbor");
      assert($images.rank === 3 || $images.rank === 4, function() {
        return "Error in resizeNearestNeighbor: x must be rank 3 or 4, but got " + "rank ".concat($images.rank, ".");
      });
      assert(size.length === 2, function() {
        return "Error in resizeNearestNeighbor: new shape must 2D, but got shape " + "".concat(size, ".");
      });
      assert($images.dtype === "float32" || $images.dtype === "int32", function() {
        return "`images` must have `int32` or `float32` as dtype";
      });
      assert(halfPixelCenters === false || alignCorners === false, function() {
        return "Error in resizeNearestNeighbor: If halfPixelCenters is true, alignCorners must be false.";
      });
      var batchImages = $images;
      var reshapedTo4D = false;
      if ($images.rank === 3) {
        reshapedTo4D = true;
        batchImages = reshape($images, [1, $images.shape[0], $images.shape[1], $images.shape[2]]);
      }
      __read(size, 0);
      var inputs = { images: batchImages };
      var attrs = { alignCorners, halfPixelCenters, size };
      var res = ENGINE.runKernel(ResizeNearestNeighbor, inputs, attrs);
      if (reshapedTo4D) {
        return reshape(res, [res.shape[1], res.shape[2], res.shape[3]]);
      }
      return res;
    }
    var resizeNearestNeighbor = /* @__PURE__ */ op({ resizeNearestNeighbor_ });
    function threshold_(image2, method, inverted, threshValue) {
      var _a;
      if (method === void 0) {
        method = "binary";
      }
      if (inverted === void 0) {
        inverted = false;
      }
      if (threshValue === void 0) {
        threshValue = 0.5;
      }
      var $image = convertToTensor(image2, "image", "threshold");
      var RED_INTENCITY_COEF = 0.2989;
      var GREEN_INTENCITY_COEF = 0.587;
      var BLUE_INTENCITY_COEF = 0.114;
      var totalPixelsInImage = $image.shape[0] * $image.shape[1];
      var $threshold = mul(tensor1d([threshValue]), 255);
      var r, g, b, grayscale;
      assert($image.rank === 3, function() {
        return "Error in threshold: image must be rank 3," + "but got rank ".concat($image.rank, ".");
      });
      assert($image.shape[2] === 3 || $image.shape[2] === 1, function() {
        return "Error in threshold: image color channel must be equal to 3 or 1" + "but got ".concat($image.shape[2], ".");
      });
      assert($image.dtype === "int32" || $image.dtype === "float32", function() {
        return "Error in dtype: image dtype must be int32 or float32," + "but got dtype ".concat($image.dtype, ".");
      });
      assert(method === "otsu" || method === "binary", function() {
        return "Method must be binary or otsu, but was ".concat(method);
      });
      if ($image.shape[2] === 3) {
        _a = __read(split($image, [1, 1, 1], -1), 3), r = _a[0], g = _a[1], b = _a[2];
        var $r = mul(r, RED_INTENCITY_COEF);
        var $g = mul(g, GREEN_INTENCITY_COEF);
        var $b = mul(b, BLUE_INTENCITY_COEF);
        grayscale = add(add($r, $g), $b);
      } else {
        grayscale = image2;
      }
      if (method === "otsu") {
        var $histogram = bincount(cast(round(grayscale), "int32"), tensor([]), 256);
        $threshold = otsu($histogram, totalPixelsInImage);
      }
      var invCondition = inverted ? lessEqual(grayscale, $threshold) : greater(grayscale, $threshold);
      var result = cast(mul(invCondition, 255), "int32");
      return result;
    }
    function otsu(histogram, total) {
      var bestThresh = tensor1d([-1]);
      var bestInBetVar = tensor1d([0]);
      var cInBetVar = tensor1d([0]);
      var classFirst, classSecond, meanFirst, meanSec, weightForeground, weightBack;
      for (var index = 0; index < histogram.size - 1; index++) {
        classFirst = slice(histogram, 0, index + 1);
        classSecond = slice(histogram, index + 1);
        weightForeground = div(sum(classFirst), total);
        weightBack = div(sum(classSecond), total);
        var meanFirstDivA = sum(mul(classFirst, range(0, classFirst.size)));
        meanFirst = div(meanFirstDivA, sum(classFirst));
        var meanSecFill = fill(classSecond.shape, classFirst.size);
        var meanSecAdd = add(range(0, classSecond.size), meanSecFill);
        var meanSecMul = mul(classSecond, meanSecAdd);
        meanSec = div(sum(meanSecMul), sum(classSecond));
        var cInBetVarSubA = sub(meanFirst, meanSec);
        var cInBetVarSubB = sub(meanFirst, meanSec);
        var cInBetVarMul = mul(weightForeground, weightBack);
        cInBetVar = mul(mul(cInBetVarMul, cInBetVarSubA), cInBetVarSubB);
        var condition = greater(cInBetVar, bestInBetVar);
        bestInBetVar = where(condition, cInBetVar, bestInBetVar);
        bestThresh = where(condition, tensor1d([index]), bestThresh);
      }
      return bestThresh;
    }
    var threshold = /* @__PURE__ */ op({ threshold_ });
    function transform_(image2, transforms, interpolation, fillMode, fillValue, outputShape) {
      if (interpolation === void 0) {
        interpolation = "nearest";
      }
      if (fillMode === void 0) {
        fillMode = "constant";
      }
      if (fillValue === void 0) {
        fillValue = 0;
      }
      var $image = convertToTensor(image2, "image", "transform", "float32");
      var $transforms = convertToTensor(transforms, "transforms", "transform", "float32");
      assert($image.rank === 4, function() {
        return "Error in transform: image must be rank 4," + "but got rank ".concat($image.rank, ".");
      });
      assert($transforms.rank === 2 && ($transforms.shape[0] === $image.shape[0] || $transforms.shape[0] === 1) && $transforms.shape[1] === 8, function() {
        return "Error in transform: Input transform should be batch x 8 or 1 x 8";
      });
      assert(outputShape == null || outputShape.length === 2, function() {
        return "Error in transform: outputShape must be [height, width] or null, " + "but got ".concat(outputShape, ".");
      });
      var inputs = { image: $image, transforms: $transforms };
      var attrs = { interpolation, fillMode, fillValue, outputShape };
      return ENGINE.runKernel(Transform, inputs, attrs);
    }
    var transform = /* @__PURE__ */ op({ transform_ });
    function bandPart_(a, numLower, numUpper) {
      var $a = convertToTensor(a, "a", "bandPart");
      assert($a.rank >= 2, function() {
        return "bandPart(): Rank must be at least 2, got ".concat($a.rank, ".");
      });
      var shape = $a.shape;
      var _a = __read($a.shape.slice(-2), 2), M = _a[0], N = _a[1];
      var $numLower;
      var $numUpper;
      if (typeof numLower === "number") {
        assert(numLower % 1 === 0, function() {
          return "bandPart(): numLower must be an integer, got ".concat(numLower, ".");
        });
        assert(numLower <= M, function() {
          return "bandPart(): numLower (".concat(numLower, ")") + " must not be greater than the number of rows (".concat(M, ").");
        });
        $numLower = convertToTensor(numLower < 0 ? M : numLower, "numLower", "bandPart");
      } else {
        assert(numLower.dtype === "int32", function() {
          return "bandPart(): numLower's dtype must be an int32.";
        });
        $numLower = where(less(numLower, 0), M, minimum(numLower, M));
      }
      if (typeof numUpper === "number") {
        assert(numUpper % 1 === 0, function() {
          return "bandPart(): numUpper must be an integer, got ".concat(numUpper, ".");
        });
        assert(numUpper <= N, function() {
          return "bandPart(): numUpper (".concat(numUpper, ")") + " must not be greater than the number of columns (".concat(N, ").");
        });
        $numUpper = convertToTensor(numUpper < 0 ? N : numUpper, "numUpper", "bandPart");
      } else {
        assert(numUpper.dtype === "int32", function() {
          return "bandPart(): numUpper's dtype must be an int32.";
        });
        $numUpper = where(less(numUpper, 0), N, minimum(numUpper, N));
      }
      var i = reshape(range(0, M, 1, "int32"), [-1, 1]);
      var j = range(0, N, 1, "int32");
      var ij = sub(i, j);
      var inBand = logicalAnd(lessEqual(ij, $numLower), greaterEqual(ij, neg($numUpper)));
      var zero = zeros([M, N], $a.dtype);
      return reshape(stack(unstack(reshape($a, [-1, M, N])).map(function(mat) {
        return where(inBand, mat, zero);
      })), shape);
    }
    var bandPart = /* @__PURE__ */ op({ bandPart_ });
    function gramSchmidt_(xs) {
      var inputIsTensor2D;
      if (Array.isArray(xs)) {
        inputIsTensor2D = false;
        assert(xs != null && xs.length > 0, function() {
          return "Gram-Schmidt process: input must not be null, undefined, or empty";
        });
        var dim_1 = xs[0].shape[0];
        var _loop_1 = function(i2) {
          assert(xs[i2].shape[0] === dim_1, function() {
            return "Gram-Schmidt: Non-unique lengths found in the input vectors: " + "(".concat(xs[i2].shape[0], " vs. ").concat(dim_1, ")");
          });
        };
        for (var i = 1; i < xs.length; ++i) {
          _loop_1(i);
        }
      } else {
        inputIsTensor2D = true;
        xs = split(xs, xs.shape[0], 0).map(function(x) {
          return squeeze(x, [0]);
        });
      }
      assert(xs.length <= xs[0].shape[0], function() {
        return "Gram-Schmidt: Number of vectors (".concat(xs.length, ") exceeds ") + "number of dimensions (".concat(xs[0].shape[0], ").");
      });
      var ys = [];
      var xs1d = xs;
      var _loop_2 = function(i2) {
        ys.push(ENGINE.tidy(function() {
          var x = xs1d[i2];
          if (i2 > 0) {
            for (var j = 0; j < i2; ++j) {
              var proj = mul(sum(mul(ys[j], x)), ys[j]);
              x = sub(x, proj);
            }
          }
          return div(x, norm(x, "euclidean"));
        }));
      };
      for (var i = 0; i < xs.length; ++i) {
        _loop_2(i);
      }
      if (inputIsTensor2D) {
        return stack(ys, 0);
      } else {
        return ys;
      }
    }
    var gramSchmidt = /* @__PURE__ */ op({ gramSchmidt_ });
    function qr_(x, fullMatrices) {
      if (fullMatrices === void 0) {
        fullMatrices = false;
      }
      assert(x.rank >= 2, function() {
        return "qr() requires input tensor to have a rank >= 2, but got rank ".concat(x.rank);
      });
      if (x.rank === 2) {
        return qr2d(x, fullMatrices);
      } else {
        var outerDimsProd = x.shape.slice(0, x.shape.length - 2).reduce(function(value, prev) {
          return value * prev;
        });
        var x2ds = unstack(reshape(x, [
          outerDimsProd,
          x.shape[x.shape.length - 2],
          x.shape[x.shape.length - 1]
        ]), 0);
        var q2ds_1 = [];
        var r2ds_1 = [];
        x2ds.forEach(function(x2d) {
          var _a = __read(qr2d(x2d, fullMatrices), 2), q2d = _a[0], r2d = _a[1];
          q2ds_1.push(q2d);
          r2ds_1.push(r2d);
        });
        var q = reshape(stack(q2ds_1, 0), x.shape);
        var r = reshape(stack(r2ds_1, 0), x.shape);
        return [q, r];
      }
    }
    function qr2d(x, fullMatrices) {
      if (fullMatrices === void 0) {
        fullMatrices = false;
      }
      return ENGINE.tidy(function() {
        assert(x.shape.length === 2, function() {
          return "qr2d() requires a 2D Tensor, but got a ".concat(x.shape.length, "D Tensor.");
        });
        var m = x.shape[0];
        var n = x.shape[1];
        var q = eye(m);
        var r = clone(x);
        var one2D = tensor2d([[1]], [1, 1]);
        var w = clone(one2D);
        var iters = m >= n ? n : m;
        var _loop_1 = function(j2) {
          var _a;
          var rTemp = r;
          var wTemp = w;
          var qTemp = q;
          _a = __read(ENGINE.tidy(function() {
            var rjEnd1 = slice(r, [j2, j2], [m - j2, 1]);
            var normX = norm(rjEnd1);
            var rjj = slice(r, [j2, j2], [1, 1]);
            var s = where(greater(rjj, 0), tensor2d([[-1]]), tensor2d([[1]]));
            var u1 = sub(rjj, mul(s, normX));
            var wPre = div(rjEnd1, u1);
            if (wPre.shape[0] === 1) {
              w = clone(one2D);
            } else {
              w = concat([
                one2D,
                slice(wPre, [1, 0], [wPre.shape[0] - 1, wPre.shape[1]])
              ], 0);
            }
            var tau = neg(div(matMul$1(s, u1), normX));
            var rjEndAll = slice(r, [j2, 0], [m - j2, n]);
            var tauTimesW = mul(tau, w);
            var wT = transpose(w);
            if (j2 === 0) {
              r = sub(rjEndAll, matMul$1(tauTimesW, matMul$1(wT, rjEndAll)));
            } else {
              var rTimesTau = sub(rjEndAll, matMul$1(tauTimesW, matMul$1(wT, rjEndAll)));
              r = concat([slice(r, [0, 0], [j2, n]), rTimesTau], 0);
            }
            var tawTimesWT = transpose(tauTimesW);
            var qAllJEnd = slice(q, [0, j2], [m, q.shape[1] - j2]);
            if (j2 === 0) {
              q = sub(qAllJEnd, matMul$1(matMul$1(qAllJEnd, w), tawTimesWT));
            } else {
              var qTimesTau = sub(qAllJEnd, matMul$1(matMul$1(qAllJEnd, w), tawTimesWT));
              q = concat([slice(q, [0, 0], [m, j2]), qTimesTau], 1);
            }
            return [w, r, q];
          }), 3), w = _a[0], r = _a[1], q = _a[2];
          dispose([rTemp, wTemp, qTemp]);
        };
        for (var j = 0; j < iters; ++j) {
          _loop_1(j);
        }
        if (!fullMatrices && m > n) {
          q = slice(q, [0, 0], [m, n]);
          r = slice(r, [0, 0], [n, n]);
        }
        return [q, r];
      });
    }
    var qr = /* @__PURE__ */ op({ qr_ });
    exports.Reduction = void 0;
    (function(Reduction) {
      Reduction[Reduction["NONE"] = 0] = "NONE";
      Reduction[Reduction["MEAN"] = 1] = "MEAN";
      Reduction[Reduction["SUM"] = 2] = "SUM";
      Reduction[Reduction["SUM_BY_NONZERO_WEIGHTS"] = 3] = "SUM_BY_NONZERO_WEIGHTS";
    })(exports.Reduction || (exports.Reduction = {}));
    function computeWeightedLoss_(losses2, weights, reduction) {
      if (reduction === void 0) {
        reduction = exports.Reduction.SUM_BY_NONZERO_WEIGHTS;
      }
      var $losses = convertToTensor(losses2, "losses", "computeWeightedLoss");
      var $weights = null;
      if (weights != null) {
        $weights = convertToTensor(weights, "weights", "computeWeightedLoss");
      }
      var weightedLoss = $weights == null ? $losses : mul($losses, $weights);
      if (reduction === exports.Reduction.NONE) {
        return weightedLoss;
      }
      if (reduction === exports.Reduction.SUM) {
        return sum(weightedLoss);
      }
      if (reduction === exports.Reduction.MEAN) {
        if ($weights == null) {
          return mean(weightedLoss);
        } else {
          var broadcastFactor = $losses.size / $weights.size;
          var result = div(sum(weightedLoss), sum($weights));
          return broadcastFactor > 1 ? div(result, scalar(broadcastFactor)) : result;
        }
      }
      if (reduction === exports.Reduction.SUM_BY_NONZERO_WEIGHTS) {
        if ($weights == null) {
          return div(sum(weightedLoss), scalar($losses.size));
        } else {
          var broadcastedWeights = mul($weights, ones($losses.shape));
          var numNonZeros = cast(sum(notEqual(broadcastedWeights, scalar(0))), "float32");
          return div(sum(weightedLoss), numNonZeros);
        }
      }
      throw Error("Unknown reduction: ".concat(reduction));
    }
    var computeWeightedLoss = /* @__PURE__ */ op({ computeWeightedLoss_ });
    function absoluteDifference_(labels, predictions, weights, reduction) {
      if (reduction === void 0) {
        reduction = exports.Reduction.SUM_BY_NONZERO_WEIGHTS;
      }
      var $labels = convertToTensor(labels, "labels", "absoluteDifference");
      var $predictions = convertToTensor(predictions, "predictions", "absoluteDifference");
      var $weights = null;
      if (weights != null) {
        $weights = convertToTensor(weights, "weights", "absoluteDifference");
      }
      assertShapesMatch($labels.shape, $predictions.shape, "Error in absoluteDifference: ");
      var losses2 = abs(sub($labels, $predictions));
      return computeWeightedLoss(losses2, $weights, reduction);
    }
    var absoluteDifference = /* @__PURE__ */ op({ absoluteDifference_ });
    function cosineDistance_(labels, predictions, axis, weights, reduction) {
      if (reduction === void 0) {
        reduction = exports.Reduction.SUM_BY_NONZERO_WEIGHTS;
      }
      var $labels = convertToTensor(labels, "labels", "cosineDistance");
      var $predictions = convertToTensor(predictions, "predictions", "cosineDistance");
      var $weights = null;
      if (weights != null) {
        $weights = convertToTensor(weights, "weights", "cosineDistance");
      }
      assertShapesMatch($labels.shape, $predictions.shape, "Error in cosineDistance: ");
      var one = scalar(1);
      var losses2 = sub(one, sum(mul($labels, $predictions), axis, true));
      return computeWeightedLoss(losses2, $weights, reduction);
    }
    var cosineDistance = /* @__PURE__ */ op({ cosineDistance_ });
    function hingeLoss_(labels, predictions, weights, reduction) {
      if (reduction === void 0) {
        reduction = exports.Reduction.SUM_BY_NONZERO_WEIGHTS;
      }
      var $labels = convertToTensor(labels, "labels", "hingeLoss");
      var $predictions = convertToTensor(predictions, "predictions", "hingeLoss");
      var $weights = null;
      if (weights != null) {
        $weights = convertToTensor(weights, "weights", "hingeLoss");
      }
      assertShapesMatch($labels.shape, $predictions.shape, "Error in hingeLoss: ");
      var one = scalar(1);
      $labels = sub(mul(scalar(2), $labels), one);
      var losses2 = relu(sub(one, mul($labels, $predictions)));
      return computeWeightedLoss(losses2, $weights, reduction);
    }
    var hingeLoss = /* @__PURE__ */ op({ hingeLoss_ });
    function huberLoss_(labels, predictions, weights, delta, reduction) {
      if (delta === void 0) {
        delta = 1;
      }
      if (reduction === void 0) {
        reduction = exports.Reduction.SUM_BY_NONZERO_WEIGHTS;
      }
      var $labels = convertToTensor(labels, "labels", "huberLoss");
      var $predictions = convertToTensor(predictions, "predictions", "huberLoss");
      var $weights = null;
      if (weights != null) {
        $weights = convertToTensor(weights, "weights", "huberLoss");
      }
      assertShapesMatch($labels.shape, $predictions.shape, "Error in huberLoss: ");
      var deltaScalar = scalar(delta);
      var error = abs(sub($predictions, $labels));
      var quadratic = minimum(error, deltaScalar);
      var linear = sub(error, quadratic);
      var losses2 = add(mul(scalar(0.5), square(quadratic)), mul(deltaScalar, linear));
      return computeWeightedLoss(losses2, $weights, reduction);
    }
    var huberLoss = /* @__PURE__ */ op({ huberLoss_ });
    function logLoss_(labels, predictions, weights, epsilon, reduction) {
      if (epsilon === void 0) {
        epsilon = 1e-7;
      }
      if (reduction === void 0) {
        reduction = exports.Reduction.SUM_BY_NONZERO_WEIGHTS;
      }
      var $labels = convertToTensor(labels, "labels", "logLoss");
      var $predictions = convertToTensor(predictions, "predictions", "logLoss");
      var $weights = null;
      if (weights != null) {
        $weights = convertToTensor(weights, "weights", "logLoss");
      }
      assertShapesMatch($labels.shape, $predictions.shape, "Error in logLoss: ");
      var one = scalar(1);
      var epsilonScalar = scalar(epsilon);
      var l1 = neg(mul($labels, log(add($predictions, epsilonScalar))));
      var l2 = mul(sub(one, $labels), log(add(sub(one, $predictions), epsilonScalar)));
      var losses2 = sub(l1, l2);
      return computeWeightedLoss(losses2, $weights, reduction);
    }
    var logLoss = /* @__PURE__ */ op({ logLoss_ });
    function meanSquaredError_(labels, predictions, weights, reduction) {
      if (reduction === void 0) {
        reduction = exports.Reduction.SUM_BY_NONZERO_WEIGHTS;
      }
      var $labels = convertToTensor(labels, "labels", "meanSquaredError");
      var $predictions = convertToTensor(predictions, "predictions", "meanSquaredError");
      var $weights = null;
      if (weights != null) {
        $weights = convertToTensor(weights, "weights", "meanSquaredError");
      }
      assertShapesMatch($labels.shape, $predictions.shape, "Error in meanSquaredError: ");
      var losses2 = squaredDifference($labels, $predictions);
      return computeWeightedLoss(losses2, $weights, reduction);
    }
    var meanSquaredError = /* @__PURE__ */ op({ meanSquaredError_ });
    function sigmoidCrossEntropyWithLogits_(labels, logits) {
      var $labels = convertToTensor(labels, "labels", "sigmoidCrossEntropyWithLogits");
      var $logits = convertToTensor(logits, "logits", "sigmoidCrossEntropyWithLogits");
      assertShapesMatch($labels.shape, $logits.shape, "Error in sigmoidCrossEntropyWithLogits: ");
      var maxOutput = relu($logits);
      var outputXTarget = mul($logits, $labels);
      var sigmoidOutput = log1p(exp(neg(abs($logits))));
      return add(sub(maxOutput, outputXTarget), sigmoidOutput);
    }
    function sigmoidCrossEntropy_(multiClassLabels, logits, weights, labelSmoothing, reduction) {
      if (labelSmoothing === void 0) {
        labelSmoothing = 0;
      }
      if (reduction === void 0) {
        reduction = exports.Reduction.SUM_BY_NONZERO_WEIGHTS;
      }
      var $multiClassLabels = convertToTensor(multiClassLabels, "multiClassLabels", "sigmoidCrossEntropy");
      var $logits = convertToTensor(logits, "logits", "sigmoidCrossEntropy");
      var $weights = null;
      if (weights != null) {
        $weights = convertToTensor(weights, "weights", "sigmoidCrossEntropy");
      }
      assertShapesMatch($multiClassLabels.shape, $logits.shape, "Error in sigmoidCrossEntropy: ");
      if (labelSmoothing > 0) {
        var labelSmoothingScalar = scalar(labelSmoothing);
        var one = scalar(1);
        var half = scalar(0.5);
        $multiClassLabels = add(mul($multiClassLabels, sub(one, labelSmoothingScalar)), mul(half, labelSmoothingScalar));
      }
      var losses2 = sigmoidCrossEntropyWithLogits_($multiClassLabels, $logits);
      return computeWeightedLoss(losses2, $weights, reduction);
    }
    var sigmoidCrossEntropy = /* @__PURE__ */ op({ sigmoidCrossEntropy_ });
    function softmaxCrossEntropyWithLogits_(labels, logits, dim) {
      if (dim === void 0) {
        dim = -1;
      }
      if (dim === -1) {
        dim = logits.rank - 1;
      }
      if (dim !== logits.rank - 1) {
        throw Error("Softmax cross entropy along a non-last dimension is not yet " + "supported. Labels / logits was rank ".concat(logits.rank, " ") + "and dim was ".concat(dim));
      }
      var customOp = customGrad(function(labels2, logits2, save) {
        var keepDims = true;
        var lse = logSumExp(logits2, [dim], keepDims);
        var logResult = sub(cast(logits2, "float32"), lse);
        save([labels2, logResult]);
        var costVector = neg(mul(logResult, labels2));
        var value = sum(costVector, [dim]);
        var gradFunc = function(dy, saved) {
          var _a = __read(saved, 2), labels3 = _a[0], logResult2 = _a[1];
          var dyShape = expandShapeToKeepDim(dy.shape, [dim]);
          return [
            mul(reshape(dy, dyShape), sub(cast(labels3, "float32"), exp(logResult2))),
            mul(reshape(dy, dyShape), sub(exp(logResult2), cast(labels3, "float32")))
          ];
        };
        return { value, gradFunc };
      });
      return customOp(labels, logits);
    }
    function softmaxCrossEntropy_(onehotLabels, logits, weights, labelSmoothing, reduction) {
      if (labelSmoothing === void 0) {
        labelSmoothing = 0;
      }
      if (reduction === void 0) {
        reduction = exports.Reduction.SUM_BY_NONZERO_WEIGHTS;
      }
      var $onehotLabels = convertToTensor(onehotLabels, "onehotLabels", "softmaxCrossEntropy");
      var $logits = convertToTensor(logits, "logits", "softmaxCrossEntropy");
      var $weights = null;
      if (weights != null) {
        $weights = convertToTensor(weights, "weights", "softmaxCrossEntropy");
      }
      assertShapesMatch($onehotLabels.shape, $logits.shape, "Error in softmaxCrossEntropy: ");
      if (labelSmoothing > 0) {
        var labelSmoothingScalar = scalar(labelSmoothing);
        var one = scalar(1);
        var numClasses = scalar($onehotLabels.shape[1]);
        $onehotLabels = add(mul($onehotLabels, sub(one, labelSmoothingScalar)), div(labelSmoothingScalar, numClasses));
      }
      var losses2 = softmaxCrossEntropyWithLogits_($onehotLabels, $logits);
      return computeWeightedLoss(losses2, $weights, reduction);
    }
    var softmaxCrossEntropy = /* @__PURE__ */ op({ softmaxCrossEntropy_ });
    function sparseFillEmptyRows_(indices, values, denseShape, defaultValue) {
      var $indices = convertToTensor(indices, "indices", "sparseFillEmptyRows", "int32");
      var $values = convertToTensor(values, "values", "sparseFillEmptyRows");
      var $denseShape = convertToTensor(denseShape, "denseShape", "sparseFillEmptyRows", "int32");
      var $defaultValue = convertToTensor(defaultValue, "defaultValue", "sparseFillEmptyRows", $values.dtype);
      if ($indices.rank !== 2) {
        throw new Error("Indices should be Tensor2D but received shape\n        ".concat($indices.shape));
      }
      if ($values.rank !== 1) {
        throw new Error("Values should be Tensor1D but received shape ".concat($values.shape));
      }
      if ($denseShape.rank !== 1) {
        throw new Error("Dense shape should be Tensor1D but received shape ".concat($denseShape.shape));
      }
      if ($defaultValue.rank !== 0) {
        throw new Error("Default value should be a scalar but received shape ".concat($defaultValue.shape));
      }
      var inputs = {
        indices: $indices,
        values: $values,
        denseShape: $denseShape,
        defaultValue: $defaultValue
      };
      var result = ENGINE.runKernel(SparseFillEmptyRows, inputs);
      return {
        outputIndices: result[0],
        outputValues: result[1],
        emptyRowIndicator: result[2],
        reverseIndexMap: result[3]
      };
    }
    var sparseFillEmptyRows = /* @__PURE__ */ op({ sparseFillEmptyRows_ });
    function sparseReshape_(inputIndices, inputShape, newShape) {
      var $inputIndices = convertToTensor(inputIndices, "inputIndices", "sparseReshape", "int32");
      var $inputShape = convertToTensor(inputShape, "inputShape", "sparseReshape", "int32");
      var $newShape = convertToTensor(newShape, "newShape", "sparseReshape", "int32");
      if ($inputIndices.rank !== 2) {
        throw new Error("Input indices should be Tensor2D but received shape\n        ".concat($inputIndices.shape));
      }
      if ($inputShape.rank !== 1) {
        throw new Error("Input shape should be Tensor1D but received shape ".concat($inputShape.shape));
      }
      if ($newShape.rank !== 1) {
        throw new Error("New shape should be Tensor1D but received shape ".concat($newShape.shape));
      }
      var inputs = {
        inputIndices: $inputIndices,
        inputShape: $inputShape,
        newShape: $newShape
      };
      var result = ENGINE.runKernel(SparseReshape, inputs);
      return { outputIndices: result[0], outputShape: result[1] };
    }
    var sparseReshape = /* @__PURE__ */ op({ sparseReshape_ });
    function sparseSegmentMean_(data, indices, segmentIds) {
      var $data = convertToTensor(data, "data", "sparseSegmentMean");
      var $indices = convertToTensor(indices, "indices", "sparseSegmentMean", "int32");
      var $segmentIds = convertToTensor(segmentIds, "segmentIds", "sparseSegmentMean", "int32");
      if ($data.rank < 1) {
        throw new Error("Data should be at least 1 dimensional but received scalar");
      }
      if ($indices.rank !== 1) {
        throw new Error("Indices should be Tensor1D but received shape\n          ".concat($indices.shape));
      }
      if ($segmentIds.rank !== 1) {
        throw new Error("Segment ids should be Tensor1D but received shape\n          ".concat($segmentIds.shape));
      }
      var inputs = {
        data: $data,
        indices: $indices,
        segmentIds: $segmentIds
      };
      return ENGINE.runKernel(SparseSegmentMean, inputs);
    }
    var sparseSegmentMean = /* @__PURE__ */ op({ sparseSegmentMean_ });
    function sparseSegmentSum_(data, indices, segmentIds) {
      var $data = convertToTensor(data, "data", "sparseSegmentSum");
      var $indices = convertToTensor(indices, "indices", "sparseSegmentSum", "int32");
      var $segmentIds = convertToTensor(segmentIds, "segmentIds", "sparseSegmentSum", "int32");
      if ($data.rank < 1) {
        throw new Error("Data should be at least 1 dimensional but received scalar");
      }
      if ($indices.rank !== 1) {
        throw new Error("Indices should be Tensor1D but received shape\n         ".concat($indices.shape));
      }
      if ($segmentIds.rank !== 1) {
        throw new Error("Segment ids should be Tensor1D but received shape\n         ".concat($segmentIds.shape));
      }
      var inputs = {
        data: $data,
        indices: $indices,
        segmentIds: $segmentIds
      };
      return ENGINE.runKernel(SparseSegmentSum, inputs);
    }
    var sparseSegmentSum = /* @__PURE__ */ op({ sparseSegmentSum_ });
    function stringNGrams_(data, dataSplits, separator, nGramWidths, leftPad, rightPad2, padWidth, preserveShortSequences) {
      var $data = convertToTensor(data, "data", "stringNGrams", "string");
      if ($data.dtype !== "string") {
        throw new Error("Data must be of datatype string");
      }
      if ($data.shape.length !== 1) {
        throw new Error("Data must be a vector, saw: ".concat($data.shape));
      }
      var $dataSplits = convertToTensor(dataSplits, "dataSplits", "stringNGrams");
      if ($dataSplits.dtype !== "int32") {
        throw new Error("Data splits must be of datatype int32");
      }
      var attrs = {
        separator,
        nGramWidths,
        leftPad,
        rightPad: rightPad2,
        padWidth,
        preserveShortSequences
      };
      var inputs = { data: $data, dataSplits: $dataSplits };
      var result = ENGINE.runKernel(StringNGrams, inputs, attrs);
      return { nGrams: result[0], nGramsSplits: result[1] };
    }
    var stringNGrams = /* @__PURE__ */ op({ stringNGrams_ });
    function stringSplit_(input, delimiter, skipEmpty) {
      if (skipEmpty === void 0) {
        skipEmpty = true;
      }
      var $input = convertToTensor(input, "input", "stringSplit", "string");
      var $delimiter = convertToTensor(delimiter, "delimiter", "stringSplit", "string");
      if ($input.rank !== 1) {
        throw new Error("Input should be Tensor1D but received shape ".concat($input.shape));
      }
      if ($delimiter.rank !== 0) {
        throw new Error("Delimiter should be a scalar but received shape ".concat($delimiter.shape));
      }
      var attrs = { skipEmpty };
      var inputs = { input: $input, delimiter: $delimiter };
      var result = ENGINE.runKernel(StringSplit, inputs, attrs);
      return { indices: result[0], values: result[1], shape: result[2] };
    }
    var stringSplit = /* @__PURE__ */ op({ stringSplit_ });
    function stringToHashBucketFast_(input, numBuckets) {
      var $input = convertToTensor(input, "input", "stringToHashBucketFast", "string");
      var attrs = { numBuckets };
      if (numBuckets <= 0) {
        throw new Error("Number of buckets must be at least 1");
      }
      var inputs = { input: $input };
      return ENGINE.runKernel(StringToHashBucketFast, inputs, attrs);
    }
    var stringToHashBucketFast = /* @__PURE__ */ op({ stringToHashBucketFast_ });
    function staticRegexReplace_(input, pattern, rewrite, replaceGlobal) {
      if (replaceGlobal === void 0) {
        replaceGlobal = true;
      }
      var $input = convertToTensor(input, "input", "staticRegexReplace", "string");
      var attrs = { pattern, rewrite, replaceGlobal };
      return ENGINE.runKernel(StaticRegexReplace, { x: $input }, attrs);
    }
    var staticRegexReplace = /* @__PURE__ */ op({ staticRegexReplace_ });
    var spectral = {
      fft,
      ifft,
      rfft,
      irfft
    };
    var signal = {
      hammingWindow,
      hannWindow,
      frame,
      stft
    };
    var image = {
      flipLeftRight,
      grayscaleToRGB,
      resizeNearestNeighbor,
      resizeBilinear,
      rotateWithOffset,
      cropAndResize,
      nonMaxSuppression,
      nonMaxSuppressionAsync,
      nonMaxSuppressionWithScore,
      nonMaxSuppressionWithScoreAsync,
      nonMaxSuppressionPadded,
      nonMaxSuppressionPaddedAsync,
      threshold,
      transform
    };
    var linalg = {
      bandPart,
      gramSchmidt,
      qr
    };
    var losses = {
      absoluteDifference,
      computeWeightedLoss,
      cosineDistance,
      hingeLoss,
      huberLoss,
      logLoss,
      meanSquaredError,
      sigmoidCrossEntropy,
      softmaxCrossEntropy
    };
    var sparse = {
      sparseFillEmptyRows,
      sparseReshape,
      sparseSegmentMean,
      sparseSegmentSum
    };
    var string = {
      stringNGrams,
      stringSplit,
      stringToHashBucketFast,
      staticRegexReplace
    };
    var Serializable = (
      /** @class */
      function() {
        function Serializable2() {
        }
        Serializable2.prototype.getClassName = function() {
          return this.constructor.className;
        };
        Serializable2.fromConfig = function(cls, config) {
          return new cls(config);
        };
        return Serializable2;
      }()
    );
    var SerializationMap = (
      /** @class */
      function() {
        function SerializationMap2() {
          this.classNameMap = {};
        }
        SerializationMap2.getMap = function() {
          if (SerializationMap2.instance == null) {
            SerializationMap2.instance = new SerializationMap2();
          }
          return SerializationMap2.instance;
        };
        SerializationMap2.register = function(cls) {
          SerializationMap2.getMap().classNameMap[cls.className] = [cls, cls.fromConfig];
        };
        return SerializationMap2;
      }()
    );
    function registerClass(cls) {
      assert(cls.className != null, function() {
        return "Class being registered does not have the static className property defined.";
      });
      assert(typeof cls.className === "string", function() {
        return "className is required to be a string, but got type " + typeof cls.className;
      });
      assert(cls.className.length > 0, function() {
        return "Class being registered has an empty-string as its className, which is disallowed.";
      });
      SerializationMap.register(cls);
    }
    var serialization = {
      __proto__: null,
      Serializable,
      SerializationMap,
      registerClass
    };
    var Optimizer = (
      /** @class */
      function(_super) {
        __extends(Optimizer2, _super);
        function Optimizer2() {
          return _super !== null && _super.apply(this, arguments) || this;
        }
        Optimizer2.prototype.minimize = function(f, returnCost, varList) {
          if (returnCost === void 0) {
            returnCost = false;
          }
          var _a = this.computeGradients(f, varList), value = _a.value, grads2 = _a.grads;
          if (varList != null) {
            var gradArray = varList.map(function(v) {
              return { name: v.name, tensor: grads2[v.name] };
            });
            this.applyGradients(gradArray);
          } else {
            this.applyGradients(grads2);
          }
          dispose(grads2);
          if (returnCost) {
            return value;
          } else {
            value.dispose();
            return null;
          }
        };
        Object.defineProperty(Optimizer2.prototype, "iterations", {
          /**
           * The number of iterations that this optimizer instance has been invoked for.
           */
          get: function() {
            if (this.iterations_ == null) {
              this.iterations_ = 0;
            }
            return this.iterations_;
          },
          enumerable: false,
          configurable: true
        });
        Optimizer2.prototype.incrementIterations = function() {
          this.iterations_ = this.iterations + 1;
        };
        Optimizer2.prototype.computeGradients = function(f, varList) {
          return variableGrads(f, varList);
        };
        Optimizer2.prototype.dispose = function() {
          if (this.iterations_ != null) {
            dispose(this.iterations_);
          }
        };
        Optimizer2.prototype.saveIterations = function() {
          return __awaiter(this, void 0, void 0, function() {
            return __generator(this, function(_a) {
              if (this.iterations_ == null) {
                this.iterations_ = 0;
              }
              return [2, {
                name: "iter",
                // TODO(cais): Use 'int64' type when available.
                tensor: scalar(this.iterations_, "int32")
              }];
            });
          });
        };
        Optimizer2.prototype.getWeights = function() {
          return __awaiter(this, void 0, void 0, function() {
            return __generator(this, function(_a) {
              throw new Error("getWeights() is not implemented for this optimizer yet.");
            });
          });
        };
        Optimizer2.prototype.setWeights = function(weightValues) {
          return __awaiter(this, void 0, void 0, function() {
            return __generator(this, function(_a) {
              throw new Error("setWeights() is not implemented for this optimizer class " + "".concat(this.getClassName()));
            });
          });
        };
        Optimizer2.prototype.extractIterations = function(weightValues) {
          return __awaiter(this, void 0, void 0, function() {
            var _a;
            return __generator(this, function(_b) {
              switch (_b.label) {
                case 0:
                  _a = this;
                  return [4, weightValues[0].tensor.data()];
                case 1:
                  _a.iterations_ = _b.sent()[0];
                  return [2, weightValues.slice(1)];
              }
            });
          });
        };
        return Optimizer2;
      }(Serializable)
    );
    Object.defineProperty(Optimizer, Symbol.hasInstance, {
      value: function(instance) {
        return instance.minimize != null && instance.computeGradients != null && instance.applyGradients != null;
      }
    });
    var AdadeltaOptimizer = (
      /** @class */
      function(_super) {
        __extends(AdadeltaOptimizer2, _super);
        function AdadeltaOptimizer2(learningRate, rho, epsilon) {
          if (epsilon === void 0) {
            epsilon = null;
          }
          var _this = _super.call(this) || this;
          _this.learningRate = learningRate;
          _this.rho = rho;
          _this.epsilon = epsilon;
          _this.accumulatedGrads = [];
          _this.accumulatedUpdates = [];
          if (epsilon == null) {
            _this.epsilon = ENGINE.backend.epsilon();
          }
          return _this;
        }
        Object.defineProperty(AdadeltaOptimizer2, "className", {
          /** @nocollapse */
          get: function() {
            return "Adadelta";
          },
          enumerable: false,
          configurable: true
        });
        AdadeltaOptimizer2.prototype.applyGradients = function(variableGradients) {
          var _this = this;
          var variableNames = Array.isArray(variableGradients) ? variableGradients.map(function(item) {
            return item.name;
          }) : Object.keys(variableGradients);
          variableNames.forEach(function(name, i) {
            var value = ENGINE.registeredVariables[name];
            var trainable = false;
            if (_this.accumulatedGrads[i] == null) {
              _this.accumulatedGrads[i] = {
                originalName: "".concat(name, "/accum_grad"),
                variable: tidy(function() {
                  return zerosLike(value).variable(trainable);
                })
              };
            }
            if (_this.accumulatedUpdates[i] == null) {
              _this.accumulatedUpdates[i] = {
                originalName: "".concat(name, "/accum_var"),
                variable: tidy(function() {
                  return zerosLike(value).variable(trainable);
                })
              };
            }
            var gradient = Array.isArray(variableGradients) ? variableGradients[i].tensor : variableGradients[name];
            if (gradient == null) {
              return;
            }
            var accumulatedGrad = _this.accumulatedGrads[i].variable;
            var accumulatedUpdate = _this.accumulatedUpdates[i].variable;
            tidy(function() {
              var newAccumulatedGrad = add(mul(accumulatedGrad, _this.rho), mul(square(gradient), 1 - _this.rho));
              var updates = mul(div(sqrt(add(accumulatedUpdate, _this.epsilon)), sqrt(add(accumulatedGrad, _this.epsilon))), gradient);
              var newAccumulatedUpdate = add(mul(accumulatedUpdate, _this.rho), mul(square(updates), 1 - _this.rho));
              accumulatedGrad.assign(newAccumulatedGrad);
              accumulatedUpdate.assign(newAccumulatedUpdate);
              var newValue = add(mul(updates, -_this.learningRate), value);
              value.assign(newValue);
            });
          });
          this.incrementIterations();
        };
        AdadeltaOptimizer2.prototype.dispose = function() {
          if (this.accumulatedUpdates != null) {
            dispose(this.accumulatedGrads.map(function(v) {
              return v.variable;
            }));
            dispose(this.accumulatedUpdates.map(function(v) {
              return v.variable;
            }));
          }
        };
        AdadeltaOptimizer2.prototype.getWeights = function() {
          return __awaiter(this, void 0, void 0, function() {
            var variables;
            return __generator(this, function(_a) {
              switch (_a.label) {
                case 0:
                  variables = __spreadArray(__spreadArray([], __read(this.accumulatedGrads), false), __read(this.accumulatedUpdates), false);
                  return [4, this.saveIterations()];
                case 1:
                  return [2, [_a.sent()].concat(variables.map(function(v) {
                    return { name: v.originalName, tensor: v.variable };
                  }))];
              }
            });
          });
        };
        AdadeltaOptimizer2.prototype.setWeights = function(weightValues) {
          return __awaiter(this, void 0, void 0, function() {
            var variableCount, trainable;
            return __generator(this, function(_a) {
              switch (_a.label) {
                case 0:
                  return [4, this.extractIterations(weightValues)];
                case 1:
                  weightValues = _a.sent();
                  variableCount = weightValues.length / 2;
                  trainable = false;
                  this.accumulatedGrads = weightValues.slice(0, variableCount).map(function(v) {
                    return {
                      originalName: v.name,
                      variable: v.tensor.variable(trainable)
                    };
                  });
                  this.accumulatedUpdates = weightValues.slice(variableCount, variableCount * 2).map(function(v) {
                    return {
                      originalName: v.name,
                      variable: v.tensor.variable(trainable)
                    };
                  });
                  return [
                    2
                    /*return*/
                  ];
              }
            });
          });
        };
        AdadeltaOptimizer2.prototype.getConfig = function() {
          return {
            "learningRate": this.learningRate,
            "rho": this.rho,
            "epsilon": this.epsilon
          };
        };
        AdadeltaOptimizer2.fromConfig = function(cls, config) {
          return new cls(config["learningRate"], config["rho"], config["epsilon"]);
        };
        return AdadeltaOptimizer2;
      }(Optimizer)
    );
    var AdagradOptimizer = (
      /** @class */
      function(_super) {
        __extends(AdagradOptimizer2, _super);
        function AdagradOptimizer2(learningRate, initialAccumulatorValue) {
          if (initialAccumulatorValue === void 0) {
            initialAccumulatorValue = 0.1;
          }
          var _this = _super.call(this) || this;
          _this.learningRate = learningRate;
          _this.initialAccumulatorValue = initialAccumulatorValue;
          _this.accumulatedGrads = [];
          return _this;
        }
        Object.defineProperty(AdagradOptimizer2, "className", {
          /** @nocollapse */
          get: function() {
            return "Adagrad";
          },
          enumerable: false,
          configurable: true
        });
        AdagradOptimizer2.prototype.applyGradients = function(variableGradients) {
          var _this = this;
          var variableNames = Array.isArray(variableGradients) ? variableGradients.map(function(item) {
            return item.name;
          }) : Object.keys(variableGradients);
          variableNames.forEach(function(name, i) {
            var value = ENGINE.registeredVariables[name];
            if (_this.accumulatedGrads[i] == null) {
              var trainable_1 = false;
              _this.accumulatedGrads[i] = {
                originalName: "".concat(name, "/accumulator"),
                variable: tidy(function() {
                  return fill(value.shape, _this.initialAccumulatorValue).variable(trainable_1);
                })
              };
            }
            var gradient = Array.isArray(variableGradients) ? variableGradients[i].tensor : variableGradients[name];
            if (gradient == null) {
              return;
            }
            var accumulatedGrad = _this.accumulatedGrads[i].variable;
            tidy(function() {
              var newAccumulatedGrad = add(accumulatedGrad, square(gradient));
              accumulatedGrad.assign(newAccumulatedGrad);
              var newValue = add(mul(div(gradient, sqrt(add(newAccumulatedGrad, ENGINE.backend.epsilon()))), -_this.learningRate), value);
              value.assign(newValue);
            });
          });
          this.incrementIterations();
        };
        AdagradOptimizer2.prototype.dispose = function() {
          if (this.accumulatedGrads != null) {
            dispose(this.accumulatedGrads.map(function(v) {
              return v.variable;
            }));
          }
        };
        AdagradOptimizer2.prototype.getWeights = function() {
          return __awaiter(this, void 0, void 0, function() {
            return __generator(this, function(_a) {
              switch (_a.label) {
                case 0:
                  return [4, this.saveIterations()];
                case 1:
                  return [2, [_a.sent()].concat(this.accumulatedGrads.map(function(v) {
                    return { name: v.originalName, tensor: v.variable };
                  }))];
              }
            });
          });
        };
        AdagradOptimizer2.prototype.setWeights = function(weightValues) {
          return __awaiter(this, void 0, void 0, function() {
            var trainable;
            return __generator(this, function(_a) {
              switch (_a.label) {
                case 0:
                  return [4, this.extractIterations(weightValues)];
                case 1:
                  weightValues = _a.sent();
                  trainable = false;
                  this.accumulatedGrads = weightValues.map(function(v) {
                    return { originalName: v.name, variable: v.tensor.variable(trainable) };
                  });
                  return [
                    2
                    /*return*/
                  ];
              }
            });
          });
        };
        AdagradOptimizer2.prototype.getConfig = function() {
          return {
            "learningRate": this.learningRate,
            "initialAccumulatorValue": this.initialAccumulatorValue
          };
        };
        AdagradOptimizer2.fromConfig = function(cls, config) {
          return new cls(config["learningRate"], config["initialAccumulatorValue"]);
        };
        return AdagradOptimizer2;
      }(Optimizer)
    );
    var AdamOptimizer = (
      /** @class */
      function(_super) {
        __extends(AdamOptimizer2, _super);
        function AdamOptimizer2(learningRate, beta1, beta2, epsilon) {
          if (epsilon === void 0) {
            epsilon = null;
          }
          var _this = _super.call(this) || this;
          _this.learningRate = learningRate;
          _this.beta1 = beta1;
          _this.beta2 = beta2;
          _this.epsilon = epsilon;
          _this.accumulatedFirstMoment = [];
          _this.accumulatedSecondMoment = [];
          tidy(function() {
            _this.accBeta1 = scalar(beta1).variable();
            _this.accBeta2 = scalar(beta2).variable();
          });
          if (epsilon == null) {
            _this.epsilon = ENGINE.backend.epsilon();
          }
          return _this;
        }
        Object.defineProperty(AdamOptimizer2, "className", {
          /** @nocollapse */
          get: function() {
            return "Adam";
          },
          enumerable: false,
          configurable: true
        });
        AdamOptimizer2.prototype.applyGradients = function(variableGradients) {
          var _this = this;
          var varNames = Array.isArray(variableGradients) ? variableGradients.map(function(v) {
            return v.name;
          }) : Object.keys(variableGradients);
          tidy(function() {
            var oneMinusAccBeta1 = sub(1, _this.accBeta1);
            var oneMinusAccBeta2 = sub(1, _this.accBeta2);
            varNames.forEach(function(name, i) {
              var value = ENGINE.registeredVariables[name];
              var trainable = false;
              if (_this.accumulatedFirstMoment[i] == null) {
                _this.accumulatedFirstMoment[i] = {
                  originalName: "".concat(name, "/m"),
                  variable: tidy(function() {
                    return zerosLike(value).variable(trainable);
                  })
                };
              }
              if (_this.accumulatedSecondMoment[i] == null) {
                _this.accumulatedSecondMoment[i] = {
                  originalName: "".concat(name, "/v"),
                  variable: tidy(function() {
                    return zerosLike(value).variable(trainable);
                  })
                };
              }
              var gradient = Array.isArray(variableGradients) ? variableGradients[i].tensor : variableGradients[name];
              if (gradient == null) {
                return;
              }
              var firstMoment = _this.accumulatedFirstMoment[i].variable;
              var secondMoment = _this.accumulatedSecondMoment[i].variable;
              var newFirstMoment = add(mul(firstMoment, _this.beta1), mul(gradient, 1 - _this.beta1));
              var newSecondMoment = add(mul(secondMoment, _this.beta2), mul(square(gradient), 1 - _this.beta2));
              var biasCorrectedFirstMoment = div(newFirstMoment, oneMinusAccBeta1);
              var biasCorrectedSecondMoment = div(newSecondMoment, oneMinusAccBeta2);
              firstMoment.assign(newFirstMoment);
              secondMoment.assign(newSecondMoment);
              var newValue = add(mul(div(biasCorrectedFirstMoment, add(sqrt(biasCorrectedSecondMoment), _this.epsilon)), -_this.learningRate), value);
              value.assign(newValue);
            });
            _this.accBeta1.assign(mul(_this.accBeta1, _this.beta1));
            _this.accBeta2.assign(mul(_this.accBeta2, _this.beta2));
          });
          this.incrementIterations();
        };
        AdamOptimizer2.prototype.dispose = function() {
          this.accBeta1.dispose();
          this.accBeta2.dispose();
          if (this.accumulatedFirstMoment != null) {
            dispose(this.accumulatedFirstMoment.map(function(v) {
              return v.variable;
            }));
          }
          if (this.accumulatedSecondMoment != null) {
            dispose(this.accumulatedSecondMoment.map(function(v) {
              return v.variable;
            }));
          }
        };
        AdamOptimizer2.prototype.getWeights = function() {
          return __awaiter(this, void 0, void 0, function() {
            var variables;
            return __generator(this, function(_a) {
              switch (_a.label) {
                case 0:
                  variables = __spreadArray(__spreadArray([], __read(this.accumulatedFirstMoment), false), __read(this.accumulatedSecondMoment), false);
                  return [4, this.saveIterations()];
                case 1:
                  return [2, [_a.sent()].concat(variables.map(function(v) {
                    return { name: v.originalName, tensor: v.variable };
                  }))];
              }
            });
          });
        };
        AdamOptimizer2.prototype.setWeights = function(weightValues) {
          return __awaiter(this, void 0, void 0, function() {
            var variableCount, trainable;
            var _this = this;
            return __generator(this, function(_a) {
              switch (_a.label) {
                case 0:
                  return [4, this.extractIterations(weightValues)];
                case 1:
                  weightValues = _a.sent();
                  tidy(function() {
                    _this.accBeta1.assign(pow(_this.beta1, _this.iterations_ + 1));
                    _this.accBeta2.assign(pow(_this.beta2, _this.iterations_ + 1));
                  });
                  variableCount = weightValues.length / 2;
                  trainable = false;
                  this.accumulatedFirstMoment = weightValues.slice(0, variableCount).map(function(v) {
                    return {
                      originalName: v.name,
                      variable: v.tensor.variable(trainable)
                    };
                  });
                  this.accumulatedSecondMoment = weightValues.slice(variableCount, variableCount * 2).map(function(v) {
                    return {
                      originalName: v.name,
                      variable: v.tensor.variable(trainable)
                    };
                  });
                  return [
                    2
                    /*return*/
                  ];
              }
            });
          });
        };
        AdamOptimizer2.prototype.getConfig = function() {
          return {
            "learningRate": this.learningRate,
            "beta1": this.beta1,
            "beta2": this.beta2,
            "epsilon": this.epsilon
          };
        };
        AdamOptimizer2.fromConfig = function(cls, config) {
          return new cls(config["learningRate"], config["beta1"], config["beta2"], config["epsilon"]);
        };
        return AdamOptimizer2;
      }(Optimizer)
    );
    var AdamaxOptimizer = (
      /** @class */
      function(_super) {
        __extends(AdamaxOptimizer2, _super);
        function AdamaxOptimizer2(learningRate, beta1, beta2, epsilon, decay) {
          if (epsilon === void 0) {
            epsilon = null;
          }
          if (decay === void 0) {
            decay = 0;
          }
          var _this = _super.call(this) || this;
          _this.learningRate = learningRate;
          _this.beta1 = beta1;
          _this.beta2 = beta2;
          _this.epsilon = epsilon;
          _this.decay = decay;
          _this.accumulatedFirstMoment = [];
          _this.accumulatedWeightedInfNorm = [];
          tidy(function() {
            _this.iteration = scalar(0).variable();
            _this.accBeta1 = scalar(beta1).variable();
          });
          if (epsilon == null) {
            _this.epsilon = ENGINE.backend.epsilon();
          }
          return _this;
        }
        Object.defineProperty(AdamaxOptimizer2, "className", {
          /** @nocollapse */
          get: function() {
            return "Adamax";
          },
          enumerable: false,
          configurable: true
        });
        AdamaxOptimizer2.prototype.applyGradients = function(variableGradients) {
          var _this = this;
          var variableNames = Array.isArray(variableGradients) ? variableGradients.map(function(item) {
            return item.name;
          }) : Object.keys(variableGradients);
          tidy(function() {
            var oneMinusAccBeta1 = sub(1, _this.accBeta1);
            var lr = div(-_this.learningRate, add(mul(_this.iteration, _this.decay), 1));
            variableNames.forEach(function(name, i) {
              var value = ENGINE.registeredVariables[name];
              var trainable = false;
              if (_this.accumulatedFirstMoment[i] == null) {
                _this.accumulatedFirstMoment[i] = {
                  originalName: "".concat(name, "/m"),
                  variable: zerosLike(value).variable(trainable)
                };
              }
              if (_this.accumulatedWeightedInfNorm[i] == null) {
                _this.accumulatedWeightedInfNorm[i] = {
                  originalName: "".concat(name, "/v"),
                  variable: zerosLike(value).variable(trainable)
                };
              }
              var gradient = Array.isArray(variableGradients) ? variableGradients[i].tensor : variableGradients[name];
              if (gradient == null) {
                return;
              }
              var firstMoment = _this.accumulatedFirstMoment[i].variable;
              var weightedInfNorm = _this.accumulatedWeightedInfNorm[i].variable;
              var newFirstMoment = add(mul(firstMoment, _this.beta1), mul(gradient, 1 - _this.beta1));
              var ut0 = mul(weightedInfNorm, _this.beta2);
              var ut1 = abs(gradient);
              var newWeightedInfNorm = maximum(ut0, ut1);
              firstMoment.assign(newFirstMoment);
              weightedInfNorm.assign(newWeightedInfNorm);
              var newValue = add(mul(div(lr, oneMinusAccBeta1), div(newFirstMoment, add(newWeightedInfNorm, _this.epsilon))), value);
              value.assign(newValue);
            });
            _this.iteration.assign(add(_this.iteration, 1));
            _this.accBeta1.assign(mul(_this.accBeta1, _this.beta1));
          });
          this.incrementIterations();
        };
        AdamaxOptimizer2.prototype.dispose = function() {
          this.accBeta1.dispose();
          this.iteration.dispose();
          if (this.accumulatedFirstMoment != null) {
            dispose(this.accumulatedFirstMoment.map(function(v) {
              return v.variable;
            }));
          }
          if (this.accumulatedWeightedInfNorm != null) {
            dispose(this.accumulatedWeightedInfNorm.map(function(v) {
              return v.variable;
            }));
          }
        };
        AdamaxOptimizer2.prototype.getWeights = function() {
          return __awaiter(this, void 0, void 0, function() {
            return __generator(this, function(_a) {
              throw new Error("getWeights() is not implemented for Adamax yet.");
            });
          });
        };
        AdamaxOptimizer2.prototype.setWeights = function(weightValues) {
          return __awaiter(this, void 0, void 0, function() {
            return __generator(this, function(_a) {
              throw new Error("setWeights() is not implemented for Adamax yet.");
            });
          });
        };
        AdamaxOptimizer2.prototype.getConfig = function() {
          return {
            "learningRate": this.learningRate,
            "beta1": this.beta1,
            "beta2": this.beta2,
            "epsilon": this.epsilon,
            "decay": this.decay
          };
        };
        AdamaxOptimizer2.fromConfig = function(cls, config) {
          return new cls(config["learningRate"], config["beta1"], config["beta2"], config["epsilon"], config["decay"]);
        };
        return AdamaxOptimizer2;
      }(Optimizer)
    );
    var SGDOptimizer = (
      /** @class */
      function(_super) {
        __extends(SGDOptimizer2, _super);
        function SGDOptimizer2(learningRate) {
          var _this = _super.call(this) || this;
          _this.learningRate = learningRate;
          _this.setLearningRate(learningRate);
          return _this;
        }
        Object.defineProperty(SGDOptimizer2, "className", {
          /** @nocollapse */
          get: function() {
            return "SGD";
          },
          enumerable: false,
          configurable: true
        });
        SGDOptimizer2.prototype.applyGradients = function(variableGradients) {
          var _this = this;
          var varNames = Array.isArray(variableGradients) ? variableGradients.map(function(v) {
            return v.name;
          }) : Object.keys(variableGradients);
          varNames.forEach(function(name, i) {
            var gradient = Array.isArray(variableGradients) ? variableGradients[i].tensor : variableGradients[name];
            if (gradient == null) {
              return;
            }
            var value = ENGINE.registeredVariables[name];
            tidy(function() {
              var newValue = add(mul(_this.c, gradient), value);
              value.assign(newValue);
            });
          });
          this.incrementIterations();
        };
        SGDOptimizer2.prototype.setLearningRate = function(learningRate) {
          this.learningRate = learningRate;
          if (this.c != null) {
            this.c.dispose();
          }
          this.c = keep(scalar(-learningRate));
        };
        SGDOptimizer2.prototype.dispose = function() {
          this.c.dispose();
        };
        SGDOptimizer2.prototype.getWeights = function() {
          return __awaiter(this, void 0, void 0, function() {
            return __generator(this, function(_a) {
              switch (_a.label) {
                case 0:
                  return [4, this.saveIterations()];
                case 1:
                  return [2, [_a.sent()]];
              }
            });
          });
        };
        SGDOptimizer2.prototype.setWeights = function(weightValues) {
          return __awaiter(this, void 0, void 0, function() {
            return __generator(this, function(_a) {
              switch (_a.label) {
                case 0:
                  return [4, this.extractIterations(weightValues)];
                case 1:
                  weightValues = _a.sent();
                  if (weightValues.length !== 0) {
                    throw new Error("SGD optimizer does not have settable weights.");
                  }
                  return [
                    2
                    /*return*/
                  ];
              }
            });
          });
        };
        SGDOptimizer2.prototype.getConfig = function() {
          return { "learningRate": this.learningRate };
        };
        SGDOptimizer2.fromConfig = function(cls, config) {
          return new cls(config["learningRate"]);
        };
        return SGDOptimizer2;
      }(Optimizer)
    );
    var MomentumOptimizer = (
      /** @class */
      function(_super) {
        __extends(MomentumOptimizer2, _super);
        function MomentumOptimizer2(learningRate, momentum, useNesterov) {
          if (useNesterov === void 0) {
            useNesterov = false;
          }
          var _this = _super.call(this, learningRate) || this;
          _this.learningRate = learningRate;
          _this.momentum = momentum;
          _this.useNesterov = useNesterov;
          _this.accumulations = [];
          _this.m = scalar(_this.momentum);
          return _this;
        }
        Object.defineProperty(MomentumOptimizer2, "className", {
          /** @nocollapse */
          // Name matters for Python compatibility.
          get: function() {
            return "Momentum";
          },
          enumerable: false,
          configurable: true
        });
        MomentumOptimizer2.prototype.applyGradients = function(variableGradients) {
          var _this = this;
          var variableNames = Array.isArray(variableGradients) ? variableGradients.map(function(item) {
            return item.name;
          }) : Object.keys(variableGradients);
          variableNames.forEach(function(name, i) {
            var value = ENGINE.registeredVariables[name];
            if (_this.accumulations[i] == null) {
              var trainable_1 = false;
              _this.accumulations[i] = {
                originalName: "".concat(name, "/momentum"),
                variable: tidy(function() {
                  return zerosLike(value).variable(trainable_1);
                })
              };
            }
            var accumulation = _this.accumulations[i].variable;
            var gradient = Array.isArray(variableGradients) ? variableGradients[i].tensor : variableGradients[name];
            if (gradient == null) {
              return;
            }
            tidy(function() {
              var newValue;
              var newAccumulation = add(mul(_this.m, accumulation), gradient);
              if (_this.useNesterov) {
                newValue = add(mul(_this.c, add(gradient, mul(newAccumulation, _this.m))), value);
              } else {
                newValue = add(mul(_this.c, newAccumulation), value);
              }
              accumulation.assign(newAccumulation);
              value.assign(newValue);
            });
          });
          this.incrementIterations();
        };
        MomentumOptimizer2.prototype.dispose = function() {
          this.m.dispose();
          if (this.accumulations != null) {
            dispose(this.accumulations.map(function(v) {
              return v.variable;
            }));
          }
        };
        MomentumOptimizer2.prototype.setMomentum = function(momentum) {
          this.momentum = momentum;
        };
        MomentumOptimizer2.prototype.getWeights = function() {
          return __awaiter(this, void 0, void 0, function() {
            return __generator(this, function(_a) {
              switch (_a.label) {
                case 0:
                  return [4, this.saveIterations()];
                case 1:
                  return [2, [_a.sent()].concat(this.accumulations.map(function(v) {
                    return { name: v.originalName, tensor: v.variable };
                  }))];
              }
            });
          });
        };
        MomentumOptimizer2.prototype.setWeights = function(weightValues) {
          return __awaiter(this, void 0, void 0, function() {
            var trainable;
            return __generator(this, function(_a) {
              switch (_a.label) {
                case 0:
                  return [4, this.extractIterations(weightValues)];
                case 1:
                  weightValues = _a.sent();
                  trainable = false;
                  this.accumulations = weightValues.map(function(v) {
                    return { originalName: v.name, variable: v.tensor.variable(trainable) };
                  });
                  return [
                    2
                    /*return*/
                  ];
              }
            });
          });
        };
        MomentumOptimizer2.prototype.getConfig = function() {
          return {
            "learningRate": this.learningRate,
            "momentum": this.momentum,
            "useNesterov": this.useNesterov
          };
        };
        MomentumOptimizer2.fromConfig = function(cls, config) {
          return new cls(config["learningRate"], config["momentum"], config["useNesterov"]);
        };
        return MomentumOptimizer2;
      }(SGDOptimizer)
    );
    var RMSPropOptimizer = (
      /** @class */
      function(_super) {
        __extends(RMSPropOptimizer2, _super);
        function RMSPropOptimizer2(learningRate, decay, momentum, epsilon, centered) {
          if (decay === void 0) {
            decay = 0.9;
          }
          if (momentum === void 0) {
            momentum = 0;
          }
          if (epsilon === void 0) {
            epsilon = null;
          }
          if (centered === void 0) {
            centered = false;
          }
          var _this = _super.call(this) || this;
          _this.learningRate = learningRate;
          _this.decay = decay;
          _this.momentum = momentum;
          _this.epsilon = epsilon;
          _this.accumulatedMeanSquares = [];
          _this.accumulatedMoments = [];
          _this.accumulatedMeanGrads = [];
          _this.centered = centered;
          if (epsilon == null) {
            _this.epsilon = ENGINE.backend.epsilon();
          }
          if (learningRate == null) {
            throw new Error("learningRate for RMSPropOptimizer must be defined.");
          }
          return _this;
        }
        Object.defineProperty(RMSPropOptimizer2, "className", {
          /** @nocollapse */
          get: function() {
            return "RMSProp";
          },
          enumerable: false,
          configurable: true
        });
        RMSPropOptimizer2.prototype.applyGradients = function(variableGradients) {
          var _this = this;
          var variableNames = Array.isArray(variableGradients) ? variableGradients.map(function(item) {
            return item.name;
          }) : Object.keys(variableGradients);
          variableNames.forEach(function(name, i) {
            var value = ENGINE.registeredVariables[name];
            var trainable = false;
            if (_this.accumulatedMeanSquares[i] == null) {
              _this.accumulatedMeanSquares[i] = {
                originalName: "".concat(name, "/rms"),
                variable: tidy(function() {
                  return zerosLike(value).variable(trainable);
                })
              };
            }
            if (_this.accumulatedMoments[i] == null) {
              _this.accumulatedMoments[i] = {
                originalName: "".concat(name, "/momentum"),
                variable: tidy(function() {
                  return zerosLike(value).variable(trainable);
                })
              };
            }
            if (_this.accumulatedMeanGrads[i] == null && _this.centered) {
              _this.accumulatedMeanGrads[i] = {
                originalName: "".concat(name, "/mg"),
                variable: tidy(function() {
                  return zerosLike(value).variable(trainable);
                })
              };
            }
            var gradient = Array.isArray(variableGradients) ? variableGradients[i].tensor : variableGradients[name];
            if (gradient == null) {
              return;
            }
            var accumulatedMeanSquare = _this.accumulatedMeanSquares[i].variable;
            var accumulatedMoments = _this.accumulatedMoments[i].variable;
            tidy(function() {
              var newAccumulatedMeanSquare = add(mul(accumulatedMeanSquare, _this.decay), mul(square(gradient), 1 - _this.decay));
              if (_this.centered) {
                var accumulatedMeanGrad = _this.accumulatedMeanGrads[i].variable;
                var newAccumulatedMeanGrad = add(mul(accumulatedMeanGrad, _this.decay), mul(gradient, 1 - _this.decay));
                var gradContribution = div(mul(gradient, _this.learningRate), sqrt(sub(newAccumulatedMeanSquare, add(square(newAccumulatedMeanGrad), _this.epsilon))));
                var newAccumulatedMoments = add(mul(accumulatedMoments, _this.momentum), gradContribution);
                accumulatedMeanSquare.assign(newAccumulatedMeanSquare);
                accumulatedMeanGrad.assign(newAccumulatedMeanGrad);
                accumulatedMoments.assign(newAccumulatedMoments);
                var newValue = sub(value, newAccumulatedMoments);
                value.assign(newValue);
              } else {
                var newAccumulatedMeanSquare_1 = add(mul(accumulatedMeanSquare, _this.decay), mul(square(gradient), 1 - _this.decay));
                var newAccumulatedMoments = add(mul(accumulatedMoments, _this.momentum), div(mul(gradient, _this.learningRate), sqrt(add(newAccumulatedMeanSquare_1, _this.epsilon))));
                accumulatedMeanSquare.assign(newAccumulatedMeanSquare_1);
                accumulatedMoments.assign(newAccumulatedMoments);
                var newValue = sub(value, newAccumulatedMoments);
                value.assign(newValue);
              }
            });
          });
          this.incrementIterations();
        };
        RMSPropOptimizer2.prototype.dispose = function() {
          if (this.accumulatedMeanSquares != null) {
            dispose(this.accumulatedMeanSquares.map(function(v) {
              return v.variable;
            }));
          }
          if (this.accumulatedMeanGrads != null && this.centered) {
            dispose(this.accumulatedMeanGrads.map(function(v) {
              return v.variable;
            }));
          }
          if (this.accumulatedMoments != null) {
            dispose(this.accumulatedMoments.map(function(v) {
              return v.variable;
            }));
          }
        };
        RMSPropOptimizer2.prototype.getWeights = function() {
          return __awaiter(this, void 0, void 0, function() {
            var variables;
            return __generator(this, function(_a) {
              switch (_a.label) {
                case 0:
                  variables = __spreadArray(__spreadArray([], __read(this.accumulatedMeanSquares), false), __read(this.accumulatedMoments), false);
                  if (this.centered) {
                    variables.push.apply(variables, __spreadArray([], __read(this.accumulatedMeanGrads), false));
                  }
                  return [4, this.saveIterations()];
                case 1:
                  return [2, [_a.sent()].concat(variables.map(function(v) {
                    return { name: v.originalName, tensor: v.variable };
                  }))];
              }
            });
          });
        };
        RMSPropOptimizer2.prototype.setWeights = function(weightValues) {
          return __awaiter(this, void 0, void 0, function() {
            var variableCount, trainable;
            return __generator(this, function(_a) {
              switch (_a.label) {
                case 0:
                  return [4, this.extractIterations(weightValues)];
                case 1:
                  weightValues = _a.sent();
                  variableCount = this.centered ? weightValues.length / 3 : weightValues.length / 2;
                  trainable = false;
                  this.accumulatedMeanSquares = weightValues.slice(0, variableCount).map(function(v) {
                    return {
                      originalName: v.name,
                      variable: v.tensor.variable(trainable)
                    };
                  });
                  this.accumulatedMoments = weightValues.slice(variableCount, variableCount * 2).map(function(v) {
                    return {
                      originalName: v.name,
                      variable: v.tensor.variable(trainable)
                    };
                  });
                  if (this.centered) {
                    this.accumulatedMeanGrads = weightValues.slice(variableCount * 2, variableCount * 3).map(function(v) {
                      return {
                        originalName: v.name,
                        variable: v.tensor.variable(trainable)
                      };
                    });
                  }
                  return [
                    2
                    /*return*/
                  ];
              }
            });
          });
        };
        RMSPropOptimizer2.prototype.getConfig = function() {
          return {
            "learningRate": this.learningRate,
            "decay": this.decay,
            "momentum": this.momentum,
            "epsilon": this.epsilon,
            "centered": this.centered
          };
        };
        RMSPropOptimizer2.fromConfig = function(cls, config) {
          return new cls(config["learningRate"], config["decay"], config["momentum"], config["epsilon"], config["centered"]);
        };
        return RMSPropOptimizer2;
      }(Optimizer)
    );
    var OPTIMIZERS = [
      AdadeltaOptimizer,
      AdagradOptimizer,
      AdamOptimizer,
      AdamaxOptimizer,
      MomentumOptimizer,
      RMSPropOptimizer,
      SGDOptimizer
    ];
    function registerOptimizers() {
      var e_1, _a;
      try {
        for (var OPTIMIZERS_1 = __values(OPTIMIZERS), OPTIMIZERS_1_1 = OPTIMIZERS_1.next(); !OPTIMIZERS_1_1.done; OPTIMIZERS_1_1 = OPTIMIZERS_1.next()) {
          var optimizer = OPTIMIZERS_1_1.value;
          registerClass(optimizer);
        }
      } catch (e_1_1) {
        e_1 = { error: e_1_1 };
      } finally {
        try {
          if (OPTIMIZERS_1_1 && !OPTIMIZERS_1_1.done && (_a = OPTIMIZERS_1.return))
            _a.call(OPTIMIZERS_1);
        } finally {
          if (e_1)
            throw e_1.error;
        }
      }
    }
    var DEFAULT_FILE_NAME_PREFIX = "model";
    var DEFAULT_JSON_EXTENSION_NAME = ".json";
    var DEFAULT_WEIGHT_DATA_EXTENSION_NAME = ".weights.bin";
    function defer(f) {
      return new Promise(function(resolve2) {
        return setTimeout(resolve2);
      }).then(f);
    }
    var BrowserDownloads = (
      /** @class */
      function() {
        function BrowserDownloads2(fileNamePrefix) {
          if (!env().getBool("IS_BROWSER")) {
            throw new Error("browserDownloads() cannot proceed because the current environment is not a browser.");
          }
          if (fileNamePrefix.startsWith(BrowserDownloads2.URL_SCHEME)) {
            fileNamePrefix = fileNamePrefix.slice(BrowserDownloads2.URL_SCHEME.length);
          }
          if (fileNamePrefix == null || fileNamePrefix.length === 0) {
            fileNamePrefix = DEFAULT_FILE_NAME_PREFIX;
          }
          this.modelJsonFileName = fileNamePrefix + DEFAULT_JSON_EXTENSION_NAME;
          this.weightDataFileName = fileNamePrefix + DEFAULT_WEIGHT_DATA_EXTENSION_NAME;
        }
        BrowserDownloads2.prototype.save = function(modelArtifacts) {
          return __awaiter(this, void 0, void 0, function() {
            var weightsURL, weightsManifest, modelJSON, modelJsonURL, jsonAnchor_1, weightDataAnchor_1;
            return __generator(this, function(_a) {
              switch (_a.label) {
                case 0:
                  if (typeof document === "undefined") {
                    throw new Error("Browser downloads are not supported in this environment since `document` is not present");
                  }
                  weightsURL = window.URL.createObjectURL(new Blob([modelArtifacts.weightData], { type: "application/octet-stream" }));
                  if (!(modelArtifacts.modelTopology instanceof ArrayBuffer))
                    return [3, 1];
                  throw new Error("BrowserDownloads.save() does not support saving model topology in binary formats yet.");
                case 1:
                  weightsManifest = [{
                    paths: ["./" + this.weightDataFileName],
                    weights: modelArtifacts.weightSpecs
                  }];
                  modelJSON = getModelJSONForModelArtifacts(modelArtifacts, weightsManifest);
                  modelJsonURL = window.URL.createObjectURL(new Blob([JSON.stringify(modelJSON)], { type: "application/json" }));
                  jsonAnchor_1 = this.modelJsonAnchor == null ? document.createElement("a") : this.modelJsonAnchor;
                  jsonAnchor_1.download = this.modelJsonFileName;
                  jsonAnchor_1.href = modelJsonURL;
                  return [4, defer(function() {
                    return jsonAnchor_1.dispatchEvent(new MouseEvent("click"));
                  })];
                case 2:
                  _a.sent();
                  if (!(modelArtifacts.weightData != null))
                    return [3, 4];
                  weightDataAnchor_1 = this.weightDataAnchor == null ? document.createElement("a") : this.weightDataAnchor;
                  weightDataAnchor_1.download = this.weightDataFileName;
                  weightDataAnchor_1.href = weightsURL;
                  return [4, defer(function() {
                    return weightDataAnchor_1.dispatchEvent(new MouseEvent("click"));
                  })];
                case 3:
                  _a.sent();
                  _a.label = 4;
                case 4:
                  return [2, { modelArtifactsInfo: getModelArtifactsInfoForJSON(modelArtifacts) }];
              }
            });
          });
        };
        return BrowserDownloads2;
      }()
    );
    BrowserDownloads.URL_SCHEME = "downloads://";
    var BrowserFiles = (
      /** @class */
      function() {
        function BrowserFiles2(files) {
          if (files == null || files.length < 1) {
            throw new Error("When calling browserFiles, at least 1 file is required, " + "but received ".concat(files));
          }
          this.jsonFile = files[0];
          this.weightsFiles = files.slice(1);
        }
        BrowserFiles2.prototype.load = function() {
          return __awaiter(this, void 0, void 0, function() {
            var _this = this;
            return __generator(this, function(_a) {
              return [2, new Promise(function(resolve2, reject) {
                var jsonReader = new FileReader();
                jsonReader.onload = function(event) {
                  var modelJSON = JSON.parse(event.target.result);
                  var modelTopology = modelJSON.modelTopology;
                  if (modelTopology == null) {
                    reject(new Error("modelTopology field is missing from file ".concat(_this.jsonFile.name)));
                    return;
                  }
                  var weightsManifest = modelJSON.weightsManifest;
                  if (weightsManifest == null) {
                    reject(new Error("weightManifest field is missing from file ".concat(_this.jsonFile.name)));
                    return;
                  }
                  if (_this.weightsFiles.length === 0) {
                    resolve2({ modelTopology });
                    return;
                  }
                  var modelArtifactsPromise = getModelArtifactsForJSON(modelJSON, function(weightsManifest2) {
                    return _this.loadWeights(weightsManifest2);
                  });
                  resolve2(modelArtifactsPromise);
                };
                jsonReader.onerror = function(error) {
                  return reject("Failed to read model topology and weights manifest JSON " + "from file '".concat(_this.jsonFile.name, "'. BrowserFiles supports loading ") + "Keras-style tf.Model artifacts only.");
                };
                jsonReader.readAsText(_this.jsonFile);
              })];
            });
          });
        };
        BrowserFiles2.prototype.loadWeights = function(weightsManifest) {
          var e_1, _a;
          var _this = this;
          var weightSpecs = [];
          var paths = [];
          try {
            for (var weightsManifest_1 = __values(weightsManifest), weightsManifest_1_1 = weightsManifest_1.next(); !weightsManifest_1_1.done; weightsManifest_1_1 = weightsManifest_1.next()) {
              var entry = weightsManifest_1_1.value;
              weightSpecs.push.apply(weightSpecs, __spreadArray([], __read(entry.weights), false));
              paths.push.apply(paths, __spreadArray([], __read(entry.paths), false));
            }
          } catch (e_1_1) {
            e_1 = { error: e_1_1 };
          } finally {
            try {
              if (weightsManifest_1_1 && !weightsManifest_1_1.done && (_a = weightsManifest_1.return))
                _a.call(weightsManifest_1);
            } finally {
              if (e_1)
                throw e_1.error;
            }
          }
          var pathToFile = this.checkManifestAndWeightFiles(weightsManifest);
          var promises = paths.map(function(path) {
            return _this.loadWeightsFile(path, pathToFile[path]);
          });
          return Promise.all(promises).then(function(buffers) {
            return [weightSpecs, concatenateArrayBuffers(buffers)];
          });
        };
        BrowserFiles2.prototype.loadWeightsFile = function(path, file) {
          return new Promise(function(resolve2, reject) {
            var weightFileReader = new FileReader();
            weightFileReader.onload = function(event) {
              var weightData = event.target.result;
              resolve2(weightData);
            };
            weightFileReader.onerror = function(error) {
              return reject("Failed to weights data from file of path '".concat(path, "'."));
            };
            weightFileReader.readAsArrayBuffer(file);
          });
        };
        BrowserFiles2.prototype.checkManifestAndWeightFiles = function(manifest) {
          var e_2, _a;
          var _this = this;
          var basenames = [];
          var fileNames = this.weightsFiles.map(function(file) {
            return basename(file.name);
          });
          var pathToFile = {};
          try {
            for (var manifest_1 = __values(manifest), manifest_1_1 = manifest_1.next(); !manifest_1_1.done; manifest_1_1 = manifest_1.next()) {
              var group = manifest_1_1.value;
              group.paths.forEach(function(path) {
                var pathBasename = basename(path);
                if (basenames.indexOf(pathBasename) !== -1) {
                  throw new Error("Duplicate file basename found in weights manifest: " + "'".concat(pathBasename, "'"));
                }
                basenames.push(pathBasename);
                if (fileNames.indexOf(pathBasename) === -1) {
                  throw new Error("Weight file with basename '".concat(pathBasename, "' is not provided."));
                } else {
                  pathToFile[path] = _this.weightsFiles[fileNames.indexOf(pathBasename)];
                }
              });
            }
          } catch (e_2_1) {
            e_2 = { error: e_2_1 };
          } finally {
            try {
              if (manifest_1_1 && !manifest_1_1.done && (_a = manifest_1.return))
                _a.call(manifest_1);
            } finally {
              if (e_2)
                throw e_2.error;
            }
          }
          if (basenames.length !== this.weightsFiles.length) {
            throw new Error("Mismatch in the number of files in weights manifest " + "(".concat(basenames.length, ") and the number of weight files provided ") + "(".concat(this.weightsFiles.length, ")."));
          }
          return pathToFile;
        };
        return BrowserFiles2;
      }()
    );
    var browserDownloadsRouter = function(url) {
      if (!env().getBool("IS_BROWSER")) {
        return null;
      } else {
        if (!Array.isArray(url) && url.startsWith(BrowserDownloads.URL_SCHEME)) {
          return browserDownloads(url.slice(BrowserDownloads.URL_SCHEME.length));
        } else {
          return null;
        }
      }
    };
    IORouterRegistry.registerSaveRouter(browserDownloadsRouter);
    function browserDownloads(fileNamePrefix) {
      if (fileNamePrefix === void 0) {
        fileNamePrefix = "model";
      }
      return new BrowserDownloads(fileNamePrefix);
    }
    function browserFiles(files) {
      return new BrowserFiles(files);
    }
    var CompositeArrayBuffer = (
      /** @class */
      function() {
        function CompositeArrayBuffer2(buffers) {
          this.shards = [];
          this.previousShardIndex = 0;
          if (!(buffers instanceof Array)) {
            buffers = [buffers];
          }
          buffers = buffers.map(function(bufferOrTypedArray) {
            if (isTypedArray(bufferOrTypedArray)) {
              return bufferOrTypedArray.buffer;
            }
            return bufferOrTypedArray;
          });
          if (buffers.length === 0) {
            return;
          }
          this.bufferUniformSize = buffers[0].byteLength;
          var start = 0;
          for (var i = 0; i < buffers.length; i++) {
            var buffer2 = buffers[i];
            if (i !== buffers.length - 1 && buffer2.byteLength !== this.bufferUniformSize) {
              this.bufferUniformSize = void 0;
            }
            var end = start + buffer2.byteLength;
            this.shards.push({ buffer: buffer2, start, end });
            start = end;
          }
          if (this.shards.length === 0) {
            this.byteLength = 0;
          }
          this.byteLength = this.shards[this.shards.length - 1].end;
        }
        CompositeArrayBuffer2.prototype.slice = function(start, end) {
          if (start === void 0) {
            start = 0;
          }
          if (end === void 0) {
            end = this.byteLength;
          }
          start = isNaN(Number(start)) ? 0 : start;
          end = isNaN(Number(end)) ? 0 : end;
          start = Math.max(0, start);
          end = Math.min(this.byteLength, end);
          if (end <= start) {
            return new ArrayBuffer(0);
          }
          var startShardIndex = this.findShardForByte(start);
          if (startShardIndex === -1) {
            throw new Error("Could not find start shard for byte ".concat(start));
          }
          var size = end - start;
          var outputBuffer = new ArrayBuffer(size);
          var outputArray = new Uint8Array(outputBuffer);
          var sliced = 0;
          for (var i = startShardIndex; i < this.shards.length; i++) {
            var shard = this.shards[i];
            var globalStart = start + sliced;
            var localStart = globalStart - shard.start;
            var outputStart = sliced;
            var globalEnd = Math.min(end, shard.end);
            var localEnd = globalEnd - shard.start;
            var outputSlice = new Uint8Array(shard.buffer.slice(localStart, localEnd));
            outputArray.set(outputSlice, outputStart);
            sliced += outputSlice.length;
            if (end < shard.end) {
              break;
            }
          }
          return outputBuffer;
        };
        CompositeArrayBuffer2.prototype.findShardForByte = function(byteIndex) {
          if (this.shards.length === 0 || byteIndex < 0 || byteIndex >= this.byteLength) {
            return -1;
          }
          if (this.bufferUniformSize != null) {
            this.previousShardIndex = Math.floor(byteIndex / this.bufferUniformSize);
            return this.previousShardIndex;
          }
          function check(shard) {
            if (byteIndex < shard.start) {
              return -1;
            }
            if (byteIndex >= shard.end) {
              return 1;
            }
            return 0;
          }
          if (check(this.shards[this.previousShardIndex]) === 0) {
            return this.previousShardIndex;
          }
          var index = search(this.shards, check);
          if (index === -1) {
            return -1;
          }
          this.previousShardIndex = index;
          return this.previousShardIndex;
        };
        return CompositeArrayBuffer2;
      }()
    );
    function search(sortedArray, compare) {
      var min2 = 0;
      var max2 = sortedArray.length;
      while (min2 <= max2) {
        var middle = Math.floor((max2 - min2) / 2) + min2;
        var side = compare(sortedArray[middle]);
        if (side === 0) {
          return middle;
        } else if (side < 0) {
          max2 = middle;
        } else {
          min2 = middle + 1;
        }
      }
      return -1;
    }
    function monitorPromisesProgress(promises, onProgress, startFraction, endFraction) {
      checkPromises(promises);
      startFraction = startFraction == null ? 0 : startFraction;
      endFraction = endFraction == null ? 1 : endFraction;
      checkFraction(startFraction, endFraction);
      var resolvedPromise = 0;
      var registerMonitor = function(promise) {
        promise.then(function(value) {
          var fraction = startFraction + ++resolvedPromise / promises.length * (endFraction - startFraction);
          onProgress(fraction);
          return value;
        });
        return promise;
      };
      function checkPromises(promises2) {
        assert(promises2 != null && Array.isArray(promises2) && promises2.length > 0, function() {
          return "promises must be a none empty array";
        });
      }
      function checkFraction(startFraction2, endFraction2) {
        assert(startFraction2 >= 0 && startFraction2 <= 1, function() {
          return "Progress fraction must be in range [0, 1], but " + "got startFraction ".concat(startFraction2);
        });
        assert(endFraction2 >= 0 && endFraction2 <= 1, function() {
          return "Progress fraction must be in range [0, 1], but " + "got endFraction ".concat(endFraction2);
        });
        assert(endFraction2 >= startFraction2, function() {
          return "startFraction must be no more than endFraction, but " + "got startFraction ".concat(startFraction2, " and endFraction ") + "".concat(endFraction2);
        });
      }
      return Promise.all(promises.map(registerMonitor));
    }
    function loadWeightsAsArrayBuffer(fetchURLs, loadOptions) {
      return __awaiter(this, void 0, void 0, function() {
        var fetchFunc, requests, fetchStartFraction, fetchEndFraction, responses, _a, bufferPromises, bufferStartFraction, bufferEndFraction, buffers, _b;
        return __generator(this, function(_c) {
          switch (_c.label) {
            case 0:
              if (loadOptions == null) {
                loadOptions = {};
              }
              fetchFunc = loadOptions.fetchFunc == null ? env().platform.fetch : loadOptions.fetchFunc;
              requests = fetchURLs.map(function(fetchURL) {
                return fetchFunc(fetchURL, loadOptions.requestInit, { isBinary: true });
              });
              fetchStartFraction = 0;
              fetchEndFraction = 0.5;
              if (!(loadOptions.onProgress == null))
                return [3, 2];
              return [4, Promise.all(requests)];
            case 1:
              _a = _c.sent();
              return [3, 4];
            case 2:
              return [4, monitorPromisesProgress(requests, loadOptions.onProgress, fetchStartFraction, fetchEndFraction)];
            case 3:
              _a = _c.sent();
              _c.label = 4;
            case 4:
              responses = _a;
              bufferPromises = responses.map(function(response) {
                return response.arrayBuffer();
              });
              bufferStartFraction = 0.5;
              bufferEndFraction = 1;
              if (!(loadOptions.onProgress == null))
                return [3, 6];
              return [4, Promise.all(bufferPromises)];
            case 5:
              _b = _c.sent();
              return [3, 8];
            case 6:
              return [4, monitorPromisesProgress(bufferPromises, loadOptions.onProgress, bufferStartFraction, bufferEndFraction)];
            case 7:
              _b = _c.sent();
              _c.label = 8;
            case 8:
              buffers = _b;
              return [2, buffers];
          }
        });
      });
    }
    function loadWeights(manifest, filePathPrefix, weightNames, requestInit) {
      if (filePathPrefix === void 0) {
        filePathPrefix = "";
      }
      return __awaiter(this, void 0, void 0, function() {
        var fetchWeights, loadWeights2;
        return __generator(this, function(_a) {
          fetchWeights = function(fetchUrls) {
            return loadWeightsAsArrayBuffer(fetchUrls, { requestInit });
          };
          loadWeights2 = weightsLoaderFactory(fetchWeights);
          return [2, loadWeights2(manifest, filePathPrefix, weightNames)];
        });
      });
    }
    function weightsLoaderFactory(fetchWeightsFunction) {
      var _this = this;
      return function(manifest, filePathPrefix, weightNames) {
        if (filePathPrefix === void 0) {
          filePathPrefix = "";
        }
        return __awaiter(_this, void 0, void 0, function() {
          var groupIndicesToFetchMap, groupWeightsToFetch, weightsFound, allManifestWeightNames, weightsNotFound, groupIndicesToFetch, fetchUrls, buffers, weightsTensorMap, bufferIndexOffset;
          return __generator(this, function(_a) {
            switch (_a.label) {
              case 0:
                groupIndicesToFetchMap = manifest.map(function() {
                  return false;
                });
                groupWeightsToFetch = {};
                weightsFound = weightNames != null ? weightNames.map(function() {
                  return false;
                }) : [];
                allManifestWeightNames = [];
                manifest.forEach(function(manifestGroupConfig, groupIndex) {
                  var groupOffset = 0;
                  manifestGroupConfig.weights.forEach(function(weightsEntry) {
                    var rawDtype = "quantization" in weightsEntry ? weightsEntry.quantization.dtype : weightsEntry.dtype;
                    var weightsBytes = DTYPE_VALUE_SIZE_MAP[rawDtype] * sizeFromShape(weightsEntry.shape);
                    var enqueueWeightsForFetchingFn = function() {
                      groupIndicesToFetchMap[groupIndex] = true;
                      if (groupWeightsToFetch[groupIndex] == null) {
                        groupWeightsToFetch[groupIndex] = [];
                      }
                      groupWeightsToFetch[groupIndex].push({
                        manifestEntry: weightsEntry,
                        groupOffset,
                        sizeBytes: weightsBytes
                      });
                    };
                    if (weightNames != null) {
                      weightNames.forEach(function(weightName, weightIndex) {
                        if (weightName === weightsEntry.name) {
                          enqueueWeightsForFetchingFn();
                          weightsFound[weightIndex] = true;
                        }
                      });
                    } else {
                      enqueueWeightsForFetchingFn();
                    }
                    allManifestWeightNames.push(weightsEntry.name);
                    groupOffset += weightsBytes;
                  });
                });
                if (!weightsFound.every(function(found) {
                  return found;
                })) {
                  weightsNotFound = weightNames.filter(function(_, i) {
                    return !weightsFound[i];
                  });
                  throw new Error("Could not find weights in manifest with names: " + "".concat(weightsNotFound.join(", "), ". \n") + "Manifest JSON has weights with names: " + "".concat(allManifestWeightNames.join(", "), "."));
                }
                groupIndicesToFetch = groupIndicesToFetchMap.reduce(function(accumulator, shouldFetch, i) {
                  if (shouldFetch) {
                    accumulator.push(i);
                  }
                  return accumulator;
                }, []);
                fetchUrls = [];
                groupIndicesToFetch.forEach(function(i) {
                  manifest[i].paths.forEach(function(filepath) {
                    var fetchUrl = filePathPrefix + (!filePathPrefix.endsWith("/") ? "/" : "") + filepath;
                    fetchUrls.push(fetchUrl);
                  });
                });
                return [4, fetchWeightsFunction(fetchUrls)];
              case 1:
                buffers = _a.sent();
                weightsTensorMap = {};
                bufferIndexOffset = 0;
                groupIndicesToFetch.forEach(function(i) {
                  var numBuffers = manifest[i].paths.length;
                  var weightsBuffer = new CompositeArrayBuffer(buffers.slice(bufferIndexOffset, bufferIndexOffset + numBuffers));
                  var weightsEntries = groupWeightsToFetch[i];
                  weightsEntries.forEach(function(weightsEntry) {
                    var byteBuffer = weightsBuffer.slice(weightsEntry.groupOffset, weightsEntry.groupOffset + weightsEntry.sizeBytes);
                    var nameToTensorMap = decodeWeights(byteBuffer, [weightsEntry.manifestEntry]);
                    for (var name in nameToTensorMap) {
                      weightsTensorMap[name] = nameToTensorMap[name];
                    }
                  });
                  bufferIndexOffset += numBuffers;
                });
                return [2, weightsTensorMap];
            }
          });
        });
      };
    }
    var OCTET_STREAM_MIME_TYPE = "application/octet-stream";
    var JSON_TYPE = "application/json";
    var HTTPRequest = (
      /** @class */
      function() {
        function HTTPRequest2(path, loadOptions) {
          this.DEFAULT_METHOD = "POST";
          if (loadOptions == null) {
            loadOptions = {};
          }
          this.weightPathPrefix = loadOptions.weightPathPrefix;
          this.onProgress = loadOptions.onProgress;
          this.weightUrlConverter = loadOptions.weightUrlConverter;
          if (loadOptions.fetchFunc != null) {
            assert(typeof loadOptions.fetchFunc === "function", function() {
              return "Must pass a function that matches the signature of `fetch` (see https://developer.mozilla.org/en-US/docs/Web/API/Fetch_API)";
            });
            this.fetch = loadOptions.fetchFunc;
          } else {
            this.fetch = env().platform.fetch;
          }
          assert(path != null && path.length > 0, function() {
            return "URL path for http must not be null, undefined or empty.";
          });
          if (Array.isArray(path)) {
            assert(path.length === 2, function() {
              return "URL paths for http must have a length of 2, " + "(actual length is ".concat(path.length, ").");
            });
          }
          this.path = path;
          if (loadOptions.requestInit != null && loadOptions.requestInit.body != null) {
            throw new Error("requestInit is expected to have no pre-existing body, but has one.");
          }
          this.requestInit = loadOptions.requestInit || {};
        }
        HTTPRequest2.prototype.save = function(modelArtifacts) {
          return __awaiter(this, void 0, void 0, function() {
            var init, weightsManifest, modelTopologyAndWeightManifest, response;
            return __generator(this, function(_a) {
              switch (_a.label) {
                case 0:
                  if (modelArtifacts.modelTopology instanceof ArrayBuffer) {
                    throw new Error("BrowserHTTPRequest.save() does not support saving model topology in binary formats yet.");
                  }
                  init = Object.assign({ method: this.DEFAULT_METHOD }, this.requestInit);
                  init.body = new FormData();
                  weightsManifest = [{
                    paths: ["./model.weights.bin"],
                    weights: modelArtifacts.weightSpecs
                  }];
                  modelTopologyAndWeightManifest = getModelJSONForModelArtifacts(modelArtifacts, weightsManifest);
                  init.body.append("model.json", new Blob([JSON.stringify(modelTopologyAndWeightManifest)], { type: JSON_TYPE }), "model.json");
                  if (modelArtifacts.weightData != null) {
                    init.body.append("model.weights.bin", new Blob([modelArtifacts.weightData], { type: OCTET_STREAM_MIME_TYPE }), "model.weights.bin");
                  }
                  return [4, this.fetch(this.path, init)];
                case 1:
                  response = _a.sent();
                  if (response.ok) {
                    return [2, {
                      modelArtifactsInfo: getModelArtifactsInfoForJSON(modelArtifacts),
                      responses: [response]
                    }];
                  } else {
                    throw new Error("BrowserHTTPRequest.save() failed due to HTTP response status " + "".concat(response.status, "."));
                  }
              }
            });
          });
        };
        HTTPRequest2.prototype.load = function() {
          return __awaiter(this, void 0, void 0, function() {
            var modelConfigRequest, modelJSON, message, modelTopology, weightsManifest;
            var _this = this;
            return __generator(this, function(_a) {
              switch (_a.label) {
                case 0:
                  return [4, this.fetch(this.path, this.requestInit)];
                case 1:
                  modelConfigRequest = _a.sent();
                  if (!modelConfigRequest.ok) {
                    throw new Error("Request to ".concat(this.path, " failed with status code ") + "".concat(modelConfigRequest.status, ". Please verify this URL points to ") + "the model JSON of the model to load.");
                  }
                  _a.label = 2;
                case 2:
                  _a.trys.push([2, 4, , 5]);
                  return [4, modelConfigRequest.json()];
                case 3:
                  modelJSON = _a.sent();
                  return [3, 5];
                case 4:
                  _a.sent();
                  message = "Failed to parse model JSON of response from ".concat(this.path, ".");
                  if (this.path.endsWith(".pb")) {
                    message += " Your path contains a .pb file extension. Support for .pb models have been removed in TensorFlow.js 1.0 in favor of .json models. You can re-convert your Python TensorFlow model using the TensorFlow.js 1.0 conversion scripts or you can convert your.pb models with the 'pb2json'NPM script in the tensorflow/tfjs-converter repository.";
                  } else {
                    message += " Please make sure the server is serving valid JSON for this request.";
                  }
                  throw new Error(message);
                case 5:
                  modelTopology = modelJSON.modelTopology;
                  weightsManifest = modelJSON.weightsManifest;
                  if (modelTopology == null && weightsManifest == null) {
                    throw new Error("The JSON from HTTP path ".concat(this.path, " contains neither model ") + "topology or manifest for weights.");
                  }
                  return [2, getModelArtifactsForJSON(modelJSON, function(weightsManifest2) {
                    return _this.loadWeights(weightsManifest2);
                  })];
              }
            });
          });
        };
        HTTPRequest2.prototype.loadWeights = function(weightsManifest) {
          return __awaiter(this, void 0, void 0, function() {
            var weightPath, _a, prefix, suffix, pathPrefix, weightSpecs, fetchURLs, urlPromises, weightsManifest_1, weightsManifest_1_1, weightsGroup, _b, _c, path, _d, _e, _f, _g, buffers;
            var e_2, _h, e_3, _j;
            return __generator(this, function(_k) {
              switch (_k.label) {
                case 0:
                  weightPath = Array.isArray(this.path) ? this.path[1] : this.path;
                  _a = __read(parseUrl(weightPath), 2), prefix = _a[0], suffix = _a[1];
                  pathPrefix = this.weightPathPrefix || prefix;
                  weightSpecs = getWeightSpecs(weightsManifest);
                  fetchURLs = [];
                  urlPromises = [];
                  try {
                    for (weightsManifest_1 = __values(weightsManifest), weightsManifest_1_1 = weightsManifest_1.next(); !weightsManifest_1_1.done; weightsManifest_1_1 = weightsManifest_1.next()) {
                      weightsGroup = weightsManifest_1_1.value;
                      try {
                        for (_b = (e_3 = void 0, __values(weightsGroup.paths)), _c = _b.next(); !_c.done; _c = _b.next()) {
                          path = _c.value;
                          if (this.weightUrlConverter != null) {
                            urlPromises.push(this.weightUrlConverter(path));
                          } else {
                            fetchURLs.push(pathPrefix + path + suffix);
                          }
                        }
                      } catch (e_3_1) {
                        e_3 = { error: e_3_1 };
                      } finally {
                        try {
                          if (_c && !_c.done && (_j = _b.return))
                            _j.call(_b);
                        } finally {
                          if (e_3)
                            throw e_3.error;
                        }
                      }
                    }
                  } catch (e_2_1) {
                    e_2 = { error: e_2_1 };
                  } finally {
                    try {
                      if (weightsManifest_1_1 && !weightsManifest_1_1.done && (_h = weightsManifest_1.return))
                        _h.call(weightsManifest_1);
                    } finally {
                      if (e_2)
                        throw e_2.error;
                    }
                  }
                  if (!this.weightUrlConverter)
                    return [3, 2];
                  _e = (_d = fetchURLs.push).apply;
                  _f = [fetchURLs];
                  _g = [[]];
                  return [4, Promise.all(urlPromises)];
                case 1:
                  _e.apply(_d, _f.concat([__spreadArray.apply(void 0, _g.concat([__read.apply(void 0, [_k.sent()]), false]))]));
                  _k.label = 2;
                case 2:
                  return [4, loadWeightsAsArrayBuffer(fetchURLs, {
                    requestInit: this.requestInit,
                    fetchFunc: this.fetch,
                    onProgress: this.onProgress
                  })];
                case 3:
                  buffers = _k.sent();
                  return [2, [weightSpecs, concatenateArrayBuffers(buffers)]];
              }
            });
          });
        };
        return HTTPRequest2;
      }()
    );
    HTTPRequest.URL_SCHEME_REGEX = /^https?:\/\//;
    function parseUrl(url) {
      var lastSlash = url.lastIndexOf("/");
      var lastSearchParam = url.lastIndexOf("?");
      var prefix = url.substring(0, lastSlash);
      var suffix = lastSearchParam > lastSlash ? url.substring(lastSearchParam) : "";
      return [prefix + "/", suffix];
    }
    function isHTTPScheme(url) {
      return url.match(HTTPRequest.URL_SCHEME_REGEX) != null;
    }
    var httpRouter = function(url, loadOptions) {
      if (typeof fetch === "undefined" && (loadOptions == null || loadOptions.fetchFunc == null)) {
        return null;
      } else {
        var isHTTP = true;
        if (Array.isArray(url)) {
          isHTTP = url.every(function(urlItem) {
            return isHTTPScheme(urlItem);
          });
        } else {
          isHTTP = isHTTPScheme(url);
        }
        if (isHTTP) {
          return http(url, loadOptions);
        }
      }
      return null;
    };
    IORouterRegistry.registerSaveRouter(httpRouter);
    IORouterRegistry.registerLoadRouter(httpRouter);
    function http(path, loadOptions) {
      return new HTTPRequest(path, loadOptions);
    }
    function browserHTTPRequest(path, loadOptions) {
      return http(path, loadOptions);
    }
    var PassthroughLoader = (
      /** @class */
      function() {
        function PassthroughLoader2(modelArtifacts) {
          this.modelArtifacts = modelArtifacts;
        }
        PassthroughLoader2.prototype.load = function() {
          return this.modelArtifacts;
        };
        return PassthroughLoader2;
      }()
    );
    var PassthroughSaver = (
      /** @class */
      function() {
        function PassthroughSaver2(saveHandler) {
          this.saveHandler = saveHandler;
        }
        PassthroughSaver2.prototype.save = function(modelArtifacts) {
          return this.saveHandler(modelArtifacts);
        };
        return PassthroughSaver2;
      }()
    );
    var PassthroughAsync = (
      /** @class */
      function() {
        function PassthroughAsync2(handler) {
          if (handler.load) {
            this.load = function() {
              return Promise.resolve(handler.load());
            };
          }
          if (handler.save) {
            this.save = function(modelArtifacts) {
              return Promise.resolve(handler.save(modelArtifacts));
            };
          }
        }
        return PassthroughAsync2;
      }()
    );
    function fromMemory(modelArtifacts, weightSpecs, weightData, trainingConfig) {
      var args = arguments;
      return new PassthroughAsync(fromMemorySync.apply(void 0, __spreadArray([], __read(args), false)));
    }
    function fromMemorySync(modelArtifacts, weightSpecs, weightData, trainingConfig) {
      if (arguments.length === 1) {
        var isModelArtifacts = modelArtifacts.modelTopology != null || modelArtifacts.weightSpecs != null;
        if (isModelArtifacts) {
          return new PassthroughLoader(modelArtifacts);
        } else {
          console.warn("Please call tf.io.fromMemory() with only one argument. The argument should be of type ModelArtifacts. The multi-argument signature of tf.io.fromMemory() has been deprecated and will be removed in a future release.");
          return new PassthroughLoader({ modelTopology: modelArtifacts });
        }
      } else {
        console.warn("Please call tf.io.fromMemory() with only one argument. The argument should be of type ModelArtifacts. The multi-argument signature of tf.io.fromMemory() has been deprecated and will be removed in a future release.");
        return new PassthroughLoader({
          modelTopology: modelArtifacts,
          weightSpecs,
          weightData,
          trainingConfig
        });
      }
    }
    function withSaveHandler(saveHandler) {
      return new PassthroughSaver(saveHandler);
    }
    function withSaveHandlerSync(saveHandler) {
      return new PassthroughSaver(saveHandler);
    }
    var io3 = {
      __proto__: null,
      browserFiles,
      browserHTTPRequest,
      concatenateArrayBuffers,
      copyModel,
      decodeWeights,
      encodeWeights,
      fromMemory,
      fromMemorySync,
      getLoadHandlers,
      getModelArtifactsForJSON,
      getModelArtifactsForJSONSync,
      getModelArtifactsInfoForJSON,
      getSaveHandlers,
      getWeightSpecs,
      http,
      isHTTPScheme,
      listModels,
      loadWeights,
      moveModel,
      registerLoadRouter,
      registerSaveRouter,
      removeModel,
      weightsLoaderFactory,
      withSaveHandler,
      withSaveHandlerSync
    };
    function confusionMatrix_(labels, predictions, numClasses) {
      var $labels = convertToTensor(labels, "labels", "confusionMatrix");
      var $predictions = convertToTensor(predictions, "predictions", "confusionMatrix");
      assert(numClasses == null || numClasses > 0 && Number.isInteger(numClasses), function() {
        return "If provided, numClasses must be a positive integer, " + "but got ".concat(numClasses);
      });
      assert($labels.rank === 1, function() {
        return "Expected the rank of labels to be 1, but got ".concat($labels.rank);
      });
      assert($predictions.rank === 1, function() {
        return "Expected the rank of predictions to be 1, " + "but got ".concat($predictions.rank);
      });
      assert($labels.shape[0] === $predictions.shape[0], function() {
        return "Mismatch in the number of examples: " + "".concat($labels.shape[0], " vs. ").concat($predictions.shape[0], ". ") + "Labels and predictions should have the same number of elements.";
      });
      assert(numClasses > 0 && Number.isInteger(numClasses), function() {
        return "numClasses is required to be a positive integer, but got " + "".concat(numClasses);
      });
      var oneHotLabels = oneHot(cast($labels, "int32"), numClasses);
      var oneHotPredictions = oneHot(cast($predictions, "int32"), numClasses);
      var oneHotLabelsT = transpose(oneHotLabels);
      var product = matMul$1(oneHotLabelsT, oneHotPredictions);
      return cast(product, "int32");
    }
    var confusionMatrix = /* @__PURE__ */ op({ confusionMatrix_ });
    var math = {
      __proto__: null,
      confusionMatrix
    };
    var fromPixels2DContext;
    function fromPixels_(pixels, numChannels) {
      if (numChannels === void 0) {
        numChannels = 3;
      }
      if (numChannels > 4) {
        throw new Error("Cannot construct Tensor with more than 4 channels from pixels.");
      }
      if (pixels == null) {
        throw new Error("pixels passed to tf.browser.fromPixels() can not be null");
      }
      var isPixelData2 = false;
      var isImageData = false;
      var isVideo = false;
      var isImage = false;
      var isCanvasLike = false;
      var isImageBitmap = false;
      if (pixels.data instanceof Uint8Array) {
        isPixelData2 = true;
      } else if (typeof ImageData !== "undefined" && pixels instanceof ImageData) {
        isImageData = true;
      } else if (typeof HTMLVideoElement !== "undefined" && pixels instanceof HTMLVideoElement) {
        isVideo = true;
      } else if (typeof HTMLImageElement !== "undefined" && pixels instanceof HTMLImageElement) {
        isImage = true;
      } else if (pixels.getContext != null) {
        isCanvasLike = true;
      } else if (typeof ImageBitmap !== "undefined" && pixels instanceof ImageBitmap) {
        isImageBitmap = true;
      } else {
        throw new Error("pixels passed to tf.browser.fromPixels() must be either an HTMLVideoElement, HTMLImageElement, HTMLCanvasElement, ImageData in browser, or OffscreenCanvas, ImageData in webworker or {data: Uint32Array, width: number, height: number}, " + "but was ".concat(pixels.constructor.name));
      }
      var kernel = getKernel(FromPixels, ENGINE.backendName);
      if (kernel != null) {
        var inputs = { pixels };
        var attrs = { numChannels };
        return ENGINE.runKernel(FromPixels, inputs, attrs);
      }
      var _a = __read(isVideo ? [
        pixels.videoWidth,
        pixels.videoHeight
      ] : [pixels.width, pixels.height], 2), width = _a[0], height = _a[1];
      var vals;
      if (isCanvasLike) {
        vals = // tslint:disable-next-line:no-any
        pixels.getContext("2d").getImageData(0, 0, width, height).data;
      } else if (isImageData || isPixelData2) {
        vals = pixels.data;
      } else if (isImage || isVideo || isImageBitmap) {
        if (fromPixels2DContext == null) {
          if (typeof document === "undefined") {
            if (typeof OffscreenCanvas !== "undefined" && typeof OffscreenCanvasRenderingContext2D !== "undefined") {
              fromPixels2DContext = new OffscreenCanvas(1, 1).getContext("2d");
            } else {
              throw new Error("Cannot parse input in current context. Reason: OffscreenCanvas Context2D rendering is not supported.");
            }
          } else {
            fromPixels2DContext = document.createElement("canvas").getContext("2d", { willReadFrequently: true });
          }
        }
        fromPixels2DContext.canvas.width = width;
        fromPixels2DContext.canvas.height = height;
        fromPixels2DContext.drawImage(pixels, 0, 0, width, height);
        vals = fromPixels2DContext.getImageData(0, 0, width, height).data;
      }
      var values;
      if (numChannels === 4) {
        values = new Int32Array(vals);
      } else {
        var numPixels = width * height;
        values = new Int32Array(numPixels * numChannels);
        for (var i = 0; i < numPixels; i++) {
          for (var channel = 0; channel < numChannels; ++channel) {
            values[i * numChannels + channel] = vals[i * 4 + channel];
          }
        }
      }
      var outShape = [height, width, numChannels];
      return tensor3d(values, outShape, "int32");
    }
    function isPixelData(pixels) {
      return pixels != null && pixels.data instanceof Uint8Array;
    }
    function isImageBitmapFullySupported() {
      return typeof window !== "undefined" && typeof ImageBitmap !== "undefined" && window.hasOwnProperty("createImageBitmap");
    }
    function isNonEmptyPixels(pixels) {
      return pixels != null && pixels.width !== 0 && pixels.height !== 0;
    }
    function canWrapPixelsToImageBitmap(pixels) {
      return isImageBitmapFullySupported() && !(pixels instanceof ImageBitmap) && isNonEmptyPixels(pixels) && !isPixelData(pixels);
    }
    function fromPixelsAsync(pixels, numChannels) {
      if (numChannels === void 0) {
        numChannels = 3;
      }
      return __awaiter(this, void 0, void 0, function() {
        var inputs, imageBitmap;
        return __generator(this, function(_a) {
          switch (_a.label) {
            case 0:
              inputs = null;
              if (!(env().getBool("WRAP_TO_IMAGEBITMAP") && canWrapPixelsToImageBitmap(pixels)))
                return [3, 5];
              imageBitmap = void 0;
              _a.label = 1;
            case 1:
              _a.trys.push([1, 3, , 4]);
              return [4, createImageBitmap(pixels, { premultiplyAlpha: "none" })];
            case 2:
              imageBitmap = _a.sent();
              return [3, 4];
            case 3:
              _a.sent();
              imageBitmap = null;
              return [3, 4];
            case 4:
              if (imageBitmap != null && imageBitmap.width === pixels.width && imageBitmap.height === pixels.height) {
                inputs = imageBitmap;
              } else {
                inputs = pixels;
              }
              return [3, 6];
            case 5:
              inputs = pixels;
              _a.label = 6;
            case 6:
              return [2, fromPixels_(inputs, numChannels)];
          }
        });
      });
    }
    function toPixels(img, canvas) {
      return __awaiter(this, void 0, void 0, function() {
        var $img, originalImgTensor, _a, height, width, depth, data, multiplier, bytes, i, rgba, d, value, j, ctx, imageData;
        return __generator(this, function(_b) {
          switch (_b.label) {
            case 0:
              $img = convertToTensor(img, "img", "toPixels");
              if (!(img instanceof Tensor)) {
                originalImgTensor = $img;
                $img = cast(originalImgTensor, "int32");
                originalImgTensor.dispose();
              }
              if ($img.rank !== 2 && $img.rank !== 3) {
                throw new Error("toPixels only supports rank 2 or 3 tensors, got rank ".concat($img.rank, "."));
              }
              _a = __read($img.shape.slice(0, 2), 2), height = _a[0], width = _a[1];
              depth = $img.rank === 2 ? 1 : $img.shape[2];
              if (depth > 4 || depth === 2) {
                throw new Error("toPixels only supports depth of size " + "1, 3 or 4 but got ".concat(depth));
              }
              if ($img.dtype !== "float32" && $img.dtype !== "int32") {
                throw new Error("Unsupported type for toPixels: ".concat($img.dtype, ".") + " Please use float32 or int32 tensors.");
              }
              return [4, $img.data()];
            case 1:
              data = _b.sent();
              multiplier = $img.dtype === "float32" ? 255 : 1;
              bytes = new Uint8ClampedArray(width * height * 4);
              for (i = 0; i < height * width; ++i) {
                rgba = [0, 0, 0, 255];
                for (d = 0; d < depth; d++) {
                  value = data[i * depth + d];
                  if ($img.dtype === "float32") {
                    if (value < 0 || value > 1) {
                      throw new Error("Tensor values for a float32 Tensor must be in the " + "range [0 - 1] but encountered ".concat(value, "."));
                    }
                  } else if ($img.dtype === "int32") {
                    if (value < 0 || value > 255) {
                      throw new Error("Tensor values for a int32 Tensor must be in the " + "range [0 - 255] but encountered ".concat(value, "."));
                    }
                  }
                  if (depth === 1) {
                    rgba[0] = value * multiplier;
                    rgba[1] = value * multiplier;
                    rgba[2] = value * multiplier;
                  } else {
                    rgba[d] = value * multiplier;
                  }
                }
                j = i * 4;
                bytes[j + 0] = Math.round(rgba[0]);
                bytes[j + 1] = Math.round(rgba[1]);
                bytes[j + 2] = Math.round(rgba[2]);
                bytes[j + 3] = Math.round(rgba[3]);
              }
              if (canvas != null) {
                canvas.width = width;
                canvas.height = height;
                ctx = canvas.getContext("2d");
                imageData = new ImageData(bytes, width, height);
                ctx.putImageData(imageData, 0, 0);
              }
              if ($img !== img) {
                $img.dispose();
              }
              return [2, bytes];
          }
        });
      });
    }
    var fromPixels = /* @__PURE__ */ op({ fromPixels_ });
    var browser = {
      __proto__: null,
      fromPixels,
      fromPixelsAsync,
      toPixels
    };
    function prepareAndValidate(tensor2, indices) {
      var tensorRank = tensor2.shape.length;
      var indicesRank = indices.shape.length;
      if (tensorRank < 1) {
        throw new Error("tf.gatherND() expects the input to be rank 1 or higher," + " but the rank was ".concat(tensorRank, "."));
      }
      if (indicesRank < 1) {
        throw new Error("tf.gatherND() expects the indices to be rank 1 or higher," + " but the rank was ".concat(indicesRank, "."));
      }
      if (indices.dtype !== "int32") {
        throw new Error("tf.gatherND() expects the indices to be int32 type," + " but the dtype was ".concat(indices.dtype, "."));
      }
      if (indices.shape[indicesRank - 1] > tensorRank) {
        throw new Error("index innermost dimension length must be <= tensor rank; saw: " + "".concat(indices.shape[indicesRank - 1], " vs. ").concat(tensorRank));
      }
      if (sizeFromShape(tensor2.shape) === 0) {
        throw new Error("Requested more than 0 entries, but input is empty." + " Input shape: ".concat(tensor2.shape, "."));
      }
      var indicesShape = indices.shape;
      var sliceRank = indicesShape[indicesShape.length - 1];
      var nResult = 1;
      for (var i = 0; i < indicesShape.length - 1; ++i) {
        nResult *= indicesShape[i];
      }
      var inputShape = tensor2.shape;
      var resultShape = indicesShape.slice();
      resultShape.pop();
      var sliceSize = 1;
      for (var i = sliceRank; i < tensorRank; ++i) {
        sliceSize *= inputShape[i];
        resultShape.push(inputShape[i]);
      }
      var strides = __spreadArray(__spreadArray([], __read(computeStrides(tensor2.shape).map(function(stride) {
        return stride / sliceSize;
      })), false), [1], false).slice(0, sliceRank);
      return [resultShape, nResult, sliceSize, strides];
    }
    var gather_nd_util = {
      __proto__: null,
      prepareAndValidate
    };
    var NEW_AXIS = -2;
    var SHRINK_AXIS = -1;
    function assertParamsValid(input, begin, size) {
      var inputRank = input.shape.length;
      assert(inputRank === begin.length, function() {
        return "Error in slice".concat(inputRank, "D: Length of begin ").concat(begin, " must ") + "match the rank of the array (".concat(inputRank, ").");
      });
      assert(inputRank === size.length, function() {
        return "Error in slice".concat(inputRank, "D: Length of size ").concat(size, " must ") + "match the rank of the array (".concat(inputRank, ").");
      });
      var _loop_1 = function(i2) {
        assert(begin[i2] + size[i2] <= input.shape[i2], function() {
          return "Error in slice".concat(inputRank, "D: begin[").concat(i2, "] + size[").concat(i2, "] ") + "(".concat(begin[i2] + size[i2], ") would overflow input.shape[").concat(i2, "] (").concat(input.shape[i2], ")");
        });
      };
      for (var i = 0; i < inputRank; ++i) {
        _loop_1(i);
      }
    }
    function maskToAxes(mask) {
      var axes = [];
      var axis = 0;
      while (mask > 0) {
        if (mask & 1) {
          axes.push(axis);
        }
        mask /= 2;
        axis++;
      }
      return axes;
    }
    function computeOutShape$2(begin, end, strides) {
      var size = [];
      for (var axis = 0; axis < begin.length; axis++) {
        size[axis] = Math.ceil((end[axis] - begin[axis]) / strides[axis]);
      }
      return size;
    }
    function stridesWithElidedDims(strides, ellipsisInsertionIndex, numElidedAxes, inputShape) {
      var newStrides = __spreadArray([], __read(strides), false);
      for (var i = newStrides.length; i < inputShape.length; i++) {
        newStrides.push(1);
      }
      for (var i = 0; i < numElidedAxes; i++) {
        if (i === 0) {
          newStrides[ellipsisInsertionIndex] = 1;
        } else {
          newStrides.splice(
            ellipsisInsertionIndex,
            0,
            1
            /* element to add */
          );
          newStrides.pop();
        }
      }
      return newStrides;
    }
    function unnormalizeAxis(ellipsisInsertionIndex, numElidedAxes, normalizedAxis) {
      if (normalizedAxis <= ellipsisInsertionIndex) {
        return normalizedAxis;
      }
      return normalizedAxis - (numElidedAxes - 1);
    }
    function getElidedAxes(numElidedAxes, ellipsisInsertionIndex) {
      var elidedAxes = [];
      for (var i = 0; i < numElidedAxes; i++) {
        elidedAxes.push(ellipsisInsertionIndex + i);
      }
      return elidedAxes;
    }
    function getNormalizedAxes(inputShape, ellipsisAxes, numInterpolatedAxes, begin, end, strides, beginMask, endMask, ellipsisMask) {
      var inputRank = inputShape.length;
      var normalizedBegin = new Array(inputRank), normalizedEnd = new Array(inputRank), normalizedStrides = new Array(inputRank);
      if (ellipsisAxes.length && numInterpolatedAxes > 0) {
        var fullIndex = ellipsisAxes[0];
        var numElidedAxes = numInterpolatedAxes + 1;
        normalizedBegin = startIndicesWithElidedDims(beginMask, fullIndex, numElidedAxes, begin, inputShape);
        normalizedEnd = stopIndicesWithElidedDims(endMask, fullIndex, numElidedAxes, end, inputShape);
        normalizedStrides = stridesWithElidedDims(strides, fullIndex, numElidedAxes, inputShape);
      } else {
        for (var axis = 0; axis < inputRank; axis++) {
          normalizedBegin[axis] = startForAxis(beginMask, begin, strides, inputShape, axis, ellipsisMask);
          normalizedEnd[axis] = stopForAxis(endMask, end, strides, inputShape, axis, ellipsisMask);
          normalizedStrides[axis] = stridesForAxis(strides, axis, ellipsisMask);
        }
      }
      return {
        begin: normalizedBegin,
        end: normalizedEnd,
        strides: normalizedStrides
      };
    }
    function startIndicesWithElidedDims(beginMask, ellipsisInsertionIndex, numElidedAxes, originalBegin, inputShape) {
      var newIndices = __spreadArray([], __read(inputShape), false);
      var elidedAxes = getElidedAxes(numElidedAxes, ellipsisInsertionIndex);
      for (var axis = 0; axis < newIndices.length; axis++) {
        if (elidedAxes.indexOf(axis) > -1) {
          newIndices[axis] = 0;
        } else {
          var originalAxis = unnormalizeAxis(ellipsisInsertionIndex, numElidedAxes, axis);
          var originalValue = originalBegin[originalAxis];
          if (beginMask & 1 << originalAxis) {
            originalValue = 0;
          }
          newIndices[axis] = originalValue;
        }
      }
      return newIndices;
    }
    function stopIndicesWithElidedDims(endMask, ellipsisInsertionIndex, numElidedAxes, originalEnd, inputShape) {
      var newIndices = __spreadArray([], __read(inputShape), false);
      var elidedAxes = getElidedAxes(numElidedAxes, ellipsisInsertionIndex);
      for (var axis = 0; axis < newIndices.length; axis++) {
        if (elidedAxes.indexOf(axis) > -1) {
          newIndices[axis] = Number.MAX_SAFE_INTEGER;
        } else {
          var originalAxis = unnormalizeAxis(ellipsisInsertionIndex, numElidedAxes, axis);
          var originalValue = originalEnd[originalAxis];
          if (endMask & 1 << originalAxis) {
            originalValue = Number.MAX_SAFE_INTEGER;
          }
          newIndices[axis] = originalValue;
        }
      }
      for (var i = 0; i < newIndices.length; i++) {
        var axisSize = inputShape[i];
        if (newIndices[i] < 0) {
          newIndices[i] += axisSize;
        }
        newIndices[i] = clamp(0, newIndices[i], inputShape[i]);
      }
      return newIndices;
    }
    function stridesForAxis(strides, axis, ellipsisMask) {
      var stride = strides[axis];
      if (ellipsisMask & 1 << axis || stride == null) {
        stride = 1;
      }
      return stride;
    }
    function startForAxis(beginMask, startIndices, strides, inputShape, axis, ellipsisMask) {
      var start = startIndices[axis];
      var stride = strides[axis] || 1;
      if (beginMask & 1 << axis || ellipsisMask & 1 << axis || start == null) {
        if (stride > 0) {
          start = Number.MIN_SAFE_INTEGER;
        } else {
          start = Number.MAX_SAFE_INTEGER;
        }
      }
      var axisSize = inputShape[axis];
      if (start < 0) {
        start += axisSize;
      }
      start = clamp(0, start, axisSize - 1);
      return start;
    }
    function stopForAxis(endMask, stopIndices, strides, inputShape, axis, ellipsisMask) {
      var stop = stopIndices[axis];
      var stride = strides[axis] || 1;
      if (endMask & 1 << axis || ellipsisMask & 1 << axis || stop == null) {
        if (stride > 0) {
          stop = Number.MAX_SAFE_INTEGER;
        } else {
          stop = Number.MIN_SAFE_INTEGER;
        }
      }
      var axisSize = inputShape[axis];
      if (stop < 0) {
        stop += axisSize;
      }
      if (stride > 0) {
        stop = clamp(0, stop, axisSize);
      } else {
        stop = clamp(-1, stop, axisSize - 1);
      }
      return stop;
    }
    function isSliceContinous(shape, begin, size) {
      var firstNonOneAxis = size.length;
      for (var i = 0; i < size.length; i++) {
        if (size[i] > 1) {
          firstNonOneAxis = i;
          break;
        }
      }
      for (var i = firstNonOneAxis + 1; i < size.length; i++) {
        if (begin[i] > 0 || size[i] !== shape[i]) {
          return false;
        }
      }
      return true;
    }
    function computeFlatOffset(begin, strides) {
      var flatOffset = begin.length > 0 ? begin[begin.length - 1] : 1;
      for (var i = 0; i < begin.length - 1; i++) {
        flatOffset += begin[i] * strides[i];
      }
      return flatOffset;
    }
    function parseSliceParams(x, begin, size) {
      var begin_;
      var xRank = x.shape.length;
      if (typeof begin === "number") {
        begin_ = __spreadArray([begin], __read(new Array(xRank - 1).fill(0)), false);
      } else if (begin.length < xRank) {
        begin_ = begin.concat(new Array(xRank - begin.length).fill(0));
      } else {
        begin_ = begin.slice();
      }
      begin_.forEach(function(d) {
        assert(d !== -1, function() {
          return "slice() does not support negative begin indexing.";
        });
      });
      var size_;
      if (size == null) {
        size_ = new Array(xRank).fill(-1);
      } else if (typeof size === "number") {
        size_ = __spreadArray([size], __read(new Array(xRank - 1).fill(-1)), false);
      } else if (size.length < xRank) {
        size_ = size.concat(new Array(xRank - size.length).fill(-1));
      } else {
        size_ = size;
      }
      size_ = size_.map(function(d, i) {
        if (d >= 0) {
          return d;
        } else {
          assert(d === -1, function() {
            return "Negative size values should be exactly -1 but got " + "".concat(d, " for the slice() size at index ").concat(i, ".");
          });
          return x.shape[i] - begin_[i];
        }
      });
      return [begin_, size_];
    }
    function sliceInfo(xShape, begin, end, strides, beginMask, endMask, ellipsisMask, newAxisMask, shrinkAxisMask) {
      var stridesNonNull;
      if (strides == null) {
        stridesNonNull = new Array(begin.length);
        stridesNonNull.fill(1);
      } else {
        stridesNonNull = strides;
      }
      if (ellipsisMask != null && (ellipsisMask & ellipsisMask - 1) !== 0) {
        throw new Error("Multiple ellipses in slice is not allowed.");
      }
      var ellipsisSeen = false;
      var sparseSpec = {
        dims: stridesNonNull.length,
        numAddAxisAfterEllipsis: 0,
        begin: begin.slice(),
        end: end.slice(),
        strides: stridesNonNull.slice(),
        beginMask,
        endMask,
        ellipsisMask,
        newAxisMask,
        shrinkAxisMask
      };
      for (var i = 0; i < sparseSpec.dims; i++) {
        if (ellipsisSeen && (1 << i & newAxisMask) !== 0) {
          sparseSpec.numAddAxisAfterEllipsis++;
        }
        if (1 << i & ellipsisMask) {
          ellipsisSeen = true;
        }
      }
      if (!ellipsisSeen) {
        sparseSpec.ellipsisMask |= 1 << sparseSpec.dims;
        sparseSpec.dims++;
      }
      var denseSpec = {
        dims: xShape.length,
        beginMask: 0,
        endMask: 0,
        beginValid: false,
        endValid: false
      };
      buildDenseSpec(sparseSpec, denseSpec);
      var isIdentity = true;
      var sliceDim0 = true;
      var isSimpleSlice = true;
      var processingShape = [];
      var finalShape = [];
      for (var i = 0; i < xShape.length; ++i) {
        if (denseSpec.strides[i] === 0) {
          throw Error("strides[".concat(i, "] must be non-zero"));
        }
        var shrinkI = !!(denseSpec.shrinkAxisMask & 1 << i);
        var dimI = xShape[i];
        if (dimI === -1) {
          processingShape.push(shrinkI ? 1 : -1);
          continue;
        }
        var masks = [denseSpec.beginMask & 1 << i, denseSpec.endMask & 1 << i];
        var validRange = [
          denseSpec.strides[i] > 0 ? 0 : -1,
          denseSpec.strides[i] > 0 ? dimI : dimI - 1
        ];
        if (shrinkI && denseSpec.strides[i] <= 0) {
          throw Error("only stride 1 allowed on non-range indexing.");
        }
        isSimpleSlice = isSimpleSlice && denseSpec.strides[i] === 1;
        var beginAndEndMasked = !!(denseSpec.beginMask & 1 << i && denseSpec.endMask & 1 << i);
        if (denseSpec.beginValid && denseSpec.endValid) {
          if (shrinkI) {
            var xFwd = denseSpec.begin[i] < 0 ? dimI + denseSpec.begin[i] : denseSpec.begin[i];
            denseSpec.begin[i] = xFwd;
            denseSpec.end[i] = denseSpec.begin[i] + 1;
            if (xFwd < 0 || xFwd >= dimI) {
              throw Error("slice index ".concat(denseSpec.begin[i], " of dimension ").concat(i, " out of bounds."));
            }
          } else {
            denseSpec.begin[i] = canonical(denseSpec.begin[i], 0, denseSpec.strides[i], dimI, masks, validRange);
            denseSpec.end[i] = canonical(denseSpec.end[i], 1, denseSpec.strides[i], dimI, masks, validRange);
          }
          var takeAllInDimension = denseSpec.strides[i] === 1 && denseSpec.begin[i] === 0 && denseSpec.end[i] === dimI;
          isIdentity = isIdentity && takeAllInDimension;
          sliceDim0 = sliceDim0 && (i === 0 && denseSpec.strides[i] === 1 || takeAllInDimension);
        } else {
          isIdentity = isIdentity && (denseSpec.strides[i] === 1 && beginAndEndMasked);
          sliceDim0 = sliceDim0 && (i === 0 && denseSpec.strides[i] === 1 || beginAndEndMasked);
        }
        var intervalLength = void 0;
        var knownInterval = false;
        if (denseSpec.beginValid && denseSpec.endValid) {
          intervalLength = denseSpec.end[i] - denseSpec.begin[i];
          knownInterval = true;
        } else if (shrinkI) {
          intervalLength = 1;
          knownInterval = true;
        } else if (beginAndEndMasked) {
          if (dimI >= 0) {
            if (denseSpec.strides[i] < 0) {
              intervalLength = -dimI;
            } else {
              intervalLength = dimI;
            }
            knownInterval = true;
          }
        }
        if (knownInterval) {
          var sizeI = void 0;
          if (intervalLength === 0 || intervalLength < 0 !== denseSpec.strides[i] < 0) {
            sizeI = 0;
          } else {
            sizeI = Math.trunc(intervalLength / denseSpec.strides[i]) + (intervalLength % denseSpec.strides[i] !== 0 ? 1 : 0);
          }
          processingShape.push(sizeI);
        } else {
          processingShape.push(-1);
        }
      }
      for (var denseDim = 0; denseDim < denseSpec.finalShapeGatherIndices.length; ++denseDim) {
        var gatherIndex = denseSpec.finalShapeGatherIndices[denseDim];
        if (gatherIndex >= 0) {
          finalShape.push(processingShape[gatherIndex]);
        } else if (gatherIndex === NEW_AXIS) {
          finalShape.push(1);
        }
      }
      var finalShapeSparse = finalShape.filter(function(dim, i2) {
        return denseSpec.finalShapeGatherIndices[i2] !== NEW_AXIS;
      });
      return {
        finalShapeSparse,
        finalShape,
        isIdentity,
        sliceDim0,
        isSimpleSlice,
        begin: denseSpec.begin,
        end: denseSpec.end,
        strides: denseSpec.strides
      };
    }
    function buildDenseSpec(sparse2, dense) {
      dense.beginMask = 0;
      dense.endMask = 0;
      dense.shrinkAxisMask = 0;
      var fullIndex = 0;
      dense.beginValid = sparse2.begin != null;
      dense.endValid = sparse2.end != null;
      dense.begin = new Array(dense.dims);
      dense.end = new Array(dense.dims);
      dense.strides = new Array(dense.dims);
      dense.finalShapeGatherIndices = [];
      dense.finalShapeGatherIndicesSparse = [];
      dense.inputShapeGatherIndicesSparse = new Array(dense.dims);
      for (var i = 0; i < sparse2.dims; i++) {
        if (1 << i & sparse2.ellipsisMask) {
          var nextIndex = Math.min(dense.dims - (sparse2.dims - i) + 1 + sparse2.numAddAxisAfterEllipsis, dense.dims);
          for (; fullIndex < nextIndex; fullIndex++) {
            dense.begin[fullIndex] = 0;
            dense.end[fullIndex] = 0;
            dense.strides[fullIndex] = 1;
            dense.beginMask |= 1 << fullIndex;
            dense.endMask |= 1 << fullIndex;
            dense.finalShapeGatherIndices.push(fullIndex);
            dense.finalShapeGatherIndicesSparse.push(-1);
            dense.inputShapeGatherIndicesSparse[fullIndex] = i;
          }
        } else if (1 << i & sparse2.newAxisMask) {
          dense.finalShapeGatherIndices.push(NEW_AXIS);
          dense.finalShapeGatherIndicesSparse.push(-1);
        } else {
          if (fullIndex === dense.begin.length) {
            throw Error("Index out of range using input dim ".concat(fullIndex, "; input ") + "has only ".concat(dense.dims, " dims, ").concat(dense.begin.length, "."));
          }
          if (sparse2.begin != null) {
            dense.begin[fullIndex] = sparse2.begin[i];
          }
          if (sparse2.end != null) {
            dense.end[fullIndex] = sparse2.end[i];
          }
          dense.strides[fullIndex] = sparse2.strides[i];
          if (sparse2.beginMask & 1 << i) {
            dense.beginMask |= 1 << fullIndex;
          }
          if (sparse2.endMask & 1 << i) {
            dense.endMask |= 1 << fullIndex;
          }
          if (sparse2.shrinkAxisMask & 1 << i) {
            dense.finalShapeGatherIndices.push(SHRINK_AXIS);
            dense.finalShapeGatherIndicesSparse.push(-1);
            dense.shrinkAxisMask |= 1 << fullIndex;
          } else {
            dense.finalShapeGatherIndices.push(fullIndex);
            dense.finalShapeGatherIndicesSparse.push(i);
          }
          dense.inputShapeGatherIndicesSparse[fullIndex] = i;
          fullIndex++;
        }
      }
    }
    function canonical(x, c, strideI, dimI, masks, validRange) {
      if (masks[c]) {
        return strideI > 0 ? validRange[c] : validRange[c + 1 & 1];
      } else {
        var xFwd = x < 0 ? dimI + x : x;
        return xFwd < validRange[0] ? validRange[0] : xFwd > validRange[1] ? validRange[1] : xFwd;
      }
    }
    var slice_util = {
      __proto__: null,
      assertParamsValid,
      computeFlatOffset,
      computeOutShape: computeOutShape$2,
      getNormalizedAxes,
      isSliceContinous,
      maskToAxes,
      parseSliceParams,
      sliceInfo,
      startForAxis,
      startIndicesWithElidedDims,
      stopForAxis,
      stopIndicesWithElidedDims,
      stridesForAxis,
      stridesWithElidedDims
    };
    var version2 = "4.5.0";
    var OptimizerConstructors = (
      /** @class */
      function() {
        function OptimizerConstructors2() {
        }
        OptimizerConstructors2.sgd = function(learningRate) {
          return new SGDOptimizer(learningRate);
        };
        OptimizerConstructors2.momentum = function(learningRate, momentum, useNesterov) {
          if (useNesterov === void 0) {
            useNesterov = false;
          }
          return new MomentumOptimizer(learningRate, momentum, useNesterov);
        };
        OptimizerConstructors2.rmsprop = function(learningRate, decay, momentum, epsilon, centered) {
          if (decay === void 0) {
            decay = 0.9;
          }
          if (momentum === void 0) {
            momentum = 0;
          }
          if (epsilon === void 0) {
            epsilon = null;
          }
          if (centered === void 0) {
            centered = false;
          }
          return new RMSPropOptimizer(learningRate, decay, momentum, epsilon, centered);
        };
        OptimizerConstructors2.adam = function(learningRate, beta1, beta2, epsilon) {
          if (learningRate === void 0) {
            learningRate = 1e-3;
          }
          if (beta1 === void 0) {
            beta1 = 0.9;
          }
          if (beta2 === void 0) {
            beta2 = 0.999;
          }
          if (epsilon === void 0) {
            epsilon = null;
          }
          return new AdamOptimizer(learningRate, beta1, beta2, epsilon);
        };
        OptimizerConstructors2.adadelta = function(learningRate, rho, epsilon) {
          if (learningRate === void 0) {
            learningRate = 1e-3;
          }
          if (rho === void 0) {
            rho = 0.95;
          }
          if (epsilon === void 0) {
            epsilon = null;
          }
          return new AdadeltaOptimizer(learningRate, rho, epsilon);
        };
        OptimizerConstructors2.adamax = function(learningRate, beta1, beta2, epsilon, decay) {
          if (learningRate === void 0) {
            learningRate = 2e-3;
          }
          if (beta1 === void 0) {
            beta1 = 0.9;
          }
          if (beta2 === void 0) {
            beta2 = 0.999;
          }
          if (epsilon === void 0) {
            epsilon = null;
          }
          if (decay === void 0) {
            decay = 0;
          }
          return new AdamaxOptimizer(learningRate, beta1, beta2, epsilon, decay);
        };
        OptimizerConstructors2.adagrad = function(learningRate, initialAccumulatorValue) {
          if (initialAccumulatorValue === void 0) {
            initialAccumulatorValue = 0.1;
          }
          return new AdagradOptimizer(learningRate, initialAccumulatorValue);
        };
        return OptimizerConstructors2;
      }()
    );
    var train = OptimizerConstructors;
    var delayCallback = function() {
      if (typeof requestAnimationFrame !== "undefined") {
        return requestAnimationFrame;
      } else if (typeof setImmediate !== "undefined") {
        return setImmediate;
      }
      return function(f) {
        return f();
      };
    }();
    function nextFrame() {
      return new Promise(function(resolve2) {
        return delayCallback(function() {
          return resolve2();
        });
      });
    }
    function assertParamsConsistent(shapes, axis) {
      var rank = shapes[0].length;
      shapes.forEach(function(shape, i) {
        assert(shape.length === rank, function() {
          return "Error in concat".concat(rank, "D: rank of tensors[").concat(i, "] must be the same ") + "as the rank of the rest (".concat(rank, ")");
        });
      });
      assert(axis >= 0 && axis < rank, function() {
        return "Error in concat".concat(rank, "D: axis must be between 0 and ").concat(rank - 1, ".");
      });
      var firstShape = shapes[0];
      shapes.forEach(function(shape, i) {
        for (var r = 0; r < rank; r++) {
          assert(r === axis || shape[r] === firstShape[r], function() {
            return "Error in concat".concat(rank, "D: Shape of tensors[").concat(i, "] (").concat(shape, ") ") + "does not match the shape of the rest (".concat(firstShape, ") ") + "along the non-concatenated axis ".concat(i, ".");
          });
        }
      });
    }
    function computeOutShape$1(shapes, axis) {
      var outputShape = shapes[0].slice();
      for (var i = 1; i < shapes.length; i++) {
        outputShape[axis] += shapes[i][axis];
      }
      return outputShape;
    }
    var RowPartitionType;
    (function(RowPartitionType2) {
      RowPartitionType2[RowPartitionType2["FIRST_DIM_SIZE"] = 0] = "FIRST_DIM_SIZE";
      RowPartitionType2[RowPartitionType2["VALUE_ROWIDS"] = 1] = "VALUE_ROWIDS";
      RowPartitionType2[RowPartitionType2["ROW_LENGTHS"] = 2] = "ROW_LENGTHS";
      RowPartitionType2[RowPartitionType2["ROW_SPLITS"] = 3] = "ROW_SPLITS";
      RowPartitionType2[RowPartitionType2["ROW_LIMITS"] = 4] = "ROW_LIMITS";
      RowPartitionType2[RowPartitionType2["ROW_STARTS"] = 5] = "ROW_STARTS";
    })(RowPartitionType || (RowPartitionType = {}));
    function combineRaggedTensorToTensorShapes(raggedRank, shape, valueShape) {
      var outputShape = new Array();
      if (valueShape == null && shape == null) {
        return outputShape;
      }
      if (shape == null) {
        while (outputShape.length < raggedRank + valueShape.length) {
          outputShape.push(-1);
        }
      } else {
        outputShape = shape.slice();
      }
      if (valueShape == null) {
        return outputShape;
      }
      if (raggedRank + valueShape.length !== outputShape.length) {
        throw new Error("rt input.shape and shape=".concat(shape, " are incompatible: rt input.rank = ").concat(raggedRank + valueShape.length, ", but shape.rank = ").concat(outputShape.length));
      }
      for (var i = 1; i < valueShape.length; ++i) {
        var valueDim = valueShape[i];
        var outputShapeDimIndex = outputShape[outputShape.length - valueShape.length + i];
        var outputShapeDim = outputShape[outputShapeDimIndex];
        if (valueDim >= 0) {
          if (outputShapeDim >= 0) {
            if (outputShapeDim !== valueDim) {
              throw new Error("rt input.shape and shape=".concat(shape, " are incompatible: rt input.shape[").concat(i + raggedRank, "] = ").concat(valueDim, " but shape[").concat(i + raggedRank, "] = ").concat(outputShapeDim));
            }
          } else {
            outputShape[outputShapeDimIndex] = valueDim;
          }
        }
      }
      return outputShape;
    }
    function getRowPartitionTypesHelper(rowPartitionTypeStrings) {
      var e_1, _a;
      var stringToType = {
        "FIRST_DIM_SIZE": RowPartitionType.FIRST_DIM_SIZE,
        "VALUE_ROWIDS": RowPartitionType.VALUE_ROWIDS,
        "ROW_LENGTHS": RowPartitionType.ROW_LENGTHS,
        "ROW_SPLITS": RowPartitionType.ROW_SPLITS,
        "ROW_LIMITS": RowPartitionType.ROW_LIMITS,
        "ROW_STARTS": RowPartitionType.ROW_STARTS
      };
      var result = [];
      try {
        for (var rowPartitionTypeStrings_1 = __values(rowPartitionTypeStrings), rowPartitionTypeStrings_1_1 = rowPartitionTypeStrings_1.next(); !rowPartitionTypeStrings_1_1.done; rowPartitionTypeStrings_1_1 = rowPartitionTypeStrings_1.next()) {
          var typeStr = rowPartitionTypeStrings_1_1.value;
          if (typeStr in stringToType) {
            result.push(stringToType[typeStr]);
          } else {
            break;
          }
        }
      } catch (e_1_1) {
        e_1 = { error: e_1_1 };
      } finally {
        try {
          if (rowPartitionTypeStrings_1_1 && !rowPartitionTypeStrings_1_1.done && (_a = rowPartitionTypeStrings_1.return))
            _a.call(rowPartitionTypeStrings_1);
        } finally {
          if (e_1)
            throw e_1.error;
        }
      }
      return result;
    }
    function getRaggedRank(rowPartitionTypes) {
      if (rowPartitionTypes.length === 0) {
        return 0;
      }
      if (rowPartitionTypes[0] === RowPartitionType.FIRST_DIM_SIZE) {
        return rowPartitionTypes.length - 1;
      }
      return rowPartitionTypes.length;
    }
    function validateDefaultValueShape(defaultValueShape, valueShape) {
      if (defaultValueShape == null || valueShape == null) {
        return;
      }
      var defaultNDims = defaultValueShape.length;
      var valuesNDims = valueShape.length;
      if (defaultNDims >= valuesNDims) {
        throw new Error("defaultValue.shape=".concat(defaultValueShape, " and ragged tensor flatValues.shape=").concat(valueShape, ", are incompatible: defaultValue.rank = ").concat(defaultNDims, " must be less than ragged tensor input flatValues.rank = ").concat(valuesNDims, ")"));
      }
      for (var i = 0; i < Math.min(defaultNDims, valuesNDims - 1); ++i) {
        var defaultDim = defaultValueShape[i];
        var valueDim = valueShape[i + 1];
        if (defaultDim >= 0 && valueDim >= 0 && defaultDim !== 1 && defaultDim !== valueDim) {
          throw new Error("defaultValue.shape=".concat(defaultValueShape, ", and ragged tensor input flatValues.shape=").concat(valueShape, " are incompatible: defaultValue.shape[").concat(i - defaultValueShape.length, "] = ").concat(defaultDim, " but ragged tensor input.flatValues.shape[").concat(i - defaultValueShape.length, "] = ").concat(valueDim));
        }
      }
    }
    var PARALLELIZE_THRESHOLD = 30;
    function computeOptimalWindowSize(inSize) {
      if (inSize <= PARALLELIZE_THRESHOLD) {
        return inSize;
      }
      return nearestDivisor(inSize, Math.floor(Math.sqrt(inSize)));
    }
    function getImageCenter(center, imageHeight, imageWidth) {
      var centerX = imageWidth * (typeof center === "number" ? center : center[0]);
      var centerY = imageHeight * (typeof center === "number" ? center : center[1]);
      return [centerX, centerY];
    }
    function getReshaped(inputShape, blockShape, prod2, batchToSpace) {
      if (batchToSpace === void 0) {
        batchToSpace = true;
      }
      var reshaped = [];
      if (batchToSpace) {
        reshaped = reshaped.concat(blockShape.slice(0));
        reshaped.push(inputShape[0] / prod2);
        reshaped = reshaped.concat(inputShape.slice(1));
      } else {
        reshaped = reshaped.concat(inputShape[0]);
        var spatialLength = blockShape.length;
        for (var i = 0; i < spatialLength; ++i) {
          reshaped = reshaped.concat([inputShape[i + 1] / blockShape[i], blockShape[i]]);
        }
        reshaped = reshaped.concat(inputShape.slice(spatialLength + 1));
      }
      return reshaped;
    }
    function getPermuted(reshapedRank, blockShapeRank, batchToSpace) {
      if (batchToSpace === void 0) {
        batchToSpace = true;
      }
      var permuted = [];
      if (batchToSpace) {
        permuted.push(blockShapeRank);
        for (var i = blockShapeRank + 1; i < reshapedRank; ++i) {
          if (i <= 2 * blockShapeRank) {
            permuted.push(i);
            permuted.push(i - (blockShapeRank + 1));
          } else {
            permuted.push(i);
          }
        }
      } else {
        var permutedBeforeBatch = [];
        var permutedAfterBatch = [];
        for (var i = 1; i < reshapedRank; ++i) {
          if (i >= blockShapeRank * 2 + 1 || i % 2 === 1) {
            permutedAfterBatch.push(i);
          } else {
            permutedBeforeBatch.push(i);
          }
        }
        permuted.push.apply(permuted, __spreadArray([], __read(permutedBeforeBatch), false));
        permuted.push(0);
        permuted.push.apply(permuted, __spreadArray([], __read(permutedAfterBatch), false));
      }
      return permuted;
    }
    function getReshapedPermuted(inputShape, blockShape, prod2, batchToSpace) {
      if (batchToSpace === void 0) {
        batchToSpace = true;
      }
      var reshapedPermuted = [];
      if (batchToSpace) {
        reshapedPermuted.push(inputShape[0] / prod2);
      } else {
        reshapedPermuted.push(inputShape[0] * prod2);
      }
      for (var i = 1; i < inputShape.length; ++i) {
        if (i <= blockShape.length) {
          if (batchToSpace) {
            reshapedPermuted.push(blockShape[i - 1] * inputShape[i]);
          } else {
            reshapedPermuted.push(inputShape[i] / blockShape[i - 1]);
          }
        } else {
          reshapedPermuted.push(inputShape[i]);
        }
      }
      return reshapedPermuted;
    }
    function getSliceBeginCoords(crops, blockShape) {
      var sliceBeginCoords = [0];
      for (var i = 0; i < blockShape; ++i) {
        sliceBeginCoords.push(crops[i][0]);
      }
      return sliceBeginCoords;
    }
    function getSliceSize(uncroppedShape, crops, blockShape) {
      var sliceSize = uncroppedShape.slice(0, 1);
      for (var i = 0; i < blockShape; ++i) {
        sliceSize.push(uncroppedShape[i + 1] - crops[i][0] - crops[i][1]);
      }
      return sliceSize;
    }
    var SELU_SCALEALPHA = 1.7580993408473768;
    var SELU_SCALE = 1.0507009873554805;
    var ERF_P = 0.3275911;
    var ERF_A1 = 0.254829592;
    var ERF_A2 = -0.284496736;
    var ERF_A3 = 1.421413741;
    var ERF_A4 = -1.453152027;
    var ERF_A5 = 1.061405429;
    function mergeRealAndImagArrays(real2, imag2) {
      if (real2.length !== imag2.length) {
        throw new Error("Cannot merge real and imag arrays of different lengths. real:" + "".concat(real2.length, ", imag: ").concat(imag2.length, "."));
      }
      var result = new Float32Array(real2.length * 2);
      for (var i = 0; i < result.length; i += 2) {
        result[i] = real2[i / 2];
        result[i + 1] = imag2[i / 2];
      }
      return result;
    }
    function splitRealAndImagArrays(complex2) {
      var real2 = new Float32Array(complex2.length / 2);
      var imag2 = new Float32Array(complex2.length / 2);
      for (var i = 0; i < complex2.length; i += 2) {
        real2[i / 2] = complex2[i];
        imag2[i / 2] = complex2[i + 1];
      }
      return { real: real2, imag: imag2 };
    }
    function complexWithEvenIndex(complex2) {
      var len = Math.ceil(complex2.length / 4);
      var real2 = new Float32Array(len);
      var imag2 = new Float32Array(len);
      for (var i = 0; i < complex2.length; i += 4) {
        real2[Math.floor(i / 4)] = complex2[i];
        imag2[Math.floor(i / 4)] = complex2[i + 1];
      }
      return { real: real2, imag: imag2 };
    }
    function complexWithOddIndex(complex2) {
      var len = Math.floor(complex2.length / 4);
      var real2 = new Float32Array(len);
      var imag2 = new Float32Array(len);
      for (var i = 2; i < complex2.length; i += 4) {
        real2[Math.floor(i / 4)] = complex2[i];
        imag2[Math.floor(i / 4)] = complex2[i + 1];
      }
      return { real: real2, imag: imag2 };
    }
    function getComplexWithIndex(complex2, index) {
      var real2 = complex2[index * 2];
      var imag2 = complex2[index * 2 + 1];
      return { real: real2, imag: imag2 };
    }
    function assignToTypedArray(data, real2, imag2, index) {
      data[index * 2] = real2;
      data[index * 2 + 1] = imag2;
    }
    function exponents(n, inverse) {
      var real2 = new Float32Array(n / 2);
      var imag2 = new Float32Array(n / 2);
      for (var i = 0; i < Math.ceil(n / 2); i++) {
        var x = (inverse ? 2 : -2) * Math.PI * (i / n);
        real2[i] = Math.cos(x);
        imag2[i] = Math.sin(x);
      }
      return { real: real2, imag: imag2 };
    }
    function exponent(k, n, inverse) {
      var x = (inverse ? 2 : -2) * Math.PI * (k / n);
      var real2 = Math.cos(x);
      var imag2 = Math.sin(x);
      return { real: real2, imag: imag2 };
    }
    var ARROW = "->";
    var ARROW_REGEX = /->/g;
    var COMMA = ",";
    var ELLIPSIS = "...";
    function decodeEinsumEquation(equation, numTensors) {
      equation = equation.replace(/\s/g, "");
      var numArrows = (equation.length - equation.replace(ARROW_REGEX, "").length) / ARROW.length;
      if (numArrows < 1) {
        throw new Error("Equations without an arrow are not supported.");
      } else if (numArrows > 1) {
        throw new Error('Equation must contain exactly one arrow ("'.concat(ARROW, '").'));
      }
      var _a = __read(equation.split(ARROW), 2), inputString = _a[0], outputString = _a[1];
      assert(inputString.indexOf(ELLIPSIS) === -1, function() {
        return 'The ellipsis notation ("'.concat(ELLIPSIS, '") is not supported yet.');
      });
      var inputTerms = inputString.split(COMMA);
      var numInputs = inputTerms.length;
      if (numTensors !== numInputs) {
        throw new Error("Expected ".concat(numInputs, " input tensors, received ").concat(numTensors));
      }
      if (numInputs > 2) {
        throw new Error("Support for more than 2 input tensors is not implemented yet.");
      }
      var allDims = [];
      var _loop_1 = function(i2) {
        var dimName2 = outputString[i2];
        if (!inputTerms.some(function(inputTerm) {
          return inputTerm.indexOf(dimName2) !== -1;
        })) {
          throw new Error("Output subscripts contain the label ".concat(dimName2, " ") + "not present in the input subscripts.");
        }
        if (allDims.indexOf(dimName2) === -1) {
          allDims.push(dimName2);
        }
      };
      for (var i = 0; i < outputString.length; ++i) {
        _loop_1(i);
      }
      for (var i = 0; i < inputString.length; ++i) {
        var dimName = inputString[i];
        if (allDims.indexOf(dimName) === -1 && dimName !== COMMA) {
          allDims.push(dimName);
        }
      }
      var idDims = new Array(inputTerms.length);
      for (var i = 0; i < numInputs; ++i) {
        if (new Set(inputTerms[i].split("")).size !== inputTerms[i].length) {
          throw new Error("Found duplicate axes in input component ".concat(inputTerms[i], ". ") + "Support for duplicate axes in input is not implemented yet.");
        }
        idDims[i] = [];
        for (var j = 0; j < inputTerms[i].length; ++j) {
          idDims[i].push(allDims.indexOf(inputTerms[i][j]));
        }
      }
      var numDims = allDims.length;
      var numOutDims = outputString.length;
      var summedDims = [];
      for (var i = numOutDims; i < numDims; ++i) {
        summedDims.push(i);
      }
      return { allDims, summedDims, idDims };
    }
    function getEinsumPermutation(nDims, idDims) {
      var permutationIndices = new Array(nDims);
      permutationIndices.fill(-1);
      for (var i = 0; i < idDims.length; ++i) {
        permutationIndices[idDims[i]] = i;
      }
      var expandDims2 = [];
      for (var i = 0; i < nDims; ++i) {
        if (permutationIndices[i] === -1) {
          expandDims2.push(i);
        }
      }
      permutationIndices = permutationIndices.filter(function(d) {
        return d !== -1;
      });
      return { permutationIndices, expandDims: expandDims2 };
    }
    function checkEinsumDimSizes(nDims, idDims, tensors) {
      var dimSizes = new Array(nDims);
      var _loop_2 = function(i2) {
        var shape = tensors[i2].shape;
        var _loop_3 = function(j2) {
          if (dimSizes[idDims[i2][j2]] === void 0) {
            dimSizes[idDims[i2][j2]] = shape[j2];
          } else {
            assert(dimSizes[idDims[i2][j2]] === shape[j2], function() {
              return "Expected dimension ".concat(dimSizes[idDims[i2][j2]], " at axis ").concat(j2, " ") + "of input shaped ".concat(JSON.stringify(shape), ", ") + "but got dimension ".concat(shape[j2]);
            });
          }
        };
        for (var j = 0; j < idDims[i2].length; ++j) {
          _loop_3(j);
        }
      };
      for (var i = 0; i < tensors.length; ++i) {
        _loop_2(i);
      }
    }
    function getEinsumComputePath(summedDims, idDims) {
      var e_1, _a;
      var path = summedDims;
      var steps = [];
      var nSteps = 0;
      if (summedDims.length === 0) {
        path.push(-1);
      }
      nSteps = summedDims.length + 1;
      for (var i = 0; i < nSteps; ++i) {
        steps.push([]);
      }
      var computedTermIndices = [];
      for (var i = 0; i < path.length; ++i) {
        var summedDim = path[i];
        var termIndices = findTermsWithDim(idDims, summedDim);
        try {
          for (var termIndices_1 = (e_1 = void 0, __values(termIndices)), termIndices_1_1 = termIndices_1.next(); !termIndices_1_1.done; termIndices_1_1 = termIndices_1.next()) {
            var termIndex = termIndices_1_1.value;
            if (computedTermIndices.indexOf(termIndex) === -1) {
              steps[i].push(termIndex);
              computedTermIndices.push(termIndex);
            }
          }
        } catch (e_1_1) {
          e_1 = { error: e_1_1 };
        } finally {
          try {
            if (termIndices_1_1 && !termIndices_1_1.done && (_a = termIndices_1.return))
              _a.call(termIndices_1);
          } finally {
            if (e_1)
              throw e_1.error;
          }
        }
      }
      return { path, steps };
    }
    function isIdentityPermutation(perm) {
      return perm.every(function(dim, index) {
        return dim === index;
      });
    }
    function findTermsWithDim(idDims, dim) {
      var termIndices = [];
      for (var i = 0; i < idDims.length; ++i) {
        if (idDims[i].length === 0 || idDims[i].indexOf(dim) !== -1 || dim === -1) {
          termIndices.push(i);
        }
      }
      return termIndices;
    }
    function prepareSplitSize(x, numOrSizeSplits, axis) {
      if (axis === void 0) {
        axis = 0;
      }
      var splitSizes = [];
      if (typeof numOrSizeSplits === "number") {
        assert(x.shape[axis] % numOrSizeSplits === 0, function() {
          return "Number of splits must evenly divide the axis.";
        });
        splitSizes = new Array(numOrSizeSplits).fill(x.shape[axis] / numOrSizeSplits);
      } else {
        var numOfNegs = numOrSizeSplits.reduce(function(count, value) {
          if (value === -1) {
            count += 1;
          }
          return count;
        }, 0);
        assert(numOfNegs <= 1, function() {
          return "There should be only one negative value in split array.";
        });
        var negIndex = numOrSizeSplits.indexOf(-1);
        if (negIndex !== -1) {
          var total = numOrSizeSplits.reduce(function(a, b) {
            return b > 0 ? a + b : a;
          });
          numOrSizeSplits[negIndex] = x.shape[axis] - total;
        }
        assert(x.shape[axis] === numOrSizeSplits.reduce(function(a, b) {
          return a + b;
        }), function() {
          return "The sum of sizes must match the size of the axis dimension.";
        });
        splitSizes = numOrSizeSplits;
      }
      return splitSizes;
    }
    function getSparseFillEmptyRowsIndicesDenseShapeMismatch(indicesLength) {
      return "Received SparseTensor with denseShape[0] = 0 but\n  indices.shape[0] = ".concat(indicesLength);
    }
    function getSparseFillEmptyRowsNegativeIndexErrorMessage(index, value) {
      return "indices(".concat(index, ", 0) is invalid: ").concat(value, " < 0");
    }
    function getSparseFillEmptyRowsOutOfRangeIndexErrorMessage(index, value, limit) {
      return "indices(".concat(index, ", 0) is invalid: ").concat(value, " >= ").concat(limit);
    }
    function getSparseReshapeMultipleNegativeOneOutputDimErrorMessage(dim1, dim2) {
      return "only one output dimension may be -1, not both ".concat(dim1, " and ").concat(dim2);
    }
    function getSparseReshapeNegativeOutputDimErrorMessage(dim, value) {
      return "size ".concat(dim, " must be non-negative, not ").concat(value);
    }
    function getSparseReshapeEmptyTensorZeroOutputDimErrorMessage() {
      return "reshape cannot infer the missing input size for an empty tensor unless all specified input sizes are non-zero";
    }
    function getSparseReshapeInputOutputMultipleErrorMessage(inputShape, outputShape) {
      var inputSize = sizeFromShape(inputShape);
      var outputSize = sizeFromShape(outputShape);
      return "Input to reshape is a SparseTensor with ".concat(inputSize, "\n  dense values, but the requested shape requires a multiple of ").concat(outputSize, ". inputShape=").concat(inputShape, " outputShape= ").concat(outputShape);
    }
    function getSparseReshapeInputOutputMismatchErrorMessage(inputShape, outputShape) {
      var inputSize = sizeFromShape(inputShape);
      var outputSize = sizeFromShape(outputShape);
      return "Input to reshape is a tensor with ".concat(inputSize, " dense values, but the requested shape has ").concat(outputSize, ". inputShape=").concat(inputShape, " outputShape=").concat(outputShape);
    }
    function getSparseSegmentReductionNegativeSegmentIdsErrorMessage() {
      return "segment ids must be >= 0";
    }
    function getSparseSegmentReductionNonIncreasingSegmentIdsErrorMessage() {
      return "segment ids are not increasing";
    }
    function getSparseSegmentReductionSegmentIdOutOfRangeErrorMessage(segmentId, outputRows) {
      return "Segment id ".concat(segmentId, " out of range [0, ").concat(outputRows, "), possibly because segmentIds input is not sorted.");
    }
    function getSparseSegmentReductionIndicesOutOfRangeErrorMessage(index, indexValue, inputRows) {
      return "Bad: indices[".concat(index, "] == ").concat(indexValue, " out of range [0, ").concat(inputRows, ")");
    }
    function segOpComputeOptimalWindowSize(inSize, numSegments) {
      var done = false;
      var res;
      if (inSize <= PARALLELIZE_THRESHOLD) {
        res = inSize;
        done = true;
      } else {
        res = nearestDivisor(inSize, Math.floor(Math.sqrt(inSize)));
      }
      while (!done) {
        if (res > numSegments || res === inSize) {
          done = true;
        } else {
          res = nearestDivisor(inSize, res + 1);
        }
      }
      return res;
    }
    function computeOutShape(aShape, axis, numSegments) {
      var outShape = [];
      var rank = aShape.length;
      for (var dim = 0; dim < rank; dim++) {
        if (dim !== axis) {
          outShape.push(aShape[dim]);
        } else {
          outShape.push(numSegments);
        }
      }
      return outShape;
    }
    function collectGatherOpShapeInfo(x, indices, axis, batchDims) {
      var indicesRank = indices.shape.length;
      var xRank = x.shape.length;
      if (batchDims !== 0) {
        if (batchDims < -indicesRank || batchDims > indicesRank) {
          throw new Error("Expect batchDims in the range of [-".concat(indicesRank, ", ").concat(indicesRank, "], but got ").concat(batchDims));
        }
      }
      if (batchDims < 0) {
        batchDims += indicesRank;
      }
      if (batchDims > xRank) {
        throw new Error("batchDims (".concat(batchDims, ") must be less than rank(x) (\n    ").concat(xRank, ")."));
      }
      if (axis < batchDims) {
        throw new Error("batchDims (".concat(batchDims, ") must be less than or equal to axis (").concat(axis, ")."));
      }
      for (var i = 0; i < batchDims; ++i) {
        if (x.shape[i] !== indices.shape[i]) {
          throw new Error("x.shape[".concat(i, "]: ").concat(x.shape[i], " should be equal to indices.shape[").concat(i, "]: ").concat(indices.shape[i], "."));
        }
      }
      var dimSize = x.shape[axis];
      var outputShape = [];
      var batchSize = 1;
      var outerSize = 1;
      var sliceSize = 1;
      for (var i = 0; i < batchDims; ++i) {
        outputShape.push(x.shape[i]);
        batchSize *= x.shape[i];
      }
      for (var i = batchDims; i < axis; i++) {
        outputShape.push(x.shape[i]);
        outerSize *= x.shape[i];
      }
      for (var i = batchDims; i < indicesRank; i++) {
        outputShape.push(indices.shape[i]);
      }
      for (var i = axis + 1; i < xRank; i++) {
        outputShape.push(x.shape[i]);
        sliceSize *= x.shape[i];
      }
      return { batchSize, sliceSize, outerSize, dimSize, outputShape };
    }
    var segment_util = {
      __proto__: null,
      collectGatherOpShapeInfo,
      computeOutShape,
      segOpComputeOptimalWindowSize
    };
    function fromUint8ToStringArray(vals) {
      try {
        return vals.map(function(val) {
          return decodeString(val);
        });
      } catch (err) {
        throw new Error("Failed to decode encoded string bytes into utf-8, error: ".concat(err));
      }
    }
    function fromStringArrayToUint8(strings) {
      return strings.map(function(s) {
        return encodeString(s);
      });
    }
    var backend_util = {
      __proto__: null,
      ERF_A1,
      ERF_A2,
      ERF_A3,
      ERF_A4,
      ERF_A5,
      ERF_P,
      PARALLELIZE_THRESHOLD,
      get RowPartitionType() {
        return RowPartitionType;
      },
      SELU_SCALE,
      SELU_SCALEALPHA,
      applyActivation,
      assertAndGetBroadcastShape,
      assertAxesAreInnerMostDims,
      assertParamsConsistent,
      assignToTypedArray,
      axesAreInnerMostDims,
      calculateShapes,
      checkEinsumDimSizes,
      checkPadOnDimRoundingMode,
      combineLocations,
      combineRaggedTensorToTensorShapes,
      complexWithEvenIndex,
      complexWithOddIndex,
      computeConv2DInfo,
      computeConv3DInfo,
      computeDefaultPad,
      computeDilation2DInfo,
      computeOptimalWindowSize,
      computeOutAndReduceShapes,
      computeOutShape: computeOutShape$1,
      computePool2DInfo,
      computePool3DInfo,
      convertConv2DDataFormat,
      decodeEinsumEquation,
      eitherStridesOrDilationsAreOne,
      expandShapeToKeepDim,
      exponent,
      exponents,
      fromStringArrayToUint8,
      fromUint8ToStringArray,
      getAxesPermutation,
      getBroadcastDims,
      getComplexWithIndex,
      getEinsumComputePath,
      getEinsumPermutation,
      getFusedBiasGradient,
      getFusedDyActivation,
      getImageCenter,
      getInnerMostAxes,
      getPermuted,
      getRaggedRank,
      getReductionAxes,
      getReshaped,
      getReshapedPermuted,
      getRowPartitionTypesHelper,
      getSliceBeginCoords,
      getSliceSize,
      getSparseFillEmptyRowsIndicesDenseShapeMismatch,
      getSparseFillEmptyRowsNegativeIndexErrorMessage,
      getSparseFillEmptyRowsOutOfRangeIndexErrorMessage,
      getSparseReshapeEmptyTensorZeroOutputDimErrorMessage,
      getSparseReshapeInputOutputMismatchErrorMessage,
      getSparseReshapeInputOutputMultipleErrorMessage,
      getSparseReshapeMultipleNegativeOneOutputDimErrorMessage,
      getSparseReshapeNegativeOutputDimErrorMessage,
      getSparseSegmentReductionIndicesOutOfRangeErrorMessage,
      getSparseSegmentReductionNegativeSegmentIdsErrorMessage,
      getSparseSegmentReductionNonIncreasingSegmentIdsErrorMessage,
      getSparseSegmentReductionSegmentIdOutOfRangeErrorMessage,
      getUndoAxesPermutation,
      isIdentityPermutation,
      log: log$1,
      mergeRealAndImagArrays,
      prepareAndValidate,
      prepareSplitSize,
      segment_util,
      shouldFuse,
      slice_util,
      splitRealAndImagArrays,
      stridesOrDilationsArePositive,
      tupleValuesAreOne,
      upcastType,
      validateDefaultValueShape,
      validateInput: validateInput$1,
      validateUpdateShape,
      warn
    };
    var kernel_impls = {
      __proto__: null,
      nonMaxSuppressionV3Impl,
      nonMaxSuppressionV4Impl,
      nonMaxSuppressionV5Impl,
      whereImpl
    };
    registerOptimizers();
    exports.Abs = Abs;
    exports.Acos = Acos;
    exports.Acosh = Acosh;
    exports.AdadeltaOptimizer = AdadeltaOptimizer;
    exports.AdagradOptimizer = AdagradOptimizer;
    exports.AdamOptimizer = AdamOptimizer;
    exports.AdamaxOptimizer = AdamaxOptimizer;
    exports.Add = Add;
    exports.AddN = AddN;
    exports.All = All;
    exports.Any = Any;
    exports.ArgMax = ArgMax;
    exports.ArgMin = ArgMin;
    exports.Asin = Asin;
    exports.Asinh = Asinh;
    exports.Atan = Atan;
    exports.Atan2 = Atan2;
    exports.Atanh = Atanh;
    exports.AvgPool = AvgPool;
    exports.AvgPool3D = AvgPool3D;
    exports.AvgPool3DGrad = AvgPool3DGrad;
    exports.AvgPoolGrad = AvgPoolGrad;
    exports.BatchMatMul = BatchMatMul;
    exports.BatchToSpaceND = BatchToSpaceND;
    exports.Bincount = Bincount;
    exports.BitwiseAnd = BitwiseAnd;
    exports.BroadcastArgs = BroadcastArgs;
    exports.BroadcastTo = BroadcastTo;
    exports.Cast = Cast;
    exports.Ceil = Ceil;
    exports.ClipByValue = ClipByValue;
    exports.Complex = Complex;
    exports.ComplexAbs = ComplexAbs;
    exports.Concat = Concat;
    exports.Conv2D = Conv2D;
    exports.Conv2DBackpropFilter = Conv2DBackpropFilter;
    exports.Conv2DBackpropInput = Conv2DBackpropInput;
    exports.Conv3D = Conv3D;
    exports.Conv3DBackpropFilterV2 = Conv3DBackpropFilterV2;
    exports.Conv3DBackpropInputV2 = Conv3DBackpropInputV2;
    exports.Cos = Cos;
    exports.Cosh = Cosh;
    exports.CropAndResize = CropAndResize;
    exports.Cumprod = Cumprod;
    exports.Cumsum = Cumsum;
    exports.DataStorage = DataStorage;
    exports.DenseBincount = DenseBincount;
    exports.DepthToSpace = DepthToSpace;
    exports.DepthwiseConv2dNative = DepthwiseConv2dNative;
    exports.DepthwiseConv2dNativeBackpropFilter = DepthwiseConv2dNativeBackpropFilter;
    exports.DepthwiseConv2dNativeBackpropInput = DepthwiseConv2dNativeBackpropInput;
    exports.Diag = Diag;
    exports.Dilation2D = Dilation2D;
    exports.Dilation2DBackpropFilter = Dilation2DBackpropFilter;
    exports.Dilation2DBackpropInput = Dilation2DBackpropInput;
    exports.Einsum = Einsum;
    exports.Elu = Elu;
    exports.EluGrad = EluGrad;
    exports.Environment = Environment;
    exports.Equal = Equal;
    exports.Erf = Erf;
    exports.Exp = Exp;
    exports.ExpandDims = ExpandDims;
    exports.Expm1 = Expm1;
    exports.FFT = FFT;
    exports.Fill = Fill;
    exports.FlipLeftRight = FlipLeftRight;
    exports.Floor = Floor;
    exports.FloorDiv = FloorDiv;
    exports.FromPixels = FromPixels;
    exports.FusedBatchNorm = FusedBatchNorm;
    exports.FusedConv2D = FusedConv2D;
    exports.FusedDepthwiseConv2D = FusedDepthwiseConv2D;
    exports.GatherNd = GatherNd;
    exports.GatherV2 = GatherV2;
    exports.Greater = Greater;
    exports.GreaterEqual = GreaterEqual;
    exports.IFFT = IFFT;
    exports.Identity = Identity;
    exports.Imag = Imag;
    exports.IsFinite = IsFinite;
    exports.IsInf = IsInf;
    exports.IsNan = IsNan;
    exports.KernelBackend = KernelBackend;
    exports.LRN = LRN;
    exports.LRNGrad = LRNGrad;
    exports.LeakyRelu = LeakyRelu;
    exports.Less = Less;
    exports.LessEqual = LessEqual;
    exports.LinSpace = LinSpace;
    exports.Log = Log;
    exports.Log1p = Log1p;
    exports.LogSoftmax = LogSoftmax;
    exports.LogicalAnd = LogicalAnd;
    exports.LogicalNot = LogicalNot;
    exports.LogicalOr = LogicalOr;
    exports.LogicalXor = LogicalXor;
    exports.LowerBound = LowerBound;
    exports.MatrixBandPart = MatrixBandPart;
    exports.Max = Max;
    exports.MaxPool = MaxPool;
    exports.MaxPool3D = MaxPool3D;
    exports.MaxPool3DGrad = MaxPool3DGrad;
    exports.MaxPoolGrad = MaxPoolGrad;
    exports.MaxPoolWithArgmax = MaxPoolWithArgmax;
    exports.Maximum = Maximum;
    exports.Mean = Mean;
    exports.Min = Min;
    exports.Minimum = Minimum;
    exports.MirrorPad = MirrorPad;
    exports.Mod = Mod;
    exports.MomentumOptimizer = MomentumOptimizer;
    exports.Multinomial = Multinomial;
    exports.Multiply = Multiply;
    exports.Neg = Neg;
    exports.NonMaxSuppressionV3 = NonMaxSuppressionV3;
    exports.NonMaxSuppressionV4 = NonMaxSuppressionV4;
    exports.NonMaxSuppressionV5 = NonMaxSuppressionV5;
    exports.NotEqual = NotEqual;
    exports.OP_SCOPE_SUFFIX = OP_SCOPE_SUFFIX;
    exports.OneHot = OneHot;
    exports.OnesLike = OnesLike;
    exports.Optimizer = Optimizer;
    exports.OptimizerConstructors = OptimizerConstructors;
    exports.Pack = Pack;
    exports.PadV2 = PadV2;
    exports.Pool = Pool;
    exports.Pow = Pow;
    exports.Prelu = Prelu;
    exports.Prod = Prod;
    exports.RMSPropOptimizer = RMSPropOptimizer;
    exports.RaggedGather = RaggedGather;
    exports.RaggedRange = RaggedRange;
    exports.RaggedTensorToTensor = RaggedTensorToTensor;
    exports.Range = Range;
    exports.Real = Real;
    exports.RealDiv = RealDiv;
    exports.Reciprocal = Reciprocal;
    exports.Relu = Relu;
    exports.Relu6 = Relu6;
    exports.Reshape = Reshape;
    exports.ResizeBilinear = ResizeBilinear;
    exports.ResizeBilinearGrad = ResizeBilinearGrad;
    exports.ResizeNearestNeighbor = ResizeNearestNeighbor;
    exports.ResizeNearestNeighborGrad = ResizeNearestNeighborGrad;
    exports.Reverse = Reverse;
    exports.RotateWithOffset = RotateWithOffset;
    exports.Round = Round;
    exports.Rsqrt = Rsqrt;
    exports.SGDOptimizer = SGDOptimizer;
    exports.ScatterNd = ScatterNd;
    exports.SearchSorted = SearchSorted;
    exports.Select = Select;
    exports.Selu = Selu;
    exports.Sigmoid = Sigmoid;
    exports.Sign = Sign;
    exports.Sin = Sin;
    exports.Sinh = Sinh;
    exports.Slice = Slice;
    exports.Softmax = Softmax;
    exports.Softplus = Softplus;
    exports.SpaceToBatchND = SpaceToBatchND;
    exports.SparseFillEmptyRows = SparseFillEmptyRows;
    exports.SparseReshape = SparseReshape;
    exports.SparseSegmentMean = SparseSegmentMean;
    exports.SparseSegmentSum = SparseSegmentSum;
    exports.SparseToDense = SparseToDense;
    exports.SplitV = SplitV;
    exports.Sqrt = Sqrt;
    exports.Square = Square;
    exports.SquaredDifference = SquaredDifference;
    exports.StaticRegexReplace = StaticRegexReplace;
    exports.Step = Step;
    exports.StridedSlice = StridedSlice;
    exports.StringNGrams = StringNGrams;
    exports.StringSplit = StringSplit;
    exports.StringToHashBucketFast = StringToHashBucketFast;
    exports.Sub = Sub;
    exports.Sum = Sum;
    exports.Tan = Tan;
    exports.Tanh = Tanh;
    exports.Tensor = Tensor;
    exports.TensorBuffer = TensorBuffer;
    exports.TensorScatterUpdate = TensorScatterUpdate;
    exports.Tile = Tile;
    exports.TopK = TopK;
    exports.Transform = Transform;
    exports.Transpose = Transpose;
    exports.Unique = Unique;
    exports.Unpack = Unpack;
    exports.UnsortedSegmentSum = UnsortedSegmentSum;
    exports.UpperBound = UpperBound;
    exports.Variable = Variable;
    exports.ZerosLike = ZerosLike;
    exports._FusedMatMul = _FusedMatMul;
    exports.abs = abs;
    exports.acos = acos;
    exports.acosh = acosh;
    exports.add = add;
    exports.addN = addN;
    exports.all = all;
    exports.any = any;
    exports.argMax = argMax;
    exports.argMin = argMin;
    exports.asin = asin;
    exports.asinh = asinh;
    exports.atan = atan;
    exports.atan2 = atan2;
    exports.atanh = atanh;
    exports.avgPool = avgPool;
    exports.avgPool3d = avgPool3d;
    exports.backend = backend;
    exports.backend_util = backend_util;
    exports.basicLSTMCell = basicLSTMCell;
    exports.batchNorm = batchNorm;
    exports.batchNorm2d = batchNorm2d;
    exports.batchNorm3d = batchNorm3d;
    exports.batchNorm4d = batchNorm4d;
    exports.batchToSpaceND = batchToSpaceND;
    exports.bincount = bincount;
    exports.bitwiseAnd = bitwiseAnd;
    exports.booleanMaskAsync = booleanMaskAsync;
    exports.broadcastArgs = broadcastArgs;
    exports.broadcastTo = broadcastTo;
    exports.broadcast_util = broadcast_util;
    exports.browser = browser;
    exports.buffer = buffer;
    exports.cast = cast;
    exports.ceil = ceil;
    exports.clipByValue = clipByValue;
    exports.clone = clone;
    exports.complex = complex;
    exports.concat = concat;
    exports.concat1d = concat1d;
    exports.concat2d = concat2d;
    exports.concat3d = concat3d;
    exports.concat4d = concat4d;
    exports.conv1d = conv1d;
    exports.conv2d = conv2d$1;
    exports.conv2dTranspose = conv2dTranspose;
    exports.conv3d = conv3d;
    exports.conv3dTranspose = conv3dTranspose;
    exports.copyRegisteredKernels = copyRegisteredKernels;
    exports.cos = cos;
    exports.cosh = cosh;
    exports.cosineWindow = cosineWindow;
    exports.cumprod = cumprod;
    exports.cumsum = cumsum;
    exports.customGrad = customGrad;
    exports.denseBincount = denseBincount;
    exports.deprecationWarn = deprecationWarn;
    exports.depthToSpace = depthToSpace;
    exports.depthwiseConv2d = depthwiseConv2d$1;
    exports.device_util = device_util;
    exports.diag = diag;
    exports.dilation2d = dilation2d;
    exports.disableDeprecationWarnings = disableDeprecationWarnings;
    exports.dispose = dispose;
    exports.disposeVariables = disposeVariables;
    exports.div = div;
    exports.divNoNan = divNoNan;
    exports.dot = dot;
    exports.dropout = dropout;
    exports.einsum = einsum;
    exports.elu = elu;
    exports.enableDebugMode = enableDebugMode;
    exports.enableProdMode = enableProdMode;
    exports.enclosingPowerOfTwo = enclosingPowerOfTwo;
    exports.engine = engine;
    exports.ensureShape = ensureShape;
    exports.env = env;
    exports.equal = equal;
    exports.erf = erf;
    exports.euclideanNorm = euclideanNorm;
    exports.exp = exp;
    exports.expandDims = expandDims;
    exports.expm1 = expm1;
    exports.eye = eye;
    exports.fft = fft;
    exports.fill = fill;
    exports.findBackend = findBackend;
    exports.findBackendFactory = findBackendFactory;
    exports.floor = floor;
    exports.floorDiv = floorDiv;
    exports.fused = fused_ops;
    exports.gather = gather;
    exports.gatherND = gatherND;
    exports.gather_util = gather_nd_util;
    exports.getBackend = getBackend;
    exports.getGradient = getGradient;
    exports.getKernel = getKernel;
    exports.getKernelsForBackend = getKernelsForBackend;
    exports.grad = grad;
    exports.grads = grads;
    exports.greater = greater;
    exports.greaterEqual = greaterEqual;
    exports.ifft = ifft;
    exports.imag = imag;
    exports.image = image;
    exports.inTopKAsync = inTopKAsync;
    exports.io = io3;
    exports.irfft = irfft;
    exports.isFinite = isFinite$1;
    exports.isInf = isInf;
    exports.isNaN = isNaN$1;
    exports.keep = keep;
    exports.kernel_impls = kernel_impls;
    exports.leakyRelu = leakyRelu;
    exports.less = less;
    exports.lessEqual = lessEqual;
    exports.linalg = linalg;
    exports.linspace = linspace;
    exports.localResponseNormalization = localResponseNormalization;
    exports.log = log;
    exports.log1p = log1p;
    exports.logSigmoid = logSigmoid;
    exports.logSoftmax = logSoftmax;
    exports.logSumExp = logSumExp;
    exports.logicalAnd = logicalAnd;
    exports.logicalNot = logicalNot;
    exports.logicalOr = logicalOr;
    exports.logicalXor = logicalXor;
    exports.losses = losses;
    exports.lowerBound = lowerBound;
    exports.matMul = matMul$1;
    exports.math = math;
    exports.max = max;
    exports.maxPool = maxPool;
    exports.maxPool3d = maxPool3d;
    exports.maxPoolWithArgmax = maxPoolWithArgmax;
    exports.maximum = maximum;
    exports.mean = mean;
    exports.memory = memory;
    exports.meshgrid = meshgrid;
    exports.min = min;
    exports.minimum = minimum;
    exports.mirrorPad = mirrorPad;
    exports.mod = mod;
    exports.moments = moments;
    exports.movingAverage = movingAverage;
    exports.mul = mul;
    exports.multiRNNCell = multiRNNCell;
    exports.multinomial = multinomial;
    exports.neg = neg;
    exports.nextFrame = nextFrame;
    exports.norm = norm;
    exports.notEqual = notEqual;
    exports.oneHot = oneHot;
    exports.ones = ones;
    exports.onesLike = onesLike;
    exports.op = op;
    exports.outerProduct = outerProduct;
    exports.pad = pad;
    exports.pad1d = pad1d;
    exports.pad2d = pad2d;
    exports.pad3d = pad3d;
    exports.pad4d = pad4d;
    exports.pool = pool;
    exports.pow = pow;
    exports.prelu = prelu;
    exports.print = print;
    exports.prod = prod;
    exports.profile = profile;
    exports.raggedGather = raggedGather;
    exports.raggedRange = raggedRange;
    exports.raggedTensorToTensor = raggedTensorToTensor;
    exports.rand = rand;
    exports.randomGamma = randomGamma;
    exports.randomNormal = randomNormal;
    exports.randomStandardNormal = randomStandardNormal;
    exports.randomUniform = randomUniform;
    exports.randomUniformInt = randomUniformInt;
    exports.range = range;
    exports.ready = ready;
    exports.real = real;
    exports.reciprocal = reciprocal;
    exports.registerBackend = registerBackend;
    exports.registerGradient = registerGradient;
    exports.registerKernel = registerKernel;
    exports.relu = relu;
    exports.relu6 = relu6;
    exports.removeBackend = removeBackend;
    exports.reshape = reshape;
    exports.reverse = reverse;
    exports.reverse1d = reverse1d;
    exports.reverse2d = reverse2d;
    exports.reverse3d = reverse3d;
    exports.reverse4d = reverse4d;
    exports.rfft = rfft;
    exports.round = round;
    exports.rsqrt = rsqrt;
    exports.scalar = scalar;
    exports.scatterND = scatterND;
    exports.scatter_util = scatter_nd_util;
    exports.searchSorted = searchSorted;
    exports.selu = selu;
    exports.separableConv2d = separableConv2d;
    exports.serialization = serialization;
    exports.setBackend = setBackend2;
    exports.setPlatform = setPlatform;
    exports.setdiff1dAsync = setdiff1dAsync;
    exports.sigmoid = sigmoid;
    exports.sign = sign;
    exports.signal = signal;
    exports.sin = sin;
    exports.sinh = sinh;
    exports.slice = slice;
    exports.slice1d = slice1d;
    exports.slice2d = slice2d;
    exports.slice3d = slice3d;
    exports.slice4d = slice4d;
    exports.slice_util = slice_util;
    exports.softmax = softmax;
    exports.softplus = softplus;
    exports.spaceToBatchND = spaceToBatchND;
    exports.sparse = sparse;
    exports.sparseToDense = sparseToDense;
    exports.spectral = spectral;
    exports.split = split;
    exports.sqrt = sqrt;
    exports.square = square;
    exports.squaredDifference = squaredDifference;
    exports.squeeze = squeeze;
    exports.stack = stack;
    exports.step = step;
    exports.stridedSlice = stridedSlice;
    exports.string = string;
    exports.sub = sub;
    exports.sum = sum;
    exports.sumOutType = sumOutType;
    exports.tan = tan;
    exports.tanh = tanh;
    exports.tensor = tensor;
    exports.tensor1d = tensor1d;
    exports.tensor2d = tensor2d;
    exports.tensor3d = tensor3d;
    exports.tensor4d = tensor4d;
    exports.tensor5d = tensor5d;
    exports.tensor6d = tensor6d;
    exports.tensorScatterUpdate = tensorScatterUpdate;
    exports.tensor_util = tensor_util;
    exports.test_util = test_util;
    exports.tidy = tidy;
    exports.tile = tile;
    exports.time = time;
    exports.topk = topk;
    exports.train = train;
    exports.transpose = transpose;
    exports.truncatedNormal = truncatedNormal;
    exports.unique = unique;
    exports.unregisterGradient = unregisterGradient;
    exports.unregisterKernel = unregisterKernel;
    exports.unsortedSegmentSum = unsortedSegmentSum;
    exports.unstack = unstack;
    exports.upcastType = upcastType;
    exports.upperBound = upperBound;
    exports.util = util2;
    exports.valueAndGrad = valueAndGrad;
    exports.valueAndGrads = valueAndGrads;
    exports.variable = variable;
    exports.variableGrads = variableGrads;
    exports.version_core = version2;
    exports.where = where;
    exports.whereAsync = whereAsync;
    exports.zeros = zeros;
    exports.zerosLike = zerosLike;
  }
});

// ../../node_modules/@tensorflow/tfjs-converter/dist/tf-converter.node.js
var require_tf_converter_node = __commonJS({
  "../../node_modules/@tensorflow/tfjs-converter/dist/tf-converter.node.js"(exports) {
    "use strict";
    var tfc = require_tf_core_node();
    function _interopNamespaceDefault(e) {
      var n = /* @__PURE__ */ Object.create(null);
      if (e) {
        Object.keys(e).forEach(function(k) {
          if (k !== "default") {
            var d = Object.getOwnPropertyDescriptor(e, k);
            Object.defineProperty(n, k, d.get ? d : {
              enumerable: true,
              get: function() {
                return e[k];
              }
            });
          }
        });
      }
      n.default = e;
      return n;
    }
    function _mergeNamespaces(n, m) {
      m.forEach(function(e) {
        e && typeof e !== "string" && !Array.isArray(e) && Object.keys(e).forEach(function(k) {
          if (k !== "default" && !(k in n)) {
            var d = Object.getOwnPropertyDescriptor(e, k);
            Object.defineProperty(n, k, d.get ? d : {
              enumerable: true,
              get: function() {
                return e[k];
              }
            });
          }
        });
      });
      return n;
    }
    var tfc__namespace = /* @__PURE__ */ _interopNamespaceDefault(tfc);
    var ENV$1 = tfc.env();
    ENV$1.registerFlag("KEEP_INTERMEDIATE_TENSORS", function() {
      return false;
    }, function(debugValue) {
      if (debugValue) {
        console.warn("Keep intermediate tensors is ON. This will print the values of all intermediate tensors during model inference. Not all models support this mode. For details, check e2e/benchmarks/ model_config.js. This significantly impacts performance.");
      }
    });
    var extendStatics = function(d, b) {
      extendStatics = Object.setPrototypeOf || { __proto__: [] } instanceof Array && function(d2, b2) {
        d2.__proto__ = b2;
      } || function(d2, b2) {
        for (var p in b2)
          if (Object.prototype.hasOwnProperty.call(b2, p))
            d2[p] = b2[p];
      };
      return extendStatics(d, b);
    };
    function __extends(d, b) {
      if (typeof b !== "function" && b !== null)
        throw new TypeError("Class extends value " + String(b) + " is not a constructor or null");
      extendStatics(d, b);
      function __() {
        this.constructor = d;
      }
      d.prototype = b === null ? Object.create(b) : (__.prototype = b.prototype, new __());
    }
    function __awaiter(thisArg, _arguments, P, generator) {
      function adopt(value) {
        return value instanceof P ? value : new P(function(resolve2) {
          resolve2(value);
        });
      }
      return new (P || (P = Promise))(function(resolve2, reject) {
        function fulfilled(value) {
          try {
            step2(generator.next(value));
          } catch (e) {
            reject(e);
          }
        }
        function rejected(value) {
          try {
            step2(generator["throw"](value));
          } catch (e) {
            reject(e);
          }
        }
        function step2(result) {
          result.done ? resolve2(result.value) : adopt(result.value).then(fulfilled, rejected);
        }
        step2((generator = generator.apply(thisArg, _arguments || [])).next());
      });
    }
    function __generator(thisArg, body) {
      var _ = { label: 0, sent: function() {
        if (t[0] & 1)
          throw t[1];
        return t[1];
      }, trys: [], ops: [] }, f, y, t, g;
      return g = { next: verb(0), "throw": verb(1), "return": verb(2) }, typeof Symbol === "function" && (g[Symbol.iterator] = function() {
        return this;
      }), g;
      function verb(n) {
        return function(v) {
          return step2([n, v]);
        };
      }
      function step2(op2) {
        if (f)
          throw new TypeError("Generator is already executing.");
        while (_)
          try {
            if (f = 1, y && (t = op2[0] & 2 ? y["return"] : op2[0] ? y["throw"] || ((t = y["return"]) && t.call(y), 0) : y.next) && !(t = t.call(y, op2[1])).done)
              return t;
            if (y = 0, t)
              op2 = [op2[0] & 2, t.value];
            switch (op2[0]) {
              case 0:
              case 1:
                t = op2;
                break;
              case 4:
                _.label++;
                return { value: op2[1], done: false };
              case 5:
                _.label++;
                y = op2[1];
                op2 = [0];
                continue;
              case 7:
                op2 = _.ops.pop();
                _.trys.pop();
                continue;
              default:
                if (!(t = _.trys, t = t.length > 0 && t[t.length - 1]) && (op2[0] === 6 || op2[0] === 2)) {
                  _ = 0;
                  continue;
                }
                if (op2[0] === 3 && (!t || op2[1] > t[0] && op2[1] < t[3])) {
                  _.label = op2[1];
                  break;
                }
                if (op2[0] === 6 && _.label < t[1]) {
                  _.label = t[1];
                  t = op2;
                  break;
                }
                if (t && _.label < t[2]) {
                  _.label = t[2];
                  _.ops.push(op2);
                  break;
                }
                if (t[2])
                  _.ops.pop();
                _.trys.pop();
                continue;
            }
            op2 = body.call(thisArg, _);
          } catch (e) {
            op2 = [6, e];
            y = 0;
          } finally {
            f = t = 0;
          }
        if (op2[0] & 5)
          throw op2[1];
        return { value: op2[0] ? op2[1] : void 0, done: true };
      }
    }
    function __values(o) {
      var s = typeof Symbol === "function" && Symbol.iterator, m = s && o[s], i = 0;
      if (m)
        return m.call(o);
      if (o && typeof o.length === "number")
        return {
          next: function() {
            if (o && i >= o.length)
              o = void 0;
            return { value: o && o[i++], done: !o };
          }
        };
      throw new TypeError(s ? "Object is not iterable." : "Symbol.iterator is not defined.");
    }
    function __read(o, n) {
      var m = typeof Symbol === "function" && o[Symbol.iterator];
      if (!m)
        return o;
      var i = m.call(o), r, ar = [], e;
      try {
        while ((n === void 0 || n-- > 0) && !(r = i.next()).done)
          ar.push(r.value);
      } catch (error) {
        e = { error };
      } finally {
        try {
          if (r && !r.done && (m = i["return"]))
            m.call(i);
        } finally {
          if (e)
            throw e.error;
        }
      }
      return ar;
    }
    function __spreadArray(to, from, pack) {
      if (pack || arguments.length === 2)
        for (var i = 0, l = from.length, ar; i < l; i++) {
          if (ar || !(i in from)) {
            if (!ar)
              ar = Array.prototype.slice.call(from, 0, i);
            ar[i] = from[i];
          }
        }
      return to.concat(ar || Array.prototype.slice.call(from));
    }
    var DataType;
    (function(DataType2) {
      DataType2[DataType2["DT_INVALID"] = 0] = "DT_INVALID";
      DataType2[DataType2["DT_FLOAT"] = 1] = "DT_FLOAT";
      DataType2[DataType2["DT_DOUBLE"] = 2] = "DT_DOUBLE";
      DataType2[DataType2["DT_INT32"] = 3] = "DT_INT32";
      DataType2[DataType2["DT_UINT8"] = 4] = "DT_UINT8";
      DataType2[DataType2["DT_INT16"] = 5] = "DT_INT16";
      DataType2[DataType2["DT_INT8"] = 6] = "DT_INT8";
      DataType2[DataType2["DT_STRING"] = 7] = "DT_STRING";
      DataType2[DataType2["DT_COMPLEX64"] = 8] = "DT_COMPLEX64";
      DataType2[DataType2["DT_INT64"] = 9] = "DT_INT64";
      DataType2[DataType2["DT_BOOL"] = 10] = "DT_BOOL";
      DataType2[DataType2["DT_QINT8"] = 11] = "DT_QINT8";
      DataType2[DataType2["DT_QUINT8"] = 12] = "DT_QUINT8";
      DataType2[DataType2["DT_QINT32"] = 13] = "DT_QINT32";
      DataType2[DataType2["DT_BFLOAT16"] = 14] = "DT_BFLOAT16";
      DataType2[DataType2["DT_QINT16"] = 15] = "DT_QINT16";
      DataType2[DataType2["DT_QUINT16"] = 16] = "DT_QUINT16";
      DataType2[DataType2["DT_UINT16"] = 17] = "DT_UINT16";
      DataType2[DataType2["DT_COMPLEX128"] = 18] = "DT_COMPLEX128";
      DataType2[DataType2["DT_HALF"] = 19] = "DT_HALF";
      DataType2[DataType2["DT_RESOURCE"] = 20] = "DT_RESOURCE";
      DataType2[DataType2["DT_VARIANT"] = 21] = "DT_VARIANT";
      DataType2[DataType2["DT_UINT32"] = 22] = "DT_UINT32";
      DataType2[DataType2["DT_UINT64"] = 23] = "DT_UINT64";
      DataType2[DataType2["DT_FLOAT_REF"] = 101] = "DT_FLOAT_REF";
      DataType2[DataType2["DT_DOUBLE_REF"] = 102] = "DT_DOUBLE_REF";
      DataType2[DataType2["DT_INT32_REF"] = 103] = "DT_INT32_REF";
      DataType2[DataType2["DT_UINT8_REF"] = 104] = "DT_UINT8_REF";
      DataType2[DataType2["DT_INT16_REF"] = 105] = "DT_INT16_REF";
      DataType2[DataType2["DT_INT8_REF"] = 106] = "DT_INT8_REF";
      DataType2[DataType2["DT_STRING_REF"] = 107] = "DT_STRING_REF";
      DataType2[DataType2["DT_COMPLEX64_REF"] = 108] = "DT_COMPLEX64_REF";
      DataType2[DataType2["DT_INT64_REF"] = 109] = "DT_INT64_REF";
      DataType2[DataType2["DT_BOOL_REF"] = 110] = "DT_BOOL_REF";
      DataType2[DataType2["DT_QINT8_REF"] = 111] = "DT_QINT8_REF";
      DataType2[DataType2["DT_QUINT8_REF"] = 112] = "DT_QUINT8_REF";
      DataType2[DataType2["DT_QINT32_REF"] = 113] = "DT_QINT32_REF";
      DataType2[DataType2["DT_BFLOAT16_REF"] = 114] = "DT_BFLOAT16_REF";
      DataType2[DataType2["DT_QINT16_REF"] = 115] = "DT_QINT16_REF";
      DataType2[DataType2["DT_QUINT16_REF"] = 116] = "DT_QUINT16_REF";
      DataType2[DataType2["DT_UINT16_REF"] = 117] = "DT_UINT16_REF";
      DataType2[DataType2["DT_COMPLEX128_REF"] = 118] = "DT_COMPLEX128_REF";
      DataType2[DataType2["DT_HALF_REF"] = 119] = "DT_HALF_REF";
      DataType2[DataType2["DT_RESOURCE_REF"] = 120] = "DT_RESOURCE_REF";
      DataType2[DataType2["DT_VARIANT_REF"] = 121] = "DT_VARIANT_REF";
      DataType2[DataType2["DT_UINT32_REF"] = 122] = "DT_UINT32_REF";
      DataType2[DataType2["DT_UINT64_REF"] = 123] = "DT_UINT64_REF";
    })(DataType || (DataType = {}));
    var SaverDef;
    (function(SaverDef2) {
      (function(CheckpointFormatVersion) {
        CheckpointFormatVersion[CheckpointFormatVersion["LEGACY"] = 0] = "LEGACY";
        CheckpointFormatVersion[CheckpointFormatVersion["V1"] = 1] = "V1";
        CheckpointFormatVersion[CheckpointFormatVersion["V2"] = 2] = "V2";
      })(SaverDef2.CheckpointFormatVersion || (SaverDef2.CheckpointFormatVersion = {}));
    })(SaverDef || (SaverDef = {}));
    var CUSTOM_OPS = {};
    function registerOp(name, opFunc) {
      var opMapper = {
        tfOpName: name,
        category: "custom",
        inputs: [],
        attrs: [],
        customExecutor: opFunc
      };
      CUSTOM_OPS[name] = opMapper;
    }
    function getRegisteredOp(name) {
      return CUSTOM_OPS[name];
    }
    function deregisterOp(name) {
      delete CUSTOM_OPS[name];
    }
    function getParamValue(paramName, node, tensorMap, context, resourceManager) {
      var inputParam = node.inputParams[paramName];
      if (inputParam && inputParam.inputIndexStart !== void 0) {
        var start = inputParam.inputIndexStart;
        var end = inputParam.inputIndexEnd === 0 ? void 0 : inputParam.inputIndexEnd === void 0 ? start + 1 : inputParam.inputIndexEnd;
        var shiftedStart = start < 0 ? node.inputNames.length + start : start;
        if (inputParam.type === "tensor") {
          return getTensor(node.inputNames[shiftedStart], tensorMap, context, resourceManager);
        }
        if (inputParam.type === "tensors") {
          var inputs_1 = node.inputs.slice(start, end);
          var inputNames = node.inputNames.slice(start, end).filter(function(_name, index) {
            var _a;
            return ((_a = inputs_1[index]) === null || _a === void 0 ? void 0 : _a.op) !== "NoOp";
          });
          return inputNames.map(function(name) {
            return getTensor(name, tensorMap, context, resourceManager);
          });
        }
        var tensor2 = getTensor(node.inputNames[shiftedStart], tensorMap, context, resourceManager);
        var data = tensor2.dataSync();
        return inputParam.type === "number" ? data[0] : tfc.util.toNestedArray(tensor2.shape, data);
      }
      var attrParam = node.attrParams[paramName];
      return attrParam && attrParam.value;
    }
    function getTensor(name, tensorsMap, context, resourceManager) {
      var _b = __read(parseNodeName(name, context), 2), nodeName = _b[0], index = _b[1];
      if (resourceManager != null) {
        var tensor2 = resourceManager.getHashTableHandleByName(nodeName);
        if (tensor2 != null) {
          return tensor2;
        }
      }
      var contextId = context.currentContextIds.find(function(contextId2) {
        return !!tensorsMap[getNodeNameWithContextId(nodeName, contextId2)];
      });
      return contextId !== void 0 ? tensorsMap[getNodeNameWithContextId(nodeName, contextId)][index] : void 0;
    }
    function getTensorsForCurrentContext(name, tensorsMap, context) {
      return tensorsMap[getNodeNameWithContextId(name, context.currentContextId)];
    }
    function getNodeNameAndIndex(inputName, context) {
      var _b = __read(parseNodeName(inputName, context), 3), nodeName = _b[0], index = _b[1], outputName = _b[2];
      return [
        getNodeNameWithContextId(nodeName, context && context.currentContextId),
        index,
        outputName
      ];
    }
    function getNodeNameWithContextId(name, contextId) {
      return !!contextId ? "".concat(name, "-").concat(contextId) : name;
    }
    function parseNodeName(name, context) {
      if (name === "") {
        return ["", 0, void 0];
      }
      var isCacheEnabled = context != null && context.parseNodeNameCache != null;
      if (isCacheEnabled) {
        var cachedResult = context.parseNodeNameCache.get(name);
        if (cachedResult != null) {
          return cachedResult;
        }
      }
      var parts = name.split(":");
      var result;
      if (parts.length === 1) {
        result = [name, 0, void 0];
      } else {
        var nodeName = parts[0];
        var outputName = parts.length === 3 ? parts[1] : void 0;
        var index = Number(parts[parts.length - 1]);
        result = [nodeName, index, outputName];
      }
      if (isCacheEnabled) {
        context.parseNodeNameCache.set(name, result);
      }
      return result;
    }
    function getPadding(node, tensorMap, context) {
      var pad2 = getParamValue("pad", node, tensorMap, context);
      if (pad2 === "explicit") {
        pad2 = getParamValue("explicitPaddings", node, tensorMap, context);
        var explicitPadding = [[0, 0], [0, 0], [0, 0], [0, 0]];
        for (var i = 0; i < 4; i++) {
          explicitPadding[i][0] = pad2[i * 2];
          explicitPadding[i][1] = pad2[i * 2 + 1];
        }
        return explicitPadding;
      }
      return pad2;
    }
    function cloneTensor(tensor2) {
      return tensor2.kept ? tensor2 : tfc.clone(tensor2);
    }
    var json$i = [
      {
        "tfOpName": "Add",
        "category": "arithmetic",
        "inputs": [
          {
            "start": 0,
            "name": "a",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "b",
            "type": "tensor"
          }
        ],
        "attrs": [
          {
            "tfName": "T",
            "name": "dtype",
            "type": "dtype",
            "notSupported": true
          }
        ]
      },
      {
        "tfOpName": "AddV2",
        "category": "arithmetic",
        "inputs": [
          {
            "start": 0,
            "name": "a",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "b",
            "type": "tensor"
          }
        ],
        "attrs": [
          {
            "tfName": "T",
            "name": "dtype",
            "type": "dtype",
            "notSupported": true
          }
        ]
      },
      {
        "tfOpName": "AddN",
        "category": "arithmetic",
        "inputs": [
          {
            "start": 0,
            "end": 0,
            "name": "tensors",
            "type": "tensors"
          }
        ]
      },
      {
        "tfOpName": "BiasAdd",
        "category": "arithmetic",
        "inputs": [
          {
            "start": 0,
            "name": "a",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "b",
            "type": "tensor"
          }
        ],
        "attrs": [
          {
            "tfName": "T",
            "name": "dtype",
            "type": "dtype",
            "notSupported": true
          },
          {
            "tfName": "data_format",
            "name": "dataFormat",
            "type": "string",
            "notSupported": true
          }
        ]
      },
      {
        "tfOpName": "Sub",
        "category": "arithmetic",
        "inputs": [
          {
            "start": 0,
            "name": "a",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "b",
            "type": "tensor"
          }
        ],
        "attrs": [
          {
            "tfName": "T",
            "name": "dtype",
            "type": "dtype",
            "notSupported": true
          }
        ]
      },
      {
        "tfOpName": "RealDiv",
        "category": "arithmetic",
        "inputs": [
          {
            "start": 0,
            "name": "a",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "b",
            "type": "tensor"
          }
        ],
        "attrs": [
          {
            "tfName": "T",
            "name": "dtype",
            "type": "dtype",
            "notSupported": true
          }
        ]
      },
      {
        "tfOpName": "Div",
        "category": "arithmetic",
        "inputs": [
          {
            "start": 0,
            "name": "a",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "b",
            "type": "tensor"
          }
        ],
        "attrs": [
          {
            "tfName": "T",
            "name": "dtype",
            "type": "dtype",
            "notSupported": true
          }
        ]
      },
      {
        "tfOpName": "DivNoNan",
        "category": "arithmetic",
        "inputs": [
          {
            "start": 0,
            "name": "a",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "b",
            "type": "tensor"
          }
        ],
        "attrs": [
          {
            "tfName": "T",
            "name": "dtype",
            "type": "dtype",
            "notSupported": true
          }
        ]
      },
      {
        "tfOpName": "FloorDiv",
        "category": "arithmetic",
        "inputs": [
          {
            "start": 0,
            "name": "a",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "b",
            "type": "tensor"
          }
        ],
        "attrs": [
          {
            "tfName": "T",
            "name": "dtype",
            "type": "dtype",
            "notSupported": true
          }
        ]
      },
      {
        "tfOpName": "Mul",
        "category": "arithmetic",
        "inputs": [
          {
            "start": 0,
            "name": "a",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "b",
            "type": "tensor"
          }
        ],
        "attrs": [
          {
            "tfName": "T",
            "name": "dtype",
            "type": "dtype",
            "notSupported": true
          }
        ]
      },
      {
        "tfOpName": "Maximum",
        "category": "arithmetic",
        "inputs": [
          {
            "start": 0,
            "name": "a",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "b",
            "type": "tensor"
          }
        ],
        "attrs": [
          {
            "tfName": "T",
            "name": "dtype",
            "type": "dtype",
            "notSupported": true
          }
        ]
      },
      {
        "tfOpName": "Minimum",
        "category": "arithmetic",
        "inputs": [
          {
            "start": 0,
            "name": "a",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "b",
            "type": "tensor"
          }
        ],
        "attrs": [
          {
            "tfName": "T",
            "name": "dtype",
            "type": "dtype",
            "notSupported": true
          }
        ]
      },
      {
        "tfOpName": "Pow",
        "category": "arithmetic",
        "inputs": [
          {
            "start": 0,
            "name": "a",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "b",
            "type": "tensor"
          }
        ],
        "attrs": [
          {
            "tfName": "T",
            "name": "dtype",
            "type": "dtype",
            "notSupported": true
          }
        ]
      },
      {
        "tfOpName": "SquaredDifference",
        "category": "arithmetic",
        "inputs": [
          {
            "start": 0,
            "name": "a",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "b",
            "type": "tensor"
          }
        ],
        "attrs": [
          {
            "tfName": "T",
            "name": "dtype",
            "type": "dtype",
            "notSupported": true
          }
        ]
      },
      {
        "tfOpName": "Mod",
        "category": "arithmetic",
        "inputs": [
          {
            "start": 0,
            "name": "a",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "b",
            "type": "tensor"
          }
        ],
        "attrs": [
          {
            "tfName": "T",
            "name": "dtype",
            "type": "dtype",
            "notSupported": true
          }
        ]
      },
      {
        "tfOpName": "FloorMod",
        "category": "arithmetic",
        "inputs": [
          {
            "start": 0,
            "name": "a",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "b",
            "type": "tensor"
          }
        ],
        "attrs": [
          {
            "tfName": "T",
            "name": "dtype",
            "type": "dtype",
            "notSupported": true
          }
        ]
      }
    ];
    var arithmetic = {
      __proto__: null,
      json: json$i
    };
    var json$h = [
      {
        "tfOpName": "Abs",
        "category": "basic_math",
        "inputs": [
          {
            "start": 0,
            "name": "x",
            "type": "tensor"
          }
        ],
        "attrs": [
          {
            "tfName": "T",
            "name": "dtype",
            "type": "dtype",
            "notSupported": true
          }
        ]
      },
      {
        "tfOpName": "Acos",
        "category": "basic_math",
        "inputs": [
          {
            "start": 0,
            "name": "x",
            "type": "tensor"
          }
        ],
        "attrs": [
          {
            "tfName": "T",
            "name": "dtype",
            "type": "dtype",
            "notSupported": true
          }
        ]
      },
      {
        "tfOpName": "Asin",
        "category": "basic_math",
        "inputs": [
          {
            "start": 0,
            "name": "x",
            "type": "tensor"
          }
        ],
        "attrs": [
          {
            "tfName": "T",
            "name": "dtype",
            "type": "dtype",
            "notSupported": true
          }
        ]
      },
      {
        "tfOpName": "Atan",
        "category": "basic_math",
        "inputs": [
          {
            "start": 0,
            "name": "x",
            "type": "tensor"
          }
        ],
        "attrs": [
          {
            "tfName": "T",
            "name": "dtype",
            "type": "dtype",
            "notSupported": true
          }
        ]
      },
      {
        "tfOpName": "Atan2",
        "category": "basic_math",
        "inputs": [
          {
            "start": 0,
            "name": "x",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "y",
            "type": "tensor"
          }
        ],
        "attrs": [
          {
            "tfName": "T",
            "name": "dtype",
            "type": "dtype",
            "notSupported": true
          }
        ]
      },
      {
        "tfOpName": "Ceil",
        "category": "basic_math",
        "inputs": [
          {
            "start": 0,
            "name": "x",
            "type": "tensor"
          }
        ],
        "attrs": [
          {
            "tfName": "T",
            "name": "dtype",
            "type": "dtype",
            "notSupported": true
          }
        ]
      },
      {
        "tfOpName": "ClipByValue",
        "category": "basic_math",
        "inputs": [
          {
            "start": 0,
            "name": "x",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "clipValueMin",
            "type": "number"
          },
          {
            "start": 2,
            "name": "clipValueMax",
            "type": "number"
          }
        ],
        "attrs": [
          {
            "tfName": "T",
            "name": "dtype",
            "type": "dtype",
            "notSupported": true
          }
        ]
      },
      {
        "tfOpName": "Complex",
        "category": "basic_math",
        "inputs": [
          {
            "start": 0,
            "name": "real",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "imag",
            "type": "tensor"
          }
        ],
        "attrs": [
          {
            "tfName": "T",
            "name": "dtype",
            "type": "dtype",
            "notSupported": true
          }
        ]
      },
      {
        "tfOpName": "ComplexAbs",
        "category": "basic_math",
        "inputs": [
          {
            "start": 0,
            "name": "x",
            "type": "tensor"
          }
        ],
        "attrs": [
          {
            "tfName": "T",
            "name": "dtype",
            "type": "dtype",
            "notSupported": true
          }
        ]
      },
      {
        "tfOpName": "Cos",
        "category": "basic_math",
        "inputs": [
          {
            "start": 0,
            "name": "x",
            "type": "tensor"
          }
        ],
        "attrs": [
          {
            "tfName": "T",
            "name": "dtype",
            "type": "dtype",
            "notSupported": true
          }
        ]
      },
      {
        "tfOpName": "Cosh",
        "category": "basic_math",
        "inputs": [
          {
            "start": 0,
            "name": "x",
            "type": "tensor"
          }
        ],
        "attrs": [
          {
            "tfName": "T",
            "name": "dtype",
            "type": "dtype",
            "notSupported": true
          }
        ]
      },
      {
        "tfOpName": "Elu",
        "category": "basic_math",
        "inputs": [
          {
            "start": 0,
            "name": "x",
            "type": "tensor"
          }
        ],
        "attrs": [
          {
            "tfName": "T",
            "name": "dtype",
            "type": "dtype",
            "notSupported": true
          }
        ]
      },
      {
        "tfOpName": "Exp",
        "category": "basic_math",
        "inputs": [
          {
            "start": 0,
            "name": "x",
            "type": "tensor"
          }
        ],
        "attrs": [
          {
            "tfName": "T",
            "name": "dtype",
            "type": "dtype",
            "notSupported": true
          }
        ]
      },
      {
        "tfOpName": "Floor",
        "category": "basic_math",
        "inputs": [
          {
            "start": 0,
            "name": "x",
            "type": "tensor"
          }
        ],
        "attrs": [
          {
            "tfName": "T",
            "name": "dtype",
            "type": "dtype",
            "notSupported": true
          }
        ]
      },
      {
        "tfOpName": "Log",
        "category": "basic_math",
        "inputs": [
          {
            "start": 0,
            "name": "x",
            "type": "tensor"
          }
        ],
        "attrs": [
          {
            "tfName": "T",
            "name": "dtype",
            "type": "dtype",
            "notSupported": true
          }
        ]
      },
      {
        "tfOpName": "Imag",
        "category": "basic_math",
        "inputs": [
          {
            "start": 0,
            "name": "x",
            "type": "tensor"
          }
        ],
        "attrs": [
          {
            "tfName": "T",
            "name": "dtype",
            "type": "dtype",
            "notSupported": true
          },
          {
            "tfName": "Tout",
            "name": "outputType",
            "type": "dtype",
            "notSupported": true
          }
        ]
      },
      {
        "tfOpName": "Neg",
        "category": "basic_math",
        "inputs": [
          {
            "start": 0,
            "name": "x",
            "type": "tensor"
          }
        ],
        "attrs": [
          {
            "tfName": "T",
            "name": "dtype",
            "type": "dtype",
            "notSupported": true
          }
        ]
      },
      {
        "tfOpName": "Real",
        "category": "basic_math",
        "inputs": [
          {
            "start": 0,
            "name": "x",
            "type": "tensor"
          }
        ],
        "attrs": [
          {
            "tfName": "T",
            "name": "dtype",
            "type": "dtype",
            "notSupported": true
          },
          {
            "tfName": "Tout",
            "name": "outputType",
            "type": "dtype",
            "notSupported": true
          }
        ]
      },
      {
        "tfOpName": "Prelu",
        "category": "basic_math",
        "inputs": [
          {
            "start": 0,
            "name": "x",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "alpha",
            "type": "tensor"
          }
        ],
        "attrs": [
          {
            "tfName": "T",
            "name": "dtype",
            "type": "dtype",
            "notSupported": true
          }
        ]
      },
      {
        "tfOpName": "Relu",
        "category": "basic_math",
        "inputs": [
          {
            "start": 0,
            "name": "x",
            "type": "tensor"
          }
        ],
        "attrs": [
          {
            "tfName": "T",
            "name": "dtype",
            "type": "dtype",
            "notSupported": true
          }
        ]
      },
      {
        "tfOpName": "Relu6",
        "category": "basic_math",
        "inputs": [
          {
            "start": 0,
            "name": "x",
            "type": "tensor"
          }
        ],
        "attrs": [
          {
            "tfName": "T",
            "name": "dtype",
            "type": "dtype",
            "notSupported": true
          }
        ]
      },
      {
        "tfOpName": "Selu",
        "category": "basic_math",
        "inputs": [
          {
            "start": 0,
            "name": "x",
            "type": "tensor"
          }
        ],
        "attrs": [
          {
            "tfName": "T",
            "name": "dtype",
            "type": "dtype",
            "notSupported": true
          }
        ]
      },
      {
        "tfOpName": "Sigmoid",
        "category": "basic_math",
        "inputs": [
          {
            "start": 0,
            "name": "x",
            "type": "tensor"
          }
        ],
        "attrs": [
          {
            "tfName": "T",
            "name": "dtype",
            "type": "dtype",
            "notSupported": true
          }
        ]
      },
      {
        "tfOpName": "Sin",
        "category": "basic_math",
        "inputs": [
          {
            "start": 0,
            "name": "x",
            "type": "tensor"
          }
        ],
        "attrs": [
          {
            "tfName": "T",
            "name": "dtype",
            "type": "dtype",
            "notSupported": true
          }
        ]
      },
      {
        "tfOpName": "Sinh",
        "category": "basic_math",
        "inputs": [
          {
            "start": 0,
            "name": "x",
            "type": "tensor"
          }
        ],
        "attrs": [
          {
            "tfName": "T",
            "name": "dtype",
            "type": "dtype",
            "notSupported": true
          }
        ]
      },
      {
        "tfOpName": "Sqrt",
        "category": "basic_math",
        "inputs": [
          {
            "start": 0,
            "name": "x",
            "type": "tensor"
          }
        ],
        "attrs": [
          {
            "tfName": "T",
            "name": "dtype",
            "type": "dtype",
            "notSupported": true
          }
        ]
      },
      {
        "tfOpName": "Rsqrt",
        "category": "basic_math",
        "inputs": [
          {
            "start": 0,
            "name": "x",
            "type": "tensor"
          }
        ],
        "attrs": [
          {
            "tfName": "T",
            "name": "dtype",
            "type": "dtype",
            "notSupported": true
          }
        ]
      },
      {
        "tfOpName": "Square",
        "category": "basic_math",
        "inputs": [
          {
            "start": 0,
            "name": "x",
            "type": "tensor"
          }
        ],
        "attrs": [
          {
            "tfName": "T",
            "name": "dtype",
            "type": "dtype",
            "notSupported": true
          }
        ]
      },
      {
        "tfOpName": "Tan",
        "category": "basic_math",
        "inputs": [
          {
            "start": 0,
            "name": "x",
            "type": "tensor"
          }
        ],
        "attrs": [
          {
            "tfName": "T",
            "name": "dtype",
            "type": "dtype",
            "notSupported": true
          }
        ]
      },
      {
        "tfOpName": "Tanh",
        "category": "basic_math",
        "inputs": [
          {
            "start": 0,
            "name": "x",
            "type": "tensor"
          }
        ],
        "attrs": [
          {
            "tfName": "T",
            "name": "dtype",
            "type": "dtype",
            "notSupported": true
          }
        ]
      },
      {
        "tfOpName": "Sign",
        "category": "basic_math",
        "inputs": [
          {
            "start": 0,
            "name": "x",
            "type": "tensor"
          }
        ],
        "attrs": [
          {
            "tfName": "T",
            "name": "dtype",
            "type": "dtype",
            "notSupported": true
          }
        ]
      },
      {
        "tfOpName": "Round",
        "category": "basic_math",
        "inputs": [
          {
            "start": 0,
            "name": "x",
            "type": "tensor"
          }
        ],
        "attrs": [
          {
            "tfName": "T",
            "name": "dtype",
            "type": "dtype",
            "notSupported": true
          }
        ]
      },
      {
        "tfOpName": "Expm1",
        "category": "basic_math",
        "inputs": [
          {
            "start": 0,
            "name": "x",
            "type": "tensor"
          }
        ],
        "attrs": [
          {
            "tfName": "T",
            "name": "dtype",
            "type": "dtype",
            "notSupported": true
          }
        ]
      },
      {
        "tfOpName": "Log1p",
        "category": "basic_math",
        "inputs": [
          {
            "start": 0,
            "name": "x",
            "type": "tensor"
          }
        ],
        "attrs": [
          {
            "tfName": "T",
            "name": "dtype",
            "type": "dtype",
            "notSupported": true
          }
        ]
      },
      {
        "tfOpName": "Reciprocal",
        "category": "basic_math",
        "inputs": [
          {
            "start": 0,
            "name": "x",
            "type": "tensor"
          }
        ],
        "attrs": [
          {
            "tfName": "T",
            "name": "dtype",
            "type": "dtype",
            "notSupported": true
          }
        ]
      },
      {
        "tfOpName": "Softplus",
        "category": "basic_math",
        "inputs": [
          {
            "start": 0,
            "name": "x",
            "type": "tensor"
          }
        ],
        "attrs": [
          {
            "tfName": "T",
            "name": "dtype",
            "type": "dtype",
            "notSupported": true
          }
        ]
      },
      {
        "tfOpName": "Asinh",
        "category": "basic_math",
        "inputs": [
          {
            "start": 0,
            "name": "x",
            "type": "tensor"
          }
        ],
        "attrs": [
          {
            "tfName": "T",
            "name": "dtype",
            "type": "dtype",
            "notSupported": true
          }
        ]
      },
      {
        "tfOpName": "Acosh",
        "category": "basic_math",
        "inputs": [
          {
            "start": 0,
            "name": "x",
            "type": "tensor"
          }
        ],
        "attrs": [
          {
            "tfName": "T",
            "name": "dtype",
            "type": "dtype",
            "notSupported": true
          }
        ]
      },
      {
        "tfOpName": "Atanh",
        "category": "basic_math",
        "inputs": [
          {
            "start": 0,
            "name": "x",
            "type": "tensor"
          }
        ],
        "attrs": [
          {
            "tfName": "T",
            "name": "dtype",
            "type": "dtype",
            "notSupported": true
          }
        ]
      },
      {
        "tfOpName": "Erf",
        "category": "basic_math",
        "inputs": [
          {
            "start": 0,
            "name": "x",
            "type": "tensor"
          }
        ],
        "attrs": [
          {
            "tfName": "T",
            "name": "dtype",
            "type": "dtype",
            "notSupported": true
          }
        ]
      },
      {
        "tfOpName": "LeakyRelu",
        "category": "basic_math",
        "inputs": [
          {
            "start": 0,
            "name": "x",
            "type": "tensor"
          }
        ],
        "attrs": [
          {
            "tfName": "alpha",
            "name": "alpha",
            "type": "number",
            "defaultValue": 0.2
          },
          {
            "tfName": "T",
            "name": "dtype",
            "type": "dtype",
            "notSupported": true
          }
        ]
      },
      {
        "tfOpName": "IsNan",
        "category": "basic_math",
        "inputs": [
          {
            "start": 0,
            "name": "x",
            "type": "tensor"
          }
        ],
        "attrs": [
          {
            "tfName": "T",
            "name": "dtype",
            "type": "dtype",
            "notSupported": true
          }
        ]
      },
      {
        "tfOpName": "IsFinite",
        "category": "basic_math",
        "inputs": [
          {
            "start": 0,
            "name": "x",
            "type": "tensor"
          }
        ],
        "attrs": [
          {
            "tfName": "T",
            "name": "dtype",
            "type": "dtype",
            "notSupported": true
          }
        ]
      },
      {
        "tfOpName": "IsInf",
        "category": "basic_math",
        "inputs": [
          {
            "start": 0,
            "name": "x",
            "type": "tensor"
          }
        ],
        "attrs": [
          {
            "tfName": "T",
            "name": "dtype",
            "type": "dtype",
            "notSupported": true
          }
        ]
      }
    ];
    var basicMath = {
      __proto__: null,
      json: json$h
    };
    var json$g = [
      {
        "tfOpName": "EmptyTensorList",
        "category": "control",
        "inputs": [
          {
            "start": 0,
            "name": "elementShape",
            "type": "shape"
          },
          {
            "start": 1,
            "name": "maxNumElements",
            "type": "number"
          }
        ],
        "attrs": [
          {
            "tfName": "element_dtype",
            "name": "elementDType",
            "type": "dtype"
          }
        ]
      },
      {
        "tfOpName": "LoopCond",
        "category": "control",
        "inputs": [
          {
            "start": 0,
            "name": "pred",
            "type": "tensor"
          }
        ]
      },
      {
        "tfOpName": "Switch",
        "category": "control",
        "inputs": [
          {
            "start": 0,
            "name": "data",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "pred",
            "type": "tensor"
          }
        ]
      },
      {
        "tfOpName": "Merge",
        "category": "control",
        "inputs": [
          {
            "start": 0,
            "end": 0,
            "name": "tensors",
            "type": "tensors"
          }
        ]
      },
      {
        "tfOpName": "Enter",
        "category": "control",
        "inputs": [
          {
            "start": 0,
            "name": "tensor",
            "type": "tensor"
          }
        ],
        "attrs": [
          {
            "tfName": "T",
            "name": "dtype",
            "type": "dtype",
            "notSupported": true
          },
          {
            "tfName": "frame_name",
            "name": "frameName",
            "type": "string"
          },
          {
            "tfName": "is_constant",
            "name": "isConstant",
            "type": "bool"
          }
        ]
      },
      {
        "tfOpName": "Exit",
        "category": "control",
        "inputs": [
          {
            "start": 0,
            "name": "tensor",
            "type": "tensor"
          }
        ],
        "attrs": [
          {
            "tfName": "T",
            "name": "dtype",
            "type": "dtype",
            "notSupported": true
          }
        ]
      },
      {
        "tfOpName": "NextIteration",
        "category": "control",
        "inputs": [
          {
            "start": 0,
            "name": "tensor",
            "type": "tensor"
          }
        ],
        "attrs": [
          {
            "tfName": "T",
            "name": "dtype",
            "type": "dtype",
            "notSupported": true
          }
        ]
      },
      {
        "tfOpName": "TensorArrayV3",
        "category": "control",
        "inputs": [
          {
            "start": 0,
            "name": "size",
            "type": "number"
          }
        ],
        "attrs": [
          {
            "tfName": "dtype",
            "name": "dtype",
            "type": "dtype"
          },
          {
            "tfName": "element_shape",
            "name": "elementShape",
            "type": "shape"
          },
          {
            "tfName": "dynamic_size",
            "name": "dynamicSize",
            "type": "bool"
          },
          {
            "tfName": "clear_after_read",
            "name": "clearAfterRead",
            "type": "bool"
          },
          {
            "tfName": "identical_element_shapes",
            "name": "identicalElementShapes",
            "type": "bool"
          },
          {
            "tfName": "tensor_array_name",
            "name": "name",
            "type": "string"
          }
        ]
      },
      {
        "tfOpName": "TensorArrayWriteV3",
        "category": "control",
        "inputs": [
          {
            "start": 0,
            "name": "tensorArrayId",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "index",
            "type": "number"
          },
          {
            "start": 2,
            "name": "tensor",
            "type": "tensor"
          },
          {
            "start": 3,
            "name": "flowIn",
            "type": "number"
          }
        ],
        "attrs": [
          {
            "tfName": "T",
            "name": "dtype",
            "type": "dtype",
            "notSupported": true
          }
        ]
      },
      {
        "tfOpName": "TensorArrayReadV3",
        "category": "control",
        "inputs": [
          {
            "start": 0,
            "name": "tensorArrayId",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "index",
            "type": "number"
          },
          {
            "start": 2,
            "name": "flowIn",
            "type": "number"
          }
        ],
        "attrs": [
          {
            "tfName": "dtype",
            "name": "dtype",
            "type": "dtype",
            "notSupported": true
          }
        ]
      },
      {
        "tfOpName": "TensorArrayGatherV3",
        "category": "control",
        "inputs": [
          {
            "start": 0,
            "name": "tensorArrayId",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "indices",
            "type": "number[]"
          },
          {
            "start": 2,
            "name": "flowIn",
            "type": "number"
          }
        ],
        "attrs": [
          {
            "tfName": "dtype",
            "name": "dtype",
            "type": "dtype"
          },
          {
            "tfName": "element_shape",
            "name": "elementShape",
            "type": "shape"
          }
        ]
      },
      {
        "tfOpName": "TensorArrayScatterV3",
        "category": "control",
        "inputs": [
          {
            "start": 0,
            "name": "tensorArrayId",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "indices",
            "type": "number[]"
          },
          {
            "start": 2,
            "name": "tensor",
            "type": "tensor"
          },
          {
            "start": 3,
            "name": "flowIn",
            "type": "number"
          }
        ],
        "attrs": [
          {
            "tfName": "T",
            "name": "dtype",
            "type": "dtype"
          }
        ]
      },
      {
        "tfOpName": "TensorArrayConcatV3",
        "category": "control",
        "inputs": [
          {
            "start": 0,
            "name": "tensorArrayId",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "flowIn",
            "type": "number"
          }
        ],
        "attrs": [
          {
            "tfName": "dtype",
            "name": "dtype",
            "type": "dtype"
          },
          {
            "tfName": "element_shape_except0",
            "name": "elementShapeExcept0",
            "type": "shape",
            "notSupported": true
          }
        ]
      },
      {
        "tfOpName": "TensorArraySplitV3",
        "category": "control",
        "inputs": [
          {
            "start": 0,
            "name": "tensorArrayId",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "tensor",
            "type": "tensor"
          },
          {
            "start": 2,
            "name": "lengths",
            "type": "number[]"
          },
          {
            "start": 3,
            "name": "flowIn",
            "type": "number"
          }
        ],
        "attrs": [
          {
            "tfName": "T",
            "name": "dtype",
            "type": "dtype"
          }
        ]
      },
      {
        "tfOpName": "TensorArraySizeV3",
        "category": "control",
        "inputs": [
          {
            "start": 0,
            "name": "tensorArrayId",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "flowIn",
            "type": "number"
          }
        ]
      },
      {
        "tfOpName": "TensorArrayCloseV3",
        "category": "control",
        "inputs": [
          {
            "start": 0,
            "name": "tensorArrayId",
            "type": "tensor"
          }
        ]
      },
      {
        "tfOpName": "StatelessIf",
        "category": "control",
        "inputs": [
          {
            "start": 0,
            "name": "cond",
            "type": "tensor"
          },
          {
            "start": 1,
            "end": 0,
            "name": "args",
            "type": "tensors"
          }
        ],
        "attrs": [
          {
            "tfName": "then_branch",
            "name": "thenBranch",
            "type": "func"
          },
          {
            "tfName": "else_branch",
            "name": "elseBranch",
            "type": "func"
          }
        ]
      },
      {
        "tfOpName": "If",
        "category": "control",
        "inputs": [
          {
            "start": 0,
            "name": "cond",
            "type": "tensor"
          },
          {
            "start": 1,
            "end": 0,
            "name": "args",
            "type": "tensors"
          }
        ],
        "attrs": [
          {
            "tfName": "then_branch",
            "name": "thenBranch",
            "type": "func"
          },
          {
            "tfName": "else_branch",
            "name": "elseBranch",
            "type": "func"
          }
        ]
      },
      {
        "tfOpName": "StatelessWhile",
        "category": "control",
        "inputs": [
          {
            "start": 0,
            "end": 0,
            "name": "args",
            "type": "tensors"
          }
        ],
        "attrs": [
          {
            "tfName": "cond",
            "name": "cond",
            "type": "func"
          },
          {
            "tfName": "body",
            "name": "body",
            "type": "func"
          }
        ]
      },
      {
        "tfOpName": "While",
        "category": "control",
        "inputs": [
          {
            "start": 0,
            "end": 0,
            "name": "args",
            "type": "tensors"
          }
        ],
        "attrs": [
          {
            "tfName": "cond",
            "name": "cond",
            "type": "func"
          },
          {
            "tfName": "body",
            "name": "body",
            "type": "func"
          }
        ]
      },
      {
        "tfOpName": "TensorListScatter",
        "category": "control",
        "inputs": [
          {
            "start": 0,
            "name": "tensor",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "indices",
            "type": "number[]"
          },
          {
            "start": 2,
            "name": "elementShape",
            "type": "shape"
          }
        ],
        "attrs": [
          {
            "tfName": "element_dtype",
            "name": "elementDType",
            "type": "dtype"
          }
        ]
      },
      {
        "tfOpName": "TensorListScatterV2",
        "category": "control",
        "inputs": [
          {
            "start": 0,
            "name": "tensor",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "indices",
            "type": "number[]"
          },
          {
            "start": 2,
            "name": "elementShape",
            "type": "shape"
          },
          {
            "start": 3,
            "name": "numElements",
            "type": "number"
          }
        ],
        "attrs": [
          {
            "tfName": "element_dtype",
            "name": "elementDType",
            "type": "dtype"
          }
        ]
      },
      {
        "tfOpName": "TensorListGather",
        "category": "control",
        "inputs": [
          {
            "start": 0,
            "name": "tensorListId",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "indices",
            "type": "number[]"
          },
          {
            "start": 2,
            "name": "elementShape",
            "type": "shape"
          }
        ],
        "attrs": [
          {
            "tfName": "element_dtype",
            "name": "elementDType",
            "type": "dtype"
          }
        ]
      },
      {
        "tfOpName": "TensorListGetItem",
        "category": "control",
        "inputs": [
          {
            "start": 0,
            "name": "tensorListId",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "index",
            "type": "number"
          },
          {
            "start": 2,
            "name": "elementShape",
            "type": "shape"
          }
        ],
        "attrs": [
          {
            "tfName": "element_dtype",
            "name": "elementDType",
            "type": "dtype"
          }
        ]
      },
      {
        "tfOpName": "TensorListSetItem",
        "category": "control",
        "inputs": [
          {
            "start": 0,
            "name": "tensorListId",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "index",
            "type": "number"
          },
          {
            "start": 2,
            "name": "tensor",
            "type": "tensor"
          }
        ],
        "attrs": [
          {
            "tfName": "element_dtype",
            "name": "elementDType",
            "type": "dtype"
          }
        ]
      },
      {
        "tfOpName": "TensorListReserve",
        "category": "control",
        "inputs": [
          {
            "start": 0,
            "name": "elementShape",
            "type": "shape"
          },
          {
            "start": 1,
            "name": "numElements",
            "type": "number"
          }
        ],
        "attrs": [
          {
            "tfName": "element_dtype",
            "name": "elementDType",
            "type": "dtype"
          }
        ]
      },
      {
        "tfOpName": "TensorListFromTensor",
        "category": "control",
        "inputs": [
          {
            "start": 0,
            "name": "tensor",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "elementShape",
            "type": "shape"
          }
        ],
        "attrs": [
          {
            "tfName": "element_dtype",
            "name": "elementDType",
            "type": "dtype"
          }
        ]
      },
      {
        "tfOpName": "TensorListStack",
        "category": "control",
        "inputs": [
          {
            "start": 0,
            "name": "tensorListId",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "elementShape",
            "type": "shape"
          }
        ],
        "attrs": [
          {
            "tfName": "element_dtype",
            "name": "elementDType",
            "type": "dtype"
          },
          {
            "tfName": "num_elements",
            "name": "numElements",
            "type": "dtype"
          }
        ]
      },
      {
        "tfOpName": "TensorListSplit",
        "category": "control",
        "inputs": [
          {
            "start": 0,
            "name": "tensor",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "elementShape",
            "type": "shape"
          },
          {
            "start": 2,
            "name": "lengths",
            "type": "number[]"
          }
        ],
        "attrs": [
          {
            "tfName": "element_dtype",
            "name": "elementDType",
            "type": "dtype"
          }
        ]
      },
      {
        "tfOpName": "TensorListConcat",
        "category": "control",
        "inputs": [
          {
            "start": 0,
            "name": "tensorListId",
            "type": "tensor"
          }
        ],
        "attrs": [
          {
            "tfName": "element_shape",
            "name": "elementShape",
            "type": "shape"
          },
          {
            "tfName": "element_dtype",
            "name": "elementDType",
            "type": "dtype"
          }
        ]
      },
      {
        "tfOpName": "TensorListConcatV2",
        "category": "control",
        "inputs": [
          {
            "start": 0,
            "name": "tensorListId",
            "type": "tensor"
          }
        ],
        "attrs": [
          {
            "tfName": "element_shape",
            "name": "elementShape",
            "type": "shape"
          },
          {
            "tfName": "element_dtype",
            "name": "elementDType",
            "type": "dtype"
          }
        ]
      },
      {
        "tfOpName": "TensorListPopBack",
        "category": "control",
        "inputs": [
          {
            "start": 0,
            "name": "tensorListId",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "elementShape",
            "type": "shape"
          }
        ],
        "attrs": [
          {
            "tfName": "element_dtype",
            "name": "elementDType",
            "type": "dtype"
          }
        ]
      },
      {
        "tfOpName": "TensorListPushBack",
        "category": "control",
        "inputs": [
          {
            "start": 0,
            "name": "tensorListId",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "tensor",
            "type": "tensor"
          }
        ],
        "attrs": [
          {
            "tfName": "element_dtype",
            "name": "elementDType",
            "type": "dtype"
          }
        ]
      },
      {
        "tfOpName": "TensorListLength",
        "category": "control",
        "inputs": [
          {
            "start": 0,
            "name": "tensorListId",
            "type": "tensor"
          }
        ]
      },
      {
        "tfOpName": "TensorListResize",
        "category": "control",
        "inputs": [
          {
            "start": 0,
            "name": "tensorListId",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "size",
            "type": "number"
          }
        ]
      }
    ];
    var control = {
      __proto__: null,
      json: json$g
    };
    var json$f = [
      {
        "tfOpName": "AvgPool",
        "category": "convolution",
        "inputs": [
          {
            "start": 0,
            "name": "x",
            "type": "tensor"
          }
        ],
        "attrs": [
          {
            "tfName": "strides",
            "name": "strides",
            "type": "number[]"
          },
          {
            "tfName": "padding",
            "name": "pad",
            "type": "string"
          },
          {
            "tfName": "data_format",
            "name": "dataFormat",
            "type": "string",
            "notSupported": true
          },
          {
            "tfName": "ksize",
            "name": "kernelSize",
            "type": "number[]"
          },
          {
            "tfName": "T",
            "name": "dtype",
            "type": "dtype",
            "notSupported": true
          }
        ]
      },
      {
        "tfOpName": "MaxPool",
        "category": "convolution",
        "inputs": [
          {
            "start": 0,
            "name": "x",
            "type": "tensor"
          }
        ],
        "attrs": [
          {
            "tfName": "strides",
            "name": "strides",
            "type": "number[]"
          },
          {
            "tfName": "padding",
            "name": "pad",
            "type": "string"
          },
          {
            "tfName": "data_format",
            "name": "dataFormat",
            "type": "string",
            "notSupported": true
          },
          {
            "tfName": "ksize",
            "name": "kernelSize",
            "type": "number[]"
          },
          {
            "tfName": "explicit_paddings",
            "name": "explicitPaddings",
            "type": "number[]",
            "defaultValue": [],
            "notSupported": true
          },
          {
            "tfName": "T",
            "name": "dtype",
            "type": "dtype",
            "notSupported": true
          }
        ]
      },
      {
        "tfOpName": "MaxPoolWithArgmax",
        "category": "convolution",
        "inputs": [
          {
            "start": 0,
            "name": "x",
            "type": "tensor"
          }
        ],
        "attrs": [
          {
            "tfName": "strides",
            "name": "strides",
            "type": "number[]"
          },
          {
            "tfName": "padding",
            "name": "pad",
            "type": "string"
          },
          {
            "tfName": "ksize",
            "name": "kernelSize",
            "type": "number[]"
          },
          {
            "tfName": "include_batch_in_index",
            "name": "includeBatchInIndex",
            "type": "bool"
          },
          {
            "tfName": "T",
            "name": "dtype",
            "type": "dtype",
            "notSupported": true
          }
        ]
      },
      {
        "tfOpName": "AvgPool3D",
        "category": "convolution",
        "inputs": [
          {
            "start": 0,
            "name": "x",
            "type": "tensor"
          }
        ],
        "attrs": [
          {
            "tfName": "strides",
            "name": "strides",
            "type": "number[]"
          },
          {
            "tfName": "padding",
            "name": "pad",
            "type": "string"
          },
          {
            "tfName": "data_format",
            "name": "dataFormat",
            "type": "string",
            "notSupported": true
          },
          {
            "tfName": "ksize",
            "name": "kernelSize",
            "type": "number[]"
          },
          {
            "tfName": "T",
            "name": "dtype",
            "type": "dtype",
            "notSupported": true
          }
        ]
      },
      {
        "tfOpName": "MaxPool3D",
        "category": "convolution",
        "inputs": [
          {
            "start": 0,
            "name": "x",
            "type": "tensor"
          }
        ],
        "attrs": [
          {
            "tfName": "strides",
            "name": "strides",
            "type": "number[]"
          },
          {
            "tfName": "padding",
            "name": "pad",
            "type": "string"
          },
          {
            "tfName": "data_format",
            "name": "dataFormat",
            "type": "string",
            "notSupported": true
          },
          {
            "tfName": "ksize",
            "name": "kernelSize",
            "type": "number[]"
          },
          {
            "tfName": "T",
            "name": "dtype",
            "type": "dtype",
            "notSupported": true
          }
        ]
      },
      {
        "tfOpName": "Conv1D",
        "category": "convolution",
        "inputs": [
          {
            "start": 0,
            "name": "x",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "filter",
            "type": "tensor"
          }
        ],
        "attrs": [
          {
            "tfName": "stride",
            "name": "stride",
            "type": "number"
          },
          {
            "tfName": "padding",
            "name": "pad",
            "type": "string"
          },
          {
            "tfName": "data_format",
            "name": "dataFormat",
            "type": "string",
            "defaultValue": "NWC"
          },
          {
            "tfName": "T",
            "name": "dtype",
            "type": "dtype",
            "notSupported": true
          },
          {
            "tfName": "dilation",
            "name": "dilation",
            "type": "number",
            "defaultValue": 1
          }
        ]
      },
      {
        "tfOpName": "Conv2D",
        "category": "convolution",
        "inputs": [
          {
            "start": 0,
            "name": "x",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "filter",
            "type": "tensor"
          }
        ],
        "attrs": [
          {
            "tfName": "T",
            "name": "dtype",
            "type": "dtype",
            "notSupported": true
          },
          {
            "tfName": "strides",
            "name": "strides",
            "type": "number[]"
          },
          {
            "tfName": "padding",
            "name": "pad",
            "type": "string"
          },
          {
            "tfName": "useCudnnOnGpu",
            "name": "useCudnnOnGpu",
            "type": "bool"
          },
          {
            "tfName": "data_format",
            "name": "dataFormat",
            "type": "string",
            "defaultValue": "NHWC"
          },
          {
            "tfName": "explicit_paddings",
            "name": "explicitPaddings",
            "type": "number[]",
            "defaultValue": []
          },
          {
            "tfName": "dilations",
            "name": "dilations",
            "type": "number[]"
          }
        ]
      },
      {
        "tfOpName": "_FusedConv2D",
        "category": "convolution",
        "inputs": [
          {
            "start": 0,
            "name": "x",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "filter",
            "type": "tensor"
          },
          {
            "start": 2,
            "end": 0,
            "name": "args",
            "type": "tensors"
          }
        ],
        "attrs": [
          {
            "tfName": "num_args",
            "name": "numArgs",
            "type": "number"
          },
          {
            "tfName": "T",
            "name": "dtype",
            "type": "dtype",
            "notSupported": true
          },
          {
            "tfName": "strides",
            "name": "strides",
            "type": "number[]"
          },
          {
            "tfName": "padding",
            "name": "pad",
            "type": "string"
          },
          {
            "tfName": "explicit_paddings",
            "name": "explicitPaddings",
            "type": "number[]",
            "defaultValue": []
          },
          {
            "tfName": "use_cudnn_on_gpu",
            "name": "useCudnnOnGpu",
            "type": "bool",
            "defaultValue": true
          },
          {
            "tfName": "data_format",
            "name": "dataFormat",
            "type": "string",
            "defaultValue": "NHWC"
          },
          {
            "tfName": "dilations",
            "name": "dilations",
            "type": "number[]",
            "defaultValue": [
              1,
              1,
              1,
              1
            ]
          },
          {
            "tfName": "fused_ops",
            "name": "fusedOps",
            "type": "string[]",
            "defaultValue": []
          },
          {
            "tfName": "epsilon",
            "name": "epsilon",
            "type": "number",
            "defaultValue": 1e-4
          },
          {
            "tfName": "leakyrelu_alpha",
            "name": "leakyreluAlpha",
            "type": "number",
            "defaultValue": 0.2
          }
        ]
      },
      {
        "tfOpName": "Conv2DBackpropInput",
        "category": "convolution",
        "inputs": [
          {
            "start": 2,
            "name": "x",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "filter",
            "type": "tensor"
          },
          {
            "start": 0,
            "name": "outputShape",
            "type": "number[]"
          }
        ],
        "attrs": [
          {
            "tfName": "strides",
            "name": "strides",
            "type": "number[]"
          },
          {
            "tfName": "padding",
            "name": "pad",
            "type": "string"
          },
          {
            "tfName": "data_format",
            "name": "dataFormat",
            "type": "string",
            "notSupported": true
          },
          {
            "tfName": "explicit_paddings",
            "name": "explicitPaddings",
            "type": "number[]",
            "defaultValue": []
          },
          {
            "tfName": "dilations",
            "name": "dilations",
            "type": "number[]",
            "notSupported": true
          }
        ]
      },
      {
        "tfOpName": "DepthwiseConv2d",
        "category": "convolution",
        "inputs": [
          {
            "start": 0,
            "name": "input",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "filter",
            "type": "tensor"
          }
        ],
        "attrs": [
          {
            "tfName": "strides",
            "name": "strides",
            "type": "number[]"
          },
          {
            "tfName": "padding",
            "name": "pad",
            "type": "string"
          },
          {
            "tfName": "data_format",
            "name": "dataFormat",
            "type": "string",
            "defaultValue": "NHWC"
          },
          {
            "tfName": "explicit_paddings",
            "name": "explicitPaddings",
            "type": "number[]",
            "defaultValue": []
          },
          {
            "tfName": "dilations",
            "name": "dilations",
            "type": "number[]"
          }
        ]
      },
      {
        "tfOpName": "DepthwiseConv2dNative",
        "category": "convolution",
        "inputs": [
          {
            "start": 0,
            "name": "input",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "filter",
            "type": "tensor"
          }
        ],
        "attrs": [
          {
            "tfName": "strides",
            "name": "strides",
            "type": "number[]"
          },
          {
            "tfName": "padding",
            "name": "pad",
            "type": "string"
          },
          {
            "tfName": "data_format",
            "name": "dataFormat",
            "type": "string",
            "defaultValue": "NHWC"
          },
          {
            "tfName": "explicit_paddings",
            "name": "explicitPaddings",
            "type": "number[]",
            "defaultValue": []
          },
          {
            "tfName": "dilations",
            "name": "dilations",
            "type": "number[]"
          }
        ]
      },
      {
        "tfOpName": "FusedDepthwiseConv2dNative",
        "category": "convolution",
        "inputs": [
          {
            "start": 0,
            "name": "x",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "filter",
            "type": "tensor"
          },
          {
            "start": 2,
            "end": 0,
            "name": "args",
            "type": "tensors"
          }
        ],
        "attrs": [
          {
            "tfName": "num_args",
            "name": "numArgs",
            "type": "number"
          },
          {
            "tfName": "T",
            "name": "dtype",
            "type": "dtype",
            "notSupported": true
          },
          {
            "tfName": "strides",
            "name": "strides",
            "type": "number[]"
          },
          {
            "tfName": "padding",
            "name": "pad",
            "type": "string"
          },
          {
            "tfName": "data_format",
            "name": "dataFormat",
            "type": "string",
            "defaultValue": "NHWC"
          },
          {
            "tfName": "dilations",
            "name": "dilations",
            "type": "number[]",
            "defaultValue": [
              1,
              1,
              1,
              1
            ]
          },
          {
            "tfName": "fused_ops",
            "name": "fusedOps",
            "type": "string[]",
            "defaultValue": []
          },
          {
            "tfName": "explicit_paddings",
            "name": "explicitPaddings",
            "type": "number[]",
            "defaultValue": []
          }
        ]
      },
      {
        "tfOpName": "Conv3D",
        "category": "convolution",
        "inputs": [
          {
            "start": 0,
            "name": "x",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "filter",
            "type": "tensor"
          }
        ],
        "attrs": [
          {
            "tfName": "strides",
            "name": "strides",
            "type": "number[]"
          },
          {
            "tfName": "padding",
            "name": "pad",
            "type": "string"
          },
          {
            "tfName": "data_format",
            "name": "dataFormat",
            "type": "string",
            "defaultValue": "NHWC"
          },
          {
            "tfName": "dilations",
            "name": "dilations",
            "type": "number[]"
          }
        ]
      },
      {
        "tfOpName": "Dilation2D",
        "category": "convolution",
        "inputs": [
          {
            "start": 0,
            "name": "x",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "filter",
            "type": "tensor"
          }
        ],
        "attrs": [
          {
            "tfName": "strides",
            "name": "strides",
            "type": "number[]"
          },
          {
            "tfName": "rates",
            "name": "dilations",
            "type": "number[]"
          },
          {
            "tfName": "padding",
            "name": "pad",
            "type": "string"
          }
        ]
      }
    ];
    var convolution = {
      __proto__: null,
      json: json$f
    };
    var json$e = [
      {
        "tfOpName": "Fill",
        "category": "creation",
        "inputs": [
          {
            "start": 0,
            "name": "shape",
            "type": "number[]"
          },
          {
            "start": 1,
            "name": "value",
            "type": "number"
          }
        ],
        "attrs": [
          {
            "tfName": "T",
            "name": "dtype",
            "type": "dtype"
          }
        ]
      },
      {
        "tfOpName": "LinSpace",
        "category": "creation",
        "inputs": [
          {
            "start": 0,
            "name": "start",
            "type": "number"
          },
          {
            "start": 1,
            "name": "stop",
            "type": "number"
          },
          {
            "start": 2,
            "name": "num",
            "type": "number"
          }
        ],
        "attrs": [
          {
            "tfName": "T",
            "name": "dtype",
            "type": "dtype",
            "notSupported": true
          }
        ]
      },
      {
        "tfOpName": "OneHot",
        "category": "creation",
        "inputs": [
          {
            "start": 0,
            "name": "indices",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "depth",
            "type": "number"
          },
          {
            "start": 2,
            "name": "onValue",
            "type": "number",
            "defaultValue": 1
          },
          {
            "start": 3,
            "name": "offValue",
            "type": "number",
            "defaultValue": 0
          }
        ],
        "attrs": [
          {
            "tfName": "axis",
            "name": "axis",
            "type": "number",
            "notSupported": true
          },
          {
            "tfName": "T",
            "name": "dtype",
            "type": "dtype"
          }
        ]
      },
      {
        "tfOpName": "Ones",
        "category": "creation",
        "inputs": [
          {
            "start": 0,
            "name": "shape",
            "type": "number[]"
          }
        ],
        "attrs": [
          {
            "tfName": "T",
            "name": "dtype",
            "type": "dtype"
          }
        ]
      },
      {
        "tfOpName": "OnesLike",
        "category": "creation",
        "inputs": [
          {
            "start": 0,
            "name": "x",
            "type": "tensor"
          }
        ],
        "attrs": [
          {
            "tfName": "dtype",
            "name": "dtype",
            "type": "dtype"
          }
        ]
      },
      {
        "tfOpName": "RandomStandardNormal",
        "category": "creation",
        "inputs": [
          {
            "start": 0,
            "name": "shape",
            "type": "number[]"
          }
        ],
        "attrs": [
          {
            "tfName": "seed",
            "name": "seed",
            "type": "number",
            "defaultValue": 0
          },
          {
            "tfName": "seed2",
            "name": "seed2",
            "type": "number",
            "defaultValue": 0,
            "notSupported": true
          },
          {
            "tfName": "dtype",
            "name": "dtype",
            "type": "dtype"
          },
          {
            "tfName": "T",
            "name": "T",
            "type": "number",
            "notSupported": true
          }
        ]
      },
      {
        "tfOpName": "RandomUniform",
        "category": "creation",
        "inputs": [
          {
            "start": 0,
            "name": "shape",
            "type": "number[]"
          }
        ],
        "attrs": [
          {
            "tfName": "minval",
            "name": "minval",
            "type": "number",
            "defaultValue": 0
          },
          {
            "tfName": "maxval",
            "name": "maxval",
            "type": "number",
            "defaultValue": 1
          },
          {
            "tfName": "dtype",
            "name": "dtype",
            "type": "dtype"
          },
          {
            "tfName": "seed",
            "name": "seed",
            "type": "number",
            "defaultValue": 0
          },
          {
            "tfName": "seed2",
            "name": "seed2",
            "type": "number",
            "defaultValue": 0,
            "notSupported": true
          },
          {
            "tfName": "T",
            "name": "T",
            "type": "number",
            "notSupported": true
          }
        ]
      },
      {
        "tfOpName": "RandomUniformInt",
        "category": "creation",
        "inputs": [
          {
            "start": 0,
            "name": "shape",
            "type": "number[]"
          }
        ],
        "attrs": [
          {
            "tfName": "minval",
            "name": "minval",
            "type": "number"
          },
          {
            "tfName": "maxval",
            "name": "maxval",
            "type": "number"
          },
          {
            "tfName": "seed",
            "name": "seed",
            "type": "number",
            "defaultValue": 0
          },
          {
            "tfName": "seed2",
            "name": "seed2",
            "type": "number",
            "defaultValue": 0,
            "notSupported": true
          }
        ]
      },
      {
        "tfOpName": "Range",
        "category": "creation",
        "inputs": [
          {
            "start": 0,
            "name": "start",
            "type": "number"
          },
          {
            "start": 1,
            "name": "stop",
            "type": "number"
          },
          {
            "start": 2,
            "name": "step",
            "type": "number",
            "defaultValue": 0
          }
        ],
        "attrs": [
          {
            "tfName": "Tidx",
            "name": "dtype",
            "type": "dtype"
          }
        ]
      },
      {
        "tfOpName": "TruncatedNormal",
        "category": "creation",
        "inputs": [
          {
            "start": 0,
            "name": "shape",
            "type": "number[]"
          }
        ],
        "attrs": [
          {
            "tfName": "means",
            "name": "mean",
            "type": "number",
            "defaultValue": 0
          },
          {
            "tfName": "stddev",
            "name": "stdDev",
            "type": "number",
            "defaultValue": 1
          },
          {
            "tfName": "seed",
            "name": "seed",
            "type": "number"
          },
          {
            "tfName": "seed2",
            "name": "seed2",
            "type": "number",
            "defaultValue": 0,
            "notSupported": true
          },
          {
            "tfName": "dtype",
            "name": "dtype",
            "type": "dtype"
          },
          {
            "tfName": "T",
            "name": "T",
            "type": "number",
            "notSupported": true
          }
        ]
      },
      {
        "tfOpName": "Zeros",
        "category": "creation",
        "inputs": [
          {
            "start": 0,
            "name": "shape",
            "type": "number[]"
          }
        ],
        "attrs": [
          {
            "tfName": "T",
            "name": "dtype",
            "type": "dtype"
          }
        ]
      },
      {
        "tfOpName": "ZerosLike",
        "category": "creation",
        "inputs": [
          {
            "start": 0,
            "name": "x",
            "type": "tensor"
          }
        ],
        "attrs": [
          {
            "tfName": "T",
            "name": "dtype",
            "type": "dtype"
          }
        ]
      },
      {
        "tfOpName": "Multinomial",
        "category": "creation",
        "inputs": [
          {
            "start": 0,
            "name": "logits",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "numSamples",
            "type": "number"
          }
        ],
        "attrs": [
          {
            "tfName": "seed",
            "name": "seed",
            "type": "number"
          },
          {
            "tfName": "seed2",
            "name": "seed2",
            "type": "number"
          },
          {
            "tfName": "T",
            "name": "dtype",
            "type": "dtype"
          },
          {
            "tfName": "output_dtype",
            "name": "output_dtype",
            "type": "dtype"
          }
        ]
      }
    ];
    var creation = {
      __proto__: null,
      json: json$e
    };
    var json$d = [
      {
        "tfOpName": "NonMaxSuppressionV2",
        "category": "dynamic",
        "inputs": [
          {
            "start": 0,
            "name": "boxes",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "scores",
            "type": "tensor"
          },
          {
            "start": 2,
            "name": "maxOutputSize",
            "type": "number"
          },
          {
            "start": 3,
            "name": "iouThreshold",
            "type": "number"
          }
        ]
      },
      {
        "tfOpName": "NonMaxSuppressionV3",
        "category": "dynamic",
        "inputs": [
          {
            "start": 0,
            "name": "boxes",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "scores",
            "type": "tensor"
          },
          {
            "start": 2,
            "name": "maxOutputSize",
            "type": "number"
          },
          {
            "start": 3,
            "name": "iouThreshold",
            "type": "number"
          },
          {
            "start": 4,
            "name": "scoreThreshold",
            "type": "number"
          }
        ]
      },
      {
        "tfOpName": "NonMaxSuppressionV4",
        "category": "dynamic",
        "inputs": [
          {
            "start": 0,
            "name": "boxes",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "scores",
            "type": "tensor"
          },
          {
            "start": 2,
            "name": "maxOutputSize",
            "type": "number"
          },
          {
            "start": 3,
            "name": "iouThreshold",
            "type": "number"
          },
          {
            "start": 4,
            "name": "scoreThreshold",
            "type": "number"
          }
        ],
        "attrs": [
          {
            "tfName": "T",
            "name": "dtype",
            "type": "dtype",
            "notSupported": true
          },
          {
            "tfName": "T_threshold",
            "name": "threshold",
            "type": "dtype",
            "notSupported": true
          },
          {
            "tfName": "pad_to_max_output_size",
            "name": "padToMaxOutputSize",
            "type": "bool"
          }
        ]
      },
      {
        "tfOpName": "NonMaxSuppressionV5",
        "category": "dynamic",
        "inputs": [
          {
            "start": 0,
            "name": "boxes",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "scores",
            "type": "tensor"
          },
          {
            "start": 2,
            "name": "maxOutputSize",
            "type": "number"
          },
          {
            "start": 3,
            "name": "iouThreshold",
            "type": "number"
          },
          {
            "start": 4,
            "name": "scoreThreshold",
            "type": "number"
          },
          {
            "start": 5,
            "name": "softNmsSigma",
            "type": "number"
          }
        ]
      },
      {
        "tfOpName": "Where",
        "category": "dynamic",
        "inputs": [
          {
            "start": 0,
            "name": "condition",
            "type": "tensor"
          }
        ],
        "attrs": [
          {
            "tfName": "T",
            "name": "dtype",
            "type": "dtype",
            "notSupported": true
          }
        ]
      },
      {
        "tfOpName": "ListDiff",
        "category": "dynamic",
        "inputs": [
          {
            "start": 0,
            "name": "x",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "y",
            "type": "tensor"
          }
        ],
        "attrs": [
          {
            "tfName": "T",
            "name": "dtype",
            "type": "dtype",
            "notSupported": true
          }
        ]
      }
    ];
    var dynamic = {
      __proto__: null,
      json: json$d
    };
    var json$c = [
      {
        "tfOpName": "LowerBound",
        "category": "evaluation",
        "inputs": [
          {
            "start": 0,
            "name": "sortedSequence",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "values",
            "type": "tensor"
          }
        ]
      },
      {
        "tfOpName": "TopKV2",
        "category": "evaluation",
        "inputs": [
          {
            "start": 0,
            "name": "x",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "k",
            "type": "number"
          }
        ],
        "attrs": [
          {
            "tfName": "sorted",
            "name": "sorted",
            "type": "bool"
          }
        ]
      },
      {
        "tfOpName": "UpperBound",
        "category": "evaluation",
        "inputs": [
          {
            "start": 0,
            "name": "sortedSequence",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "values",
            "type": "tensor"
          }
        ]
      },
      {
        "tfOpName": "Unique",
        "category": "evaluation",
        "inputs": [
          {
            "start": 0,
            "name": "x",
            "type": "tensor"
          }
        ]
      },
      {
        "tfOpName": "UniqueV2",
        "category": "evaluation",
        "inputs": [
          {
            "start": 0,
            "name": "x",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "axis",
            "type": "number"
          }
        ]
      }
    ];
    var evaluation = {
      __proto__: null,
      json: json$c
    };
    var json$b = [
      {
        "tfOpName": "PlaceholderWithDefault",
        "category": "graph",
        "inputs": [
          {
            "start": 0,
            "name": "default",
            "type": "tensor"
          }
        ],
        "attrs": [
          {
            "tfName": "shape",
            "name": "shape",
            "type": "shape"
          },
          {
            "tfName": "dtype",
            "name": "dtype",
            "type": "dtype"
          }
        ]
      },
      {
        "tfOpName": "Placeholder",
        "category": "graph",
        "attrs": [
          {
            "tfName": "shape",
            "name": "shape",
            "type": "shape"
          },
          {
            "tfName": "dtype",
            "name": "dtype",
            "type": "dtype"
          }
        ]
      },
      {
        "tfOpName": "Const",
        "category": "graph"
      },
      {
        "tfOpName": "Identity",
        "category": "graph",
        "inputs": [
          {
            "start": 0,
            "name": "x",
            "type": "tensor"
          }
        ]
      },
      {
        "tfOpName": "IdentityN",
        "category": "graph",
        "inputs": [
          {
            "start": 0,
            "end": 0,
            "name": "x",
            "type": "tensors"
          }
        ]
      },
      {
        "tfOpName": "Snapshot",
        "category": "graph",
        "inputs": [
          {
            "start": 0,
            "name": "x",
            "type": "tensor"
          }
        ]
      },
      {
        "tfOpName": "Rank",
        "category": "graph",
        "inputs": [
          {
            "start": 0,
            "name": "x",
            "type": "tensor"
          }
        ]
      },
      {
        "tfOpName": "Size",
        "category": "graph",
        "inputs": [
          {
            "start": 0,
            "name": "x",
            "type": "tensor"
          }
        ]
      },
      {
        "tfOpName": "Shape",
        "category": "graph",
        "inputs": [
          {
            "start": 0,
            "name": "x",
            "type": "tensor"
          }
        ]
      },
      {
        "tfOpName": "ShapeN",
        "category": "graph",
        "inputs": [
          {
            "start": 0,
            "end": 0,
            "name": "x",
            "type": "tensors"
          }
        ]
      },
      {
        "tfOpName": "Print",
        "category": "graph",
        "inputs": [
          {
            "start": 0,
            "name": "x",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "data",
            "type": "tensors"
          }
        ],
        "attrs": [
          {
            "tfName": "message",
            "name": "message",
            "type": "string"
          },
          {
            "tfName": "first_n",
            "name": "firstN",
            "type": "number",
            "notSupported": true
          },
          {
            "tfName": "summarize",
            "name": "summarize",
            "type": "number",
            "defaultValue": 3
          }
        ]
      },
      {
        "tfOpName": "NoOp",
        "category": "graph",
        "inputs": []
      },
      {
        "tfOpName": "StopGradient",
        "category": "graph",
        "inputs": [
          {
            "start": 0,
            "name": "x",
            "type": "tensor"
          }
        ]
      },
      {
        "tfOpName": "FakeQuantWithMinMaxVars",
        "category": "graph",
        "inputs": [
          {
            "start": 0,
            "name": "x",
            "type": "tensor"
          }
        ],
        "attrs": [
          {
            "tfName": "min",
            "name": "min",
            "type": "number"
          },
          {
            "tfName": "max",
            "name": "max",
            "type": "number"
          }
        ]
      }
    ];
    var graph = {
      __proto__: null,
      json: json$b
    };
    var json$a = [
      {
        "tfOpName": "HashTable",
        "category": "hash_table",
        "inputs": [],
        "attrs": [
          {
            "tfName": "shared_name",
            "name": "sharedName",
            "type": "string"
          },
          {
            "tfName": "use_node_name_sharing",
            "name": "useNodeNameSharing",
            "type": "bool"
          },
          {
            "tfName": "key_dtype",
            "name": "keyDType",
            "type": "dtype"
          },
          {
            "tfName": "value_dtype",
            "name": "valueDType",
            "type": "dtype"
          }
        ]
      },
      {
        "tfOpName": "HashTableV2",
        "category": "hash_table",
        "inputs": [],
        "attrs": [
          {
            "tfName": "shared_name",
            "name": "sharedName",
            "type": "string"
          },
          {
            "tfName": "use_node_name_sharing",
            "name": "useNodeNameSharing",
            "type": "bool"
          },
          {
            "tfName": "key_dtype",
            "name": "keyDType",
            "type": "dtype"
          },
          {
            "tfName": "value_dtype",
            "name": "valueDType",
            "type": "dtype"
          }
        ]
      },
      {
        "tfOpName": "LookupTableImport",
        "category": "hash_table",
        "inputs": [
          {
            "start": 0,
            "name": "tableHandle",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "keys",
            "type": "tensor"
          },
          {
            "start": 2,
            "name": "values",
            "type": "tensor"
          }
        ],
        "attrs": [
          {
            "tfName": "Tin",
            "name": "tIn",
            "type": "dtype",
            "notSupported": true
          },
          {
            "tfName": "Tout",
            "name": "tOut",
            "type": "dtype",
            "notSupported": true
          }
        ]
      },
      {
        "tfOpName": "LookupTableImportV2",
        "category": "hash_table",
        "inputs": [
          {
            "start": 0,
            "name": "tableHandle",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "keys",
            "type": "tensor"
          },
          {
            "start": 2,
            "name": "values",
            "type": "tensor"
          }
        ],
        "attrs": [
          {
            "tfName": "Tin",
            "name": "tIn",
            "type": "dtype",
            "notSupported": true
          },
          {
            "tfName": "Tout",
            "name": "tOut",
            "type": "dtype",
            "notSupported": true
          }
        ]
      },
      {
        "tfOpName": "LookupTableFind",
        "category": "hash_table",
        "inputs": [
          {
            "start": 0,
            "name": "tableHandle",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "keys",
            "type": "tensor"
          },
          {
            "start": 2,
            "name": "defaultValue",
            "type": "tensor"
          }
        ],
        "attrs": [
          {
            "tfName": "Tin",
            "name": "tIn",
            "type": "dtype",
            "notSupported": true
          },
          {
            "tfName": "Tout",
            "name": "tOut",
            "type": "dtype",
            "notSupported": true
          }
        ]
      },
      {
        "tfOpName": "LookupTableFindV2",
        "category": "hash_table",
        "inputs": [
          {
            "start": 0,
            "name": "tableHandle",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "keys",
            "type": "tensor"
          },
          {
            "start": 2,
            "name": "defaultValue",
            "type": "tensor"
          }
        ],
        "attrs": [
          {
            "tfName": "Tin",
            "name": "tIn",
            "type": "dtype",
            "notSupported": true
          },
          {
            "tfName": "Tout",
            "name": "tOut",
            "type": "dtype",
            "notSupported": true
          }
        ]
      },
      {
        "tfOpName": "LookupTableSize",
        "category": "hash_table",
        "inputs": [
          {
            "start": 0,
            "name": "tableHandle",
            "type": "tensor"
          }
        ]
      },
      {
        "tfOpName": "LookupTableSizeV2",
        "category": "hash_table",
        "inputs": [
          {
            "start": 0,
            "name": "tableHandle",
            "type": "tensor"
          }
        ]
      },
      {
        "tfOpName": "InitializeTable",
        "category": "hash_table",
        "inputs": [
          {
            "start": 0,
            "name": "tableHandle",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "keys",
            "type": "tensor"
          },
          {
            "start": 2,
            "name": "values",
            "type": "tensor"
          }
        ]
      },
      {
        "tfOpName": "InitializeTableV2",
        "category": "hash_table",
        "inputs": [
          {
            "start": 0,
            "name": "tableHandle",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "keys",
            "type": "tensor"
          },
          {
            "start": 2,
            "name": "values",
            "type": "tensor"
          }
        ]
      }
    ];
    var hashTable = {
      __proto__: null,
      json: json$a
    };
    var json$9 = [
      {
        "tfOpName": "ResizeBilinear",
        "category": "image",
        "inputs": [
          {
            "start": 0,
            "name": "images",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "size",
            "type": "number[]"
          }
        ],
        "attrs": [
          {
            "tfName": "align_corners",
            "name": "alignCorners",
            "type": "bool"
          },
          {
            "tfName": "half_pixel_centers",
            "name": "halfPixelCenters",
            "type": "bool"
          },
          {
            "tfName": "T",
            "name": "dtype",
            "type": "dtype",
            "notSupported": true
          }
        ]
      },
      {
        "tfOpName": "ResizeNearestNeighbor",
        "category": "image",
        "inputs": [
          {
            "start": 0,
            "name": "images",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "size",
            "type": "number[]"
          }
        ],
        "attrs": [
          {
            "tfName": "align_corners",
            "name": "alignCorners",
            "type": "bool"
          },
          {
            "tfName": "half_pixel_centers",
            "name": "halfPixelCenters",
            "type": "bool"
          },
          {
            "tfName": "T",
            "name": "dtype",
            "type": "dtype",
            "notSupported": true
          }
        ]
      },
      {
        "tfOpName": "CropAndResize",
        "category": "image",
        "inputs": [
          {
            "start": 0,
            "name": "image",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "boxes",
            "type": "tensor"
          },
          {
            "start": 2,
            "name": "boxInd",
            "type": "tensor"
          },
          {
            "start": 3,
            "name": "cropSize",
            "type": "number[]"
          }
        ],
        "attrs": [
          {
            "tfName": "method",
            "name": "method",
            "type": "string"
          },
          {
            "tfName": "extrapolation_value",
            "name": "extrapolationValue",
            "type": "number"
          }
        ]
      },
      {
        "tfOpName": "ImageProjectiveTransformV3",
        "category": "image",
        "inputs": [
          {
            "start": 0,
            "name": "images",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "transforms",
            "type": "tensor"
          },
          {
            "start": 2,
            "name": "outputShape",
            "type": "number[]"
          },
          {
            "start": 3,
            "name": "fillValue",
            "type": "number"
          }
        ],
        "attrs": [
          {
            "tfName": "interpolation",
            "name": "interpolation",
            "type": "string"
          },
          {
            "tfName": "fill_mode",
            "name": "fillMode",
            "type": "string"
          }
        ]
      }
    ];
    var image$1 = {
      __proto__: null,
      json: json$9
    };
    var json$8 = [
      {
        "tfOpName": "Equal",
        "category": "logical",
        "inputs": [
          {
            "start": 0,
            "name": "a",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "b",
            "type": "tensor"
          }
        ],
        "attrs": [
          {
            "tfName": "T",
            "name": "dtype",
            "type": "dtype",
            "notSupported": true
          }
        ]
      },
      {
        "tfOpName": "NotEqual",
        "category": "logical",
        "inputs": [
          {
            "start": 0,
            "name": "a",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "b",
            "type": "tensor"
          }
        ],
        "attrs": [
          {
            "tfName": "T",
            "name": "dtype",
            "type": "dtype",
            "notSupported": true
          }
        ]
      },
      {
        "tfOpName": "Greater",
        "category": "logical",
        "inputs": [
          {
            "start": 0,
            "name": "a",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "b",
            "type": "tensor"
          }
        ],
        "attrs": [
          {
            "tfName": "T",
            "name": "dtype",
            "type": "dtype",
            "notSupported": true
          }
        ]
      },
      {
        "tfOpName": "GreaterEqual",
        "category": "logical",
        "inputs": [
          {
            "start": 0,
            "name": "a",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "b",
            "type": "tensor"
          }
        ],
        "attrs": [
          {
            "tfName": "T",
            "name": "dtype",
            "type": "dtype",
            "notSupported": true
          }
        ]
      },
      {
        "tfOpName": "Less",
        "category": "logical",
        "inputs": [
          {
            "start": 0,
            "name": "a",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "b",
            "type": "tensor"
          }
        ],
        "attrs": [
          {
            "tfName": "T",
            "name": "dtype",
            "type": "dtype",
            "notSupported": true
          }
        ]
      },
      {
        "tfOpName": "LessEqual",
        "category": "logical",
        "inputs": [
          {
            "start": 0,
            "name": "a",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "b",
            "type": "tensor"
          }
        ],
        "attrs": [
          {
            "tfName": "T",
            "name": "dtype",
            "type": "dtype",
            "notSupported": true
          }
        ]
      },
      {
        "tfOpName": "LogicalAnd",
        "category": "logical",
        "inputs": [
          {
            "start": 0,
            "name": "a",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "b",
            "type": "tensor"
          }
        ],
        "attrs": [
          {
            "tfName": "T",
            "name": "dtype",
            "type": "dtype",
            "notSupported": true
          }
        ]
      },
      {
        "tfOpName": "LogicalNot",
        "category": "logical",
        "inputs": [
          {
            "start": 0,
            "name": "a",
            "type": "tensor"
          }
        ],
        "attrs": [
          {
            "tfName": "T",
            "name": "dtype",
            "type": "dtype",
            "notSupported": true
          }
        ]
      },
      {
        "tfOpName": "LogicalOr",
        "category": "logical",
        "inputs": [
          {
            "start": 0,
            "name": "a",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "b",
            "type": "tensor"
          }
        ],
        "attrs": [
          {
            "tfName": "T",
            "name": "dtype",
            "type": "dtype",
            "notSupported": true
          }
        ]
      },
      {
        "tfOpName": "Select",
        "category": "logical",
        "inputs": [
          {
            "start": 0,
            "name": "condition",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "a",
            "type": "tensor"
          },
          {
            "start": 2,
            "name": "b",
            "type": "tensor"
          }
        ],
        "attrs": [
          {
            "tfName": "T",
            "name": "dtype",
            "type": "dtype",
            "notSupported": true
          }
        ]
      },
      {
        "tfOpName": "SelectV2",
        "category": "logical",
        "inputs": [
          {
            "start": 0,
            "name": "condition",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "a",
            "type": "tensor"
          },
          {
            "start": 2,
            "name": "b",
            "type": "tensor"
          }
        ],
        "attrs": [
          {
            "tfName": "T",
            "name": "dtype",
            "type": "dtype",
            "notSupported": true
          }
        ]
      },
      {
        "tfOpName": "BitwiseAnd",
        "category": "logical",
        "inputs": [
          {
            "start": 0,
            "name": "x",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "y",
            "type": "tensor"
          }
        ]
      }
    ];
    var logical = {
      __proto__: null,
      json: json$8
    };
    var json$7 = [
      {
        "tfOpName": "_FusedMatMul",
        "category": "matrices",
        "inputs": [
          {
            "start": 0,
            "name": "a",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "b",
            "type": "tensor"
          },
          {
            "start": 2,
            "end": 0,
            "name": "args",
            "type": "tensors"
          }
        ],
        "attrs": [
          {
            "tfName": "num_args",
            "name": "numArgs",
            "type": "number"
          },
          {
            "tfName": "fused_ops",
            "name": "fusedOps",
            "type": "string[]",
            "defaultValue": []
          },
          {
            "tfName": "epsilon",
            "name": "epsilon",
            "type": "number",
            "defaultValue": 1e-4
          },
          {
            "tfName": "transpose_a",
            "name": "transposeA",
            "type": "bool",
            "defaultValue": false
          },
          {
            "tfName": "transpose_b",
            "name": "transposeB",
            "type": "bool",
            "defaultValue": false
          },
          {
            "tfName": "leakyrelu_alpha",
            "name": "leakyreluAlpha",
            "type": "number",
            "defaultValue": 0.2
          },
          {
            "tfName": "T",
            "name": "dtype",
            "type": "dtype",
            "notSupported": true
          }
        ]
      },
      {
        "tfOpName": "MatMul",
        "category": "matrices",
        "inputs": [
          {
            "start": 0,
            "name": "a",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "b",
            "type": "tensor"
          }
        ],
        "attrs": [
          {
            "tfName": "transpose_a",
            "name": "transposeA",
            "type": "bool",
            "defaultValue": false
          },
          {
            "tfName": "transpose_b",
            "name": "transposeB",
            "type": "bool",
            "defaultValue": false
          },
          {
            "tfName": "T",
            "name": "dtype",
            "type": "dtype",
            "notSupported": true
          }
        ]
      },
      {
        "tfOpName": "BatchMatMul",
        "category": "matrices",
        "inputs": [
          {
            "start": 0,
            "name": "a",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "b",
            "type": "tensor"
          }
        ],
        "attrs": [
          {
            "tfName": "adj_x",
            "name": "transposeA",
            "type": "bool",
            "defaultValue": false
          },
          {
            "tfName": "adj_y",
            "name": "transposeB",
            "type": "bool",
            "defaultValue": false
          },
          {
            "tfName": "T",
            "name": "dtype",
            "type": "dtype",
            "notSupported": true
          }
        ]
      },
      {
        "tfOpName": "BatchMatMulV2",
        "category": "matrices",
        "inputs": [
          {
            "start": 0,
            "name": "a",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "b",
            "type": "tensor"
          }
        ],
        "attrs": [
          {
            "tfName": "adj_x",
            "name": "transposeA",
            "type": "bool",
            "defaultValue": false
          },
          {
            "tfName": "adj_y",
            "name": "transposeB",
            "type": "bool",
            "defaultValue": false
          },
          {
            "tfName": "T",
            "name": "dtype",
            "type": "dtype",
            "notSupported": true
          }
        ]
      },
      {
        "tfOpName": "Transpose",
        "category": "matrices",
        "inputs": [
          {
            "start": 0,
            "name": "x",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "perm",
            "type": "number[]"
          }
        ],
        "attrs": [
          {
            "tfName": "T",
            "name": "dtype",
            "type": "dtype",
            "notSupported": true
          }
        ]
      },
      {
        "tfOpName": "Einsum",
        "category": "matrices",
        "inputs": [
          {
            "start": 0,
            "end": 0,
            "name": "tensors",
            "type": "tensors"
          }
        ],
        "attrs": [
          {
            "tfName": "equation",
            "name": "equation",
            "type": "string"
          },
          {
            "tfName": "N",
            "name": "n",
            "type": "number",
            "defaultValue": 2
          },
          {
            "tfName": "T",
            "name": "dtype",
            "type": "dtype"
          }
        ]
      },
      {
        "tfOpName": "MatrixBandPart",
        "category": "matrices",
        "inputs": [
          {
            "start": 0,
            "name": "a",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "numLower",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "numUpper",
            "type": "tensor"
          }
        ]
      }
    ];
    var matrices = {
      __proto__: null,
      json: json$7
    };
    var json$6 = [
      {
        "tfOpName": "EuclideanNorm",
        "category": "normalization",
        "inputs": [
          {
            "start": 0,
            "name": "x",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "axis",
            "type": "number[]"
          }
        ],
        "attrs": [
          {
            "tfName": "keep_dims",
            "name": "keepDims",
            "type": "bool",
            "defaultValue": false
          }
        ]
      },
      {
        "tfOpName": "FusedBatchNorm",
        "category": "normalization",
        "inputs": [
          {
            "start": 0,
            "name": "x",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "scale",
            "type": "tensor"
          },
          {
            "start": 2,
            "name": "offset",
            "type": "tensor"
          },
          {
            "start": 3,
            "name": "mean",
            "type": "tensor"
          },
          {
            "start": 4,
            "name": "variance",
            "type": "tensor"
          }
        ],
        "attrs": [
          {
            "tfName": "epsilon",
            "name": "epsilon",
            "type": "number",
            "defaultValue": 1e-3
          },
          {
            "tfName": "data_format",
            "name": "dataFormat",
            "type": "string",
            "notSupported": true
          }
        ]
      },
      {
        "tfOpName": "FusedBatchNormV2",
        "category": "normalization",
        "inputs": [
          {
            "start": 0,
            "name": "x",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "scale",
            "type": "tensor"
          },
          {
            "start": 2,
            "name": "offset",
            "type": "tensor"
          },
          {
            "start": 3,
            "name": "mean",
            "type": "tensor"
          },
          {
            "start": 4,
            "name": "variance",
            "type": "tensor"
          }
        ],
        "attrs": [
          {
            "tfName": "epsilon",
            "name": "epsilon",
            "type": "number",
            "defaultValue": 1e-3
          },
          {
            "tfName": "data_format",
            "name": "dataFormat",
            "type": "string",
            "notSupported": true
          }
        ]
      },
      {
        "tfOpName": "FusedBatchNormV3",
        "category": "normalization",
        "inputs": [
          {
            "start": 0,
            "name": "x",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "scale",
            "type": "tensor"
          },
          {
            "start": 2,
            "name": "offset",
            "type": "tensor"
          },
          {
            "start": 3,
            "name": "mean",
            "type": "tensor"
          },
          {
            "start": 4,
            "name": "variance",
            "type": "tensor"
          }
        ],
        "attrs": [
          {
            "tfName": "epsilon",
            "name": "epsilon",
            "type": "number",
            "defaultValue": 1e-3
          },
          {
            "tfName": "data_format",
            "name": "dataFormat",
            "type": "string",
            "notSupported": true
          }
        ]
      },
      {
        "tfOpName": "LRN",
        "category": "normalization",
        "inputs": [
          {
            "start": 0,
            "name": "x",
            "type": "tensor"
          }
        ],
        "attrs": [
          {
            "tfName": "depth_radius",
            "name": "radius",
            "type": "number",
            "defaultValue": 5
          },
          {
            "tfName": "bias",
            "name": "bias",
            "type": "number",
            "defaultValue": 1
          },
          {
            "tfName": "alpha",
            "name": "alpha",
            "type": "number",
            "defaultValue": 1
          },
          {
            "tfName": "beta",
            "name": "beta",
            "type": "number",
            "defaultValue": 0.5
          }
        ]
      },
      {
        "tfOpName": "Softmax",
        "category": "normalization",
        "inputs": [
          {
            "start": 0,
            "name": "x",
            "type": "tensor"
          }
        ]
      },
      {
        "tfOpName": "LogSoftmax",
        "category": "normalization",
        "inputs": [
          {
            "start": 0,
            "name": "x",
            "type": "tensor"
          }
        ]
      }
    ];
    var normalization = {
      __proto__: null,
      json: json$6
    };
    var json$5 = [
      {
        "tfOpName": "Bincount",
        "category": "reduction",
        "inputs": [
          {
            "start": 0,
            "name": "x",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "size",
            "type": "number"
          },
          {
            "start": 2,
            "name": "weights",
            "type": "tensor"
          }
        ]
      },
      {
        "tfOpName": "DenseBincount",
        "category": "reduction",
        "inputs": [
          {
            "start": 0,
            "name": "x",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "size",
            "type": "number"
          },
          {
            "start": 2,
            "name": "weights",
            "type": "tensor"
          }
        ],
        "attrs": [
          {
            "tfName": "binary_output",
            "name": "binaryOutput",
            "type": "bool"
          }
        ]
      },
      {
        "tfOpName": "Max",
        "category": "reduction",
        "inputs": [
          {
            "start": 0,
            "name": "x",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "axis",
            "type": "number[]"
          }
        ],
        "attrs": [
          {
            "tfName": "keep_dims",
            "name": "keepDims",
            "type": "bool"
          }
        ]
      },
      {
        "tfOpName": "Mean",
        "category": "reduction",
        "inputs": [
          {
            "start": 0,
            "name": "x",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "axis",
            "type": "number[]"
          }
        ],
        "attrs": [
          {
            "tfName": "keep_dims",
            "name": "keepDims",
            "type": "bool"
          }
        ]
      },
      {
        "tfOpName": "Min",
        "category": "reduction",
        "inputs": [
          {
            "start": 0,
            "name": "x",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "axis",
            "type": "number[]"
          }
        ],
        "attrs": [
          {
            "tfName": "keep_dims",
            "name": "keepDims",
            "type": "bool"
          }
        ]
      },
      {
        "tfOpName": "Sum",
        "category": "reduction",
        "inputs": [
          {
            "start": 0,
            "name": "x",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "axis",
            "type": "number[]"
          }
        ],
        "attrs": [
          {
            "tfName": "keep_dims",
            "name": "keepDims",
            "type": "bool"
          }
        ]
      },
      {
        "tfOpName": "All",
        "category": "reduction",
        "inputs": [
          {
            "start": 0,
            "name": "x",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "axis",
            "type": "number[]"
          }
        ],
        "attrs": [
          {
            "tfName": "keep_dims",
            "name": "keepDims",
            "type": "bool"
          }
        ]
      },
      {
        "tfOpName": "Any",
        "category": "reduction",
        "inputs": [
          {
            "start": 0,
            "name": "x",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "axis",
            "type": "number[]"
          }
        ],
        "attrs": [
          {
            "tfName": "keep_dims",
            "name": "keepDims",
            "type": "bool"
          }
        ]
      },
      {
        "tfOpName": "ArgMax",
        "category": "reduction",
        "inputs": [
          {
            "start": 0,
            "name": "x",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "axis",
            "type": "number"
          }
        ]
      },
      {
        "tfOpName": "ArgMin",
        "category": "reduction",
        "inputs": [
          {
            "start": 0,
            "name": "x",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "axis",
            "type": "number"
          }
        ]
      },
      {
        "tfOpName": "Prod",
        "category": "reduction",
        "inputs": [
          {
            "start": 0,
            "name": "x",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "axis",
            "type": "number[]"
          }
        ],
        "attrs": [
          {
            "tfName": "keep_dims",
            "name": "keepDims",
            "type": "bool"
          },
          {
            "tfName": "T",
            "name": "dtype",
            "type": "dtype",
            "notSupported": true
          }
        ]
      },
      {
        "tfOpName": "Cumprod",
        "category": "reduction",
        "inputs": [
          {
            "start": 0,
            "name": "x",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "axis",
            "type": "number"
          }
        ],
        "attrs": [
          {
            "tfName": "exclusive",
            "name": "exclusive",
            "type": "bool"
          },
          {
            "tfName": "reverse",
            "name": "reverse",
            "type": "bool"
          }
        ]
      },
      {
        "tfOpName": "Cumsum",
        "category": "reduction",
        "inputs": [
          {
            "start": 0,
            "name": "x",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "axis",
            "type": "number"
          }
        ],
        "attrs": [
          {
            "tfName": "exclusive",
            "name": "exclusive",
            "type": "bool"
          },
          {
            "tfName": "reverse",
            "name": "reverse",
            "type": "bool"
          }
        ]
      }
    ];
    var reduction = {
      __proto__: null,
      json: json$5
    };
    var json$4 = [
      {
        "tfOpName": "ConcatV2",
        "category": "slice_join",
        "inputs": [
          {
            "start": 0,
            "end": -1,
            "name": "tensors",
            "type": "tensors"
          },
          {
            "start": -1,
            "name": "axis",
            "type": "number"
          }
        ],
        "attrs": [
          {
            "tfName": "N",
            "name": "n",
            "type": "number",
            "defaultValue": 2
          }
        ]
      },
      {
        "tfOpName": "Concat",
        "category": "slice_join",
        "inputs": [
          {
            "start": 1,
            "end": 0,
            "name": "tensors",
            "type": "tensors"
          },
          {
            "start": 0,
            "name": "axis",
            "type": "number"
          }
        ],
        "attrs": [
          {
            "tfName": "N",
            "name": "n",
            "type": "number",
            "defaultValue": 2
          }
        ]
      },
      {
        "tfOpName": "GatherV2",
        "category": "slice_join",
        "inputs": [
          {
            "start": 0,
            "name": "x",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "indices",
            "type": "tensor"
          },
          {
            "start": 2,
            "name": "axis",
            "type": "number",
            "defaultValue": 0
          }
        ],
        "attrs": [
          {
            "tfName": "batch_dims",
            "name": "batchDims",
            "type": "number",
            "defaultValue": 0
          }
        ]
      },
      {
        "tfOpName": "Gather",
        "category": "slice_join",
        "inputs": [
          {
            "start": 0,
            "name": "x",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "indices",
            "type": "tensor"
          }
        ],
        "attrs": [
          {
            "tfName": "validate_indices",
            "name": "validateIndices",
            "type": "bool",
            "notSupported": true
          }
        ]
      },
      {
        "tfOpName": "Reverse",
        "category": "slice_join",
        "inputs": [
          {
            "start": 0,
            "name": "x",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "dims",
            "type": "bool[]"
          }
        ]
      },
      {
        "tfOpName": "ReverseV2",
        "category": "slice_join",
        "inputs": [
          {
            "start": 0,
            "name": "x",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "axis",
            "type": "number[]"
          }
        ]
      },
      {
        "tfOpName": "Slice",
        "category": "slice_join",
        "inputs": [
          {
            "start": 0,
            "name": "x",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "begin",
            "type": "number[]"
          },
          {
            "start": 2,
            "name": "size",
            "type": "number[]"
          }
        ]
      },
      {
        "tfOpName": "StridedSlice",
        "category": "slice_join",
        "inputs": [
          {
            "start": 0,
            "name": "x",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "begin",
            "type": "number[]"
          },
          {
            "start": 2,
            "name": "end",
            "type": "number[]"
          },
          {
            "start": 3,
            "name": "strides",
            "type": "number[]"
          }
        ],
        "attrs": [
          {
            "tfName": "begin_mask",
            "name": "beginMask",
            "type": "number",
            "defaultValue": 0
          },
          {
            "tfName": "end_mask",
            "name": "endMask",
            "type": "number",
            "defaultValue": 0
          },
          {
            "tfName": "new_axis_mask",
            "name": "newAxisMask",
            "type": "number",
            "defaultValue": 0
          },
          {
            "tfName": "ellipsis_mask",
            "name": "ellipsisMask",
            "type": "number",
            "defaultValue": 0
          },
          {
            "tfName": "shrink_axis_mask",
            "name": "shrinkAxisMask",
            "type": "number",
            "defaultValue": 0
          }
        ]
      },
      {
        "tfOpName": "Pack",
        "category": "slice_join",
        "inputs": [
          {
            "start": 0,
            "end": 0,
            "name": "tensors",
            "type": "tensors"
          }
        ],
        "attrs": [
          {
            "tfName": "axis",
            "name": "axis",
            "type": "number",
            "defaultValue": 0
          }
        ]
      },
      {
        "tfOpName": "Unpack",
        "category": "slice_join",
        "inputs": [
          {
            "start": 0,
            "name": "tensor",
            "type": "tensor"
          }
        ],
        "attrs": [
          {
            "tfName": "axis",
            "name": "axis",
            "type": "number",
            "defaultValue": 0
          },
          {
            "tfName": "num",
            "name": "num",
            "type": "number",
            "defaultValue": 0,
            "notSupported": true
          }
        ]
      },
      {
        "tfOpName": "Tile",
        "category": "slice_join",
        "inputs": [
          {
            "start": 0,
            "name": "x",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "reps",
            "type": "number[]"
          }
        ]
      },
      {
        "tfOpName": "Split",
        "category": "slice_join",
        "inputs": [
          {
            "start": 0,
            "name": "axis",
            "type": "number",
            "defaultValue": 0
          },
          {
            "start": 1,
            "name": "x",
            "type": "tensor"
          }
        ],
        "attrs": [
          {
            "tfName": "num_split",
            "name": "numOrSizeSplits",
            "type": "number",
            "defaultValue": 1
          }
        ]
      },
      {
        "tfOpName": "SplitV",
        "category": "slice_join",
        "inputs": [
          {
            "start": 0,
            "name": "x",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "numOrSizeSplits",
            "type": "number[]"
          },
          {
            "start": 2,
            "name": "axis",
            "type": "number",
            "defaultValue": 0
          }
        ]
      },
      {
        "tfOpName": "ScatterNd",
        "category": "slice_join",
        "inputs": [
          {
            "start": 0,
            "name": "indices",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "values",
            "type": "tensor"
          },
          {
            "start": 2,
            "name": "shape",
            "type": "number[]"
          }
        ]
      },
      {
        "tfOpName": "GatherNd",
        "category": "slice_join",
        "inputs": [
          {
            "start": 0,
            "name": "x",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "indices",
            "type": "tensor"
          }
        ]
      },
      {
        "tfOpName": "SparseToDense",
        "category": "slice_join",
        "inputs": [
          {
            "start": 0,
            "name": "sparseIndices",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "outputShape",
            "type": "number[]"
          },
          {
            "start": 2,
            "name": "sparseValues",
            "type": "tensor"
          },
          {
            "start": 3,
            "name": "defaultValue",
            "type": "tensor"
          }
        ],
        "attrs": [
          {
            "tfName": "validate_indices",
            "name": "validateIndices",
            "type": "bool",
            "defaultValue": false,
            "notSupported": true
          }
        ]
      },
      {
        "tfOpName": "TensorScatterUpdate",
        "category": "slice_join",
        "inputs": [
          {
            "start": 0,
            "name": "tensor",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "indices",
            "type": "tensor"
          },
          {
            "start": 2,
            "name": "values",
            "type": "tensor"
          }
        ]
      }
    ];
    var sliceJoin = {
      __proto__: null,
      json: json$4
    };
    var json$3 = [
      {
        "tfOpName": "SparseFillEmptyRows",
        "category": "sparse",
        "inputs": [
          {
            "start": 0,
            "name": "indices",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "values",
            "type": "tensor"
          },
          {
            "start": 2,
            "name": "denseShape",
            "type": "tensor"
          },
          {
            "start": 3,
            "name": "defaultValue",
            "type": "tensor"
          }
        ]
      },
      {
        "tfOpName": "SparseReshape",
        "category": "sparse",
        "inputs": [
          {
            "start": 0,
            "name": "inputIndices",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "inputShape",
            "type": "tensor"
          },
          {
            "start": 2,
            "name": "newShape",
            "type": "tensor"
          }
        ],
        "attrs": [
          {
            "tfName": "T",
            "name": "dtype",
            "type": "dtype",
            "notSupported": true
          }
        ]
      },
      {
        "tfOpName": "SparseSegmentMean",
        "category": "sparse",
        "inputs": [
          {
            "start": 0,
            "name": "data",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "indices",
            "type": "tensor"
          },
          {
            "start": 2,
            "name": "segmentIds",
            "type": "tensor"
          }
        ]
      },
      {
        "tfOpName": "SparseSegmentSum",
        "category": "sparse",
        "inputs": [
          {
            "start": 0,
            "name": "data",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "indices",
            "type": "tensor"
          },
          {
            "start": 2,
            "name": "segmentIds",
            "type": "tensor"
          }
        ]
      }
    ];
    var sparse$1 = {
      __proto__: null,
      json: json$3
    };
    var json$2 = [
      {
        "tfOpName": "FFT",
        "category": "spectral",
        "inputs": [
          {
            "start": 0,
            "name": "x",
            "type": "tensor"
          }
        ]
      },
      {
        "tfOpName": "IFFT",
        "category": "spectral",
        "inputs": [
          {
            "start": 0,
            "name": "x",
            "type": "tensor"
          }
        ]
      },
      {
        "tfOpName": "RFFT",
        "category": "spectral",
        "inputs": [
          {
            "start": 0,
            "name": "x",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "fft_length",
            "type": "number",
            "notSupported": true
          }
        ]
      },
      {
        "tfOpName": "IRFFT",
        "category": "spectral",
        "inputs": [
          {
            "start": 0,
            "name": "x",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "fft_length",
            "type": "number",
            "notSupported": true
          }
        ]
      }
    ];
    var spectral$1 = {
      __proto__: null,
      json: json$2
    };
    var json$1 = [
      {
        "tfOpName": "StaticRegexReplace",
        "category": "string",
        "inputs": [
          {
            "start": 0,
            "name": "input",
            "type": "tensor"
          }
        ],
        "attrs": [
          {
            "tfName": "pattern",
            "name": "pattern",
            "type": "string"
          },
          {
            "tfName": "rewrite",
            "name": "rewrite",
            "type": "string"
          },
          {
            "tfName": "replace_global",
            "name": "replaceGlobal",
            "type": "bool"
          }
        ]
      },
      {
        "tfOpName": "StringNGrams",
        "category": "string",
        "inputs": [
          {
            "start": 0,
            "name": "data",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "dataSplits",
            "type": "tensor"
          }
        ],
        "attrs": [
          {
            "tfName": "separator",
            "name": "separator",
            "type": "string"
          },
          {
            "tfName": "ngram_widths",
            "name": "nGramWidths",
            "type": "number[]"
          },
          {
            "tfName": "left_pad",
            "name": "leftPad",
            "type": "string"
          },
          {
            "tfName": "right_pad",
            "name": "rightPad",
            "type": "string"
          },
          {
            "tfName": "pad_width",
            "name": "padWidth",
            "type": "number"
          },
          {
            "tfName": "preserve_short_sequences",
            "name": "preserveShortSequences",
            "type": "bool"
          }
        ],
        "outputs": [
          "ngrams",
          "ngrams_splits"
        ]
      },
      {
        "tfOpName": "StringSplit",
        "category": "string",
        "inputs": [
          {
            "start": 0,
            "name": "input",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "delimiter",
            "type": "tensor"
          }
        ],
        "attrs": [
          {
            "tfName": "skip_empty",
            "name": "skipEmpty",
            "type": "bool"
          }
        ],
        "outputs": [
          "indices",
          "values",
          "shape"
        ]
      },
      {
        "tfOpName": "StringToHashBucketFast",
        "category": "string",
        "inputs": [
          {
            "start": 0,
            "name": "input",
            "type": "tensor"
          }
        ],
        "attrs": [
          {
            "tfName": "num_buckets",
            "name": "numBuckets",
            "type": "number"
          }
        ]
      }
    ];
    var string$1 = {
      __proto__: null,
      json: json$1
    };
    var json = [
      {
        "tfOpName": "Cast",
        "category": "transformation",
        "inputs": [
          {
            "start": 0,
            "name": "x",
            "type": "tensor"
          }
        ],
        "attrs": [
          {
            "tfName": "SrcT",
            "name": "sdtype",
            "type": "dtype",
            "notSupported": true
          },
          {
            "tfName": "DstT",
            "name": "dtype",
            "type": "dtype"
          }
        ]
      },
      {
        "tfOpName": "ExpandDims",
        "category": "transformation",
        "inputs": [
          {
            "start": 0,
            "name": "x",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "axis",
            "type": "number"
          }
        ]
      },
      {
        "tfOpName": "MirrorPad",
        "category": "transformation",
        "inputs": [
          {
            "start": 0,
            "name": "x",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "padding",
            "type": "number[]"
          }
        ],
        "attrs": [
          {
            "tfName": "mode",
            "name": "mode",
            "type": "string"
          }
        ]
      },
      {
        "tfOpName": "Pad",
        "category": "transformation",
        "inputs": [
          {
            "start": 0,
            "name": "x",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "padding",
            "type": "number[]"
          }
        ],
        "attrs": [
          {
            "tfName": "constant_value",
            "name": "constantValue",
            "type": "number",
            "defaultValue": 0
          }
        ]
      },
      {
        "tfOpName": "PadV2",
        "category": "transformation",
        "inputs": [
          {
            "start": 0,
            "name": "x",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "padding",
            "type": "number[]"
          },
          {
            "start": 2,
            "name": "constantValue",
            "type": "number",
            "defaultValue": 0
          }
        ]
      },
      {
        "tfOpName": "Reshape",
        "category": "transformation",
        "inputs": [
          {
            "start": 0,
            "name": "x",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "shape",
            "type": "number[]"
          }
        ]
      },
      {
        "tfOpName": "EnsureShape",
        "category": "transformation",
        "inputs": [
          {
            "start": 0,
            "name": "x",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "shape",
            "type": "number[]"
          }
        ]
      },
      {
        "tfOpName": "Squeeze",
        "category": "transformation",
        "inputs": [
          {
            "start": 0,
            "name": "x",
            "type": "tensor"
          }
        ],
        "attrs": [
          {
            "tfName": "axis",
            "tfDeprecatedName": "squeeze_dims",
            "name": "axis",
            "type": "number[]"
          }
        ]
      },
      {
        "tfOpName": "SpaceToBatchND",
        "category": "transformation",
        "inputs": [
          {
            "start": 0,
            "name": "x",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "blockShape",
            "type": "number[]"
          },
          {
            "start": 2,
            "name": "paddings",
            "type": "number[]"
          }
        ]
      },
      {
        "tfOpName": "BatchToSpaceND",
        "category": "transformation",
        "inputs": [
          {
            "start": 0,
            "name": "x",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "blockShape",
            "type": "number[]"
          },
          {
            "start": 2,
            "name": "crops",
            "type": "number[]"
          }
        ]
      },
      {
        "tfOpName": "DepthToSpace",
        "category": "transformation",
        "inputs": [
          {
            "start": 0,
            "name": "x",
            "type": "tensor"
          }
        ],
        "attrs": [
          {
            "tfName": "block_size",
            "name": "blockSize",
            "type": "number"
          },
          {
            "tfName": "data_format",
            "name": "dataFormat",
            "type": "string"
          }
        ]
      },
      {
        "tfOpName": "BroadcastTo",
        "category": "transformation",
        "inputs": [
          {
            "start": 0,
            "name": "x",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "shape",
            "type": "number[]"
          }
        ],
        "attrs": []
      },
      {
        "tfOpName": "BroadcastArgs",
        "category": "transformation",
        "inputs": [
          {
            "start": 0,
            "name": "s0",
            "type": "tensor"
          },
          {
            "start": 1,
            "name": "s1",
            "type": "tensor"
          }
        ],
        "attrs": []
      }
    ];
    var transformation = {
      __proto__: null,
      json
    };
    var OperationMapper = (
      /** @class */
      function() {
        function OperationMapper2() {
          var ops = [
            arithmetic,
            basicMath,
            control,
            convolution,
            creation,
            dynamic,
            evaluation,
            graph,
            hashTable,
            image$1,
            logical,
            matrices,
            normalization,
            reduction,
            sliceJoin,
            sparse$1,
            spectral$1,
            string$1,
            transformation
          ];
          var mappersJson = [].concat.apply([], __spreadArray([], __read(ops.map(function(op2) {
            return op2.json;
          })), false));
          this.opMappers = mappersJson.reduce(function(map, mapper) {
            map[mapper.tfOpName] = mapper;
            return map;
          }, {});
        }
        Object.defineProperty(OperationMapper2, "Instance", {
          // Singleton instance for the mapper
          get: function() {
            return this._instance || (this._instance = new this());
          },
          enumerable: false,
          configurable: true
        });
        OperationMapper2.prototype.transformGraph = function(graph2, signature) {
          var _this = this;
          if (signature === void 0) {
            signature = {};
          }
          var tfNodes = graph2.node;
          var placeholders = [];
          var weights = [];
          var initNodes = [];
          var nodes = tfNodes.reduce(function(map, node) {
            map[node.name] = _this.mapNode(node);
            if (node.op.startsWith("Placeholder")) {
              placeholders.push(map[node.name]);
            } else if (node.op === "Const") {
              weights.push(map[node.name]);
            } else if (node.input == null || node.input.length === 0) {
              initNodes.push(map[node.name]);
            }
            return map;
          }, {});
          var inputs = [];
          var outputs = [];
          var inputNodeNameToKey = {};
          var outputNodeNameToKey = {};
          if (signature != null) {
            inputNodeNameToKey = this.mapSignatureEntries(signature.inputs);
            outputNodeNameToKey = this.mapSignatureEntries(signature.outputs);
          }
          var allNodes = Object.keys(nodes);
          allNodes.forEach(function(key) {
            var node = nodes[key];
            node.inputNames.forEach(function(name, index) {
              var _a = __read(getNodeNameAndIndex(name), 3), nodeName = _a[0], outputName = _a[2];
              var inputNode = nodes[nodeName];
              if (inputNode.outputs != null) {
                var outputIndex = inputNode.outputs.indexOf(outputName);
                if (outputIndex !== -1) {
                  var inputName = "".concat(nodeName, ":").concat(outputIndex);
                  node.inputNames[index] = inputName;
                }
              }
              node.inputs.push(inputNode);
              inputNode.children.push(node);
            });
          });
          if (Object.keys(outputNodeNameToKey).length === 0) {
            allNodes.forEach(function(key) {
              var node = nodes[key];
              if (node.children.length === 0) {
                outputs.push(node);
              }
            });
          } else {
            Object.keys(outputNodeNameToKey).forEach(function(name) {
              var _a = __read(getNodeNameAndIndex(name), 1), nodeName = _a[0];
              var node = nodes[nodeName];
              if (node != null) {
                node.signatureKey = outputNodeNameToKey[name];
                outputs.push(node);
              }
            });
          }
          if (Object.keys(inputNodeNameToKey).length > 0) {
            Object.keys(inputNodeNameToKey).forEach(function(name) {
              var _a = __read(getNodeNameAndIndex(name), 1), nodeName = _a[0];
              var node = nodes[nodeName];
              if (node) {
                node.signatureKey = inputNodeNameToKey[name];
                inputs.push(node);
              }
            });
          } else {
            inputs = placeholders;
          }
          var functions = {};
          if (graph2.library != null && graph2.library.function != null) {
            functions = graph2.library.function.reduce(function(functions2, func) {
              functions2[func.signature.name] = _this.mapFunction(func);
              return functions2;
            }, {});
          }
          var result = { nodes, inputs, outputs, weights, placeholders, signature, functions };
          if (initNodes.length > 0) {
            result.initNodes = initNodes;
          }
          return result;
        };
        OperationMapper2.prototype.mapSignatureEntries = function(entries) {
          return Object.keys(entries || {}).reduce(function(prev, curr) {
            prev[entries[curr].name] = curr;
            return prev;
          }, {});
        };
        OperationMapper2.prototype.mapNode = function(node) {
          var mapper = getRegisteredOp(node.op) || this.opMappers[node.op] || {};
          if (node.attr == null) {
            node.attr = {};
          }
          var newNode = {
            name: node.name,
            op: node.op,
            category: mapper.category,
            inputNames: (node.input || []).map(function(input) {
              return input.startsWith("^") ? input.slice(1) : input;
            }),
            inputs: [],
            children: [],
            inputParams: {},
            attrParams: {},
            rawAttrs: node.attr,
            outputs: mapper.outputs
          };
          if (mapper.inputs != null) {
            newNode.inputParams = mapper.inputs.reduce(function(map, param) {
              map[param.name] = {
                type: param.type,
                inputIndexStart: param.start,
                inputIndexEnd: param.end
              };
              return map;
            }, {});
          }
          if (mapper.attrs != null) {
            newNode.attrParams = mapper.attrs.reduce(function(map, param) {
              var type = param.type;
              var value = void 0;
              switch (param.type) {
                case "string":
                  value = getStringParam(node.attr, param.tfName, param.defaultValue);
                  if (value === void 0 && !!param.tfDeprecatedName) {
                    value = getStringParam(node.attr, param.tfDeprecatedName, param.defaultValue);
                  }
                  break;
                case "string[]":
                  value = getStringArrayParam(node.attr, param.tfName, param.defaultValue);
                  if (value === void 0 && !!param.tfDeprecatedName) {
                    value = getStringArrayParam(node.attr, param.tfDeprecatedName, param.defaultValue);
                  }
                  break;
                case "number":
                  value = getNumberParam(node.attr, param.tfName, param.defaultValue || 0);
                  if (value === void 0 && !!param.tfDeprecatedName) {
                    value = getNumberParam(node.attr, param.tfDeprecatedName, param.defaultValue);
                  }
                  break;
                case "number[]":
                  value = getNumericArrayParam(node.attr, param.tfName, param.defaultValue);
                  if (value === void 0 && !!param.tfDeprecatedName) {
                    value = getNumericArrayParam(node.attr, param.tfDeprecatedName, param.defaultValue);
                  }
                  break;
                case "bool":
                  value = getBoolParam(node.attr, param.tfName, param.defaultValue);
                  if (value === void 0 && !!param.tfDeprecatedName) {
                    value = getBoolParam(node.attr, param.tfDeprecatedName, param.defaultValue);
                  }
                  break;
                case "bool[]":
                  value = getBoolArrayParam(node.attr, param.tfName, param.defaultValue);
                  if (value === void 0 && !!param.tfDeprecatedName) {
                    value = getBoolArrayParam(node.attr, param.tfDeprecatedName, param.defaultValue);
                  }
                  break;
                case "shape":
                  value = getTensorShapeParam(node.attr, param.tfName, param.defaultValue);
                  if (value === void 0 && !!param.tfDeprecatedName) {
                    value = getTensorShapeParam(node.attr, param.tfDeprecatedName, param.defaultValue);
                  }
                  break;
                case "shape[]":
                  value = getTensorShapeArrayParam(node.attr, param.tfName, param.defaultValue);
                  if (value === void 0 && !!param.tfDeprecatedName) {
                    value = getTensorShapeArrayParam(node.attr, param.tfDeprecatedName, param.defaultValue);
                  }
                  break;
                case "dtype":
                  value = getDtypeParam(node.attr, param.tfName, param.defaultValue);
                  if (value === void 0 && !!param.tfDeprecatedName) {
                    value = getDtypeParam(node.attr, param.tfDeprecatedName, param.defaultValue);
                  }
                  break;
                case "dtype[]":
                  value = getDtypeArrayParam(node.attr, param.tfName, param.defaultValue);
                  if (value === void 0 && !!param.tfDeprecatedName) {
                    value = getDtypeArrayParam(node.attr, param.tfDeprecatedName, param.defaultValue);
                  }
                  break;
                case "func":
                  value = getFuncParam(node.attr, param.tfName, param.defaultValue);
                  if (value === void 0 && !!param.tfDeprecatedName) {
                    value = getFuncParam(node.attr, param.tfDeprecatedName, param.defaultValue);
                  }
                  break;
                case "tensor":
                case "tensors":
                  break;
                default:
                  throw new Error("Unsupported param type: ".concat(param.type, " for op: ").concat(node.op));
              }
              map[param.name] = { value, type };
              return map;
            }, {});
          }
          return newNode;
        };
        OperationMapper2.prototype.mapFunction = function(functionDef) {
          var _this = this;
          var tfNodes = functionDef.nodeDef;
          var placeholders = [];
          var weights = [];
          var nodes = {};
          if (tfNodes != null) {
            nodes = tfNodes.reduce(function(map, node) {
              map[node.name] = _this.mapNode(node);
              if (node.op === "Const") {
                weights.push(map[node.name]);
              }
              return map;
            }, {});
          }
          var inputs = [];
          var outputs = [];
          functionDef.signature.inputArg.forEach(function(arg) {
            var _a = __read(getNodeNameAndIndex(arg.name), 1), nodeName = _a[0];
            var node = {
              name: nodeName,
              op: "Placeholder",
              inputs: [],
              inputNames: [],
              category: "graph",
              inputParams: {},
              attrParams: { dtype: { value: parseDtypeParam(arg.type), type: "dtype" } },
              children: []
            };
            node.signatureKey = arg.name;
            inputs.push(node);
            nodes[nodeName] = node;
          });
          var allNodes = Object.keys(nodes);
          allNodes.forEach(function(key) {
            var node = nodes[key];
            node.inputNames.forEach(function(name, index) {
              var _a = __read(getNodeNameAndIndex(name), 3), nodeName = _a[0], outputName = _a[2];
              var inputNode = nodes[nodeName];
              if (inputNode.outputs != null) {
                var outputIndex = inputNode.outputs.indexOf(outputName);
                if (outputIndex !== -1) {
                  var inputName = "".concat(nodeName, ":").concat(outputIndex);
                  node.inputNames[index] = inputName;
                }
              }
              node.inputs.push(inputNode);
              inputNode.children.push(node);
            });
          });
          var returnNodeMap = functionDef.ret;
          functionDef.signature.outputArg.forEach(function(output) {
            var _a = __read(getNodeNameAndIndex(returnNodeMap[output.name]), 2), nodeName = _a[0], index = _a[1];
            var node = nodes[nodeName];
            if (node != null) {
              node.defaultOutput = index;
              outputs.push(node);
            }
          });
          var signature = this.mapArgsToSignature(functionDef);
          return { nodes, inputs, outputs, weights, placeholders, signature };
        };
        OperationMapper2.prototype.mapArgsToSignature = function(functionDef) {
          var _this = this;
          return {
            methodName: functionDef.signature.name,
            inputs: functionDef.signature.inputArg.reduce(function(map, arg) {
              map[arg.name] = _this.mapArgToTensorInfo(arg);
              return map;
            }, {}),
            outputs: functionDef.signature.outputArg.reduce(function(map, arg) {
              map[arg.name] = _this.mapArgToTensorInfo(arg, functionDef.ret);
              return map;
            }, {})
          };
        };
        OperationMapper2.prototype.mapArgToTensorInfo = function(arg, nameMap) {
          var name = arg.name;
          if (nameMap != null) {
            name = nameMap[name];
          }
          return { name, dtype: arg.type };
        };
        return OperationMapper2;
      }()
    );
    function decodeBase64(text) {
      var global2 = tfc.env().global;
      if (typeof global2.atob !== "undefined") {
        return global2.atob(text);
      } else if (typeof Buffer !== "undefined") {
        return new Buffer(text, "base64").toString();
      } else {
        throw new Error("Unable to decode base64 in this environment. Missing built-in atob() or Buffer()");
      }
    }
    function parseStringParam(s, keepCase) {
      var value = Array.isArray(s) ? String.fromCharCode.apply(null, s) : decodeBase64(s);
      return keepCase ? value : value.toLowerCase();
    }
    function getStringParam(attrs, name, def, keepCase) {
      if (keepCase === void 0) {
        keepCase = false;
      }
      var param = attrs[name];
      if (param != null) {
        return parseStringParam(param.s, keepCase);
      }
      return def;
    }
    function getBoolParam(attrs, name, def) {
      var param = attrs[name];
      return param ? param.b : def;
    }
    function getNumberParam(attrs, name, def) {
      var param = attrs[name] || {};
      var value = param["i"] != null ? param["i"] : param["f"] != null ? param["f"] : def;
      return typeof value === "number" ? value : parseInt(value, 10);
    }
    function parseDtypeParam(value) {
      if (typeof value === "string") {
        value = DataType[value];
      }
      switch (value) {
        case DataType.DT_FLOAT:
        case DataType.DT_HALF:
          return "float32";
        case DataType.DT_INT32:
        case DataType.DT_INT64:
        case DataType.DT_INT8:
        case DataType.DT_UINT8:
          return "int32";
        case DataType.DT_BOOL:
          return "bool";
        case DataType.DT_DOUBLE:
          return "float32";
        case DataType.DT_STRING:
          return "string";
        default:
          return null;
      }
    }
    function getFuncParam(attrs, name, def) {
      var param = attrs[name];
      if (param && param.func) {
        return param.func.name;
      }
      return def;
    }
    function getDtypeParam(attrs, name, def) {
      var param = attrs[name];
      if (param && param.type) {
        return parseDtypeParam(param.type);
      }
      return def;
    }
    function getDtypeArrayParam(attrs, name, def) {
      var param = attrs[name];
      if (param && param.list && param.list.type) {
        return param.list.type.map(function(v) {
          return parseDtypeParam(v);
        });
      }
      return def;
    }
    function parseTensorShapeParam(shape) {
      if (shape.unknownRank) {
        return void 0;
      }
      if (shape.dim != null) {
        return shape.dim.map(function(dim) {
          return typeof dim.size === "number" ? dim.size : parseInt(dim.size, 10);
        });
      }
      return [];
    }
    function getTensorShapeParam(attrs, name, def) {
      var param = attrs[name];
      if (param && param.shape) {
        return parseTensorShapeParam(param.shape);
      }
      return def;
    }
    function getNumericArrayParam(attrs, name, def) {
      var param = attrs[name];
      if (param) {
        return ((param.list.f && param.list.f.length ? param.list.f : param.list.i) || []).map(function(v) {
          return typeof v === "number" ? v : parseInt(v, 10);
        });
      }
      return def;
    }
    function getStringArrayParam(attrs, name, def, keepCase) {
      if (keepCase === void 0) {
        keepCase = false;
      }
      var param = attrs[name];
      if (param && param.list && param.list.s) {
        return param.list.s.map(function(v) {
          return parseStringParam(v, keepCase);
        });
      }
      return def;
    }
    function getTensorShapeArrayParam(attrs, name, def) {
      var param = attrs[name];
      if (param && param.list && param.list.shape) {
        return param.list.shape.map(function(v) {
          return parseTensorShapeParam(v);
        });
      }
      return def;
    }
    function getBoolArrayParam(attrs, name, def) {
      var param = attrs[name];
      if (param && param.list && param.list.b) {
        return param.list.b;
      }
      return def;
    }
    var NodeValueImpl = (
      /** @class */
      function() {
        function NodeValueImpl2(node, tensorMap, context) {
          var _this = this;
          this.node = node;
          this.tensorMap = tensorMap;
          this.context = context;
          this.inputs = [];
          this.attrs = {};
          this.inputs = node.inputNames.map(function(name) {
            return _this.getInput(name);
          });
          if (node.rawAttrs != null) {
            this.attrs = Object.keys(node.rawAttrs).reduce(function(attrs, key) {
              attrs[key] = _this.getAttr(key);
              return attrs;
            }, {});
          }
        }
        NodeValueImpl2.prototype.getInput = function(name) {
          return getTensor(name, this.tensorMap, this.context);
        };
        NodeValueImpl2.prototype.getAttr = function(name, defaultValue) {
          var value = this.node.rawAttrs[name];
          if (value.tensor != null) {
            return getTensor(name, this.tensorMap, this.context);
          }
          if (value.i != null || value.f != null) {
            return getNumberParam(this.node.rawAttrs, name, defaultValue);
          }
          if (value.s != null) {
            return getStringParam(this.node.rawAttrs, name, defaultValue);
          }
          if (value.b != null) {
            return getBoolParam(this.node.rawAttrs, name, defaultValue);
          }
          if (value.shape != null) {
            return getTensorShapeParam(this.node.rawAttrs, name, defaultValue);
          }
          if (value.type != null) {
            return getDtypeParam(this.node.rawAttrs, name, defaultValue);
          }
          if (value.list != null) {
            if (value.list.i != null || value.list.f != null) {
              return getNumericArrayParam(this.node.rawAttrs, name, defaultValue);
            }
            if (value.list.s != null) {
              return getStringArrayParam(this.node.rawAttrs, name, defaultValue);
            }
            if (value.list.shape != null) {
              return getTensorShapeArrayParam(this.node.rawAttrs, name, defaultValue);
            }
            if (value.list.b != null) {
              return getBoolArrayParam(this.node.rawAttrs, name, defaultValue);
            }
            if (value.list.type != null) {
              return getDtypeArrayParam(this.node.rawAttrs, name, defaultValue);
            }
          }
          return defaultValue;
        };
        return NodeValueImpl2;
      }()
    );
    var EPSILON_FLOAT32 = 1e-7;
    var EPSILON_FLOAT16 = 1e-4;
    var KernelBackend = (
      /** @class */
      function() {
        function KernelBackend2() {
        }
        KernelBackend2.prototype.refCount = function(dataId) {
          return notYetImplemented("refCount");
        };
        KernelBackend2.prototype.incRef = function(dataId) {
          return notYetImplemented("incRef");
        };
        KernelBackend2.prototype.timerAvailable = function() {
          return true;
        };
        KernelBackend2.prototype.time = function(f) {
          return notYetImplemented("time");
        };
        KernelBackend2.prototype.read = function(dataId) {
          return notYetImplemented("read");
        };
        KernelBackend2.prototype.readSync = function(dataId) {
          return notYetImplemented("readSync");
        };
        KernelBackend2.prototype.readToGPU = function(dataId, options) {
          return notYetImplemented("readToGPU");
        };
        KernelBackend2.prototype.numDataIds = function() {
          return notYetImplemented("numDataIds");
        };
        KernelBackend2.prototype.disposeData = function(dataId, force) {
          return notYetImplemented("disposeData");
        };
        KernelBackend2.prototype.write = function(values, shape, dtype) {
          return notYetImplemented("write");
        };
        KernelBackend2.prototype.move = function(dataId, values, shape, dtype, refCount) {
          return notYetImplemented("move");
        };
        KernelBackend2.prototype.createTensorFromGPUData = function(values, shape, dtype) {
          return notYetImplemented("createTensorFromGPUData");
        };
        KernelBackend2.prototype.memory = function() {
          return notYetImplemented("memory");
        };
        KernelBackend2.prototype.floatPrecision = function() {
          return notYetImplemented("floatPrecision");
        };
        KernelBackend2.prototype.epsilon = function() {
          return this.floatPrecision() === 32 ? EPSILON_FLOAT32 : EPSILON_FLOAT16;
        };
        KernelBackend2.prototype.dispose = function() {
          return notYetImplemented("dispose");
        };
        return KernelBackend2;
      }()
    );
    function notYetImplemented(kernelName) {
      throw new Error("'".concat(kernelName, "' not yet implemented or not found in the registry. ") + "This kernel may not be supported by the tfjs backend you have chosen");
    }
    function assert(expr, msg) {
      if (!expr) {
        throw new Error(typeof msg === "string" ? msg : msg());
      }
    }
    function assertShapesMatch(shapeA, shapeB, errorMessagePrefix) {
      if (errorMessagePrefix === void 0) {
        errorMessagePrefix = "";
      }
      assert(arraysEqual(shapeA, shapeB), function() {
        return errorMessagePrefix + " Shapes ".concat(shapeA, " and ").concat(shapeB, " must match");
      });
    }
    function assertNonNull(a) {
      assert(a != null, function() {
        return "The input to the tensor constructor must be a non-null value.";
      });
    }
    function sizeFromShape(shape) {
      if (shape.length === 0) {
        return 1;
      }
      var size = shape[0];
      for (var i = 1; i < shape.length; i++) {
        size *= shape[i];
      }
      return size;
    }
    function arraysEqualWithNull(n1, n2) {
      if (n1 === n2) {
        return true;
      }
      if (n1 == null || n2 == null) {
        return false;
      }
      if (n1.length !== n2.length) {
        return false;
      }
      for (var i = 0; i < n1.length; i++) {
        if (n1[i] !== null && n2[i] !== null && n1[i] !== n2[i]) {
          return false;
        }
      }
      return true;
    }
    function arraysEqual(n1, n2) {
      if (n1 === n2) {
        return true;
      }
      if (n1 == null || n2 == null) {
        return false;
      }
      if (n1.length !== n2.length) {
        return false;
      }
      for (var i = 0; i < n1.length; i++) {
        if (n1[i] !== n2[i]) {
          return false;
        }
      }
      return true;
    }
    function isInt(a) {
      return a % 1 === 0;
    }
    function rightPad(a, size) {
      if (size <= a.length) {
        return a;
      }
      return a + " ".repeat(size - a.length);
    }
    function parseAxisParam(axis, shape) {
      var rank = shape.length;
      axis = axis == null ? shape.map(function(s, i) {
        return i;
      }) : [].concat(axis);
      assert(axis.every(function(ax) {
        return ax >= -rank && ax < rank;
      }), function() {
        return "All values in axis param must be in range [-".concat(rank, ", ").concat(rank, ") but ") + "got axis ".concat(axis);
      });
      assert(axis.every(function(ax) {
        return isInt(ax);
      }), function() {
        return "All values in axis param must be integers but " + "got axis ".concat(axis);
      });
      return axis.map(function(a) {
        return a < 0 ? rank + a : a;
      });
    }
    function squeezeShape(shape, axis) {
      var newShape = [];
      var keptDims = [];
      var isEmptyArray = axis != null && Array.isArray(axis) && axis.length === 0;
      var axes = axis == null || isEmptyArray ? null : parseAxisParam(axis, shape).sort();
      var j = 0;
      for (var i = 0; i < shape.length; ++i) {
        if (axes != null) {
          if (axes[j] === i && shape[i] !== 1) {
            throw new Error("Can't squeeze axis ".concat(i, " since its dim '").concat(shape[i], "' is not 1"));
          }
          if ((axes[j] == null || axes[j] > i) && shape[i] === 1) {
            newShape.push(shape[i]);
            keptDims.push(i);
          }
          if (axes[j] <= i) {
            j++;
          }
        }
        if (shape[i] !== 1) {
          newShape.push(shape[i]);
          keptDims.push(i);
        }
      }
      return { newShape, keptDims };
    }
    function getTypedArrayFromDType(dtype, size) {
      return getArrayFromDType(dtype, size);
    }
    function getArrayFromDType(dtype, size) {
      var values = null;
      if (dtype == null || dtype === "float32") {
        values = new Float32Array(size);
      } else if (dtype === "int32") {
        values = new Int32Array(size);
      } else if (dtype === "bool") {
        values = new Uint8Array(size);
      } else if (dtype === "string") {
        values = new Array(size);
      } else {
        throw new Error("Unknown data type ".concat(dtype));
      }
      return values;
    }
    function checkConversionForErrors(vals, dtype) {
      for (var i = 0; i < vals.length; i++) {
        var num = vals[i];
        if (isNaN(num) || !isFinite(num)) {
          throw Error("A tensor of type ".concat(dtype, " being uploaded contains ").concat(num, "."));
        }
      }
    }
    function isValidDtype(dtype) {
      return dtype === "bool" || dtype === "complex64" || dtype === "float32" || dtype === "int32" || dtype === "string";
    }
    function bytesPerElement(dtype) {
      if (dtype === "float32" || dtype === "int32") {
        return 4;
      } else if (dtype === "complex64") {
        return 8;
      } else if (dtype === "bool") {
        return 1;
      } else {
        throw new Error("Unknown dtype ".concat(dtype));
      }
    }
    function bytesFromStringArray(arr) {
      if (arr == null) {
        return 0;
      }
      var bytes = 0;
      arr.forEach(function(x) {
        return bytes += x.length;
      });
      return bytes;
    }
    function isString(value) {
      return typeof value === "string" || value instanceof String;
    }
    function isBoolean(value) {
      return typeof value === "boolean";
    }
    function isNumber(value) {
      return typeof value === "number";
    }
    function inferDtype(values) {
      if (Array.isArray(values)) {
        return inferDtype(values[0]);
      }
      if (values instanceof Float32Array) {
        return "float32";
      } else if (values instanceof Int32Array || values instanceof Uint8Array || values instanceof Uint8ClampedArray) {
        return "int32";
      } else if (isNumber(values)) {
        return "float32";
      } else if (isString(values)) {
        return "string";
      } else if (isBoolean(values)) {
        return "bool";
      }
      return "float32";
    }
    function isFunction(f) {
      return !!(f && f.constructor && f.call && f.apply);
    }
    function computeStrides(shape) {
      var rank = shape.length;
      if (rank < 2) {
        return [];
      }
      var strides = new Array(rank - 1);
      strides[rank - 2] = shape[rank - 1];
      for (var i = rank - 3; i >= 0; --i) {
        strides[i] = strides[i + 1] * shape[i + 1];
      }
      return strides;
    }
    function createNestedArray(offset, shape, a, isComplex) {
      if (isComplex === void 0) {
        isComplex = false;
      }
      var ret = new Array();
      if (shape.length === 1) {
        var d = shape[0] * (isComplex ? 2 : 1);
        for (var i = 0; i < d; i++) {
          ret[i] = a[offset + i];
        }
      } else {
        var d = shape[0];
        var rest = shape.slice(1);
        var len = rest.reduce(function(acc, c) {
          return acc * c;
        }) * (isComplex ? 2 : 1);
        for (var i = 0; i < d; i++) {
          ret[i] = createNestedArray(offset + i * len, rest, a, isComplex);
        }
      }
      return ret;
    }
    function toNestedArray(shape, a, isComplex) {
      if (isComplex === void 0) {
        isComplex = false;
      }
      if (shape.length === 0) {
        return a[0];
      }
      var size = shape.reduce(function(acc, c) {
        return acc * c;
      }) * (isComplex ? 2 : 1);
      if (size === 0) {
        return [];
      }
      if (size !== a.length) {
        throw new Error("[".concat(shape, "] does not match the input size ").concat(a.length).concat(isComplex ? " for a complex tensor" : "", "."));
      }
      return createNestedArray(0, shape, a, isComplex);
    }
    function makeOnesTypedArray(size, dtype) {
      var array = makeZerosTypedArray(size, dtype);
      for (var i = 0; i < array.length; i++) {
        array[i] = 1;
      }
      return array;
    }
    function makeZerosTypedArray(size, dtype) {
      if (dtype == null || dtype === "float32" || dtype === "complex64") {
        return new Float32Array(size);
      } else if (dtype === "int32") {
        return new Int32Array(size);
      } else if (dtype === "bool") {
        return new Uint8Array(size);
      } else {
        throw new Error("Unknown data type ".concat(dtype));
      }
    }
    function assertNonNegativeIntegerDimensions(shape) {
      shape.forEach(function(dimSize) {
        assert(Number.isInteger(dimSize) && dimSize >= 0, function() {
          return "Tensor must have a shape comprised of positive integers but got " + "shape [".concat(shape, "].");
        });
      });
    }
    function isPromise(object) {
      return object && object.then && typeof object.then === "function";
    }
    var TENSORFLOWJS_FLAGS_PREFIX = "tfjsflags";
    var Environment = (
      /** @class */
      function() {
        function Environment2(global2) {
          this.global = global2;
          this.flags = {};
          this.flagRegistry = {};
          this.urlFlags = {};
          this.getQueryParams = getQueryParams;
          this.populateURLFlags();
        }
        Environment2.prototype.setPlatform = function(platformName, platform) {
          if (this.platform != null) {
            if (!(env().getBool("IS_TEST") || env().getBool("PROD"))) {
              console.warn("Platform ".concat(this.platformName, " has already been set. ") + "Overwriting the platform with ".concat(platformName, "."));
            }
          }
          this.platformName = platformName;
          this.platform = platform;
        };
        Environment2.prototype.registerFlag = function(flagName, evaluationFn, setHook) {
          this.flagRegistry[flagName] = { evaluationFn, setHook };
          if (this.urlFlags[flagName] != null) {
            var flagValue = this.urlFlags[flagName];
            if (!(env().getBool("IS_TEST") || env().getBool("PROD"))) {
              console.warn("Setting feature override from URL ".concat(flagName, ": ").concat(flagValue, "."));
            }
            this.set(flagName, flagValue);
          }
        };
        Environment2.prototype.getAsync = function(flagName) {
          return __awaiter(this, void 0, void 0, function() {
            var _a, _b;
            return __generator(this, function(_c) {
              switch (_c.label) {
                case 0:
                  if (flagName in this.flags) {
                    return [2, this.flags[flagName]];
                  }
                  _a = this.flags;
                  _b = flagName;
                  return [4, this.evaluateFlag(flagName)];
                case 1:
                  _a[_b] = _c.sent();
                  return [2, this.flags[flagName]];
              }
            });
          });
        };
        Environment2.prototype.get = function(flagName) {
          if (flagName in this.flags) {
            return this.flags[flagName];
          }
          var flagValue = this.evaluateFlag(flagName);
          if (isPromise(flagValue)) {
            throw new Error("Flag ".concat(flagName, " cannot be synchronously evaluated. ") + "Please use getAsync() instead.");
          }
          this.flags[flagName] = flagValue;
          return this.flags[flagName];
        };
        Environment2.prototype.getNumber = function(flagName) {
          return this.get(flagName);
        };
        Environment2.prototype.getBool = function(flagName) {
          return this.get(flagName);
        };
        Environment2.prototype.getString = function(flagName) {
          return this.get(flagName);
        };
        Environment2.prototype.getFlags = function() {
          return this.flags;
        };
        Object.defineProperty(Environment2.prototype, "features", {
          // For backwards compatibility.
          get: function() {
            return this.flags;
          },
          enumerable: false,
          configurable: true
        });
        Environment2.prototype.set = function(flagName, value) {
          if (this.flagRegistry[flagName] == null) {
            throw new Error("Cannot set flag ".concat(flagName, " as it has not been registered."));
          }
          this.flags[flagName] = value;
          if (this.flagRegistry[flagName].setHook != null) {
            this.flagRegistry[flagName].setHook(value);
          }
        };
        Environment2.prototype.evaluateFlag = function(flagName) {
          if (this.flagRegistry[flagName] == null) {
            throw new Error("Cannot evaluate flag '".concat(flagName, "': no evaluation function found."));
          }
          return this.flagRegistry[flagName].evaluationFn();
        };
        Environment2.prototype.setFlags = function(flags) {
          this.flags = Object.assign({}, flags);
        };
        Environment2.prototype.reset = function() {
          this.flags = {};
          this.urlFlags = {};
          this.populateURLFlags();
        };
        Environment2.prototype.populateURLFlags = function() {
          var _this = this;
          if (typeof this.global === "undefined" || typeof this.global.location === "undefined" || typeof this.global.location.search === "undefined") {
            return;
          }
          var urlParams = this.getQueryParams(this.global.location.search);
          if (TENSORFLOWJS_FLAGS_PREFIX in urlParams) {
            var keyValues = urlParams[TENSORFLOWJS_FLAGS_PREFIX].split(",");
            keyValues.forEach(function(keyValue) {
              var _a = __read(keyValue.split(":"), 2), key = _a[0], value = _a[1];
              _this.urlFlags[key] = parseValue(key, value);
            });
          }
        };
        return Environment2;
      }()
    );
    function getQueryParams(queryString) {
      var params = {};
      queryString.replace(/[?&]([^=?&]+)(?:=([^&]*))?/g, function(s) {
        var t = [];
        for (var _i = 1; _i < arguments.length; _i++) {
          t[_i - 1] = arguments[_i];
        }
        decodeParam(params, t[0], t[1]);
        return t.join("=");
      });
      return params;
    }
    function decodeParam(params, name, value) {
      params[decodeURIComponent(name)] = decodeURIComponent(value || "");
    }
    function parseValue(flagName, value) {
      var lowerCaseValue = value.toLowerCase();
      if (lowerCaseValue === "true" || lowerCaseValue === "false") {
        return lowerCaseValue === "true";
      } else if ("".concat(+lowerCaseValue) === lowerCaseValue) {
        return +lowerCaseValue;
      } else {
        return value;
      }
    }
    function env() {
      return ENV;
    }
    var ENV = null;
    function setEnvironmentGlobal(environment) {
      ENV = environment;
    }
    var globalNameSpace;
    function getGlobalNamespace() {
      if (globalNameSpace == null) {
        var ns = void 0;
        if (typeof window !== "undefined") {
          ns = window;
        } else if (typeof global !== "undefined") {
          ns = global;
        } else if (typeof process !== "undefined") {
          ns = process;
        } else if (typeof self !== "undefined") {
          ns = self;
        } else {
          throw new Error("Could not find a global object");
        }
        globalNameSpace = ns;
      }
      return globalNameSpace;
    }
    function getGlobalMap() {
      var ns = getGlobalNamespace();
      if (ns._tfGlobals == null) {
        ns._tfGlobals = /* @__PURE__ */ new Map();
      }
      return ns._tfGlobals;
    }
    function getGlobal(key, init) {
      var globalMap = getGlobalMap();
      if (globalMap.has(key)) {
        return globalMap.get(key);
      } else {
        var singleton = init();
        globalMap.set(key, singleton);
        return globalMap.get(key);
      }
    }
    var Abs = "Abs";
    var Acos = "Acos";
    var Acosh = "Acosh";
    var Add = "Add";
    var AddN = "AddN";
    var All = "All";
    var Any = "Any";
    var ArgMax = "ArgMax";
    var ArgMin = "ArgMin";
    var Asin = "Asin";
    var Asinh = "Asinh";
    var Atan = "Atan";
    var Atanh = "Atanh";
    var Atan2 = "Atan2";
    var AvgPool = "AvgPool";
    var AvgPool3D = "AvgPool3D";
    var BatchMatMul = "BatchMatMul";
    var BatchToSpaceND = "BatchToSpaceND";
    var Bincount = "Bincount";
    var BitwiseAnd = "BitwiseAnd";
    var BroadcastArgs = "BroadcastArgs";
    var Cast = "Cast";
    var Ceil = "Ceil";
    var ClipByValue = "ClipByValue";
    var Complex = "Complex";
    var ComplexAbs = "ComplexAbs";
    var Concat = "Concat";
    var Conv2D = "Conv2D";
    var Conv2DBackpropFilter = "Conv2DBackpropFilter";
    var Conv2DBackpropInput = "Conv2DBackpropInput";
    var Conv3D = "Conv3D";
    var Conv3DBackpropInputV2 = "Conv3DBackpropInputV2";
    var Cos = "Cos";
    var Cosh = "Cosh";
    var Cumprod = "Cumprod";
    var Cumsum = "Cumsum";
    var CropAndResize = "CropAndResize";
    var DenseBincount = "DenseBincount";
    var DepthToSpace = "DepthToSpace";
    var DepthwiseConv2dNative = "DepthwiseConv2dNative";
    var DepthwiseConv2dNativeBackpropFilter = "DepthwiseConv2dNativeBackpropFilter";
    var DepthwiseConv2dNativeBackpropInput = "DepthwiseConv2dNativeBackpropInput";
    var Diag = "Diag";
    var Dilation2D = "Dilation2D";
    var RealDiv = "RealDiv";
    var Einsum = "Einsum";
    var Elu = "Elu";
    var Erf = "Erf";
    var Equal = "Equal";
    var Exp = "Exp";
    var ExpandDims = "ExpandDims";
    var Expm1 = "Expm1";
    var FFT = "FFT";
    var Fill = "Fill";
    var FlipLeftRight = "FlipLeftRight";
    var Floor = "Floor";
    var FloorDiv = "FloorDiv";
    var FusedBatchNorm = "FusedBatchNorm";
    var GatherV2 = "GatherV2";
    var GatherNd = "GatherNd";
    var Greater = "Greater";
    var GreaterEqual = "GreaterEqual";
    var Identity = "Identity";
    var IFFT = "IFFT";
    var Imag = "Imag";
    var IsFinite = "IsFinite";
    var IsInf = "IsInf";
    var IsNan = "IsNan";
    var LeakyRelu = "LeakyRelu";
    var Less = "Less";
    var LessEqual = "LessEqual";
    var LinSpace = "LinSpace";
    var Log = "Log";
    var Log1p = "Log1p";
    var LogicalAnd = "LogicalAnd";
    var LogicalNot = "LogicalNot";
    var LogicalOr = "LogicalOr";
    var LRN = "LRN";
    var Max = "Max";
    var Maximum = "Maximum";
    var MaxPool = "MaxPool";
    var MaxPool3D = "MaxPool3D";
    var MaxPoolWithArgmax = "MaxPoolWithArgmax";
    var Mean = "Mean";
    var Min = "Min";
    var Minimum = "Minimum";
    var MirrorPad = "MirrorPad";
    var Mod = "Mod";
    var Multinomial = "Multinomial";
    var Multiply = "Multiply";
    var Neg = "Neg";
    var NotEqual = "NotEqual";
    var NonMaxSuppressionV3 = "NonMaxSuppressionV3";
    var NonMaxSuppressionV4 = "NonMaxSuppressionV4";
    var NonMaxSuppressionV5 = "NonMaxSuppressionV5";
    var OnesLike = "OnesLike";
    var OneHot = "OneHot";
    var Pack = "Pack";
    var PadV2 = "PadV2";
    var Pow = "Pow";
    var Prelu = "Prelu";
    var Prod = "Prod";
    var RaggedGather = "RaggedGather";
    var RaggedRange = "RaggedRange";
    var RaggedTensorToTensor = "RaggedTensorToTensor";
    var Range = "Range";
    var Real = "Real";
    var Reciprocal = "Reciprocal";
    var Relu = "Relu";
    var Reshape = "Reshape";
    var ResizeNearestNeighbor = "ResizeNearestNeighbor";
    var ResizeBilinear = "ResizeBilinear";
    var Relu6 = "Relu6";
    var Reverse = "Reverse";
    var Round = "Round";
    var Rsqrt = "Rsqrt";
    var ScatterNd = "ScatterNd";
    var TensorScatterUpdate = "TensorScatterUpdate";
    var SearchSorted = "SearchSorted";
    var Select = "Select";
    var Selu = "Selu";
    var Slice = "Slice";
    var Sin = "Sin";
    var Sinh = "Sinh";
    var Sign = "Sign";
    var Sigmoid = "Sigmoid";
    var Softplus = "Softplus";
    var Sqrt = "Sqrt";
    var Sum = "Sum";
    var SpaceToBatchND = "SpaceToBatchND";
    var SplitV = "SplitV";
    var Softmax = "Softmax";
    var SparseFillEmptyRows = "SparseFillEmptyRows";
    var SparseReshape = "SparseReshape";
    var SparseSegmentMean = "SparseSegmentMean";
    var SparseSegmentSum = "SparseSegmentSum";
    var SparseToDense = "SparseToDense";
    var SquaredDifference = "SquaredDifference";
    var StaticRegexReplace = "StaticRegexReplace";
    var StridedSlice = "StridedSlice";
    var StringNGrams = "StringNGrams";
    var StringSplit = "StringSplit";
    var StringToHashBucketFast = "StringToHashBucketFast";
    var Sub = "Sub";
    var Tan = "Tan";
    var Tanh = "Tanh";
    var Tile = "Tile";
    var TopK = "TopK";
    var Transform = "Transform";
    var Transpose = "Transpose";
    var Unique = "Unique";
    var Unpack = "Unpack";
    var UnsortedSegmentSum = "UnsortedSegmentSum";
    var ZerosLike = "ZerosLike";
    var Step = "Step";
    var RotateWithOffset = "RotateWithOffset";
    var _FusedMatMul = "_FusedMatMul";
    var FusedConv2D = "FusedConv2D";
    var FusedDepthwiseConv2D = "FusedDepthwiseConv2D";
    function warn() {
      var msg = [];
      for (var _i = 0; _i < arguments.length; _i++) {
        msg[_i] = arguments[_i];
      }
      if (!(env().getBool("IS_TEST") || env().getBool("PROD"))) {
        console.warn.apply(console, __spreadArray([], __read(msg), false));
      }
    }
    var kernelRegistry = getGlobal("kernelRegistry", function() {
      return /* @__PURE__ */ new Map();
    });
    var gradRegistry = getGlobal("gradRegistry", function() {
      return /* @__PURE__ */ new Map();
    });
    function getKernel(kernelName, backendName) {
      var key = makeKey(kernelName, backendName);
      return kernelRegistry.get(key);
    }
    function getGradient(kernelName) {
      return gradRegistry.get(kernelName);
    }
    function getKernelsForBackend(backendName) {
      var it = kernelRegistry.entries();
      var result = [];
      while (true) {
        var _a = it.next(), done = _a.done, value = _a.value;
        if (done) {
          break;
        }
        var _b = __read(value, 2), key = _b[0], config = _b[1];
        var _c = __read(key.split("_"), 1), backend = _c[0];
        if (backend === backendName) {
          result.push(config);
        }
      }
      return result;
    }
    function makeKey(kernelName, backendName) {
      return "".concat(backendName, "_").concat(kernelName);
    }
    function isTypedArrayBrowser(a) {
      return a instanceof Float32Array || a instanceof Int32Array || a instanceof Uint8Array || a instanceof Uint8ClampedArray;
    }
    var commonjsGlobal = typeof globalThis !== "undefined" ? globalThis : typeof window !== "undefined" ? window : typeof global !== "undefined" ? global : typeof self !== "undefined" ? self : {};
    function getDefaultExportFromCjs(x) {
      return x && x.__esModule && Object.prototype.hasOwnProperty.call(x, "default") ? x["default"] : x;
    }
    function getAugmentedNamespace(n) {
      if (n.__esModule)
        return n;
      var f = n.default;
      if (typeof f == "function") {
        var a = function a2() {
          if (this instanceof a2) {
            var args = [null];
            args.push.apply(args, arguments);
            var Ctor = Function.bind.apply(f, args);
            return new Ctor();
          }
          return f.apply(this, arguments);
        };
        a.prototype = f.prototype;
      } else
        a = {};
      Object.defineProperty(a, "__esModule", { value: true });
      Object.keys(n).forEach(function(k) {
        var d = Object.getOwnPropertyDescriptor(n, k);
        Object.defineProperty(a, k, d.get ? d : {
          enumerable: true,
          get: function() {
            return n[k];
          }
        });
      });
      return a;
    }
    var long = Long$1;
    var wasm = null;
    try {
      wasm = new WebAssembly.Instance(new WebAssembly.Module(new Uint8Array([
        0,
        97,
        115,
        109,
        1,
        0,
        0,
        0,
        1,
        13,
        2,
        96,
        0,
        1,
        127,
        96,
        4,
        127,
        127,
        127,
        127,
        1,
        127,
        3,
        7,
        6,
        0,
        1,
        1,
        1,
        1,
        1,
        6,
        6,
        1,
        127,
        1,
        65,
        0,
        11,
        7,
        50,
        6,
        3,
        109,
        117,
        108,
        0,
        1,
        5,
        100,
        105,
        118,
        95,
        115,
        0,
        2,
        5,
        100,
        105,
        118,
        95,
        117,
        0,
        3,
        5,
        114,
        101,
        109,
        95,
        115,
        0,
        4,
        5,
        114,
        101,
        109,
        95,
        117,
        0,
        5,
        8,
        103,
        101,
        116,
        95,
        104,
        105,
        103,
        104,
        0,
        0,
        10,
        191,
        1,
        6,
        4,
        0,
        35,
        0,
        11,
        36,
        1,
        1,
        126,
        32,
        0,
        173,
        32,
        1,
        173,
        66,
        32,
        134,
        132,
        32,
        2,
        173,
        32,
        3,
        173,
        66,
        32,
        134,
        132,
        126,
        34,
        4,
        66,
        32,
        135,
        167,
        36,
        0,
        32,
        4,
        167,
        11,
        36,
        1,
        1,
        126,
        32,
        0,
        173,
        32,
        1,
        173,
        66,
        32,
        134,
        132,
        32,
        2,
        173,
        32,
        3,
        173,
        66,
        32,
        134,
        132,
        127,
        34,
        4,
        66,
        32,
        135,
        167,
        36,
        0,
        32,
        4,
        167,
        11,
        36,
        1,
        1,
        126,
        32,
        0,
        173,
        32,
        1,
        173,
        66,
        32,
        134,
        132,
        32,
        2,
        173,
        32,
        3,
        173,
        66,
        32,
        134,
        132,
        128,
        34,
        4,
        66,
        32,
        135,
        167,
        36,
        0,
        32,
        4,
        167,
        11,
        36,
        1,
        1,
        126,
        32,
        0,
        173,
        32,
        1,
        173,
        66,
        32,
        134,
        132,
        32,
        2,
        173,
        32,
        3,
        173,
        66,
        32,
        134,
        132,
        129,
        34,
        4,
        66,
        32,
        135,
        167,
        36,
        0,
        32,
        4,
        167,
        11,
        36,
        1,
        1,
        126,
        32,
        0,
        173,
        32,
        1,
        173,
        66,
        32,
        134,
        132,
        32,
        2,
        173,
        32,
        3,
        173,
        66,
        32,
        134,
        132,
        130,
        34,
        4,
        66,
        32,
        135,
        167,
        36,
        0,
        32,
        4,
        167,
        11
      ])), {}).exports;
    } catch (e) {
    }
    function Long$1(low, high, unsigned) {
      this.low = low | 0;
      this.high = high | 0;
      this.unsigned = !!unsigned;
    }
    Long$1.prototype.__isLong__;
    Object.defineProperty(Long$1.prototype, "__isLong__", { value: true });
    function isLong(obj) {
      return (obj && obj["__isLong__"]) === true;
    }
    Long$1.isLong = isLong;
    var INT_CACHE = {};
    var UINT_CACHE = {};
    function fromInt(value, unsigned) {
      var obj, cachedObj, cache;
      if (unsigned) {
        value >>>= 0;
        if (cache = 0 <= value && value < 256) {
          cachedObj = UINT_CACHE[value];
          if (cachedObj)
            return cachedObj;
        }
        obj = fromBits(value, (value | 0) < 0 ? -1 : 0, true);
        if (cache)
          UINT_CACHE[value] = obj;
        return obj;
      } else {
        value |= 0;
        if (cache = -128 <= value && value < 128) {
          cachedObj = INT_CACHE[value];
          if (cachedObj)
            return cachedObj;
        }
        obj = fromBits(value, value < 0 ? -1 : 0, false);
        if (cache)
          INT_CACHE[value] = obj;
        return obj;
      }
    }
    Long$1.fromInt = fromInt;
    function fromNumber(value, unsigned) {
      if (isNaN(value))
        return unsigned ? UZERO : ZERO;
      if (unsigned) {
        if (value < 0)
          return UZERO;
        if (value >= TWO_PWR_64_DBL)
          return MAX_UNSIGNED_VALUE;
      } else {
        if (value <= -TWO_PWR_63_DBL)
          return MIN_VALUE;
        if (value + 1 >= TWO_PWR_63_DBL)
          return MAX_VALUE;
      }
      if (value < 0)
        return fromNumber(-value, unsigned).neg();
      return fromBits(value % TWO_PWR_32_DBL | 0, value / TWO_PWR_32_DBL | 0, unsigned);
    }
    Long$1.fromNumber = fromNumber;
    function fromBits(lowBits, highBits, unsigned) {
      return new Long$1(lowBits, highBits, unsigned);
    }
    Long$1.fromBits = fromBits;
    var pow_dbl = Math.pow;
    function fromString(str, unsigned, radix) {
      if (str.length === 0)
        throw Error("empty string");
      if (str === "NaN" || str === "Infinity" || str === "+Infinity" || str === "-Infinity")
        return ZERO;
      if (typeof unsigned === "number") {
        radix = unsigned, unsigned = false;
      } else {
        unsigned = !!unsigned;
      }
      radix = radix || 10;
      if (radix < 2 || 36 < radix)
        throw RangeError("radix");
      var p;
      if ((p = str.indexOf("-")) > 0)
        throw Error("interior hyphen");
      else if (p === 0) {
        return fromString(str.substring(1), unsigned, radix).neg();
      }
      var radixToPower = fromNumber(pow_dbl(radix, 8));
      var result = ZERO;
      for (var i = 0; i < str.length; i += 8) {
        var size = Math.min(8, str.length - i), value = parseInt(str.substring(i, i + size), radix);
        if (size < 8) {
          var power = fromNumber(pow_dbl(radix, size));
          result = result.mul(power).add(fromNumber(value));
        } else {
          result = result.mul(radixToPower);
          result = result.add(fromNumber(value));
        }
      }
      result.unsigned = unsigned;
      return result;
    }
    Long$1.fromString = fromString;
    function fromValue(val, unsigned) {
      if (typeof val === "number")
        return fromNumber(val, unsigned);
      if (typeof val === "string")
        return fromString(val, unsigned);
      return fromBits(val.low, val.high, typeof unsigned === "boolean" ? unsigned : val.unsigned);
    }
    Long$1.fromValue = fromValue;
    var TWO_PWR_16_DBL = 1 << 16;
    var TWO_PWR_24_DBL = 1 << 24;
    var TWO_PWR_32_DBL = TWO_PWR_16_DBL * TWO_PWR_16_DBL;
    var TWO_PWR_64_DBL = TWO_PWR_32_DBL * TWO_PWR_32_DBL;
    var TWO_PWR_63_DBL = TWO_PWR_64_DBL / 2;
    var TWO_PWR_24 = fromInt(TWO_PWR_24_DBL);
    var ZERO = fromInt(0);
    Long$1.ZERO = ZERO;
    var UZERO = fromInt(0, true);
    Long$1.UZERO = UZERO;
    var ONE = fromInt(1);
    Long$1.ONE = ONE;
    var UONE = fromInt(1, true);
    Long$1.UONE = UONE;
    var NEG_ONE = fromInt(-1);
    Long$1.NEG_ONE = NEG_ONE;
    var MAX_VALUE = fromBits(4294967295 | 0, 2147483647 | 0, false);
    Long$1.MAX_VALUE = MAX_VALUE;
    var MAX_UNSIGNED_VALUE = fromBits(4294967295 | 0, 4294967295 | 0, true);
    Long$1.MAX_UNSIGNED_VALUE = MAX_UNSIGNED_VALUE;
    var MIN_VALUE = fromBits(0, 2147483648 | 0, false);
    Long$1.MIN_VALUE = MIN_VALUE;
    var LongPrototype = Long$1.prototype;
    LongPrototype.toInt = function toInt() {
      return this.unsigned ? this.low >>> 0 : this.low;
    };
    LongPrototype.toNumber = function toNumber() {
      if (this.unsigned)
        return (this.high >>> 0) * TWO_PWR_32_DBL + (this.low >>> 0);
      return this.high * TWO_PWR_32_DBL + (this.low >>> 0);
    };
    LongPrototype.toString = function toString(radix) {
      radix = radix || 10;
      if (radix < 2 || 36 < radix)
        throw RangeError("radix");
      if (this.isZero())
        return "0";
      if (this.isNegative()) {
        if (this.eq(MIN_VALUE)) {
          var radixLong = fromNumber(radix), div2 = this.div(radixLong), rem1 = div2.mul(radixLong).sub(this);
          return div2.toString(radix) + rem1.toInt().toString(radix);
        } else
          return "-" + this.neg().toString(radix);
      }
      var radixToPower = fromNumber(pow_dbl(radix, 6), this.unsigned), rem = this;
      var result = "";
      while (true) {
        var remDiv = rem.div(radixToPower), intval = rem.sub(remDiv.mul(radixToPower)).toInt() >>> 0, digits = intval.toString(radix);
        rem = remDiv;
        if (rem.isZero())
          return digits + result;
        else {
          while (digits.length < 6)
            digits = "0" + digits;
          result = "" + digits + result;
        }
      }
    };
    LongPrototype.getHighBits = function getHighBits() {
      return this.high;
    };
    LongPrototype.getHighBitsUnsigned = function getHighBitsUnsigned() {
      return this.high >>> 0;
    };
    LongPrototype.getLowBits = function getLowBits() {
      return this.low;
    };
    LongPrototype.getLowBitsUnsigned = function getLowBitsUnsigned() {
      return this.low >>> 0;
    };
    LongPrototype.getNumBitsAbs = function getNumBitsAbs() {
      if (this.isNegative())
        return this.eq(MIN_VALUE) ? 64 : this.neg().getNumBitsAbs();
      var val = this.high != 0 ? this.high : this.low;
      for (var bit = 31; bit > 0; bit--)
        if ((val & 1 << bit) != 0)
          break;
      return this.high != 0 ? bit + 33 : bit + 1;
    };
    LongPrototype.isZero = function isZero() {
      return this.high === 0 && this.low === 0;
    };
    LongPrototype.eqz = LongPrototype.isZero;
    LongPrototype.isNegative = function isNegative() {
      return !this.unsigned && this.high < 0;
    };
    LongPrototype.isPositive = function isPositive() {
      return this.unsigned || this.high >= 0;
    };
    LongPrototype.isOdd = function isOdd() {
      return (this.low & 1) === 1;
    };
    LongPrototype.isEven = function isEven() {
      return (this.low & 1) === 0;
    };
    LongPrototype.equals = function equals(other) {
      if (!isLong(other))
        other = fromValue(other);
      if (this.unsigned !== other.unsigned && this.high >>> 31 === 1 && other.high >>> 31 === 1)
        return false;
      return this.high === other.high && this.low === other.low;
    };
    LongPrototype.eq = LongPrototype.equals;
    LongPrototype.notEquals = function notEquals(other) {
      return !this.eq(
        /* validates */
        other
      );
    };
    LongPrototype.neq = LongPrototype.notEquals;
    LongPrototype.ne = LongPrototype.notEquals;
    LongPrototype.lessThan = function lessThan(other) {
      return this.comp(
        /* validates */
        other
      ) < 0;
    };
    LongPrototype.lt = LongPrototype.lessThan;
    LongPrototype.lessThanOrEqual = function lessThanOrEqual(other) {
      return this.comp(
        /* validates */
        other
      ) <= 0;
    };
    LongPrototype.lte = LongPrototype.lessThanOrEqual;
    LongPrototype.le = LongPrototype.lessThanOrEqual;
    LongPrototype.greaterThan = function greaterThan(other) {
      return this.comp(
        /* validates */
        other
      ) > 0;
    };
    LongPrototype.gt = LongPrototype.greaterThan;
    LongPrototype.greaterThanOrEqual = function greaterThanOrEqual(other) {
      return this.comp(
        /* validates */
        other
      ) >= 0;
    };
    LongPrototype.gte = LongPrototype.greaterThanOrEqual;
    LongPrototype.ge = LongPrototype.greaterThanOrEqual;
    LongPrototype.compare = function compare(other) {
      if (!isLong(other))
        other = fromValue(other);
      if (this.eq(other))
        return 0;
      var thisNeg = this.isNegative(), otherNeg = other.isNegative();
      if (thisNeg && !otherNeg)
        return -1;
      if (!thisNeg && otherNeg)
        return 1;
      if (!this.unsigned)
        return this.sub(other).isNegative() ? -1 : 1;
      return other.high >>> 0 > this.high >>> 0 || other.high === this.high && other.low >>> 0 > this.low >>> 0 ? -1 : 1;
    };
    LongPrototype.comp = LongPrototype.compare;
    LongPrototype.negate = function negate() {
      if (!this.unsigned && this.eq(MIN_VALUE))
        return MIN_VALUE;
      return this.not().add(ONE);
    };
    LongPrototype.neg = LongPrototype.negate;
    LongPrototype.add = function add2(addend) {
      if (!isLong(addend))
        addend = fromValue(addend);
      var a48 = this.high >>> 16;
      var a32 = this.high & 65535;
      var a16 = this.low >>> 16;
      var a00 = this.low & 65535;
      var b48 = addend.high >>> 16;
      var b32 = addend.high & 65535;
      var b16 = addend.low >>> 16;
      var b00 = addend.low & 65535;
      var c48 = 0, c32 = 0, c16 = 0, c00 = 0;
      c00 += a00 + b00;
      c16 += c00 >>> 16;
      c00 &= 65535;
      c16 += a16 + b16;
      c32 += c16 >>> 16;
      c16 &= 65535;
      c32 += a32 + b32;
      c48 += c32 >>> 16;
      c32 &= 65535;
      c48 += a48 + b48;
      c48 &= 65535;
      return fromBits(c16 << 16 | c00, c48 << 16 | c32, this.unsigned);
    };
    LongPrototype.subtract = function subtract(subtrahend) {
      if (!isLong(subtrahend))
        subtrahend = fromValue(subtrahend);
      return this.add(subtrahend.neg());
    };
    LongPrototype.sub = LongPrototype.subtract;
    LongPrototype.multiply = function multiply(multiplier) {
      if (this.isZero())
        return ZERO;
      if (!isLong(multiplier))
        multiplier = fromValue(multiplier);
      if (wasm) {
        var low = wasm.mul(this.low, this.high, multiplier.low, multiplier.high);
        return fromBits(low, wasm.get_high(), this.unsigned);
      }
      if (multiplier.isZero())
        return ZERO;
      if (this.eq(MIN_VALUE))
        return multiplier.isOdd() ? MIN_VALUE : ZERO;
      if (multiplier.eq(MIN_VALUE))
        return this.isOdd() ? MIN_VALUE : ZERO;
      if (this.isNegative()) {
        if (multiplier.isNegative())
          return this.neg().mul(multiplier.neg());
        else
          return this.neg().mul(multiplier).neg();
      } else if (multiplier.isNegative())
        return this.mul(multiplier.neg()).neg();
      if (this.lt(TWO_PWR_24) && multiplier.lt(TWO_PWR_24))
        return fromNumber(this.toNumber() * multiplier.toNumber(), this.unsigned);
      var a48 = this.high >>> 16;
      var a32 = this.high & 65535;
      var a16 = this.low >>> 16;
      var a00 = this.low & 65535;
      var b48 = multiplier.high >>> 16;
      var b32 = multiplier.high & 65535;
      var b16 = multiplier.low >>> 16;
      var b00 = multiplier.low & 65535;
      var c48 = 0, c32 = 0, c16 = 0, c00 = 0;
      c00 += a00 * b00;
      c16 += c00 >>> 16;
      c00 &= 65535;
      c16 += a16 * b00;
      c32 += c16 >>> 16;
      c16 &= 65535;
      c16 += a00 * b16;
      c32 += c16 >>> 16;
      c16 &= 65535;
      c32 += a32 * b00;
      c48 += c32 >>> 16;
      c32 &= 65535;
      c32 += a16 * b16;
      c48 += c32 >>> 16;
      c32 &= 65535;
      c32 += a00 * b32;
      c48 += c32 >>> 16;
      c32 &= 65535;
      c48 += a48 * b00 + a32 * b16 + a16 * b32 + a00 * b48;
      c48 &= 65535;
      return fromBits(c16 << 16 | c00, c48 << 16 | c32, this.unsigned);
    };
    LongPrototype.mul = LongPrototype.multiply;
    LongPrototype.divide = function divide(divisor) {
      if (!isLong(divisor))
        divisor = fromValue(divisor);
      if (divisor.isZero())
        throw Error("division by zero");
      if (wasm) {
        if (!this.unsigned && this.high === -2147483648 && divisor.low === -1 && divisor.high === -1) {
          return this;
        }
        var low = (this.unsigned ? wasm.div_u : wasm.div_s)(this.low, this.high, divisor.low, divisor.high);
        return fromBits(low, wasm.get_high(), this.unsigned);
      }
      if (this.isZero())
        return this.unsigned ? UZERO : ZERO;
      var approx, rem, res;
      if (!this.unsigned) {
        if (this.eq(MIN_VALUE)) {
          if (divisor.eq(ONE) || divisor.eq(NEG_ONE))
            return MIN_VALUE;
          else if (divisor.eq(MIN_VALUE))
            return ONE;
          else {
            var halfThis = this.shr(1);
            approx = halfThis.div(divisor).shl(1);
            if (approx.eq(ZERO)) {
              return divisor.isNegative() ? ONE : NEG_ONE;
            } else {
              rem = this.sub(divisor.mul(approx));
              res = approx.add(rem.div(divisor));
              return res;
            }
          }
        } else if (divisor.eq(MIN_VALUE))
          return this.unsigned ? UZERO : ZERO;
        if (this.isNegative()) {
          if (divisor.isNegative())
            return this.neg().div(divisor.neg());
          return this.neg().div(divisor).neg();
        } else if (divisor.isNegative())
          return this.div(divisor.neg()).neg();
        res = ZERO;
      } else {
        if (!divisor.unsigned)
          divisor = divisor.toUnsigned();
        if (divisor.gt(this))
          return UZERO;
        if (divisor.gt(this.shru(1)))
          return UONE;
        res = UZERO;
      }
      rem = this;
      while (rem.gte(divisor)) {
        approx = Math.max(1, Math.floor(rem.toNumber() / divisor.toNumber()));
        var log2 = Math.ceil(Math.log(approx) / Math.LN2), delta = log2 <= 48 ? 1 : pow_dbl(2, log2 - 48), approxRes = fromNumber(approx), approxRem = approxRes.mul(divisor);
        while (approxRem.isNegative() || approxRem.gt(rem)) {
          approx -= delta;
          approxRes = fromNumber(approx, this.unsigned);
          approxRem = approxRes.mul(divisor);
        }
        if (approxRes.isZero())
          approxRes = ONE;
        res = res.add(approxRes);
        rem = rem.sub(approxRem);
      }
      return res;
    };
    LongPrototype.div = LongPrototype.divide;
    LongPrototype.modulo = function modulo(divisor) {
      if (!isLong(divisor))
        divisor = fromValue(divisor);
      if (wasm) {
        var low = (this.unsigned ? wasm.rem_u : wasm.rem_s)(this.low, this.high, divisor.low, divisor.high);
        return fromBits(low, wasm.get_high(), this.unsigned);
      }
      return this.sub(this.div(divisor).mul(divisor));
    };
    LongPrototype.mod = LongPrototype.modulo;
    LongPrototype.rem = LongPrototype.modulo;
    LongPrototype.not = function not() {
      return fromBits(~this.low, ~this.high, this.unsigned);
    };
    LongPrototype.and = function and(other) {
      if (!isLong(other))
        other = fromValue(other);
      return fromBits(this.low & other.low, this.high & other.high, this.unsigned);
    };
    LongPrototype.or = function or(other) {
      if (!isLong(other))
        other = fromValue(other);
      return fromBits(this.low | other.low, this.high | other.high, this.unsigned);
    };
    LongPrototype.xor = function xor(other) {
      if (!isLong(other))
        other = fromValue(other);
      return fromBits(this.low ^ other.low, this.high ^ other.high, this.unsigned);
    };
    LongPrototype.shiftLeft = function shiftLeft(numBits) {
      if (isLong(numBits))
        numBits = numBits.toInt();
      if ((numBits &= 63) === 0)
        return this;
      else if (numBits < 32)
        return fromBits(this.low << numBits, this.high << numBits | this.low >>> 32 - numBits, this.unsigned);
      else
        return fromBits(0, this.low << numBits - 32, this.unsigned);
    };
    LongPrototype.shl = LongPrototype.shiftLeft;
    LongPrototype.shiftRight = function shiftRight(numBits) {
      if (isLong(numBits))
        numBits = numBits.toInt();
      if ((numBits &= 63) === 0)
        return this;
      else if (numBits < 32)
        return fromBits(this.low >>> numBits | this.high << 32 - numBits, this.high >> numBits, this.unsigned);
      else
        return fromBits(this.high >> numBits - 32, this.high >= 0 ? 0 : -1, this.unsigned);
    };
    LongPrototype.shr = LongPrototype.shiftRight;
    LongPrototype.shiftRightUnsigned = function shiftRightUnsigned(numBits) {
      if (isLong(numBits))
        numBits = numBits.toInt();
      numBits &= 63;
      if (numBits === 0)
        return this;
      else {
        var high = this.high;
        if (numBits < 32) {
          var low = this.low;
          return fromBits(low >>> numBits | high << 32 - numBits, high >>> numBits, this.unsigned);
        } else if (numBits === 32)
          return fromBits(high, 0, this.unsigned);
        else
          return fromBits(high >>> numBits - 32, 0, this.unsigned);
      }
    };
    LongPrototype.shru = LongPrototype.shiftRightUnsigned;
    LongPrototype.shr_u = LongPrototype.shiftRightUnsigned;
    LongPrototype.toSigned = function toSigned() {
      if (!this.unsigned)
        return this;
      return fromBits(this.low, this.high, false);
    };
    LongPrototype.toUnsigned = function toUnsigned() {
      if (this.unsigned)
        return this;
      return fromBits(this.low, this.high, true);
    };
    LongPrototype.toBytes = function toBytes(le) {
      return le ? this.toBytesLE() : this.toBytesBE();
    };
    LongPrototype.toBytesLE = function toBytesLE() {
      var hi = this.high, lo = this.low;
      return [
        lo & 255,
        lo >>> 8 & 255,
        lo >>> 16 & 255,
        lo >>> 24,
        hi & 255,
        hi >>> 8 & 255,
        hi >>> 16 & 255,
        hi >>> 24
      ];
    };
    LongPrototype.toBytesBE = function toBytesBE() {
      var hi = this.high, lo = this.low;
      return [
        hi >>> 24,
        hi >>> 16 & 255,
        hi >>> 8 & 255,
        hi & 255,
        lo >>> 24,
        lo >>> 16 & 255,
        lo >>> 8 & 255,
        lo & 255
      ];
    };
    Long$1.fromBytes = function fromBytes(bytes, unsigned, le) {
      return le ? Long$1.fromBytesLE(bytes, unsigned) : Long$1.fromBytesBE(bytes, unsigned);
    };
    Long$1.fromBytesLE = function fromBytesLE(bytes, unsigned) {
      return new Long$1(bytes[0] | bytes[1] << 8 | bytes[2] << 16 | bytes[3] << 24, bytes[4] | bytes[5] << 8 | bytes[6] << 16 | bytes[7] << 24, unsigned);
    };
    Long$1.fromBytesBE = function fromBytesBE(bytes, unsigned) {
      return new Long$1(bytes[4] << 24 | bytes[5] << 16 | bytes[6] << 8 | bytes[7], bytes[0] << 24 | bytes[1] << 16 | bytes[2] << 8 | bytes[3], unsigned);
    };
    var long$1 = /* @__PURE__ */ getDefaultExportFromCjs(long);
    var LongExports = /* @__PURE__ */ _mergeNamespaces({
      __proto__: null,
      default: long$1
    }, [long]);
    var Long = (
      // tslint:disable-next-line
      long$1 || LongExports
    );
    function hexToLong(hex) {
      return Long.fromString(hex, true, 16);
    }
    hexToLong("c3a5c85c97cb3127");
    hexToLong("b492b66fbe98f273");
    hexToLong("9ae16a3b2f90404f");
    function noConversionNeeded(a, dtype) {
      return a instanceof Float32Array && dtype === "float32" || a instanceof Int32Array && dtype === "int32" || a instanceof Uint8Array && dtype === "bool";
    }
    function toTypedArray(a, dtype) {
      if (dtype === "string") {
        throw new Error("Cannot convert a string[] to a TypedArray");
      }
      if (Array.isArray(a)) {
        a = flatten(a);
      }
      if (env().getBool("DEBUG")) {
        checkConversionForErrors(a, dtype);
      }
      if (noConversionNeeded(a, dtype)) {
        return a;
      }
      if (dtype == null || dtype === "float32" || dtype === "complex64") {
        return new Float32Array(a);
      } else if (dtype === "int32") {
        return new Int32Array(a);
      } else if (dtype === "bool") {
        var bool = new Uint8Array(a.length);
        for (var i = 0; i < bool.length; ++i) {
          if (Math.round(a[i]) !== 0) {
            bool[i] = 1;
          }
        }
        return bool;
      } else {
        throw new Error("Unknown data type ".concat(dtype));
      }
    }
    function now() {
      return env().platform.now();
    }
    function encodeString(s, encoding) {
      if (encoding === void 0) {
        encoding = "utf-8";
      }
      encoding = encoding || "utf-8";
      return env().platform.encode(s, encoding);
    }
    function decodeString(bytes, encoding) {
      if (encoding === void 0) {
        encoding = "utf-8";
      }
      encoding = encoding || "utf-8";
      return env().platform.decode(bytes, encoding);
    }
    function isTypedArray(a) {
      if (env().platform.isTypedArray != null) {
        return env().platform.isTypedArray(a);
      } else {
        return isTypedArrayBrowser(a);
      }
    }
    function flatten(arr, result, skipTypedArray) {
      var e_1, _a;
      if (result === void 0) {
        result = [];
      }
      if (skipTypedArray === void 0) {
        skipTypedArray = false;
      }
      if (result == null) {
        result = [];
      }
      if (typeof arr === "boolean" || typeof arr === "number" || typeof arr === "string" || isPromise(arr) || arr == null || isTypedArray(arr) && skipTypedArray) {
        result.push(arr);
      } else if (Array.isArray(arr) || isTypedArray(arr)) {
        for (var i = 0; i < arr.length; ++i) {
          flatten(arr[i], result, skipTypedArray);
        }
      } else {
        var maxIndex = -1;
        try {
          for (var _b = __values(Object.keys(arr)), _c = _b.next(); !_c.done; _c = _b.next()) {
            var key = _c.value;
            if (/^([1-9]+[0-9]*|0)$/.test(key)) {
              maxIndex = Math.max(maxIndex, Number(key));
            }
          }
        } catch (e_1_1) {
          e_1 = { error: e_1_1 };
        } finally {
          try {
            if (_c && !_c.done && (_a = _b.return))
              _a.call(_b);
          } finally {
            if (e_1)
              throw e_1.error;
          }
        }
        for (var i = 0; i <= maxIndex; i++) {
          flatten(arr[i], result, skipTypedArray);
        }
      }
      return result;
    }
    var Profiler = (
      /** @class */
      function() {
        function Profiler2(backendTimer, logger) {
          this.backendTimer = backendTimer;
          this.logger = logger;
          if (logger == null) {
            this.logger = new Logger();
          }
        }
        Profiler2.prototype.profileKernel = function(kernelName, inputs, f) {
          var e_1, _a;
          var outputs;
          var holdResultWrapperFn = function() {
            outputs = f();
          };
          var timer;
          var start = now();
          if (this.backendTimer.timerAvailable()) {
            timer = this.backendTimer.time(holdResultWrapperFn);
          } else {
            holdResultWrapperFn();
            try {
              for (var outputs_1 = __values(outputs), outputs_1_1 = outputs_1.next(); !outputs_1_1.done; outputs_1_1 = outputs_1.next()) {
                var output = outputs_1_1.value;
                output.dataSync();
              }
            } catch (e_1_1) {
              e_1 = { error: e_1_1 };
            } finally {
              try {
                if (outputs_1_1 && !outputs_1_1.done && (_a = outputs_1.return))
                  _a.call(outputs_1);
              } finally {
                if (e_1)
                  throw e_1.error;
              }
            }
            timer = Promise.resolve({ kernelMs: now() - start });
          }
          if (env().getBool("CHECK_COMPUTATION_FOR_ERRORS")) {
            var _loop_1 = function(i2) {
              var output2 = outputs[i2];
              output2.data().then(function(tensorVals) {
                checkComputationForErrors(tensorVals, output2.dtype, kernelName);
              });
            };
            for (var i = 0; i < outputs.length; i++) {
              _loop_1(i);
            }
          }
          var kernelProfile = {
            kernelName,
            outputs,
            inputs,
            timeMs: timer.then(function(timing) {
              return timing.kernelMs;
            }),
            extraInfo: timer.then(function(timing) {
              return timing.getExtraProfileInfo != null ? timing.getExtraProfileInfo() : "";
            })
          };
          return kernelProfile;
        };
        Profiler2.prototype.logKernelProfile = function(kernelProfile) {
          var _this = this;
          var kernelName = kernelProfile.kernelName, outputs = kernelProfile.outputs, timeMs = kernelProfile.timeMs, inputs = kernelProfile.inputs, extraInfo = kernelProfile.extraInfo;
          outputs.forEach(function(result) {
            Promise.all([result.data(), timeMs, extraInfo]).then(function(valueContainer) {
              _this.logger.logKernelProfile(kernelName, result, valueContainer[0], valueContainer[1], inputs, valueContainer[2]);
            });
          });
        };
        return Profiler2;
      }()
    );
    function checkComputationForErrors(vals, dtype, kernelName) {
      if (dtype !== "float32") {
        return false;
      }
      for (var i = 0; i < vals.length; i++) {
        var num = vals[i];
        if (isNaN(num) || !isFinite(num)) {
          console.warn("Found ".concat(num, " in the result of '").concat(kernelName, "'"));
          return true;
        }
      }
      return false;
    }
    var Logger = (
      /** @class */
      function() {
        function Logger2() {
        }
        Logger2.prototype.logKernelProfile = function(name, result, vals, timeMs, inputs, extraInfo) {
          var time = typeof timeMs === "number" ? rightPad("".concat(timeMs, "ms"), 9) : timeMs["error"];
          var paddedName = rightPad(name, 25);
          var rank = result.rank;
          var size = result.size;
          var shape = rightPad(result.shape.toString(), 14);
          var inputShapesDescription = "";
          for (var name_1 in inputs) {
            var input = inputs[name_1];
            if (input != null) {
              var inputShape = input.shape || result.shape;
              var inputRank = inputShape.length;
              inputShapesDescription += "".concat(name_1, ": ").concat(inputRank, "D ").concat(inputRank > 0 ? inputShape : "", " ");
            }
          }
          console.log("%c".concat(paddedName, "	%c").concat(time, "	%c").concat(rank, "D ").concat(shape, "	%c").concat(size, "	%c").concat(inputShapesDescription, "	%c").concat(extraInfo), "font-weight:bold", "color:red", "color:blue", "color: orange", "color: green", "color: steelblue");
        };
        return Logger2;
      }()
    );
    function getFilteredNodesXToY(tape, xs, y) {
      var tensorsFromX = {};
      var nodesFromX = {};
      for (var i = 0; i < xs.length; i++) {
        tensorsFromX[xs[i].id] = true;
      }
      for (var i = 0; i < tape.length; i++) {
        var node = tape[i];
        var nodeInputs = node.inputs;
        for (var inputName in nodeInputs) {
          var input = nodeInputs[inputName];
          var anyInputFromX = false;
          for (var j = 0; j < xs.length; j++) {
            if (tensorsFromX[input.id]) {
              node.outputs.forEach(function(output) {
                return tensorsFromX[output.id] = true;
              });
              anyInputFromX = true;
              nodesFromX[node.id] = true;
              break;
            }
          }
          if (anyInputFromX) {
            break;
          }
        }
      }
      var tensorsLeadToY = {};
      tensorsLeadToY[y.id] = true;
      var nodesToY = {};
      for (var i = tape.length - 1; i >= 0; i--) {
        var node = tape[i];
        var nodeInputs = node.inputs;
        for (var j = 0; j < node.outputs.length; j++) {
          if (tensorsLeadToY[node.outputs[j].id]) {
            for (var inputName in nodeInputs) {
              tensorsLeadToY[nodeInputs[inputName].id] = true;
              nodesToY[node.id] = true;
            }
            break;
          }
        }
      }
      var filteredTape = [];
      for (var i = 0; i < tape.length; i++) {
        var node = tape[i];
        if (nodesFromX[node.id] && nodesToY[node.id]) {
          var prunedInputs = {};
          for (var inputName in node.inputs) {
            var nodeInput = node.inputs[inputName];
            if (tensorsFromX[nodeInput.id]) {
              prunedInputs[inputName] = nodeInput;
            }
          }
          var prunedNode = Object.assign({}, node);
          prunedNode.inputs = prunedInputs;
          prunedNode.outputs = node.outputs;
          filteredTape.push(prunedNode);
        }
      }
      return filteredTape;
    }
    function backpropagateGradients(tensorAccumulatedGradientMap, filteredTape, tidy2, add2) {
      var _loop_1 = function(i2) {
        var node = filteredTape[i2];
        var dys = [];
        node.outputs.forEach(function(o) {
          var gradTensor = tensorAccumulatedGradientMap[o.id];
          if (gradTensor != null) {
            dys.push(gradTensor);
          } else {
            dys.push(null);
          }
        });
        if (node.gradient == null) {
          throw new Error("Cannot compute gradient: gradient function not found " + "for ".concat(node.kernelName, "."));
        }
        var inputGradients = node.gradient(dys);
        var _loop_2 = function(inputName2) {
          if (!(inputName2 in inputGradients)) {
            throw new Error("Cannot backprop through input ".concat(inputName2, ". ") + "Available gradients found: ".concat(Object.keys(inputGradients), "."));
          }
          var dx = tidy2(function() {
            return inputGradients[inputName2]();
          });
          if (dx.dtype !== "float32") {
            throw new Error("Error in gradient for op ".concat(node.kernelName, ". The gradient of input ") + "".concat(inputName2, " must have 'float32' dtype, but has '").concat(dx.dtype, "'"));
          }
          var x = node.inputs[inputName2];
          if (!arraysEqual(dx.shape, x.shape)) {
            throw new Error("Error in gradient for op ".concat(node.kernelName, ". The gradient of input ") + "'".concat(inputName2, "' has shape '").concat(dx.shape, "', which does not match ") + "the shape of the input '".concat(x.shape, "'"));
          }
          if (tensorAccumulatedGradientMap[x.id] == null) {
            tensorAccumulatedGradientMap[x.id] = dx;
          } else {
            var curGradient = tensorAccumulatedGradientMap[x.id];
            tensorAccumulatedGradientMap[x.id] = add2(curGradient, dx);
            curGradient.dispose();
          }
        };
        for (var inputName in node.inputs) {
          _loop_2(inputName);
        }
      };
      for (var i = filteredTape.length - 1; i >= 0; i--) {
        _loop_1(i);
      }
    }
    var FORMAT_LIMIT_NUM_VALS = 20;
    var FORMAT_NUM_FIRST_LAST_VALS = 3;
    var FORMAT_NUM_SIG_DIGITS = 7;
    function tensorToString(vals, shape, dtype, verbose) {
      var strides = computeStrides(shape);
      var padPerCol = computeMaxSizePerColumn(vals, shape, dtype, strides);
      var rank = shape.length;
      var valsLines = subTensorToString(vals, shape, dtype, strides, padPerCol);
      var lines = ["Tensor"];
      if (verbose) {
        lines.push("  dtype: ".concat(dtype));
        lines.push("  rank: ".concat(rank));
        lines.push("  shape: [".concat(shape, "]"));
        lines.push("  values:");
      }
      lines.push(valsLines.map(function(l) {
        return "    " + l;
      }).join("\n"));
      return lines.join("\n");
    }
    function computeMaxSizePerColumn(vals, shape, dtype, strides) {
      var n = sizeFromShape(shape);
      var numCols = strides[strides.length - 1];
      var padPerCol = new Array(numCols).fill(0);
      var rank = shape.length;
      var valuesOrTuples = dtype === "complex64" ? createComplexTuples(vals) : vals;
      if (rank > 1) {
        for (var row = 0; row < n / numCols; row++) {
          var offset = row * numCols;
          for (var j = 0; j < numCols; j++) {
            padPerCol[j] = Math.max(padPerCol[j], valToString(valuesOrTuples[offset + j], 0, dtype).length);
          }
        }
      }
      return padPerCol;
    }
    function valToString(val, pad2, dtype) {
      var valStr;
      if (Array.isArray(val)) {
        valStr = "".concat(parseFloat(val[0].toFixed(FORMAT_NUM_SIG_DIGITS)), " + ") + "".concat(parseFloat(val[1].toFixed(FORMAT_NUM_SIG_DIGITS)), "j");
      } else if (isString(val)) {
        valStr = "'".concat(val, "'");
      } else if (dtype === "bool") {
        valStr = boolNumToString(val);
      } else {
        valStr = parseFloat(val.toFixed(FORMAT_NUM_SIG_DIGITS)).toString();
      }
      return rightPad(valStr, pad2);
    }
    function boolNumToString(v) {
      return v === 0 ? "false" : "true";
    }
    function subTensorToString(vals, shape, dtype, strides, padPerCol, isLast) {
      if (isLast === void 0) {
        isLast = true;
      }
      var storagePerElement = dtype === "complex64" ? 2 : 1;
      var size = shape[0];
      var rank = shape.length;
      if (rank === 0) {
        if (dtype === "complex64") {
          var complexTuple = createComplexTuples(vals);
          return [valToString(complexTuple[0], 0, dtype)];
        }
        if (dtype === "bool") {
          return [boolNumToString(vals[0])];
        }
        return [vals[0].toString()];
      }
      if (rank === 1) {
        if (size > FORMAT_LIMIT_NUM_VALS) {
          var firstValsSize = FORMAT_NUM_FIRST_LAST_VALS * storagePerElement;
          var firstVals = Array.from(vals.slice(0, firstValsSize));
          var lastVals = Array.from(vals.slice((size - FORMAT_NUM_FIRST_LAST_VALS) * storagePerElement, size * storagePerElement));
          if (dtype === "complex64") {
            firstVals = createComplexTuples(firstVals);
            lastVals = createComplexTuples(lastVals);
          }
          return [
            "[" + firstVals.map(function(x, i2) {
              return valToString(x, padPerCol[i2], dtype);
            }).join(", ") + ", ..., " + lastVals.map(function(x, i2) {
              return valToString(x, padPerCol[size - FORMAT_NUM_FIRST_LAST_VALS + i2], dtype);
            }).join(", ") + "]"
          ];
        }
        var displayVals = dtype === "complex64" ? createComplexTuples(vals) : Array.from(vals);
        return [
          "[" + displayVals.map(function(x, i2) {
            return valToString(x, padPerCol[i2], dtype);
          }).join(", ") + "]"
        ];
      }
      var subshape = shape.slice(1);
      var substrides = strides.slice(1);
      var stride = strides[0] * storagePerElement;
      var lines = [];
      if (size > FORMAT_LIMIT_NUM_VALS) {
        for (var i = 0; i < FORMAT_NUM_FIRST_LAST_VALS; i++) {
          var start = i * stride;
          var end = start + stride;
          lines.push.apply(lines, __spreadArray([], __read(subTensorToString(
            vals.slice(start, end),
            subshape,
            dtype,
            substrides,
            padPerCol,
            false
            /* isLast */
          )), false));
        }
        lines.push("...");
        for (var i = size - FORMAT_NUM_FIRST_LAST_VALS; i < size; i++) {
          var start = i * stride;
          var end = start + stride;
          lines.push.apply(lines, __spreadArray([], __read(subTensorToString(
            vals.slice(start, end),
            subshape,
            dtype,
            substrides,
            padPerCol,
            i === size - 1
            /* isLast */
          )), false));
        }
      } else {
        for (var i = 0; i < size; i++) {
          var start = i * stride;
          var end = start + stride;
          lines.push.apply(lines, __spreadArray([], __read(subTensorToString(
            vals.slice(start, end),
            subshape,
            dtype,
            substrides,
            padPerCol,
            i === size - 1
            /* isLast */
          )), false));
        }
      }
      var sep = rank === 2 ? "," : "";
      lines[0] = "[" + (size > 0 ? lines[0] + sep : "");
      for (var i = 1; i < lines.length - 1; i++) {
        lines[i] = " " + lines[i] + sep;
      }
      var newLineSep = ",\n";
      for (var i = 2; i < rank; i++) {
        newLineSep += "\n";
      }
      lines[lines.length - 1] = " " + lines[lines.length - 1] + "]" + (isLast ? "" : newLineSep);
      return lines;
    }
    function createComplexTuples(vals) {
      var complexTuples = [];
      for (var i = 0; i < vals.length; i += 2) {
        complexTuples.push([vals[i], vals[i + 1]]);
      }
      return complexTuples;
    }
    var TensorBuffer = (
      /** @class */
      function() {
        function TensorBuffer2(shape, dtype, values) {
          var _this = this;
          this.dtype = dtype;
          this.shape = shape.slice();
          this.size = sizeFromShape(shape);
          if (values != null) {
            var n_1 = values.length;
            assert(n_1 === this.size, function() {
              return "Length of values '".concat(n_1, "' does not match the size ") + "inferred by the shape '".concat(_this.size, "'.");
            });
          }
          if (dtype === "complex64") {
            throw new Error("complex64 dtype TensorBuffers are not supported. Please create a TensorBuffer for the real and imaginary parts separately and call tf.complex(real, imag).");
          }
          this.values = values || getArrayFromDType(dtype, this.size);
          this.strides = computeStrides(shape);
        }
        TensorBuffer2.prototype.set = function(value) {
          var _this = this;
          var locs = [];
          for (var _i = 1; _i < arguments.length; _i++) {
            locs[_i - 1] = arguments[_i];
          }
          if (locs.length === 0) {
            locs = [0];
          }
          assert(locs.length === this.rank, function() {
            return "The number of provided coordinates (".concat(locs.length, ") must ") + "match the rank (".concat(_this.rank, ")");
          });
          var index = this.locToIndex(locs);
          this.values[index] = value;
        };
        TensorBuffer2.prototype.get = function() {
          var e_1, _b;
          var locs = [];
          for (var _i = 0; _i < arguments.length; _i++) {
            locs[_i] = arguments[_i];
          }
          if (locs.length === 0) {
            locs = [0];
          }
          var i = 0;
          try {
            for (var locs_1 = __values(locs), locs_1_1 = locs_1.next(); !locs_1_1.done; locs_1_1 = locs_1.next()) {
              var loc = locs_1_1.value;
              if (loc < 0 || loc >= this.shape[i]) {
                var msg = "Requested out of range element at ".concat(locs, ". ") + "  Buffer shape=".concat(this.shape);
                throw new Error(msg);
              }
              i++;
            }
          } catch (e_1_1) {
            e_1 = { error: e_1_1 };
          } finally {
            try {
              if (locs_1_1 && !locs_1_1.done && (_b = locs_1.return))
                _b.call(locs_1);
            } finally {
              if (e_1)
                throw e_1.error;
            }
          }
          var index = locs[locs.length - 1];
          for (var i_1 = 0; i_1 < locs.length - 1; ++i_1) {
            index += this.strides[i_1] * locs[i_1];
          }
          return this.values[index];
        };
        TensorBuffer2.prototype.locToIndex = function(locs) {
          if (this.rank === 0) {
            return 0;
          } else if (this.rank === 1) {
            return locs[0];
          }
          var index = locs[locs.length - 1];
          for (var i = 0; i < locs.length - 1; ++i) {
            index += this.strides[i] * locs[i];
          }
          return index;
        };
        TensorBuffer2.prototype.indexToLoc = function(index) {
          if (this.rank === 0) {
            return [];
          } else if (this.rank === 1) {
            return [index];
          }
          var locs = new Array(this.shape.length);
          for (var i = 0; i < locs.length - 1; ++i) {
            locs[i] = Math.floor(index / this.strides[i]);
            index -= locs[i] * this.strides[i];
          }
          locs[locs.length - 1] = index;
          return locs;
        };
        Object.defineProperty(TensorBuffer2.prototype, "rank", {
          get: function() {
            return this.shape.length;
          },
          enumerable: false,
          configurable: true
        });
        TensorBuffer2.prototype.toTensor = function() {
          return trackerFn().makeTensor(this.values, this.shape, this.dtype);
        };
        return TensorBuffer2;
      }()
    );
    var trackerFn = null;
    var opHandler = null;
    function setTensorTracker(fn) {
      trackerFn = fn;
    }
    var Tensor = (
      /** @class */
      function() {
        function Tensor2(shape, dtype, dataId, id) {
          this.kept = false;
          this.isDisposedInternal = false;
          this.shape = shape.slice();
          this.dtype = dtype || "float32";
          this.size = sizeFromShape(shape);
          this.strides = computeStrides(shape);
          this.dataId = dataId;
          this.id = id;
          this.rankType = this.rank < 5 ? this.rank.toString() : "higher";
        }
        Object.defineProperty(Tensor2.prototype, "rank", {
          get: function() {
            return this.shape.length;
          },
          enumerable: false,
          configurable: true
        });
        Tensor2.prototype.buffer = function() {
          return __awaiter(this, void 0, void 0, function() {
            var vals;
            return __generator(this, function(_b) {
              switch (_b.label) {
                case 0:
                  return [4, this.data()];
                case 1:
                  vals = _b.sent();
                  return [2, opHandler.buffer(this.shape, this.dtype, vals)];
              }
            });
          });
        };
        Tensor2.prototype.bufferSync = function() {
          return opHandler.buffer(this.shape, this.dtype, this.dataSync());
        };
        Tensor2.prototype.array = function() {
          return __awaiter(this, void 0, void 0, function() {
            var vals;
            return __generator(this, function(_b) {
              switch (_b.label) {
                case 0:
                  return [4, this.data()];
                case 1:
                  vals = _b.sent();
                  return [2, toNestedArray(this.shape, vals, this.dtype === "complex64")];
              }
            });
          });
        };
        Tensor2.prototype.arraySync = function() {
          return toNestedArray(this.shape, this.dataSync(), this.dtype === "complex64");
        };
        Tensor2.prototype.data = function() {
          return __awaiter(this, void 0, void 0, function() {
            var data, bytes;
            return __generator(this, function(_b) {
              switch (_b.label) {
                case 0:
                  this.throwIfDisposed();
                  data = trackerFn().read(this.dataId);
                  if (!(this.dtype === "string"))
                    return [3, 2];
                  return [4, data];
                case 1:
                  bytes = _b.sent();
                  try {
                    return [2, bytes.map(function(b) {
                      return decodeString(b);
                    })];
                  } catch (_a) {
                    throw new Error("Failed to decode the string bytes into utf-8. To get the original bytes, call tensor.bytes().");
                  }
                  _b.label = 2;
                case 2:
                  return [2, data];
              }
            });
          });
        };
        Tensor2.prototype.dataToGPU = function(options) {
          this.throwIfDisposed();
          return trackerFn().readToGPU(this.dataId, options);
        };
        Tensor2.prototype.dataSync = function() {
          this.throwIfDisposed();
          var data = trackerFn().readSync(this.dataId);
          if (this.dtype === "string") {
            try {
              return data.map(function(b) {
                return decodeString(b);
              });
            } catch (_a) {
              throw new Error("Failed to decode the string bytes into utf-8. To get the original bytes, call tensor.bytes().");
            }
          }
          return data;
        };
        Tensor2.prototype.bytes = function() {
          return __awaiter(this, void 0, void 0, function() {
            var data;
            return __generator(this, function(_b) {
              switch (_b.label) {
                case 0:
                  this.throwIfDisposed();
                  return [4, trackerFn().read(this.dataId)];
                case 1:
                  data = _b.sent();
                  if (this.dtype === "string") {
                    return [2, data];
                  } else {
                    return [2, new Uint8Array(data.buffer)];
                  }
              }
            });
          });
        };
        Tensor2.prototype.dispose = function() {
          if (this.isDisposed) {
            return;
          }
          trackerFn().disposeTensor(this);
          this.isDisposedInternal = true;
        };
        Object.defineProperty(Tensor2.prototype, "isDisposed", {
          get: function() {
            return this.isDisposedInternal;
          },
          enumerable: false,
          configurable: true
        });
        Tensor2.prototype.throwIfDisposed = function() {
          if (this.isDisposed) {
            throw new Error("Tensor is disposed.");
          }
        };
        Tensor2.prototype.print = function(verbose) {
          if (verbose === void 0) {
            verbose = false;
          }
          return opHandler.print(this, verbose);
        };
        Tensor2.prototype.clone = function() {
          this.throwIfDisposed();
          return opHandler.clone(this);
        };
        Tensor2.prototype.toString = function(verbose) {
          if (verbose === void 0) {
            verbose = false;
          }
          var vals = this.dataSync();
          return tensorToString(vals, this.shape, this.dtype, verbose);
        };
        Tensor2.prototype.cast = function(dtype) {
          this.throwIfDisposed();
          return opHandler.cast(this, dtype);
        };
        Tensor2.prototype.variable = function(trainable, name, dtype) {
          if (trainable === void 0) {
            trainable = true;
          }
          this.throwIfDisposed();
          return trackerFn().makeVariable(this, trainable, name, dtype);
        };
        return Tensor2;
      }()
    );
    Object.defineProperty(Tensor, Symbol.hasInstance, {
      value: function(instance) {
        return !!instance && instance.data != null && instance.dataSync != null && instance.throwIfDisposed != null;
      }
    });
    function getGlobalTensorClass() {
      return getGlobal("Tensor", function() {
        return Tensor;
      });
    }
    getGlobalTensorClass();
    var Variable = (
      /** @class */
      function(_super) {
        __extends(Variable2, _super);
        function Variable2(initialValue, trainable, name, tensorId) {
          var _this = _super.call(this, initialValue.shape, initialValue.dtype, initialValue.dataId, tensorId) || this;
          _this.trainable = trainable;
          _this.name = name;
          return _this;
        }
        Variable2.prototype.assign = function(newValue) {
          if (newValue.dtype !== this.dtype) {
            throw new Error("dtype of the new value (".concat(newValue.dtype, ") and ") + "previous value (".concat(this.dtype, ") must match"));
          }
          if (!arraysEqual(newValue.shape, this.shape)) {
            throw new Error("shape of the new value (".concat(newValue.shape, ") and ") + "previous value (".concat(this.shape, ") must match"));
          }
          trackerFn().disposeTensor(this);
          this.dataId = newValue.dataId;
          trackerFn().incRef(
            this,
            null
            /* backend */
          );
        };
        Variable2.prototype.dispose = function() {
          trackerFn().disposeVariable(this);
          this.isDisposedInternal = true;
        };
        return Variable2;
      }(Tensor)
    );
    Object.defineProperty(Variable, Symbol.hasInstance, {
      value: function(instance) {
        return instance instanceof Tensor && instance.assign != null && instance.assign instanceof Function;
      }
    });
    var Rank;
    (function(Rank2) {
      Rank2["R0"] = "R0";
      Rank2["R1"] = "R1";
      Rank2["R2"] = "R2";
      Rank2["R3"] = "R3";
      Rank2["R4"] = "R4";
      Rank2["R5"] = "R5";
      Rank2["R6"] = "R6";
    })(Rank || (Rank = {}));
    var UpcastInt32AndMap;
    (function(UpcastInt32AndMap2) {
      UpcastInt32AndMap2["float32"] = "float32";
      UpcastInt32AndMap2["int32"] = "int32";
      UpcastInt32AndMap2["bool"] = "int32";
      UpcastInt32AndMap2["complex64"] = "complex64";
    })(UpcastInt32AndMap || (UpcastInt32AndMap = {}));
    var UpcastBoolAndMap;
    (function(UpcastBoolAndMap2) {
      UpcastBoolAndMap2["float32"] = "float32";
      UpcastBoolAndMap2["int32"] = "int32";
      UpcastBoolAndMap2["bool"] = "bool";
      UpcastBoolAndMap2["complex64"] = "complex64";
    })(UpcastBoolAndMap || (UpcastBoolAndMap = {}));
    var UpcastFloat32AndMap;
    (function(UpcastFloat32AndMap2) {
      UpcastFloat32AndMap2["float32"] = "float32";
      UpcastFloat32AndMap2["int32"] = "float32";
      UpcastFloat32AndMap2["bool"] = "float32";
      UpcastFloat32AndMap2["complex64"] = "complex64";
    })(UpcastFloat32AndMap || (UpcastFloat32AndMap = {}));
    var UpcastComplex64AndMap;
    (function(UpcastComplex64AndMap2) {
      UpcastComplex64AndMap2["float32"] = "complex64";
      UpcastComplex64AndMap2["int32"] = "complex64";
      UpcastComplex64AndMap2["bool"] = "complex64";
      UpcastComplex64AndMap2["complex64"] = "complex64";
    })(UpcastComplex64AndMap || (UpcastComplex64AndMap = {}));
    var upcastTypeMap = {
      "float32": UpcastFloat32AndMap,
      "int32": UpcastInt32AndMap,
      "bool": UpcastBoolAndMap,
      "complex64": UpcastComplex64AndMap
    };
    function upcastType(typeA, typeB) {
      if (typeA === "string" || typeB === "string") {
        if (typeA === "string" && typeB === "string") {
          return "string";
        }
        throw new Error("Can not upcast ".concat(typeA, " with ").concat(typeB));
      }
      return upcastTypeMap[typeA][typeB];
    }
    function isWebGLData(values) {
      return values != null && typeof values === "object" && "texture" in values && values.texture instanceof WebGLTexture;
    }
    function isWebGPUData(values) {
      return typeof GPUBuffer !== "undefined" && values != null && typeof values === "object" && "buffer" in values && values.buffer instanceof GPUBuffer;
    }
    function makeTypesMatch(a, b) {
      if (a.dtype === b.dtype) {
        return [a, b];
      }
      var dtype = upcastType(a.dtype, b.dtype);
      return [a.cast(dtype), b.cast(dtype)];
    }
    function assertTypesMatch(a, b) {
      assert(a.dtype === b.dtype, function() {
        return "The dtypes of the first(".concat(a.dtype, ") and") + " second(".concat(b.dtype, ") input must match");
      });
    }
    function getTensorsInContainer(result) {
      var list = [];
      var seen = /* @__PURE__ */ new Set();
      walkTensorContainer(result, list, seen);
      return list;
    }
    function walkTensorContainer(container, list, seen) {
      if (container == null) {
        return;
      }
      if (container instanceof Tensor) {
        list.push(container);
        return;
      }
      if (!isIterable(container)) {
        return;
      }
      var iterable = container;
      for (var k in iterable) {
        var val = iterable[k];
        if (!seen.has(val)) {
          seen.add(val);
          walkTensorContainer(val, list, seen);
        }
      }
    }
    function isIterable(obj) {
      return Array.isArray(obj) || typeof obj === "object";
    }
    function isRegisteredKernelInvocation(kernelInvocation) {
      return kernelInvocation.kernelName != null;
    }
    var EngineState = (
      /** @class */
      function() {
        function EngineState2() {
          this.registeredVariables = {};
          this.nextTapeNodeId = 0;
          this.numBytes = 0;
          this.numTensors = 0;
          this.numStringTensors = 0;
          this.numDataBuffers = 0;
          this.gradientDepth = 0;
          this.kernelDepth = 0;
          this.scopeStack = [];
          this.numDataMovesStack = [];
          this.nextScopeId = 0;
          this.tensorInfo = /* @__PURE__ */ new WeakMap();
          this.profiling = false;
          this.activeProfile = {
            newBytes: 0,
            newTensors: 0,
            peakBytes: 0,
            kernels: [],
            result: null,
            get kernelNames() {
              return Array.from(new Set(this.kernels.map(function(k) {
                return k.name;
              })));
            }
          };
        }
        EngineState2.prototype.dispose = function() {
          for (var variableName in this.registeredVariables) {
            this.registeredVariables[variableName].dispose();
          }
        };
        return EngineState2;
      }()
    );
    var Engine = (
      /** @class */
      function() {
        function Engine2(ENV2) {
          this.ENV = ENV2;
          this.registry = {};
          this.registryFactory = {};
          this.pendingBackendInitId = 0;
          this.state = new EngineState();
        }
        Engine2.prototype.ready = function() {
          return __awaiter(this, void 0, void 0, function() {
            var sortedBackends, i, backendName, success;
            return __generator(this, function(_a) {
              switch (_a.label) {
                case 0:
                  if (this.pendingBackendInit != null) {
                    return [2, this.pendingBackendInit.then(function() {
                    })];
                  }
                  if (this.backendInstance != null) {
                    return [
                      2
                      /*return*/
                    ];
                  }
                  sortedBackends = this.getSortedBackends();
                  i = 0;
                  _a.label = 1;
                case 1:
                  if (!(i < sortedBackends.length))
                    return [3, 5];
                  backendName = sortedBackends[i];
                  return [4, this.initializeBackend(backendName).success];
                case 2:
                  success = _a.sent();
                  if (!success)
                    return [3, 4];
                  return [4, this.setBackend(backendName)];
                case 3:
                  _a.sent();
                  return [
                    2
                    /*return*/
                  ];
                case 4:
                  i++;
                  return [3, 1];
                case 5:
                  throw new Error("Could not initialize any backends, all backend initializations failed.");
              }
            });
          });
        };
        Object.defineProperty(Engine2.prototype, "backend", {
          get: function() {
            if (this.pendingBackendInit != null) {
              throw new Error("Backend '".concat(this.backendName, "' has not yet been initialized. Make ") + "sure to await tf.ready() or await tf.setBackend() before calling other methods");
            }
            if (this.backendInstance == null) {
              var _a = this.initializeBackendsAndReturnBest(), name = _a.name, asyncInit = _a.asyncInit;
              if (asyncInit) {
                throw new Error("The highest priority backend '".concat(name, "' has not yet been ") + "initialized. Make sure to await tf.ready() or await tf.setBackend() before calling other methods");
              }
              this.setBackend(name);
            }
            return this.backendInstance;
          },
          enumerable: false,
          configurable: true
        });
        Engine2.prototype.backendNames = function() {
          return Object.keys(this.registryFactory);
        };
        Engine2.prototype.findBackend = function(backendName) {
          if (!(backendName in this.registry)) {
            if (backendName in this.registryFactory) {
              var asyncInit = this.initializeBackend(backendName).asyncInit;
              if (asyncInit) {
                return null;
              }
            } else {
              return null;
            }
          }
          return this.registry[backendName];
        };
        Engine2.prototype.findBackendFactory = function(backendName) {
          if (!(backendName in this.registryFactory)) {
            return null;
          }
          return this.registryFactory[backendName].factory;
        };
        Engine2.prototype.registerBackend = function(backendName, factory, priority) {
          if (priority === void 0) {
            priority = 1;
          }
          if (backendName in this.registryFactory) {
            warn("".concat(backendName, " backend was already registered. ") + "Reusing existing backend factory.");
            return false;
          }
          this.registryFactory[backendName] = { factory, priority };
          return true;
        };
        Engine2.prototype.setBackend = function(backendName) {
          return __awaiter(this, void 0, void 0, function() {
            var _a, success, asyncInit, result, _b;
            return __generator(this, function(_c) {
              switch (_c.label) {
                case 0:
                  if (this.registryFactory[backendName] == null) {
                    throw new Error("Backend name '".concat(backendName, "' not found in registry"));
                  }
                  this.backendName = backendName;
                  if (!(this.registry[backendName] == null))
                    return [3, 4];
                  this.backendInstance = null;
                  _a = this.initializeBackend(backendName), success = _a.success, asyncInit = _a.asyncInit;
                  if (!asyncInit)
                    return [3, 2];
                  return [4, success];
                case 1:
                  _b = _c.sent();
                  return [3, 3];
                case 2:
                  _b = success;
                  _c.label = 3;
                case 3:
                  result = _b;
                  if (!result) {
                    return [2, false];
                  }
                  _c.label = 4;
                case 4:
                  this.backendInstance = this.registry[backendName];
                  this.setupRegisteredKernels();
                  this.profiler = new Profiler(this.backendInstance);
                  return [2, true];
              }
            });
          });
        };
        Engine2.prototype.setupRegisteredKernels = function() {
          var _this = this;
          var kernels = getKernelsForBackend(this.backendName);
          kernels.forEach(function(kernel) {
            if (kernel.setupFunc != null) {
              kernel.setupFunc(_this.backendInstance);
            }
          });
        };
        Engine2.prototype.disposeRegisteredKernels = function(backendName) {
          var _this = this;
          var kernels = getKernelsForBackend(backendName);
          kernels.forEach(function(kernel) {
            if (kernel.disposeFunc != null) {
              kernel.disposeFunc(_this.registry[backendName]);
            }
          });
        };
        Engine2.prototype.initializeBackend = function(backendName) {
          var _this = this;
          var registryFactoryEntry = this.registryFactory[backendName];
          if (registryFactoryEntry == null) {
            throw new Error("Cannot initialize backend ".concat(backendName, ", no registration found."));
          }
          try {
            var backend = registryFactoryEntry.factory();
            if (backend && !(backend instanceof KernelBackend) && typeof backend.then === "function") {
              var promiseId_1 = ++this.pendingBackendInitId;
              var success = backend.then(function(backendInstance) {
                if (promiseId_1 < _this.pendingBackendInitId) {
                  return false;
                }
                _this.registry[backendName] = backendInstance;
                _this.pendingBackendInit = null;
                return true;
              }).catch(function(err) {
                if (promiseId_1 < _this.pendingBackendInitId) {
                  return false;
                }
                _this.pendingBackendInit = null;
                warn("Initialization of backend ".concat(backendName, " failed"));
                warn(err.stack || err.message);
                return false;
              });
              this.pendingBackendInit = success;
              return { success, asyncInit: true };
            } else {
              this.registry[backendName] = backend;
              return { success: true, asyncInit: false };
            }
          } catch (err) {
            warn("Initialization of backend ".concat(backendName, " failed"));
            warn(err.stack || err.message);
            return { success: false, asyncInit: false };
          }
        };
        Engine2.prototype.removeBackend = function(backendName) {
          if (!(backendName in this.registryFactory)) {
            throw new Error("".concat(backendName, " backend not found in registry"));
          }
          if (this.backendName === backendName && this.pendingBackendInit != null) {
            this.pendingBackendInitId++;
          }
          if (backendName in this.registry) {
            this.disposeRegisteredKernels(backendName);
            this.registry[backendName].dispose();
            delete this.registry[backendName];
          }
          delete this.registryFactory[backendName];
          if (this.backendName === backendName) {
            this.pendingBackendInit = null;
            this.backendName = null;
            this.backendInstance = null;
          }
        };
        Engine2.prototype.getSortedBackends = function() {
          var _this = this;
          if (Object.keys(this.registryFactory).length === 0) {
            throw new Error("No backend found in registry.");
          }
          return Object.keys(this.registryFactory).sort(function(a, b) {
            return _this.registryFactory[b].priority - _this.registryFactory[a].priority;
          });
        };
        Engine2.prototype.initializeBackendsAndReturnBest = function() {
          var sortedBackends = this.getSortedBackends();
          for (var i = 0; i < sortedBackends.length; i++) {
            var backendName = sortedBackends[i];
            var _a = this.initializeBackend(backendName), success = _a.success, asyncInit = _a.asyncInit;
            if (asyncInit || success) {
              return { name: backendName, asyncInit };
            }
          }
          throw new Error("Could not initialize any backends, all backend initializations failed.");
        };
        Engine2.prototype.moveData = function(backend, dataId) {
          var info = this.state.tensorInfo.get(dataId);
          var srcBackend = info.backend;
          var values = this.readSync(dataId);
          var refCount = srcBackend.refCount(dataId);
          srcBackend.disposeData(dataId, true);
          info.backend = backend;
          backend.move(dataId, values, info.shape, info.dtype, refCount);
          if (this.shouldCheckForMemLeaks()) {
            this.state.numDataMovesStack[this.state.numDataMovesStack.length - 1]++;
          }
        };
        Engine2.prototype.tidy = function(nameOrFn, fn) {
          var _this = this;
          var name = null;
          if (fn == null) {
            if (typeof nameOrFn !== "function") {
              throw new Error("Please provide a function to tidy()");
            }
            fn = nameOrFn;
          } else {
            if (typeof nameOrFn !== "string" && !(nameOrFn instanceof String)) {
              throw new Error("When calling with two arguments, the first argument to tidy() must be a string");
            }
            if (typeof fn !== "function") {
              throw new Error("When calling with two arguments, the 2nd argument to tidy() must be a function");
            }
            name = nameOrFn;
          }
          var result;
          return this.scopedRun(function() {
            return _this.startScope(name);
          }, function() {
            return _this.endScope(result);
          }, function() {
            result = fn();
            if (result instanceof Promise) {
              console.error("Cannot return a Promise inside of tidy.");
            }
            return result;
          });
        };
        Engine2.prototype.scopedRun = function(start, end, f) {
          start();
          try {
            var res = f();
            end();
            return res;
          } catch (ex) {
            end();
            throw ex;
          }
        };
        Engine2.prototype.nextTensorId = function() {
          return Engine2.nextTensorId++;
        };
        Engine2.prototype.nextVariableId = function() {
          return Engine2.nextVariableId++;
        };
        Engine2.prototype.clone = function(x) {
          var y = ENGINE.runKernel(Identity, { x });
          var inputs = { x };
          var grad = function(dy) {
            return {
              x: function() {
                var dtype = "float32";
                var gradInputs = { x: dy };
                var attrs = { dtype };
                return ENGINE.runKernel(
                  Cast,
                  gradInputs,
                  // tslint:disable-next-line: no-unnecessary-type-assertion
                  attrs
                );
              }
            };
          };
          var saved = [];
          this.addTapeNode(this.state.activeScope.name, inputs, [y], grad, saved, {});
          return y;
        };
        Engine2.prototype.runKernel = function(kernelName, inputs, attrs) {
          if (this.backendName == null) {
            this.backend;
          }
          var hasKernel = getKernel(kernelName, this.backendName) != null;
          if (!hasKernel) {
            throw new Error("Kernel '".concat(kernelName, "' not registered for backend '").concat(this.backendName, "'"));
          }
          return this.runKernelFunc({ kernelName, inputs, attrs });
        };
        Engine2.prototype.shouldCheckForMemLeaks = function() {
          return this.ENV.getBool("IS_TEST");
        };
        Engine2.prototype.checkKernelForMemLeak = function(kernelName, numDataIdsBefore, outInfos) {
          var numDataIdsAfter = this.backend.numDataIds();
          var numOutputDataIds = 0;
          outInfos.forEach(function(info) {
            numOutputDataIds += info.dtype === "complex64" ? 3 : 1;
          });
          var numMoves = this.state.numDataMovesStack[this.state.numDataMovesStack.length - 1];
          var dataIdsLeaked = numDataIdsAfter - numDataIdsBefore - numOutputDataIds - numMoves;
          if (dataIdsLeaked > 0) {
            throw new Error("Backend '".concat(this.backendName, "' has an internal memory leak ") + "(".concat(dataIdsLeaked, " data ids) after running '").concat(kernelName, "'"));
          }
        };
        Engine2.prototype.runKernelFunc = function(kernelParams) {
          var _this = this;
          var outputs;
          var saved = [];
          var isTapeOn = this.isTapeOn();
          var startingBytecount = this.state.numBytes;
          var startingNumTensors = this.state.numTensors;
          if (this.shouldCheckForMemLeaks()) {
            this.state.numDataMovesStack.push(0);
          }
          var kernelFunc;
          if (this.backendName == null) {
            this.backend;
          }
          var out;
          var kernelOrScopeName = isRegisteredKernelInvocation(kernelParams) ? kernelParams.kernelName : this.state.activeScope != null ? this.state.activeScope.name : "";
          if (isRegisteredKernelInvocation(kernelParams)) {
            var kernelName_1 = kernelParams.kernelName, inputs_1 = kernelParams.inputs, attrs_1 = kernelParams.attrs;
            if (this.backendName == null) {
              this.backend;
            }
            var kernel_1 = getKernel(kernelName_1, this.backendName);
            assert(kernel_1 != null, function() {
              return "Cannot find registered kernel '".concat(kernelName_1, "' for backend '").concat(_this.backendName, "'");
            });
            kernelFunc = function() {
              var numDataIdsBefore = _this.backend.numDataIds();
              out = kernel_1.kernelFunc({ inputs: inputs_1, attrs: attrs_1, backend: _this.backend });
              var outInfos = Array.isArray(out) ? out : [out];
              if (_this.shouldCheckForMemLeaks()) {
                _this.checkKernelForMemLeak(kernelName_1, numDataIdsBefore, outInfos);
              }
              var outTensors = outInfos.map(function(outInfo) {
                if (outInfo.rank != null) {
                  return outInfo;
                }
                return _this.makeTensorFromTensorInfo(outInfo);
              });
              if (isTapeOn) {
                var tensorsToSave = _this.getTensorsForGradient(kernelName_1, inputs_1, outTensors);
                saved = _this.saveTensorsForBackwardMode(tensorsToSave);
              }
              return outTensors;
            };
          } else {
            var forwardFunc_1 = kernelParams.forwardFunc;
            var saveFunc_1 = function(tensors) {
              if (!isTapeOn) {
                return;
              }
              saved = tensors.map(function(tensor2) {
                return _this.keep(_this.clone(tensor2));
              });
            };
            kernelFunc = function() {
              var numDataIdsBefore = _this.backend.numDataIds();
              out = _this.tidy(function() {
                return forwardFunc_1(_this.backend, saveFunc_1);
              });
              var outs = Array.isArray(out) ? out : [out];
              if (_this.shouldCheckForMemLeaks()) {
                _this.checkKernelForMemLeak(kernelOrScopeName, numDataIdsBefore, outs);
              }
              return outs;
            };
          }
          var inputs = kernelParams.inputs, attrs = kernelParams.attrs;
          var backwardsFunc = isRegisteredKernelInvocation(kernelParams) ? null : kernelParams.backwardsFunc;
          var kernelProfile;
          this.scopedRun(
            // Stop recording to a tape when running a kernel.
            function() {
              return _this.state.kernelDepth++;
            },
            function() {
              return _this.state.kernelDepth--;
            },
            function() {
              if (!_this.ENV.getBool("DEBUG") && !_this.state.profiling) {
                outputs = kernelFunc();
              } else {
                kernelProfile = _this.profiler.profileKernel(kernelOrScopeName, inputs, function() {
                  return kernelFunc();
                });
                if (_this.ENV.getBool("DEBUG")) {
                  _this.profiler.logKernelProfile(kernelProfile);
                }
                outputs = kernelProfile.outputs;
              }
            }
          );
          if (isTapeOn) {
            this.addTapeNode(kernelOrScopeName, inputs, outputs, backwardsFunc, saved, attrs);
          }
          if (this.state.profiling) {
            this.state.activeProfile.kernels.push({
              name: kernelOrScopeName,
              bytesAdded: this.state.numBytes - startingBytecount,
              totalBytesSnapshot: this.state.numBytes,
              tensorsAdded: this.state.numTensors - startingNumTensors,
              totalTensorsSnapshot: this.state.numTensors,
              inputShapes: Object.keys(inputs).map(function(key) {
                return inputs[key] != null ? inputs[key].shape : null;
              }),
              outputShapes: outputs.map(function(item) {
                return item.shape;
              }),
              kernelTimeMs: kernelProfile.timeMs,
              extraInfo: kernelProfile.extraInfo
            });
          }
          return Array.isArray(out) ? outputs : outputs[0];
        };
        Engine2.prototype.saveTensorsForBackwardMode = function(tensors) {
          var _this = this;
          var saved = tensors.map(function(tensor2) {
            return _this.keep(_this.clone(tensor2));
          });
          return saved;
        };
        Engine2.prototype.getTensorsForGradient = function(kernelName, inputs, outputs) {
          var gradConfig = getGradient(kernelName);
          if (gradConfig != null) {
            var inputsToSave = gradConfig.inputsToSave || [];
            var outputsToSave_1 = gradConfig.outputsToSave || [];
            var inputTensorsToSave = void 0;
            if (gradConfig.saveAllInputs) {
              assert(Array.isArray(inputs), function() {
                return "saveAllInputs is true, expected inputs to be an array.";
              });
              inputTensorsToSave = Object.keys(inputs).map(function(key) {
                return inputs[key];
              });
            } else {
              inputTensorsToSave = inputsToSave.map(function(inputName) {
                return inputs[inputName];
              });
            }
            var outputTensorsToSave = outputs.filter(function(_, i) {
              return outputsToSave_1[i];
            });
            return inputTensorsToSave.concat(outputTensorsToSave);
          }
          return [];
        };
        Engine2.prototype.makeTensor = function(values, shape, dtype, backend) {
          if (values == null) {
            throw new Error("Values passed to engine.makeTensor() are null");
          }
          dtype = dtype || "float32";
          backend = backend || this.backend;
          var backendVals = values;
          if (dtype === "string" && isString(values[0])) {
            backendVals = values.map(function(d) {
              return encodeString(d);
            });
          }
          var dataId = backend.write(backendVals, shape, dtype);
          var t = new Tensor(shape, dtype, dataId, this.nextTensorId());
          this.trackTensor(t, backend);
          if (dtype === "string") {
            var info = this.state.tensorInfo.get(dataId);
            var newBytes = bytesFromStringArray(backendVals);
            this.state.numBytes += newBytes - info.bytes;
            info.bytes = newBytes;
          }
          return t;
        };
        Engine2.prototype.makeTensorFromDataId = function(dataId, shape, dtype, backend) {
          dtype = dtype || "float32";
          var tensorInfo = { dataId, shape, dtype };
          return this.makeTensorFromTensorInfo(tensorInfo, backend);
        };
        Engine2.prototype.makeTensorFromTensorInfo = function(tensorInfo, backend) {
          var dataId = tensorInfo.dataId, shape = tensorInfo.shape, dtype = tensorInfo.dtype;
          var t = new Tensor(shape, dtype, dataId, this.nextTensorId());
          this.trackTensor(t, backend);
          return t;
        };
        Engine2.prototype.makeVariable = function(initialValue, trainable, name, dtype) {
          if (trainable === void 0) {
            trainable = true;
          }
          name = name || this.nextVariableId().toString();
          if (dtype != null && dtype !== initialValue.dtype) {
            initialValue = initialValue.cast(dtype);
          }
          var v = new Variable(initialValue, trainable, name, this.nextTensorId());
          if (this.state.registeredVariables[v.name] != null) {
            throw new Error("Variable with name ".concat(v.name, " was already registered"));
          }
          this.state.registeredVariables[v.name] = v;
          this.incRef(v, this.backend);
          return v;
        };
        Engine2.prototype.trackTensor = function(a, backend) {
          this.state.numTensors++;
          if (a.dtype === "string") {
            this.state.numStringTensors++;
          }
          var bytes = 0;
          if (a.dtype !== "complex64" && a.dtype !== "string") {
            bytes = a.size * bytesPerElement(a.dtype);
          }
          this.state.numBytes += bytes;
          if (!this.state.tensorInfo.has(a.dataId)) {
            this.state.numDataBuffers++;
            this.state.tensorInfo.set(a.dataId, {
              backend: backend || this.backend,
              dtype: a.dtype,
              shape: a.shape,
              bytes
            });
          }
          if (!(a instanceof Variable)) {
            this.track(a);
          }
        };
        Engine2.prototype.incRef = function(a, backend) {
          this.trackTensor(a, backend);
          this.backend.incRef(a.dataId);
        };
        Engine2.prototype.removeDataId = function(dataId, backend) {
          if (this.state.tensorInfo.has(dataId) && this.state.tensorInfo.get(dataId).backend === backend) {
            this.state.tensorInfo.delete(dataId);
            this.state.numDataBuffers--;
          }
        };
        Engine2.prototype.disposeTensor = function(a) {
          if (!this.state.tensorInfo.has(a.dataId)) {
            return;
          }
          var info = this.state.tensorInfo.get(a.dataId);
          this.state.numTensors--;
          if (a.dtype === "string") {
            this.state.numStringTensors--;
            this.state.numBytes -= info.bytes;
          }
          if (a.dtype !== "complex64" && a.dtype !== "string") {
            var bytes = a.size * bytesPerElement(a.dtype);
            this.state.numBytes -= bytes;
          }
          if (info.backend.disposeData(a.dataId)) {
            this.removeDataId(a.dataId, info.backend);
          }
        };
        Engine2.prototype.disposeVariables = function() {
          for (var varName in this.state.registeredVariables) {
            var v = this.state.registeredVariables[varName];
            this.disposeVariable(v);
          }
        };
        Engine2.prototype.disposeVariable = function(v) {
          this.disposeTensor(v);
          if (this.state.registeredVariables[v.name] != null) {
            delete this.state.registeredVariables[v.name];
          }
        };
        Engine2.prototype.memory = function() {
          var info = this.backend.memory();
          info.numTensors = this.state.numTensors;
          info.numDataBuffers = this.state.numDataBuffers;
          info.numBytes = this.state.numBytes;
          if (this.state.numStringTensors > 0) {
            info.unreliable = true;
            if (info.reasons == null) {
              info.reasons = [];
            }
            info.reasons.push("Memory usage by string tensors is approximate (2 bytes per character)");
          }
          return info;
        };
        Engine2.prototype.profile = function(query) {
          return __awaiter(this, void 0, void 0, function() {
            var startBytes, startNumTensors, _a, _b, _c, kernel, _d, _e, e_1_1;
            var e_1, _f;
            return __generator(this, function(_g) {
              switch (_g.label) {
                case 0:
                  this.state.profiling = true;
                  startBytes = this.state.numBytes;
                  startNumTensors = this.state.numTensors;
                  this.state.activeProfile.kernels = [];
                  _a = this.state.activeProfile;
                  return [4, query()];
                case 1:
                  _a.result = _g.sent();
                  this.state.profiling = false;
                  this.state.activeProfile.peakBytes = Math.max.apply(Math, __spreadArray([], __read(this.state.activeProfile.kernels.map(function(d) {
                    return d.totalBytesSnapshot;
                  })), false));
                  this.state.activeProfile.newBytes = this.state.numBytes - startBytes;
                  this.state.activeProfile.newTensors = this.state.numTensors - startNumTensors;
                  _g.label = 2;
                case 2:
                  _g.trys.push([2, 8, 9, 10]);
                  _b = __values(this.state.activeProfile.kernels), _c = _b.next();
                  _g.label = 3;
                case 3:
                  if (!!_c.done)
                    return [3, 7];
                  kernel = _c.value;
                  _d = kernel;
                  return [4, kernel.kernelTimeMs];
                case 4:
                  _d.kernelTimeMs = _g.sent();
                  _e = kernel;
                  return [4, kernel.extraInfo];
                case 5:
                  _e.extraInfo = _g.sent();
                  _g.label = 6;
                case 6:
                  _c = _b.next();
                  return [3, 3];
                case 7:
                  return [3, 10];
                case 8:
                  e_1_1 = _g.sent();
                  e_1 = { error: e_1_1 };
                  return [3, 10];
                case 9:
                  try {
                    if (_c && !_c.done && (_f = _b.return))
                      _f.call(_b);
                  } finally {
                    if (e_1)
                      throw e_1.error;
                  }
                  return [
                    7
                    /*endfinally*/
                  ];
                case 10:
                  return [2, this.state.activeProfile];
              }
            });
          });
        };
        Engine2.prototype.isTapeOn = function() {
          return this.state.gradientDepth > 0 && this.state.kernelDepth === 0;
        };
        Engine2.prototype.addTapeNode = function(kernelName, inputs, outputs, gradientsFunc, saved, attrs) {
          var _this = this;
          var tapeNode = { id: this.state.nextTapeNodeId++, kernelName, inputs, outputs, saved };
          var gradConfig = getGradient(kernelName);
          if (gradConfig != null) {
            gradientsFunc = gradConfig.gradFunc;
          }
          if (gradientsFunc != null) {
            tapeNode.gradient = function(dys) {
              dys = dys.map(function(dy, i) {
                if (dy == null) {
                  var output = outputs[i];
                  var vals = makeZerosTypedArray(output.size, output.dtype);
                  return _this.makeTensor(vals, output.shape, output.dtype);
                }
                return dy;
              });
              return gradientsFunc(dys.length > 1 ? dys : dys[0], saved, attrs);
            };
          }
          this.state.activeTape.push(tapeNode);
        };
        Engine2.prototype.keep = function(result) {
          result.kept = true;
          return result;
        };
        Engine2.prototype.startTape = function() {
          if (this.state.gradientDepth === 0) {
            this.state.activeTape = [];
          }
          this.state.gradientDepth++;
        };
        Engine2.prototype.endTape = function() {
          this.state.gradientDepth--;
        };
        Engine2.prototype.startScope = function(name) {
          var scopeInfo = {
            track: [],
            name: "unnamed scope",
            id: this.state.nextScopeId++
          };
          if (name) {
            scopeInfo.name = name;
          }
          this.state.scopeStack.push(scopeInfo);
          this.state.activeScope = scopeInfo;
        };
        Engine2.prototype.endScope = function(result) {
          var _this = this;
          var tensorsToTrackInParent = getTensorsInContainer(result);
          var tensorsToTrackInParentSet = new Set(tensorsToTrackInParent.map(function(t) {
            return t.id;
          }));
          for (var i = 0; i < this.state.activeScope.track.length; i++) {
            var tensor2 = this.state.activeScope.track[i];
            if (!tensor2.kept && !tensorsToTrackInParentSet.has(tensor2.id)) {
              tensor2.dispose();
            }
          }
          var oldScope = this.state.scopeStack.pop();
          this.state.activeScope = this.state.scopeStack.length === 0 ? null : this.state.scopeStack[this.state.scopeStack.length - 1];
          tensorsToTrackInParent.forEach(function(tensor3) {
            if (!tensor3.kept && tensor3.scopeId === oldScope.id) {
              _this.track(tensor3);
            }
          });
        };
        Engine2.prototype.gradients = function(f, xs, dy, allowNoGradients) {
          var _this = this;
          if (allowNoGradients === void 0) {
            allowNoGradients = false;
          }
          assert(xs.length > 0, function() {
            return "gradients() received an empty list of xs.";
          });
          if (dy != null && dy.dtype !== "float32") {
            throw new Error("dy must have 'float32' dtype, but has '".concat(dy.dtype, "'"));
          }
          var y = this.scopedRun(function() {
            return _this.startTape();
          }, function() {
            return _this.endTape();
          }, function() {
            return _this.tidy("forward", f);
          });
          assert(y instanceof Tensor, function() {
            return "The result y returned by f() must be a tensor.";
          });
          var filteredTape = getFilteredNodesXToY(this.state.activeTape, xs, y);
          if (!allowNoGradients && filteredTape.length === 0 && xs.length > 0) {
            throw new Error("Cannot compute gradient of y=f(x) with respect to x. Make sure that the f you passed encloses all operations that lead from x to y.");
          }
          return this.tidy("backward", function() {
            var accumulatedGradientMap = {};
            accumulatedGradientMap[y.id] = dy == null ? ones$1(y.shape) : dy;
            backpropagateGradients(
              accumulatedGradientMap,
              filteredTape,
              // Pass the tidy function to avoid circular dep with `tape.ts`.
              function(f2) {
                return _this.tidy(f2);
              },
              // Pass an add function to avoide a circular dep with `tape.ts`.
              add$1
            );
            var grads = xs.map(function(x) {
              return accumulatedGradientMap[x.id];
            });
            if (_this.state.gradientDepth === 0) {
              _this.state.activeTape.forEach(function(node) {
                var e_2, _a;
                try {
                  for (var _b = __values(node.saved), _c = _b.next(); !_c.done; _c = _b.next()) {
                    var tensor2 = _c.value;
                    tensor2.dispose();
                  }
                } catch (e_2_1) {
                  e_2 = { error: e_2_1 };
                } finally {
                  try {
                    if (_c && !_c.done && (_a = _b.return))
                      _a.call(_b);
                  } finally {
                    if (e_2)
                      throw e_2.error;
                  }
                }
              });
              _this.state.activeTape = null;
            }
            return { value: y, grads };
          });
        };
        Engine2.prototype.customGrad = function(f) {
          var _this = this;
          assert(isFunction(f), function() {
            return "The f passed in customGrad(f) must be a function.";
          });
          return function() {
            var inputs = [];
            for (var _i = 0; _i < arguments.length; _i++) {
              inputs[_i] = arguments[_i];
            }
            assert(inputs.every(function(t) {
              return t instanceof Tensor;
            }), function() {
              return "The args passed in customGrad(f)(x1, x2,...) must all be tensors";
            });
            var res;
            var inputMap = {};
            inputs.forEach(function(input, i) {
              inputMap[i] = input;
            });
            var forwardFunc = function(_, save) {
              res = f.apply(void 0, __spreadArray([], __read(__spreadArray(__spreadArray([], __read(inputs), false), [save], false)), false));
              assert(res.value instanceof Tensor, function() {
                return "The function f passed in customGrad(f) must return an object where `obj.value` is a tensor";
              });
              assert(isFunction(res.gradFunc), function() {
                return "The function f passed in customGrad(f) must return an object where `obj.gradFunc` is a function.";
              });
              return res.value;
            };
            var backwardsFunc = function(dy, saved) {
              var gradRes = res.gradFunc(dy, saved);
              var grads = Array.isArray(gradRes) ? gradRes : [gradRes];
              assert(grads.length === inputs.length, function() {
                return "The function f passed in customGrad(f) must return an object where `obj.gradFunc` is a function that returns the same number of tensors as inputs passed to f(...).";
              });
              assert(grads.every(function(t) {
                return t instanceof Tensor;
              }), function() {
                return "The function f passed in customGrad(f) must return an object where `obj.gradFunc` is a function that returns a list of only tensors.";
              });
              var gradMap = {};
              grads.forEach(function(grad, i) {
                gradMap[i] = function() {
                  return grad;
                };
              });
              return gradMap;
            };
            return _this.runKernelFunc({
              forwardFunc,
              backwardsFunc,
              inputs: inputMap
            });
          };
        };
        Engine2.prototype.readSync = function(dataId) {
          var info = this.state.tensorInfo.get(dataId);
          return info.backend.readSync(dataId);
        };
        Engine2.prototype.read = function(dataId) {
          var info = this.state.tensorInfo.get(dataId);
          return info.backend.read(dataId);
        };
        Engine2.prototype.readToGPU = function(dataId, options) {
          var info = this.state.tensorInfo.get(dataId);
          return info.backend.readToGPU(dataId, options);
        };
        Engine2.prototype.time = function(query) {
          return __awaiter(this, void 0, void 0, function() {
            var start, timingInfo;
            return __generator(this, function(_a) {
              switch (_a.label) {
                case 0:
                  start = now();
                  return [4, this.backend.time(query)];
                case 1:
                  timingInfo = _a.sent();
                  timingInfo.wallMs = now() - start;
                  return [2, timingInfo];
              }
            });
          });
        };
        Engine2.prototype.track = function(result) {
          if (this.state.activeScope != null) {
            result.scopeId = this.state.activeScope.id;
            this.state.activeScope.track.push(result);
          }
          return result;
        };
        Object.defineProperty(Engine2.prototype, "registeredVariables", {
          get: function() {
            return this.state.registeredVariables;
          },
          enumerable: false,
          configurable: true
        });
        Engine2.prototype.reset = function() {
          this.pendingBackendInitId++;
          this.state.dispose();
          this.ENV.reset();
          this.state = new EngineState();
          for (var backendName in this.registry) {
            this.disposeRegisteredKernels(backendName);
            this.registry[backendName].dispose();
            delete this.registry[backendName];
          }
          this.backendName = null;
          this.backendInstance = null;
          this.pendingBackendInit = null;
        };
        return Engine2;
      }()
    );
    Engine.nextTensorId = 0;
    Engine.nextVariableId = 0;
    function ones$1(shape) {
      var values = makeOnesTypedArray(sizeFromShape(shape), "float32");
      return ENGINE.makeTensor(values, shape, "float32");
    }
    function getOrMakeEngine() {
      var ns = getGlobalNamespace();
      if (ns._tfengine == null) {
        var environment = new Environment(ns);
        ns._tfengine = new Engine(environment);
      }
      setEnvironmentGlobal(ns._tfengine.ENV);
      setTensorTracker(function() {
        return ns._tfengine;
      });
      return ns._tfengine;
    }
    var ENGINE = getOrMakeEngine();
    function add$1(a, b) {
      var inputs = { a, b };
      return ENGINE.runKernel(Add, inputs);
    }
    function inferShape(val, dtype) {
      var firstElem = val;
      if (isTypedArray(val)) {
        return dtype === "string" ? [] : [val.length];
      }
      if (isWebGLData(val)) {
        var usedChannels = val.channels || "RGBA";
        return [val.height, val.width * usedChannels.length];
      } else if (isWebGPUData(val)) {
        return [val.buffer.size / (dtype == null ? 4 : bytesPerElement(dtype))];
      }
      if (!Array.isArray(val)) {
        return [];
      }
      var shape = [];
      while (Array.isArray(firstElem) || isTypedArray(firstElem) && dtype !== "string") {
        shape.push(firstElem.length);
        firstElem = firstElem[0];
      }
      if (Array.isArray(val) && env().getBool("TENSORLIKE_CHECK_SHAPE_CONSISTENCY")) {
        deepAssertShapeConsistency(val, shape, []);
      }
      return shape;
    }
    function deepAssertShapeConsistency(val, shape, indices) {
      indices = indices || [];
      if (!Array.isArray(val) && !isTypedArray(val)) {
        assert(shape.length === 0, function() {
          return "Element arr[".concat(indices.join("]["), "] is a primitive, ") + "but should be an array/TypedArray of ".concat(shape[0], " elements");
        });
        return;
      }
      assert(shape.length > 0, function() {
        return "Element arr[".concat(indices.join("]["), "] should be a primitive, ") + "but is an array of ".concat(val.length, " elements");
      });
      assert(val.length === shape[0], function() {
        return "Element arr[".concat(indices.join("]["), "] should have ").concat(shape[0], " ") + "elements, but has ".concat(val.length, " elements");
      });
      var subShape = shape.slice(1);
      for (var i = 0; i < val.length; ++i) {
        deepAssertShapeConsistency(val[i], subShape, indices.concat(i));
      }
    }
    function assertDtype(expectedDtype, actualDType, argName, functionName) {
      if (expectedDtype === "string_or_numeric") {
        return;
      }
      if (expectedDtype == null) {
        throw new Error("Expected dtype cannot be null.");
      }
      if (expectedDtype !== "numeric" && expectedDtype !== actualDType || expectedDtype === "numeric" && actualDType === "string") {
        throw new Error("Argument '".concat(argName, "' passed to '").concat(functionName, "' must ") + "be ".concat(expectedDtype, " tensor, but got ").concat(actualDType, " tensor"));
      }
    }
    function convertToTensor(x, argName, functionName, parseAsDtype) {
      if (parseAsDtype === void 0) {
        parseAsDtype = "numeric";
      }
      if (x instanceof Tensor) {
        assertDtype(parseAsDtype, x.dtype, argName, functionName);
        return x;
      }
      var inferredDtype = inferDtype(x);
      if (inferredDtype !== "string" && ["bool", "int32", "float32"].indexOf(parseAsDtype) >= 0) {
        inferredDtype = parseAsDtype;
      }
      assertDtype(parseAsDtype, inferredDtype, argName, functionName);
      if (x == null || !isTypedArray(x) && !Array.isArray(x) && typeof x !== "number" && typeof x !== "boolean" && typeof x !== "string") {
        var type = x == null ? "null" : x.constructor.name;
        throw new Error("Argument '".concat(argName, "' passed to '").concat(functionName, "' must be a ") + "Tensor or TensorLike, but got '".concat(type, "'"));
      }
      var inferredShape = inferShape(x, inferredDtype);
      if (!isTypedArray(x) && !Array.isArray(x)) {
        x = [x];
      }
      var skipTypedArray = true;
      var values = inferredDtype !== "string" ? toTypedArray(x, inferredDtype) : flatten(x, [], skipTypedArray);
      return ENGINE.makeTensor(values, inferredShape, inferredDtype);
    }
    function convertToTensorArray(arg, argName, functionName, parseAsDtype) {
      if (parseAsDtype === void 0) {
        parseAsDtype = "numeric";
      }
      if (!Array.isArray(arg)) {
        throw new Error("Argument ".concat(argName, " passed to ").concat(functionName, " must be a ") + "`Tensor[]` or `TensorLike[]`");
      }
      var tensors = arg;
      return tensors.map(function(t, i) {
        return convertToTensor(t, "".concat(argName, "[").concat(i, "]"), functionName, parseAsDtype);
      });
    }
    var OP_SCOPE_SUFFIX = "__op";
    function op(f) {
      var keys = Object.keys(f);
      if (keys.length !== 1) {
        throw new Error("Please provide an object with a single key (operation name) mapping to a function. Got an object with " + "".concat(keys.length, " keys."));
      }
      var opName = keys[0];
      var fn = f[opName];
      if (opName.endsWith("_")) {
        opName = opName.substring(0, opName.length - 1);
      }
      opName = opName + OP_SCOPE_SUFFIX;
      var f2 = function() {
        var args = [];
        for (var _i = 0; _i < arguments.length; _i++) {
          args[_i] = arguments[_i];
        }
        ENGINE.startScope(opName);
        try {
          var result = fn.apply(void 0, __spreadArray([], __read(args), false));
          if (isPromise(result)) {
            console.error("Cannot return a Promise inside of tidy.");
          }
          ENGINE.endScope(result);
          return result;
        } catch (ex) {
          ENGINE.endScope(null);
          throw ex;
        }
      };
      Object.defineProperty(f2, "name", { value: opName, configurable: true });
      return f2;
    }
    function abs_(x) {
      var $x = convertToTensor(x, "x", "abs");
      if ($x.dtype === "complex64") {
        var inputs = { x: $x };
        return ENGINE.runKernel(ComplexAbs, inputs);
      } else {
        var inputs = { x: $x };
        return ENGINE.runKernel(Abs, inputs);
      }
    }
    var abs = /* @__PURE__ */ op({ abs_ });
    function acos_(x) {
      var $x = convertToTensor(x, "x", "acos");
      var inputs = { x: $x };
      return ENGINE.runKernel(Acos, inputs);
    }
    var acos = /* @__PURE__ */ op({ acos_ });
    function acosh_(x) {
      var $x = convertToTensor(x, "x", "acosh");
      var inputs = { x: $x };
      return ENGINE.runKernel(Acosh, inputs);
    }
    var acosh = /* @__PURE__ */ op({ acosh_ });
    function add_(a, b) {
      var _a;
      var $a = convertToTensor(a, "a", "add");
      var $b = convertToTensor(b, "b", "add");
      _a = __read(makeTypesMatch($a, $b), 2), $a = _a[0], $b = _a[1];
      var inputs = { a: $a, b: $b };
      return ENGINE.runKernel(Add, inputs);
    }
    var add = /* @__PURE__ */ op({ add_ });
    function addN_(tensors) {
      assert(Array.isArray(tensors), function() {
        return "The argument passed to tf.addN() must be a list of tensors";
      });
      assert(tensors.length >= 1, function() {
        return "Must pass at least one tensor to tf.addN(), but got " + "".concat(tensors.length);
      });
      var $tensors = tensors.map(function(t, i) {
        return convertToTensor(t, "tensors".concat(i), "addN");
      });
      var firstTensor = $tensors[0];
      $tensors.forEach(function(t) {
        if (t.dtype !== firstTensor.dtype) {
          throw new Error("All tensors passed to tf.addN() must have the same dtype");
        }
      });
      $tensors.forEach(function(t) {
        if (!arraysEqual(t.shape, firstTensor.shape)) {
          throw new Error("All tensors passed to tf.addN() must have the same shape");
        }
      });
      var inputs = $tensors;
      return ENGINE.runKernel(AddN, inputs);
    }
    var addN = /* @__PURE__ */ op({ addN_ });
    function all_(x, axis, keepDims) {
      if (axis === void 0) {
        axis = null;
      }
      if (keepDims === void 0) {
        keepDims = false;
      }
      var $x = convertToTensor(x, "x", "all", "bool");
      var inputs = { x: $x };
      var attrs = { axis, keepDims };
      return ENGINE.runKernel(All, inputs, attrs);
    }
    var all = /* @__PURE__ */ op({ all_ });
    function any_(x, axis, keepDims) {
      if (axis === void 0) {
        axis = null;
      }
      if (keepDims === void 0) {
        keepDims = false;
      }
      var $x = convertToTensor(x, "x", "any", "bool");
      var inputs = { x: $x };
      var attrs = { axis, keepDims };
      return ENGINE.runKernel(Any, inputs, attrs);
    }
    var any = /* @__PURE__ */ op({ any_ });
    function argMax_(x, axis) {
      if (axis === void 0) {
        axis = 0;
      }
      var $x = convertToTensor(x, "x", "argMax");
      var inputs = { x: $x };
      var attrs = { axis };
      return ENGINE.runKernel(ArgMax, inputs, attrs);
    }
    var argMax = /* @__PURE__ */ op({ argMax_ });
    function argMin_(x, axis) {
      if (axis === void 0) {
        axis = 0;
      }
      var $x = convertToTensor(x, "x", "argMin");
      var inputs = { x: $x };
      var attrs = { axis };
      return ENGINE.runKernel(ArgMin, inputs, attrs);
    }
    var argMin = /* @__PURE__ */ op({ argMin_ });
    function asin_(x) {
      var $x = convertToTensor(x, "x", "asin");
      var inputs = { x: $x };
      return ENGINE.runKernel(Asin, inputs);
    }
    var asin = /* @__PURE__ */ op({ asin_ });
    function asinh_(x) {
      var $x = convertToTensor(x, "x", "asinh");
      var inputs = { x: $x };
      return ENGINE.runKernel(Asinh, inputs);
    }
    var asinh = /* @__PURE__ */ op({ asinh_ });
    function atan_(x) {
      var $x = convertToTensor(x, "x", "atan");
      var inputs = { x: $x };
      return ENGINE.runKernel(Atan, inputs);
    }
    var atan = /* @__PURE__ */ op({ atan_ });
    function atan2_(a, b) {
      var _a;
      var $a = convertToTensor(a, "a", "atan2");
      var $b = convertToTensor(b, "b", "atan2");
      _a = __read(makeTypesMatch($a, $b), 2), $a = _a[0], $b = _a[1];
      var inputs = { a: $a, b: $b };
      return ENGINE.runKernel(Atan2, inputs);
    }
    var atan2 = /* @__PURE__ */ op({ atan2_ });
    function atanh_(x) {
      var $x = convertToTensor(x, "x", "atanh");
      var inputs = { x: $x };
      return ENGINE.runKernel(Atanh, inputs);
    }
    var atanh = /* @__PURE__ */ op({ atanh_ });
    function cast_(x, dtype) {
      var $x = convertToTensor(x, "x", "cast");
      if (!isValidDtype(dtype)) {
        throw new Error("Failed to cast to unknown dtype ".concat(dtype));
      }
      if (dtype === "string" && $x.dtype !== "string" || dtype !== "string" && $x.dtype === "string") {
        throw new Error("Only strings can be casted to strings");
      }
      var inputs = { x: $x };
      var attrs = { dtype };
      return ENGINE.runKernel(Cast, inputs, attrs);
    }
    var cast = /* @__PURE__ */ op({ cast_ });
    function computePool2DInfo(inShape, filterSize, strides, dilations, pad2, roundingMode, dataFormat) {
      if (dataFormat === void 0) {
        dataFormat = "channelsLast";
      }
      var _a = __read(parseTupleParam(filterSize), 2), filterHeight = _a[0], filterWidth = _a[1];
      var filterShape;
      if (dataFormat === "channelsLast") {
        filterShape = [filterHeight, filterWidth, inShape[3], inShape[3]];
      } else if (dataFormat === "channelsFirst") {
        filterShape = [filterHeight, filterWidth, inShape[1], inShape[1]];
      } else {
        throw new Error("Unknown dataFormat ".concat(dataFormat));
      }
      return computeConv2DInfo(inShape, filterShape, strides, dilations, pad2, roundingMode, false, dataFormat);
    }
    function computeConv2DInfo(inShape, filterShape, strides, dilations, pad2, roundingMode, depthwise, dataFormat) {
      var _a, _b;
      if (depthwise === void 0) {
        depthwise = false;
      }
      if (dataFormat === void 0) {
        dataFormat = "channelsLast";
      }
      var _c = __read([-1, -1, -1, -1], 4), batchSize = _c[0], inHeight = _c[1], inWidth = _c[2], inChannels = _c[3];
      if (dataFormat === "channelsLast") {
        _a = __read(inShape, 4), batchSize = _a[0], inHeight = _a[1], inWidth = _a[2], inChannels = _a[3];
      } else if (dataFormat === "channelsFirst") {
        _b = __read(inShape, 4), batchSize = _b[0], inChannels = _b[1], inHeight = _b[2], inWidth = _b[3];
      } else {
        throw new Error("Unknown dataFormat ".concat(dataFormat));
      }
      var _d = __read(filterShape, 4), filterHeight = _d[0], filterWidth = _d[1], filterChannels = _d[3];
      var _e = __read(parseTupleParam(strides), 2), strideHeight = _e[0], strideWidth = _e[1];
      var _f = __read(parseTupleParam(dilations), 2), dilationHeight = _f[0], dilationWidth = _f[1];
      var effectiveFilterHeight = getEffectiveFilterSize(filterHeight, dilationHeight);
      var effectiveFilterWidth = getEffectiveFilterSize(filterWidth, dilationWidth);
      var _g = getPadAndOutInfo(pad2, inHeight, inWidth, strideHeight, strideWidth, effectiveFilterHeight, effectiveFilterWidth, roundingMode, dataFormat), padInfo = _g.padInfo, outHeight = _g.outHeight, outWidth = _g.outWidth;
      var outChannels = depthwise ? filterChannels * inChannels : filterChannels;
      var outShape;
      if (dataFormat === "channelsFirst") {
        outShape = [batchSize, outChannels, outHeight, outWidth];
      } else if (dataFormat === "channelsLast") {
        outShape = [batchSize, outHeight, outWidth, outChannels];
      }
      return {
        batchSize,
        dataFormat,
        inHeight,
        inWidth,
        inChannels,
        outHeight,
        outWidth,
        outChannels,
        padInfo,
        strideHeight,
        strideWidth,
        filterHeight,
        filterWidth,
        effectiveFilterHeight,
        effectiveFilterWidth,
        dilationHeight,
        dilationWidth,
        inShape,
        outShape,
        filterShape
      };
    }
    function computeOutputShape2D(inShape, fieldSize, stride, zeroPad, roundingMode) {
      if (zeroPad == null) {
        zeroPad = computeDefaultPad(inShape, fieldSize, stride);
      }
      var inputRows = inShape[0];
      var inputCols = inShape[1];
      var outputRows = round$1((inputRows - fieldSize + 2 * zeroPad) / stride + 1, roundingMode);
      var outputCols = round$1((inputCols - fieldSize + 2 * zeroPad) / stride + 1, roundingMode);
      return [outputRows, outputCols];
    }
    function computeDefaultPad(inputShape, fieldSize, stride, dilation) {
      if (dilation === void 0) {
        dilation = 1;
      }
      var effectiveFieldSize = getEffectiveFilterSize(fieldSize, dilation);
      return Math.floor((inputShape[0] * (stride - 1) - stride + effectiveFieldSize) / 2);
    }
    function parseTupleParam(param) {
      if (typeof param === "number") {
        return [param, param, param];
      }
      if (param.length === 2) {
        return [param[0], param[1], 1];
      }
      return param;
    }
    function getEffectiveFilterSize(filterSize, dilation) {
      if (dilation <= 1) {
        return filterSize;
      }
      return filterSize + (filterSize - 1) * (dilation - 1);
    }
    function getPadAndOutInfo(pad2, inHeight, inWidth, strideHeight, strideWidth, filterHeight, filterWidth, roundingMode, dataFormat) {
      var padInfo;
      var outHeight;
      var outWidth;
      if (typeof pad2 === "number") {
        var padType = pad2 === 0 ? "VALID" : "NUMBER";
        padInfo = { top: pad2, bottom: pad2, left: pad2, right: pad2, type: padType };
        var outShape = computeOutputShape2D([inHeight, inWidth], filterHeight, strideHeight, pad2, roundingMode);
        outHeight = outShape[0];
        outWidth = outShape[1];
      } else if (pad2 === "same") {
        outHeight = Math.ceil(inHeight / strideHeight);
        outWidth = Math.ceil(inWidth / strideWidth);
        var padAlongHeight = Math.max(0, (outHeight - 1) * strideHeight + filterHeight - inHeight);
        var padAlongWidth = Math.max(0, (outWidth - 1) * strideWidth + filterWidth - inWidth);
        var top = Math.floor(padAlongHeight / 2);
        var bottom = padAlongHeight - top;
        var left = Math.floor(padAlongWidth / 2);
        var right = padAlongWidth - left;
        padInfo = { top, bottom, left, right, type: "SAME" };
      } else if (pad2 === "valid") {
        padInfo = { top: 0, bottom: 0, left: 0, right: 0, type: "VALID" };
        outHeight = Math.ceil((inHeight - filterHeight + 1) / strideHeight);
        outWidth = Math.ceil((inWidth - filterWidth + 1) / strideWidth);
      } else if (typeof pad2 === "object") {
        var top = dataFormat === "channelsLast" ? pad2[1][0] : pad2[2][0];
        var bottom = dataFormat === "channelsLast" ? pad2[1][1] : pad2[2][1];
        var left = dataFormat === "channelsLast" ? pad2[2][0] : pad2[3][0];
        var right = dataFormat === "channelsLast" ? pad2[2][1] : pad2[3][1];
        var padType = top === 0 && bottom === 0 && left === 0 && right === 0 ? "VALID" : "EXPLICIT";
        padInfo = { top, bottom, left, right, type: padType };
        outHeight = round$1((inHeight - filterHeight + top + bottom) / strideHeight + 1, roundingMode);
        outWidth = round$1((inWidth - filterWidth + left + right) / strideWidth + 1, roundingMode);
      } else {
        throw Error("Unknown padding parameter: ".concat(pad2));
      }
      return { padInfo, outHeight, outWidth };
    }
    function round$1(value, roundingMode) {
      if (!roundingMode) {
        return Math.trunc(value);
      }
      switch (roundingMode) {
        case "round":
          return Math.round(value);
        case "ceil":
          return Math.ceil(value);
        case "floor":
          return Math.floor(value);
        default:
          throw new Error("Unknown roundingMode ".concat(roundingMode));
      }
    }
    function tupleValuesAreOne(param) {
      var _a = __read(parseTupleParam(param), 3), dimA = _a[0], dimB = _a[1], dimC = _a[2];
      return dimA === 1 && dimB === 1 && dimC === 1;
    }
    function eitherStridesOrDilationsAreOne(strides, dilations) {
      return tupleValuesAreOne(strides) || tupleValuesAreOne(dilations);
    }
    function stridesOrDilationsArePositive(values) {
      return parseTupleParam(values).every(function(value) {
        return value > 0;
      });
    }
    function checkPadOnDimRoundingMode(opDesc, pad2, dimRoundingMode) {
      if (dimRoundingMode != null) {
        if (typeof pad2 === "string") {
          throw Error("Error in ".concat(opDesc, ": pad must be an integer when using ") + "dimRoundingMode ".concat(dimRoundingMode, " but got pad ").concat(pad2, "."));
        } else if (typeof pad2 === "number") {
          assert(isInt(pad2), function() {
            return "Error in ".concat(opDesc, ": pad must be an integer when using ") + "dimRoundingMode ".concat(dimRoundingMode, " but got pad ").concat(pad2, ".");
          });
        } else if (typeof pad2 === "object") {
          pad2.forEach(function(p) {
            p.forEach(function(v) {
              assert(isInt(v), function() {
                return "Error in ".concat(opDesc, ": pad must be an integer when using ") + "dimRoundingMode ".concat(dimRoundingMode, " but got pad ").concat(v, ".");
              });
            });
          });
        } else {
          throw Error("Error in ".concat(opDesc, ": Unknown padding parameter: ").concat(pad2));
        }
      }
    }
    function reshape_(x, shape) {
      var $x = convertToTensor(x, "x", "reshape", "string_or_numeric");
      var inputs = { x: $x };
      var attrs = { shape };
      return ENGINE.runKernel(Reshape, inputs, attrs);
    }
    var reshape = /* @__PURE__ */ op({ reshape_ });
    function avgPool_(x, filterSize, strides, pad2, dimRoundingMode) {
      var $x = convertToTensor(x, "x", "avgPool", "float32");
      var dilations = 1;
      assert(eitherStridesOrDilationsAreOne(strides, dilations), function() {
        return "Error in avgPool: Either strides or dilations must be 1. " + "Got strides ".concat(strides, " and dilations '").concat(dilations, "'");
      });
      var x4D = $x;
      var reshapedTo4D = false;
      if ($x.rank === 3) {
        reshapedTo4D = true;
        x4D = reshape($x, [1, $x.shape[0], $x.shape[1], $x.shape[2]]);
      }
      assert(x4D.rank === 4, function() {
        return "Error in avgPool: x must be rank 4 but got rank ".concat(x4D.rank, ".");
      });
      checkPadOnDimRoundingMode("avgPool", pad2, dimRoundingMode);
      var inputs = { x: x4D };
      var attrs = { filterSize, strides, pad: pad2, dimRoundingMode };
      var res = ENGINE.runKernel(AvgPool, inputs, attrs);
      res = cast(res, $x.dtype);
      if (reshapedTo4D) {
        return reshape(res, [res.shape[1], res.shape[2], res.shape[3]]);
      }
      return res;
    }
    var avgPool = /* @__PURE__ */ op({ avgPool_ });
    function avgPool3d_(x, filterSize, strides, pad2, dimRoundingMode, dataFormat) {
      if (dataFormat === void 0) {
        dataFormat = "NDHWC";
      }
      var $x = convertToTensor(x, "x", "avgPool3d", "float32");
      var x5D = $x;
      var reshapedTo5D = false;
      if ($x.rank === 4) {
        reshapedTo5D = true;
        x5D = reshape($x, [1, $x.shape[0], $x.shape[1], $x.shape[2], $x.shape[3]]);
      }
      assert(x5D.rank === 5, function() {
        return "Error in avgPool3d: x must be rank 5 but got rank ".concat(x5D.rank, ".");
      });
      assert(dataFormat === "NDHWC", function() {
        return "Error in avgPool3d: Only NDHWC is currently supported, " + "but got dataFormat of ".concat(dataFormat);
      });
      assert(typeof strides === "number" && strides > 0 || Array.isArray(strides) && strides[0] > 0 && strides[1] > 0 && strides[2] > 0, function() {
        return "Error in avgPool3d: Stride must be > 0, but got '".concat(strides, "'");
      });
      checkPadOnDimRoundingMode("avgPool3d", pad2, dimRoundingMode);
      var inputs = { x: x5D };
      var attrs = { filterSize, strides, pad: pad2, dimRoundingMode, dataFormat };
      var res = ENGINE.runKernel(AvgPool3D, inputs, attrs);
      res = cast(res, x5D.dtype);
      if (reshapedTo5D) {
        return reshape(res, [res.shape[1], res.shape[2], res.shape[3], res.shape[4]]);
      }
      return res;
    }
    var avgPool3d = /* @__PURE__ */ op({ avgPool3d_ });
    function clone_(x) {
      var $x = convertToTensor(x, "x", "clone", "string_or_numeric");
      var inputs = { x: $x };
      return ENGINE.runKernel(Identity, inputs);
    }
    var clone = /* @__PURE__ */ op({ clone_ });
    function concat_(tensors, axis) {
      if (axis === void 0) {
        axis = 0;
      }
      assert(tensors.length >= 1, function() {
        return "Pass at least one tensor to concat";
      });
      var $tensors = convertToTensorArray(tensors, "tensors", "concat", "string_or_numeric");
      if ($tensors[0].dtype === "complex64") {
        $tensors.forEach(function(tensor2) {
          if (tensor2.dtype !== "complex64") {
            throw new Error("Cannot concatenate complex64 tensors with a tensor\n          with dtype ".concat(tensor2.dtype, ". "));
          }
        });
      }
      if ($tensors.length === 1) {
        return clone($tensors[0]);
      }
      var inputs = $tensors;
      var attr = { axis };
      return ENGINE.runKernel(Concat, inputs, attr);
    }
    var concat = /* @__PURE__ */ op({ concat_ });
    function matMul_(a, b, transposeA, transposeB) {
      var _a;
      if (transposeA === void 0) {
        transposeA = false;
      }
      if (transposeB === void 0) {
        transposeB = false;
      }
      var $a = convertToTensor(a, "a", "matMul");
      var $b = convertToTensor(b, "b", "matMul");
      _a = __read(makeTypesMatch($a, $b), 2), $a = _a[0], $b = _a[1];
      var inputs = { a: $a, b: $b };
      var attrs = { transposeA, transposeB };
      return ENGINE.runKernel(BatchMatMul, inputs, attrs);
    }
    var matMul$1 = /* @__PURE__ */ op({ matMul_ });
    function mul_(a, b) {
      var _a;
      var $a = convertToTensor(a, "a", "mul");
      var $b = convertToTensor(b, "b", "mul");
      _a = __read(makeTypesMatch($a, $b), 2), $a = _a[0], $b = _a[1];
      var inputs = { a: $a, b: $b };
      return ENGINE.runKernel(Multiply, inputs);
    }
    var mul = /* @__PURE__ */ op({ mul_ });
    function sigmoid_(x) {
      var $x = convertToTensor(x, "x", "sigmoid", "float32");
      var inputs = { x: $x };
      return ENGINE.runKernel(Sigmoid, inputs);
    }
    var sigmoid = /* @__PURE__ */ op({ sigmoid_ });
    function slice_(x, begin, size) {
      var $x = convertToTensor(x, "x", "slice", "string_or_numeric");
      if ($x.rank === 0) {
        throw new Error("Slicing scalar is not possible");
      }
      var inputs = { x: $x };
      var attrs = { begin, size };
      return ENGINE.runKernel(Slice, inputs, attrs);
    }
    var slice = /* @__PURE__ */ op({ slice_ });
    function tanh_(x) {
      var $x = convertToTensor(x, "x", "tanh", "float32");
      var inputs = { x: $x };
      return ENGINE.runKernel(Tanh, inputs);
    }
    var tanh = /* @__PURE__ */ op({ tanh_ });
    function basicLSTMCell_(forgetBias, lstmKernel, lstmBias, data, c, h) {
      var $forgetBias = convertToTensor(forgetBias, "forgetBias", "basicLSTMCell");
      var $lstmKernel = convertToTensor(lstmKernel, "lstmKernel", "basicLSTMCell");
      var $lstmBias = convertToTensor(lstmBias, "lstmBias", "basicLSTMCell");
      var $data = convertToTensor(data, "data", "basicLSTMCell");
      var $c = convertToTensor(c, "c", "basicLSTMCell");
      var $h = convertToTensor(h, "h", "basicLSTMCell");
      var combined = concat([$data, $h], 1);
      var weighted = matMul$1(combined, $lstmKernel);
      var res = add(weighted, $lstmBias);
      var batchSize = res.shape[0];
      var sliceCols = res.shape[1] / 4;
      var sliceSize = [batchSize, sliceCols];
      var i = slice(res, [0, 0], sliceSize);
      var j = slice(res, [0, sliceCols], sliceSize);
      var f = slice(res, [0, sliceCols * 2], sliceSize);
      var o = slice(res, [0, sliceCols * 3], sliceSize);
      var newC = add(mul(sigmoid(i), tanh(j)), mul($c, sigmoid(add($forgetBias, f))));
      var newH = mul(tanh(newC), sigmoid(o));
      return [newC, newH];
    }
    var basicLSTMCell = /* @__PURE__ */ op({ basicLSTMCell_ });
    function batchToSpaceND_(x, blockShape, crops) {
      var $x = convertToTensor(x, "x", "batchToSpaceND");
      var prod2 = blockShape.reduce(function(a, b) {
        return a * b;
      });
      assert($x.rank >= 1 + blockShape.length, function() {
        return "input rank is ".concat($x.rank, " but should be > than blockShape.length ").concat(blockShape.length);
      });
      assert(crops.length === blockShape.length, function() {
        return "crops.length is ".concat(crops.length, " but should be equal to blockShape.length  ").concat(blockShape.length);
      });
      assert($x.shape[0] % prod2 === 0, function() {
        return "input tensor batch is ".concat($x.shape[0], " but is not divisible by the product of ") + "the elements of blockShape ".concat(blockShape.join(" * "), " === ").concat(prod2);
      });
      var inputs = { x: $x };
      var attrs = { blockShape, crops };
      return ENGINE.runKernel(BatchToSpaceND, inputs, attrs);
    }
    var batchToSpaceND = /* @__PURE__ */ op({ batchToSpaceND_ });
    function xAs4D(x) {
      var x4D;
      if (x.rank === 0 || x.rank === 1) {
        x4D = reshape(x, [1, 1, 1, x.size]);
      } else if (x.rank === 2) {
        x4D = reshape(x, [1, 1, x.shape[0], x.shape[1]]);
      } else if (x.rank === 3) {
        x4D = reshape(x, [1, x.shape[0], x.shape[1], x.shape[2]]);
      } else {
        x4D = x;
      }
      return x4D;
    }
    function batchNorm_(x, mean2, variance, offset, scale, varianceEpsilon) {
      if (varianceEpsilon == null) {
        varianceEpsilon = 1e-3;
      }
      var $x = convertToTensor(x, "x", "batchNorm");
      var $mean = convertToTensor(mean2, "mean", "batchNorm");
      var $variance = convertToTensor(variance, "variance", "batchNorm");
      var $scale;
      if (scale != null) {
        $scale = convertToTensor(scale, "scale", "batchNorm");
      }
      var $offset;
      if (offset != null) {
        $offset = convertToTensor(offset, "offset", "batchNorm");
      }
      assert($mean.rank === $variance.rank, function() {
        return "Batch normalization gradient requires mean and variance to have equal ranks.";
      });
      assert($offset == null || $mean.rank === $offset.rank, function() {
        return "Batch normalization gradient requires mean and offset to have equal ranks.";
      });
      assert($scale == null || $mean.rank === $scale.rank, function() {
        return "Batch normalization gradient requires mean and scale to have equal ranks.";
      });
      var x4D = xAs4D($x);
      var inputs = {
        x: x4D,
        scale: $scale,
        offset: $offset,
        mean: $mean,
        variance: $variance
      };
      var attrs = { varianceEpsilon };
      var res = ENGINE.runKernel(FusedBatchNorm, inputs, attrs);
      return reshape(res, $x.shape);
    }
    var batchNorm = /* @__PURE__ */ op({ batchNorm_ });
    function batchNorm2d_(x, mean2, variance, offset, scale, varianceEpsilon) {
      var $x = convertToTensor(x, "x", "batchNorm");
      var $mean = convertToTensor(mean2, "mean", "batchNorm");
      var $variance = convertToTensor(variance, "variance", "batchNorm");
      var $scale;
      if (scale != null) {
        $scale = convertToTensor(scale, "scale", "batchNorm");
      }
      var $offset;
      if (offset != null) {
        $offset = convertToTensor(offset, "offset", "batchNorm");
      }
      assert($x.rank === 2, function() {
        return "Error in batchNorm2D: x must be rank 2 but got rank " + "".concat($x.rank, ".");
      });
      assert($mean.rank === 2 || $mean.rank === 1, function() {
        return "Error in batchNorm2D: mean must be rank 2 or rank 1 but " + "got rank ".concat($mean.rank, ".");
      });
      assert($variance.rank === 2 || $variance.rank === 1, function() {
        return "Error in batchNorm2D: variance must be rank 2 or rank 1 " + "but got rank ".concat($variance.rank, ".");
      });
      if ($scale != null) {
        assert($scale.rank === 2 || $scale.rank === 1, function() {
          return "Error in batchNorm2D: scale must be rank 2 or rank 1 " + "but got rank ".concat($scale.rank, ".");
        });
      }
      if ($offset != null) {
        assert($offset.rank === 2 || $offset.rank === 1, function() {
          return "Error in batchNorm2D: offset must be rank 2 or rank 1 " + "but got rank ".concat($offset.rank, ".");
        });
      }
      return batchNorm($x, $mean, $variance, $offset, $scale, varianceEpsilon);
    }
    var batchNorm2d = /* @__PURE__ */ op({ batchNorm2d_ });
    function batchNorm3d_(x, mean2, variance, offset, scale, varianceEpsilon) {
      var $x = convertToTensor(x, "x", "batchNorm");
      var $mean = convertToTensor(mean2, "mean", "batchNorm");
      var $variance = convertToTensor(variance, "variance", "batchNorm");
      var $scale;
      if (scale != null) {
        $scale = convertToTensor(scale, "scale", "batchNorm");
      }
      var $offset;
      if (offset != null) {
        $offset = convertToTensor(offset, "offset", "batchNorm");
      }
      assert($x.rank === 3, function() {
        return "Error in batchNorm3D: x must be rank 3 but got rank " + "".concat($x.rank, ".");
      });
      assert($mean.rank === 3 || $mean.rank === 1, function() {
        return "Error in batchNorm3D: mean must be rank 3 or rank 1 but " + "got rank ".concat($mean.rank, ".");
      });
      assert($variance.rank === 3 || $variance.rank === 1, function() {
        return "Error in batchNorm3D: variance must be rank 3 or rank 1 " + "but got rank ".concat($variance.rank, ".");
      });
      if ($scale != null) {
        assert($scale.rank === 3 || $scale.rank === 1, function() {
          return "Error in batchNorm3D: scale must be rank 3 or rank 1 " + "but got rank ".concat($scale.rank, ".");
        });
      }
      if ($offset != null) {
        assert($offset.rank === 3 || $offset.rank === 1, function() {
          return "Error in batchNorm3D: offset must be rank 3 or rank 1 " + "but got rank ".concat($offset.rank, ".");
        });
      }
      return batchNorm($x, $mean, $variance, $offset, $scale, varianceEpsilon);
    }
    var batchNorm3d = /* @__PURE__ */ op({ batchNorm3d_ });
    function batchNorm4d_(x, mean2, variance, offset, scale, varianceEpsilon) {
      var $x = convertToTensor(x, "x", "batchNorm");
      var $mean = convertToTensor(mean2, "mean", "batchNorm");
      var $variance = convertToTensor(variance, "variance", "batchNorm");
      var $scale;
      if (scale != null) {
        $scale = convertToTensor(scale, "scale", "batchNorm");
      }
      var $offset;
      if (offset != null) {
        $offset = convertToTensor(offset, "offset", "batchNorm");
      }
      assert($x.rank === 4, function() {
        return "Error in batchNorm4D: x must be rank 4 but got rank " + "".concat($x.rank, ".");
      });
      assert($mean.rank === 4 || $mean.rank === 1, function() {
        return "Error in batchNorm4D: mean must be rank 4 or rank 1 but " + "got rank ".concat($mean.rank, ".");
      });
      assert($variance.rank === 4 || $variance.rank === 1, function() {
        return "Error in batchNorm4D: variance must be rank 4 or rank 1 " + "but got rank ".concat($variance.rank, ".");
      });
      if ($scale != null) {
        assert($scale.rank === 4 || $scale.rank === 1, function() {
          return "Error in batchNorm4D: scale must be rank 4 or rank 1 " + "but got rank ".concat($scale.rank, ".");
        });
      }
      if ($offset != null) {
        assert($offset.rank === 4 || $offset.rank === 1, function() {
          return "Error in batchNorm4D: offset must be rank 4 or rank 1 " + "but got rank ".concat($offset.rank, ".");
        });
      }
      return batchNorm($x, $mean, $variance, $offset, $scale, varianceEpsilon);
    }
    var batchNorm4d = /* @__PURE__ */ op({ batchNorm4d_ });
    function bincount_(x, weights, size) {
      var $x = convertToTensor(x, "x", "bincount");
      var $weights = convertToTensor(weights, "weights", "bincount");
      assert($x.dtype === "int32", function() {
        return "Error in bincount: input " + "dtype must be int32, but got ".concat($x.dtype);
      });
      assert(size >= 0, function() {
        return "size must be non-negative, but got ".concat(size, ".");
      });
      assert($weights.size === $x.size || $weights.size === 0, function() {
        return "Error in bincount: weights must have the same size as input or" + "0-length, but got input shape: ".concat($x.shape, ", weights shape: ") + "".concat($weights.shape, ".");
      });
      var inputs = { x: $x, weights: $weights };
      var attrs = { size };
      return ENGINE.runKernel(Bincount, inputs, attrs);
    }
    var bincount = /* @__PURE__ */ op({ bincount_ });
    function bitwiseAnd_(x, y) {
      var $x = convertToTensor(x, "x", "bitwiseAnd");
      var $y = convertToTensor(y, "y", "bitwiseAnd");
      if (!arraysEqual($x.shape, $y.shape)) {
        throw new Error("BitwiseAnd: Tensors must have the same shape. x: ".concat($x.shape, ", y: ").concat($y.shape));
      }
      if ($x.dtype !== "int32" || $y.dtype !== "int32") {
        throw new Error("BitwiseAnd: Only supports 'int32' values in tensor, found type of x: ".concat($x.dtype, " and type of y: ").concat($y.dtype));
      }
      var inputs = { a: $x, b: $y };
      return ENGINE.runKernel(BitwiseAnd, inputs);
    }
    var bitwiseAnd = /* @__PURE__ */ op({ bitwiseAnd_ });
    function broadcastArgs_(s0, s1) {
      var shape1Input = convertToTensor(s0, "s0", "broadcastArgs", "int32");
      var shape2Input = convertToTensor(s1, "s1", "broadcastArgs", "int32");
      if (shape1Input.rank !== 1) {
        throw new Error("broadcastArgs(): first input must be a vector (rank=1). " + "Has rank ".concat(shape1Input.rank));
      }
      if (shape2Input.rank !== 1) {
        throw new Error("broadcastArgs(): second input must be a vector (rank=1). " + "Has rank ".concat(shape2Input.rank));
      }
      var inputs = { s0: shape1Input, s1: shape2Input };
      return ENGINE.runKernel(BroadcastArgs, inputs);
    }
    var broadcastArgs = /* @__PURE__ */ op({ broadcastArgs_ });
    function broadcastTo_(x, shape) {
      var input = convertToTensor(x, "broadcastTo", "x");
      var xShape = input.shape;
      assertNonNegativeIntegerDimensions(shape);
      if (shape.length < input.rank) {
        throw new Error("broadcastTo(): shape.length=".concat(shape.length, " < input.rank=").concat(input.rank, "."));
      }
      if (shape.length > input.rank) {
        var newShape = input.shape.slice();
        while (newShape.length < shape.length) {
          newShape.unshift(1);
        }
        input = reshape(input, newShape);
      }
      var inputShape = input.shape;
      var reps = Array.from(shape);
      for (var i = shape.length - 1; i >= 0; i--) {
        if (inputShape[i] === shape[i]) {
          reps[i] = 1;
        } else if (input.shape[i] !== 1) {
          throw new Error("broadcastTo(): [".concat(xShape, "] cannot be broadcast to [").concat(shape, "]."));
        }
      }
      var axes = reps.map(function(n, i2) {
        return n > 1 ? i2 : -1;
      }).filter(function(i2) {
        return i2 >= 0;
      });
      if (axes.length === 0) {
        return clone(input);
      }
      var inputs = { x: input };
      var attrs = { reps };
      return ENGINE.runKernel(Tile, inputs, attrs);
    }
    var broadcastTo = /* @__PURE__ */ op({ broadcastTo_ });
    function buffer(shape, dtype, values) {
      if (dtype === void 0) {
        dtype = "float32";
      }
      dtype = dtype || "float32";
      assertNonNegativeIntegerDimensions(shape);
      return new TensorBuffer(shape, dtype, values);
    }
    function ceil_(x) {
      var $x = convertToTensor(x, "x", "ceil", "float32");
      var inputs = { x: $x };
      return ENGINE.runKernel(Ceil, inputs);
    }
    var ceil = /* @__PURE__ */ op({ ceil_ });
    function fill(shape, value, dtype) {
      assertNonNegativeIntegerDimensions(shape);
      dtype = dtype || inferDtype(value);
      var attrs = { shape, value, dtype };
      return ENGINE.runKernel(Fill, {}, attrs);
    }
    function clipByValue_(x, clipValueMin, clipValueMax) {
      var $x = convertToTensor(x, "x", "clipByValue");
      assert(clipValueMin <= clipValueMax, function() {
        return "Error in clip: min (".concat(clipValueMin, ") must be ") + "less than or equal to max (".concat(clipValueMax, ").");
      });
      if (clipValueMin === clipValueMax) {
        return fill($x.shape, clipValueMin, $x.dtype);
      }
      var inputs = { x: $x };
      var attrs = { clipValueMin, clipValueMax };
      return ENGINE.runKernel(ClipByValue, inputs, attrs);
    }
    var clipByValue = /* @__PURE__ */ op({ clipByValue_ });
    function complex_(real2, imag2) {
      var $real = convertToTensor(real2, "real", "complex");
      var $imag = convertToTensor(imag2, "imag", "complex");
      assertShapesMatch($real.shape, $imag.shape, "real and imag shapes, ".concat($real.shape, " and ").concat($imag.shape, ", ") + "must match in call to tf.complex().");
      var inputs = { real: $real, imag: $imag };
      return ENGINE.runKernel(Complex, inputs);
    }
    var complex = /* @__PURE__ */ op({ complex_ });
    function concat1d_(tensors) {
      return concat(
        tensors,
        0
        /* axis */
      );
    }
    var concat1d = /* @__PURE__ */ op({ concat1d_ });
    function concat2d_(tensors, axis) {
      return concat(tensors, axis);
    }
    var concat2d = /* @__PURE__ */ op({ concat2d_ });
    function concat3d_(tensors, axis) {
      return concat(tensors, axis);
    }
    var concat3d = /* @__PURE__ */ op({ concat3d_ });
    function concat4d_(tensors, axis) {
      return concat(tensors, axis);
    }
    var concat4d = /* @__PURE__ */ op({ concat4d_ });
    function conv2d_(x, filter, strides, pad2, dataFormat, dilations, dimRoundingMode) {
      if (dataFormat === void 0) {
        dataFormat = "NHWC";
      }
      if (dilations === void 0) {
        dilations = [1, 1];
      }
      var $x = convertToTensor(x, "x", "conv2d", "float32");
      var $filter = convertToTensor(filter, "filter", "conv2d", "float32");
      var x4D = $x;
      var reshapedTo4D = false;
      if ($x.rank === 3) {
        reshapedTo4D = true;
        x4D = reshape($x, [1, $x.shape[0], $x.shape[1], $x.shape[2]]);
      }
      assert(x4D.rank === 4, function() {
        return "Error in conv2d: input must be rank 4, but got rank ".concat(x4D.rank, ".");
      });
      assert($filter.rank === 4, function() {
        return "Error in conv2d: filter must be rank 4, but got rank " + "".concat($filter.rank, ".");
      });
      checkPadOnDimRoundingMode("conv2d", pad2, dimRoundingMode);
      var inDepth = dataFormat === "NHWC" ? x4D.shape[3] : x4D.shape[1];
      assert(inDepth === $filter.shape[2], function() {
        return "Error in conv2d: depth of input (".concat(inDepth, ") must match ") + "input depth for filter ".concat($filter.shape[2], ".");
      });
      assert(eitherStridesOrDilationsAreOne(strides, dilations), function() {
        return "Error in conv2D: Either strides or dilations must be 1. " + "Got strides ".concat(strides, " and dilations '").concat(dilations, "'");
      });
      assert(stridesOrDilationsArePositive(dilations), function() {
        return "Error in conv2D: Dilated rates should be larger than 0.";
      });
      assert(stridesOrDilationsArePositive(strides), function() {
        return "Error in conv2D: Strides should be larger than 0.";
      });
      var inputs = { x: x4D, filter: $filter };
      var attrs = { strides, pad: pad2, dataFormat, dilations, dimRoundingMode };
      var res = ENGINE.runKernel(Conv2D, inputs, attrs);
      if (reshapedTo4D) {
        return reshape(res, [res.shape[1], res.shape[2], res.shape[3]]);
      }
      return res;
    }
    var conv2d$1 = /* @__PURE__ */ op({ conv2d_ });
    function conv1d_(x, filter, stride, pad2, dataFormat, dilation, dimRoundingMode) {
      if (dataFormat === void 0) {
        dataFormat = "NWC";
      }
      if (dilation === void 0) {
        dilation = 1;
      }
      var $x = convertToTensor(x, "x", "conv1d");
      var $filter = convertToTensor(filter, "filter", "conv1d");
      var x3D = $x;
      var reshapedTo3D = false;
      if ($x.rank === 2) {
        reshapedTo3D = true;
        x3D = reshape($x, [1, $x.shape[0], $x.shape[1]]);
      }
      assert(x3D.rank === 3, function() {
        return "Error in conv1d: input must be rank 3, but got rank ".concat(x3D.rank, ".");
      });
      assert($filter.rank === 3, function() {
        return "Error in conv1d: filter must be rank 3, but got rank " + "".concat($filter.rank, ".");
      });
      checkPadOnDimRoundingMode("conv1d", pad2, dimRoundingMode);
      assert(x3D.shape[2] === $filter.shape[1], function() {
        return "Error in conv1d: depth of input (".concat(x3D.shape[2], ") must match ") + "input depth for filter ".concat($filter.shape[1], ".");
      });
      assert(eitherStridesOrDilationsAreOne(stride, dilation), function() {
        return "Error in conv1D: Either stride or dilation must be 1. " + "Got stride ".concat(stride, " and dilation '").concat(dilation, "'");
      });
      assert(stridesOrDilationsArePositive(dilation), function() {
        return "Error in conv1D: Dilated rates should be larger than 0.";
      });
      assert(stridesOrDilationsArePositive(stride), function() {
        return "Error in conv1D: Stride should be larger than 0.";
      });
      assert(dataFormat === "NWC", function() {
        return "Error in conv1d: got dataFormat of ".concat(dataFormat, " but only NWC is currently supported.");
      });
      var filter4D = reshape($filter, [1, $filter.shape[0], $filter.shape[1], $filter.shape[2]]);
      var input4D = reshape(x3D, [x3D.shape[0], 1, x3D.shape[1], x3D.shape[2]]);
      var strides = [1, stride];
      var dilations = [1, dilation];
      var conv2dDataFormat = "NHWC";
      var res = conv2d$1(input4D, filter4D, strides, pad2, conv2dDataFormat, dilations, dimRoundingMode);
      if (reshapedTo3D) {
        return reshape(res, [res.shape[2], res.shape[3]]);
      }
      return reshape(res, [res.shape[0], res.shape[2], res.shape[3]]);
    }
    var conv1d = /* @__PURE__ */ op({ conv1d_ });
    function conv2DBackpropInput_(xShape, dy, filter, strides, pad2, dataFormat, dimRoundingMode) {
      if (dataFormat === void 0) {
        dataFormat = "NHWC";
      }
      assert(xShape.length === dy.rank, function() {
        return "Length of inShape " + "(".concat(xShape.length, ") and rank of dy (").concat(dy.rank, ") must match");
      });
      var xShape4D = xShape;
      var dy4D = dy;
      var reshapedTo4D = false;
      if (dy.rank === 3) {
        reshapedTo4D = true;
        dy4D = reshape(dy, [1, dy.shape[0], dy.shape[1], dy.shape[2]]);
        xShape4D = [1, xShape[0], xShape[1], xShape[2]];
      }
      assert(xShape4D.length === 4, function() {
        return "Error in conv2dDerInput: inShape must be length 4, but got length " + "".concat(xShape4D.length, ".");
      });
      assert(dy4D.rank === 4, function() {
        return "Error in conv2dDerInput: dy must be rank 4, but got " + "rank ".concat(dy4D.rank);
      });
      assert(filter.rank === 4, function() {
        return "Error in conv2dDerInput: filter must be rank 4, but got " + "rank ".concat(filter.rank);
      });
      var inDepth = dataFormat === "NHWC" ? xShape4D[3] : xShape4D[1];
      var outDepth = dataFormat === "NHWC" ? dy4D.shape[3] : dy4D.shape[1];
      assert(inDepth === filter.shape[2], function() {
        return "Error in conv2dDerInput: depth of input (".concat(inDepth, ") must ") + "match input depth for filter ".concat(filter.shape[2], ".");
      });
      assert(outDepth === filter.shape[3], function() {
        return "Error in conv2dDerInput: depth of output (".concat(outDepth, ") must ") + "match output depth for filter ".concat(filter.shape[3], ".");
      });
      checkPadOnDimRoundingMode("conv2dDerInput", pad2, dimRoundingMode);
      var inputs = { dy: dy4D, filter };
      var attrs = { strides, pad: pad2, dataFormat, dimRoundingMode, inputShape: xShape4D };
      var res = ENGINE.runKernel(Conv2DBackpropInput, inputs, attrs);
      if (reshapedTo4D) {
        return reshape(res, [res.shape[1], res.shape[2], res.shape[3]]);
      }
      return res;
    }
    var conv2DBackpropInput = /* @__PURE__ */ op({ conv2DBackpropInput_ });
    function conv2dTranspose_(x, filter, outputShape, strides, pad2, dimRoundingMode) {
      var $x = convertToTensor(x, "x", "conv2dTranspose");
      var $filter = convertToTensor(filter, "filter", "conv2dTranspose");
      return conv2DBackpropInput(outputShape, $x, $filter, strides, pad2, "NHWC", dimRoundingMode);
    }
    var conv2dTranspose = /* @__PURE__ */ op({ conv2dTranspose_ });
    function conv3d_(x, filter, strides, pad2, dataFormat, dilations) {
      if (dataFormat === void 0) {
        dataFormat = "NDHWC";
      }
      if (dilations === void 0) {
        dilations = [1, 1, 1];
      }
      var $x = convertToTensor(x, "x", "conv3d");
      var $filter = convertToTensor(filter, "filter", "conv3d");
      var x5D = $x;
      var reshapedTo5D = false;
      if ($x.rank === 4) {
        reshapedTo5D = true;
        x5D = reshape($x, [1, $x.shape[0], $x.shape[1], $x.shape[2], $x.shape[3]]);
      }
      assert(x5D.rank === 5, function() {
        return "Error in conv3d: input must be rank 5, but got rank ".concat(x5D.rank, ".");
      });
      assert($filter.rank === 5, function() {
        return "Error in conv3d: filter must be rank 5, but got rank " + "".concat($filter.rank, ".");
      });
      assert(x5D.shape[4] === $filter.shape[3], function() {
        return "Error in conv3d: depth of input (".concat(x5D.shape[4], ") must match ") + "input depth for filter ".concat($filter.shape[3], ".");
      });
      assert(eitherStridesOrDilationsAreOne(strides, dilations), function() {
        return "Error in conv3D: Either strides or dilations must be 1. " + "Got strides ".concat(strides, " and dilations '").concat(dilations, "'");
      });
      assert(dataFormat === "NDHWC", function() {
        return "Error in conv3d: got dataFormat of ".concat(dataFormat, " but only NDHWC is currently supported.");
      });
      assert(stridesOrDilationsArePositive(dilations), function() {
        return "Error in conv3D: Dilated rates should be larger than 0.";
      });
      assert(stridesOrDilationsArePositive(strides), function() {
        return "Error in conv3D: Strides should be larger than 0.";
      });
      var inputs = { x: x5D, filter: $filter };
      var attrs = { strides, pad: pad2, dataFormat, dilations };
      var res = ENGINE.runKernel(Conv3D, inputs, attrs);
      if (reshapedTo5D) {
        return reshape(res, [res.shape[1], res.shape[2], res.shape[3], res.shape[4]]);
      }
      return res;
    }
    var conv3d = /* @__PURE__ */ op({ conv3d_ });
    function conv3DBackpropInput_(xShape, dy, filter, strides, pad2) {
      assert(xShape.length === dy.rank, function() {
        return "Length of inShape " + "(".concat(xShape.length, ") and rank of dy (").concat(dy.rank, ") must match");
      });
      var xShape5D = xShape;
      var dy5D = dy;
      var reshapedTo5D = false;
      if (dy.rank === 4) {
        reshapedTo5D = true;
        dy5D = reshape(dy, [1, dy.shape[0], dy.shape[1], dy.shape[2], dy.shape[3]]);
        xShape5D = [1, xShape[0], xShape[1], xShape[2], xShape[3]];
      }
      var inDepth = xShape5D[4];
      var outDepth = dy5D.shape[4];
      assert(xShape5D.length === 5, function() {
        return "Error in conv3dDerInput: inShape must be length 5, but got length " + "".concat(xShape5D.length, ".");
      });
      assert(dy5D.rank === 5, function() {
        return "Error in conv3dDerInput: dy must be rank 5, but got " + "rank ".concat(dy5D.rank);
      });
      assert(filter.rank === 5, function() {
        return "Error in conv3dDerInput: filter must be rank 5, but got " + "rank ".concat(filter.rank);
      });
      assert(inDepth === filter.shape[3], function() {
        return "Error in conv3dDerInput: depth of input (".concat(inDepth, ") must ") + "match input depth for filter ".concat(filter.shape[3], ".");
      });
      assert(outDepth === filter.shape[4], function() {
        return "Error in conv3dDerInput: depth of output (".concat(outDepth, ") must ") + "match output depth for filter ".concat(filter.shape[4], ".");
      });
      var inputs = { dy: dy5D, filter };
      var attrs = { pad: pad2, strides, inputShape: xShape5D };
      var res = ENGINE.runKernel(Conv3DBackpropInputV2, inputs, attrs);
      if (reshapedTo5D) {
        return reshape(res, [res.shape[1], res.shape[2], res.shape[3], res.shape[4]]);
      }
      return res;
    }
    var conv3DBackpropInput = /* @__PURE__ */ op({ conv3DBackpropInput_ });
    function conv3dTranspose_(x, filter, outputShape, strides, pad2) {
      var $x = convertToTensor(x, "x", "conv3dTranspose");
      var $filter = convertToTensor(filter, "filter", "conv3dTranspose");
      return conv3DBackpropInput(outputShape, $x, $filter, strides, pad2);
    }
    var conv3dTranspose = /* @__PURE__ */ op({ conv3dTranspose_ });
    function cos_(x) {
      var $x = convertToTensor(x, "x", "cos", "float32");
      var inputs = { x: $x };
      return ENGINE.runKernel(Cos, inputs);
    }
    var cos = /* @__PURE__ */ op({ cos_ });
    function cosh_(x) {
      var $x = convertToTensor(x, "x", "cosh", "float32");
      var inputs = { x: $x };
      return ENGINE.runKernel(Cosh, inputs);
    }
    var cosh = /* @__PURE__ */ op({ cosh_ });
    function cumprod_(x, axis, exclusive, reverse2) {
      if (axis === void 0) {
        axis = 0;
      }
      if (exclusive === void 0) {
        exclusive = false;
      }
      if (reverse2 === void 0) {
        reverse2 = false;
      }
      var $x = convertToTensor(x, "x", "cumprod");
      var inputs = { x: $x };
      var attrs = { axis, exclusive, reverse: reverse2 };
      return ENGINE.runKernel(Cumprod, inputs, attrs);
    }
    var cumprod = /* @__PURE__ */ op({ cumprod_ });
    function cumsum_(x, axis, exclusive, reverse2) {
      if (axis === void 0) {
        axis = 0;
      }
      if (exclusive === void 0) {
        exclusive = false;
      }
      if (reverse2 === void 0) {
        reverse2 = false;
      }
      var $x = convertToTensor(x, "x", "cumsum");
      var inputs = { x: $x };
      var attrs = { axis, exclusive, reverse: reverse2 };
      return ENGINE.runKernel(Cumsum, inputs, attrs);
    }
    var cumsum = /* @__PURE__ */ op({ cumsum_ });
    function denseBincount_(x, weights, size, binaryOutput) {
      if (binaryOutput === void 0) {
        binaryOutput = false;
      }
      var $x = convertToTensor(x, "x", "denseBincount");
      var $weights = convertToTensor(weights, "weights", "denseBincount");
      assert($x.dtype === "int32", function() {
        return "Error in denseBincount: input " + "dtype must be int32, but got ".concat($x.dtype);
      });
      assert($x.rank <= 2, function() {
        return "Error in denseBincount: input must be at most rank 2, but got " + "rank ".concat($x.rank, ".");
      });
      assert(size >= 0, function() {
        return "size must be non-negative, but got ".concat(size, ".");
      });
      assert($weights.size === $x.size || $weights.size === 0, function() {
        return "Error in denseBincount: weights must have the same shape as x or " + "0-length, but got x shape: ".concat($x.shape, ", weights shape: ") + "".concat($weights.shape, ".");
      });
      var inputs = { x: $x, weights: $weights };
      var attrs = { size, binaryOutput };
      return ENGINE.runKernel(DenseBincount, inputs, attrs);
    }
    var denseBincount = /* @__PURE__ */ op({ denseBincount_ });
    function depthToSpace_(x, blockSize, dataFormat) {
      if (dataFormat === void 0) {
        dataFormat = "NHWC";
      }
      var $x = convertToTensor(x, "x", "depthToSpace", "float32");
      var inputHeight = dataFormat === "NHWC" ? $x.shape[1] : $x.shape[2];
      var inputWidth = dataFormat === "NHWC" ? $x.shape[2] : $x.shape[3];
      var inputDepth = dataFormat === "NHWC" ? $x.shape[3] : $x.shape[1];
      assert(blockSize > 1, function() {
        return "blockSize should be > 1 for depthToSpace, but was: ".concat(blockSize);
      });
      assert(inputHeight * blockSize >= 0, function() {
        return "Negative dimension size caused by overflow when multiplying\n    ".concat(inputHeight, " and ").concat(blockSize, "  for depthToSpace with input shape\n    ").concat($x.shape);
      });
      assert(inputWidth * blockSize >= 0, function() {
        return "Negative dimension size caused by overflow when multiplying\n    ".concat(inputWidth, " and ").concat(blockSize, " for depthToSpace with input shape\n        ").concat($x.shape);
      });
      assert(inputDepth % (blockSize * blockSize) === 0, function() {
        return "Dimension size must be evenly divisible by ".concat(blockSize * blockSize, " but is ").concat(inputDepth, " for depthToSpace with input shape ").concat($x.shape);
      });
      var inputs = { x: $x };
      var attrs = { blockSize, dataFormat };
      return ENGINE.runKernel(DepthToSpace, inputs, attrs);
    }
    var depthToSpace = /* @__PURE__ */ op({ depthToSpace_ });
    function depthwiseConv2d_(x, filter, strides, pad2, dataFormat, dilations, dimRoundingMode) {
      if (dataFormat === void 0) {
        dataFormat = "NHWC";
      }
      if (dilations === void 0) {
        dilations = [1, 1];
      }
      var $x = convertToTensor(x, "x", "depthwiseConv2d", "float32");
      var $filter = convertToTensor(filter, "filter", "depthwiseConv2d", "float32");
      var x4D = $x;
      var reshapedTo4D = false;
      if ($x.rank === 3) {
        reshapedTo4D = true;
        x4D = reshape($x, [1, $x.shape[0], $x.shape[1], $x.shape[2]]);
      }
      assert(x4D.rank === 4, function() {
        return "Error in depthwiseConv2d: input must be rank 4, but got " + "rank ".concat(x4D.rank, ".");
      });
      assert($filter.rank === 4, function() {
        return "Error in depthwiseConv2d: filter must be rank 4, but got rank " + "".concat($filter.rank, ".");
      });
      var inChannels = dataFormat === "NHWC" ? x4D.shape[3] : x4D.shape[1];
      assert(inChannels === $filter.shape[2], function() {
        return "Error in depthwiseConv2d: number of input channels " + "(".concat(inChannels, ") must match the inChannels dimension in ") + "filter ".concat($filter.shape[2], ".");
      });
      checkPadOnDimRoundingMode("depthwiseConv2d", pad2, dimRoundingMode);
      var inputs = { x: x4D, filter: $filter };
      var attrs = { strides, pad: pad2, dataFormat, dilations, dimRoundingMode };
      var res = ENGINE.runKernel(DepthwiseConv2dNative, inputs, attrs);
      if (reshapedTo4D) {
        return reshape(res, [res.shape[1], res.shape[2], res.shape[3]]);
      }
      return res;
    }
    var depthwiseConv2d$1 = /* @__PURE__ */ op({ depthwiseConv2d_ });
    function diag_(x) {
      var $x = convertToTensor(x, "x", "diag");
      var inputs = { x: $x };
      return ENGINE.runKernel(Diag, inputs);
    }
    var diag = /* @__PURE__ */ op({ diag_ });
    function dilation2d_(x, filter, strides, pad2, dilations, dataFormat) {
      if (dilations === void 0) {
        dilations = [1, 1];
      }
      if (dataFormat === void 0) {
        dataFormat = "NHWC";
      }
      var $x = convertToTensor(x, "x", "dilation2d");
      var $filter = convertToTensor(filter, "filter", "dilation2d");
      assert($x.rank === 3 || $x.rank === 4, function() {
        return "Error in dilation2d: input must be rank 3 or 4, but got rank " + "".concat($x.rank, ".");
      });
      assert($filter.rank === 3, function() {
        return "Error in dilation2d: filter must be rank 3, but got rank " + "".concat($filter.rank, ".");
      });
      assert(dataFormat === "NHWC", function() {
        return "Error in dilation2d: Only NHWC is currently supported, " + "but got dataFormat of ".concat(dataFormat);
      });
      var x4D = $x;
      var reshapedTo4D = false;
      if ($x.rank === 3) {
        x4D = reshape($x, [1, $x.shape[0], $x.shape[1], $x.shape[2]]);
        reshapedTo4D = true;
      }
      assert(x4D.shape[3] === $filter.shape[2], function() {
        return "Error in dilation2d:  input and filter must have the same depth: ".concat(x4D.shape[3], " vs ").concat($filter.shape[2]);
      });
      var inputs = { x: x4D, filter: $filter };
      var attrs = { strides, pad: pad2, dilations };
      var res = ENGINE.runKernel(Dilation2D, inputs, attrs);
      if (reshapedTo4D) {
        return reshape(res, [res.shape[1], res.shape[2], res.shape[3]]);
      }
      return res;
    }
    var dilation2d = /* @__PURE__ */ op({ dilation2d_ });
    function floorDiv_(a, b) {
      var _a;
      var $a = convertToTensor(a, "a", "floorDiv");
      var $b = convertToTensor(b, "b", "floorDiv");
      _a = __read(makeTypesMatch($a, $b), 2), $a = _a[0], $b = _a[1];
      var inputs = { a: $a, b: $b };
      return ENGINE.runKernel(FloorDiv, inputs);
    }
    var floorDiv = /* @__PURE__ */ op({ floorDiv_ });
    function div_(a, b) {
      var _a;
      var $a = convertToTensor(a, "a", "div");
      var $b = convertToTensor(b, "b", "div");
      _a = __read(makeTypesMatch($a, $b), 2), $a = _a[0], $b = _a[1];
      if ($a.dtype === "int32" && $b.dtype === "int32") {
        return floorDiv($a, $b);
      }
      var inputs = { a: $a, b: $b };
      var attrs = {};
      return ENGINE.runKernel(RealDiv, inputs, attrs);
    }
    var div = /* @__PURE__ */ op({ div_ });
    function getReductionAxes(inShape, outShape) {
      var result = [];
      for (var i = 0; i < outShape.length; i++) {
        var inDim = inShape[inShape.length - i - 1];
        var outAxis = outShape.length - i - 1;
        var outDim = outShape[outAxis];
        if (inDim == null || inDim === 1 && outDim > 1) {
          result.unshift(outAxis);
        }
      }
      return result;
    }
    function assertAndGetBroadcastShape(shapeA, shapeB) {
      var l = Math.max(shapeA.length, shapeB.length);
      var result = new Array(l);
      for (var i = 0; i < l; i++) {
        var a = shapeA[shapeA.length - i - 1];
        if (a == null) {
          a = 1;
        }
        var b = shapeB[shapeB.length - i - 1];
        if (b == null) {
          b = 1;
        }
        if (a === 1) {
          result[l - i - 1] = b;
        } else if (b === 1) {
          result[l - i - 1] = a;
        } else if (a !== b) {
          var errMsg = "Operands could not be broadcast together with shapes " + "".concat(shapeA, " and ").concat(shapeB, ".");
          throw Error(errMsg);
        } else {
          result[l - i - 1] = a;
        }
      }
      return result;
    }
    function equal_(a, b) {
      var _a;
      var $a = convertToTensor(a, "a", "equal", "string_or_numeric");
      var $b = convertToTensor(b, "b", "equal", "string_or_numeric");
      _a = __read(makeTypesMatch($a, $b), 2), $a = _a[0], $b = _a[1];
      assertAndGetBroadcastShape($a.shape, $b.shape);
      var inputs = { a: $a, b: $b };
      return ENGINE.runKernel(Equal, inputs);
    }
    var equal = /* @__PURE__ */ op({ equal_ });
    function where_(condition, a, b) {
      var $a = convertToTensor(a, "a", "where");
      var $b = convertToTensor(b, "b", "where");
      var $condition = convertToTensor(condition, "condition", "where", "bool");
      var broadcastShape = assertAndGetBroadcastShape(assertAndGetBroadcastShape($condition.shape, $a.shape), $b.shape);
      var $broadcastedCondition = broadcastTo($condition, broadcastShape);
      var $broadcastedA = broadcastTo($a, broadcastShape);
      var $broadcastedB = broadcastTo($b, broadcastShape);
      var inputs = {
        condition: $broadcastedCondition,
        t: $broadcastedA,
        e: $broadcastedB
      };
      return ENGINE.runKernel(Select, inputs);
    }
    var where = /* @__PURE__ */ op({ where_ });
    function zerosLike_(x) {
      var $x = convertToTensor(x, "x", "zerosLike");
      var inputs = { x: $x };
      return ENGINE.runKernel(ZerosLike, inputs);
    }
    var zerosLike = /* @__PURE__ */ op({ zerosLike_ });
    function divNoNan_(a, b) {
      var _a;
      var $a = convertToTensor(a, "a", "div");
      var $b = convertToTensor(b, "b", "div");
      _a = __read(makeTypesMatch($a, $b), 2), $a = _a[0], $b = _a[1];
      var divResult = div($a, $b);
      var zeros2 = zerosLike(divResult);
      var bEqualsZero = equal($b, zeros2);
      return where(bEqualsZero, zeros2, divResult);
    }
    var divNoNan = /* @__PURE__ */ op({ divNoNan_ });
    function dot_(t1, t2) {
      var $t1 = convertToTensor(t1, "t1", "dot");
      var $t2 = convertToTensor(t2, "t2", "dot");
      assert(($t1.rank === 1 || $t1.rank === 2) && ($t2.rank === 1 || $t2.rank === 2), function() {
        return "Error in dot: inputs must all be rank 1 or 2, but got ranks " + "".concat($t1.rank, " and ").concat($t2.rank, ".");
      });
      var t1Inner = $t1.rank === 1 ? $t1.size : $t1.shape[1];
      var t2Inner = $t2.rank === 1 ? $t2.size : $t2.shape[0];
      assert(t1Inner === t2Inner, function() {
        return "Error in dot: inner dimensions of inputs must match, but got " + "".concat(t1Inner, " and ").concat(t2Inner, ".");
      });
      if ($t1.rank === 1 && $t2.rank === 1) {
        var t12D = reshape($t1, [1, -1]);
        var t22D = reshape($t2, [-1, 1]);
        var t1t2 = matMul$1(t12D, t22D);
        return reshape(t1t2, []);
      } else if ($t1.rank === 1 && $t2.rank === 2) {
        var t12D = reshape($t1, [1, -1]);
        var t22D = reshape($t2, [$t2.shape[0], $t2.shape[1]]);
        var t1t2 = matMul$1(t12D, t22D);
        return reshape(t1t2, [t1t2.size]);
      } else if ($t1.rank === 2 && $t2.rank === 1) {
        var t22D = reshape($t2, [-1, 1]);
        var t1t2 = matMul$1($t1, t22D);
        return reshape(t1t2, [t1t2.size]);
      } else {
        var t22D = reshape($t2, [$t2.shape[0], $t2.shape[1]]);
        var t1t2 = matMul$1($t1, t22D);
        return t1t2;
      }
    }
    var dot = /* @__PURE__ */ op({ dot_ });
    function einsum_(equation) {
      var tensors = [];
      for (var _i = 1; _i < arguments.length; _i++) {
        tensors[_i - 1] = arguments[_i];
      }
      var $tensors = tensors.map(function(t, i) {
        return convertToTensor(t, "tensors".concat(i), "einsum");
      });
      var attrs = { equation };
      return ENGINE.runKernel(Einsum, $tensors, attrs);
    }
    var einsum = /* @__PURE__ */ op({ einsum_ });
    function elu_(x) {
      var $x = convertToTensor(x, "x", "elu", "float32");
      var inputs = { x: $x };
      return ENGINE.runKernel(Elu, inputs);
    }
    var elu = /* @__PURE__ */ op({ elu_ });
    function ensureShape_(x, shape) {
      var $x = convertToTensor(x, "x", "ensureShape", "string_or_numeric");
      if (!arraysEqualWithNull($x.shape, shape)) {
        throw new Error("EnsureShape: Shape of tensor ".concat($x.shape, " is not compatible with expected shape ").concat(shape));
      }
      return x;
    }
    var ensureShape = /* @__PURE__ */ op({ ensureShape_ });
    function erf_(x) {
      var $x = convertToTensor(x, "x", "erf");
      assert($x.dtype === "int32" || $x.dtype === "float32", function() {
        return "Input dtype must be `int32` or `float32`.";
      });
      if ($x.dtype === "int32") {
        $x = cast($x, "float32");
      }
      var inputs = { x: $x };
      return ENGINE.runKernel(Erf, inputs);
    }
    var erf = /* @__PURE__ */ op({ erf_ });
    function combineLocations(outputLoc, reduceLoc, axes) {
      var rank = outputLoc.length + reduceLoc.length;
      var loc = [];
      var outIdx = 0;
      var reduceIdx = 0;
      for (var dim = 0; dim < rank; dim++) {
        if (axes.indexOf(dim) === -1) {
          loc.push(outputLoc[outIdx++]);
        } else {
          loc.push(reduceLoc[reduceIdx++]);
        }
      }
      return loc;
    }
    function expandShapeToKeepDim(shape, axes) {
      var reduceSubShape = axes.map(function(x) {
        return 1;
      });
      return combineLocations(shape, reduceSubShape, axes);
    }
    function max_(x, axis, keepDims) {
      if (axis === void 0) {
        axis = null;
      }
      if (keepDims === void 0) {
        keepDims = false;
      }
      var $x = convertToTensor(x, "x", "max");
      var inputs = { x: $x };
      var attrs = { reductionIndices: axis, keepDims };
      return ENGINE.runKernel(Max, inputs, attrs);
    }
    var max = /* @__PURE__ */ op({ max_ });
    function min_(x, axis, keepDims) {
      if (axis === void 0) {
        axis = null;
      }
      if (keepDims === void 0) {
        keepDims = false;
      }
      var $x = convertToTensor(x, "x", "min");
      var inputs = { x: $x };
      var attrs = { axis, keepDims };
      return ENGINE.runKernel(Min, inputs, attrs);
    }
    var min = /* @__PURE__ */ op({ min_ });
    function pow_(base, exp2) {
      var _a;
      var $base = convertToTensor(base, "base", "pow");
      var $exp = convertToTensor(exp2, "exp", "pow");
      _a = __read(makeTypesMatch($base, $exp), 2), $base = _a[0], $exp = _a[1];
      var inputs = { a: $base, b: $exp };
      return ENGINE.runKernel(Pow, inputs);
    }
    var pow = /* @__PURE__ */ op({ pow_ });
    function makeTensor(values, shape, inferredShape, dtype) {
      if (dtype == null) {
        dtype = inferDtype(values);
      } else if (dtype === "complex64") {
        throw new Error("Cannot construct a complex64 tensor directly. Please use tf.complex(real, imag).");
      }
      if (isWebGPUData(values) || isWebGLData(values)) {
        if (dtype !== "float32" && dtype !== "int32") {
          throw new Error("Creating tensor from GPU data only supports " + "'float32'|'int32' dtype, while the dtype is ".concat(dtype, "."));
        }
        return ENGINE.backend.createTensorFromGPUData(values, shape || inferredShape, dtype);
      }
      if (!isTypedArray(values) && !Array.isArray(values) && typeof values !== "number" && typeof values !== "boolean" && typeof values !== "string") {
        throw new Error("values passed to tensor(values) must be a number/boolean/string or an array of numbers/booleans/strings, or a TypedArray");
      }
      if (shape != null) {
        assertNonNegativeIntegerDimensions(shape);
        var providedSize_1 = sizeFromShape(shape);
        var inferredSize_1 = sizeFromShape(inferredShape);
        assert(providedSize_1 === inferredSize_1, function() {
          return "Based on the provided shape, [".concat(shape, "], the tensor should have ") + "".concat(providedSize_1, " values but has ").concat(inferredSize_1);
        });
        for (var i = 0; i < inferredShape.length; ++i) {
          var inferred = inferredShape[i];
          var flatDimsDontMatch = i === inferredShape.length - 1 ? inferred !== sizeFromShape(shape.slice(i)) : true;
          assert(inferredShape[i] === shape[i] || !flatDimsDontMatch, function() {
            return "Error creating a new Tensor. Inferred shape " + "(".concat(inferredShape, ") does not match the provided ") + "shape (".concat(shape, "). ");
          });
        }
      }
      if (!isTypedArray(values) && !Array.isArray(values)) {
        values = [values];
      }
      shape = shape || inferredShape;
      values = dtype !== "string" ? toTypedArray(values, dtype) : flatten(values, [], true);
      return ENGINE.makeTensor(values, shape, dtype);
    }
    function scalar(value, dtype) {
      if ((isTypedArray(value) && dtype !== "string" || Array.isArray(value)) && dtype !== "complex64") {
        throw new Error("Error creating a new Scalar: value must be a primitive (number|boolean|string)");
      }
      if (dtype === "string" && isTypedArray(value) && !(value instanceof Uint8Array)) {
        throw new Error("When making a scalar from encoded string, the value must be `Uint8Array`.");
      }
      var shape = [];
      var inferredShape = [];
      return makeTensor(value, shape, inferredShape, dtype);
    }
    function sqrt_(x) {
      var $x = convertToTensor(x, "x", "sqrt", "float32");
      var inputs = { x: $x };
      return ENGINE.runKernel(Sqrt, inputs);
    }
    var sqrt = /* @__PURE__ */ op({ sqrt_ });
    function square_(x) {
      var $x = convertToTensor(x, "x", "square");
      var attrs = {};
      return ENGINE.runKernel("Square", { x: $x }, attrs);
    }
    var square = /* @__PURE__ */ op({ square_ });
    function sum_(x, axis, keepDims) {
      if (axis === void 0) {
        axis = null;
      }
      if (keepDims === void 0) {
        keepDims = false;
      }
      var $x = convertToTensor(x, "x", "sum");
      if ($x.dtype === "bool") {
        $x = cast($x, "int32");
      }
      var inputs = { x: $x };
      var attrs = { axis, keepDims };
      return ENGINE.runKernel(Sum, inputs, attrs);
    }
    var sum = /* @__PURE__ */ op({ sum_ });
    function norm_(x, ord, axis, keepDims) {
      if (ord === void 0) {
        ord = "euclidean";
      }
      if (axis === void 0) {
        axis = null;
      }
      if (keepDims === void 0) {
        keepDims = false;
      }
      x = convertToTensor(x, "x", "norm");
      var norm2 = normImpl(x, ord, axis);
      var keepDimsShape = norm2.shape;
      if (keepDims) {
        var axes = parseAxisParam(axis, x.shape);
        keepDimsShape = expandShapeToKeepDim(norm2.shape, axes);
      }
      return reshape(norm2, keepDimsShape);
    }
    function normImpl(x, p, axis) {
      if (axis === void 0) {
        axis = null;
      }
      if (x.rank === 0) {
        return abs(x);
      }
      if (x.rank !== 1 && axis === null) {
        return normImpl(reshape(x, [-1]), p, axis);
      }
      if (x.rank === 1 || typeof axis === "number" || Array.isArray(axis) && axis.length === 1) {
        if (p === 1) {
          return sum(abs(x), axis);
        }
        if (p === Infinity) {
          return max(abs(x), axis);
        }
        if (p === -Infinity) {
          return min(abs(x), axis);
        }
        if (p === "euclidean" || p === 2) {
          return sqrt(sum(pow(abs(x), scalar(2, "int32")), axis));
        }
        throw new Error("Error in norm: invalid ord value: ".concat(p));
      }
      if (Array.isArray(axis) && axis.length === 2) {
        if (p === 1) {
          return max(sum(abs(x), axis[0]), axis[1] - 1);
        }
        if (p === Infinity) {
          return max(sum(abs(x), axis[1]), axis[0]);
        }
        if (p === -Infinity) {
          return min(sum(abs(x), axis[1]), axis[0]);
        }
        if (p === "fro" || p === "euclidean") {
          return sqrt(sum(square(x), axis));
        }
        throw new Error("Error in norm: invalid ord value: ".concat(p));
      }
      throw new Error("Error in norm: invalid axis: ".concat(axis));
    }
    var norm = /* @__PURE__ */ op({ norm_ });
    function euclideanNorm_(x, axis, keepDims) {
      if (axis === void 0) {
        axis = null;
      }
      if (keepDims === void 0) {
        keepDims = false;
      }
      return norm(x, "euclidean", axis, keepDims);
    }
    var euclideanNorm = /* @__PURE__ */ op({ euclideanNorm_ });
    function exp_(x) {
      var $x = convertToTensor(x, "x", "exp");
      var inputs = { x: $x };
      return ENGINE.runKernel(Exp, inputs);
    }
    var exp = /* @__PURE__ */ op({ exp_ });
    function expandDims_(x, axis) {
      if (axis === void 0) {
        axis = 0;
      }
      var $x = convertToTensor(x, "x", "expandDims", "string_or_numeric");
      assert(axis <= $x.rank, function() {
        return "Axis must be <= rank of the tensor";
      });
      var inputs = { input: $x };
      var attrs = { dim: axis };
      return ENGINE.runKernel(ExpandDims, inputs, attrs);
    }
    var expandDims = /* @__PURE__ */ op({ expandDims_ });
    function expm1_(x) {
      var $x = convertToTensor(x, "x", "expm1");
      var inputs = { x: $x };
      return ENGINE.runKernel(Expm1, inputs);
    }
    var expm1 = /* @__PURE__ */ op({ expm1_ });
    function tile_(x, reps) {
      var $x = convertToTensor(x, "x", "tile", "string_or_numeric");
      assert($x.rank === reps.length, function() {
        return "Error in transpose: rank of input ".concat($x.rank, " ") + "must match length of reps ".concat(reps, ".");
      });
      var inputs = { x: $x };
      var attrs = { reps };
      return ENGINE.runKernel(Tile, inputs, attrs);
    }
    var tile = /* @__PURE__ */ op({ tile_ });
    function eye_(numRows, numColumns, batchShape, dtype) {
      if (dtype === void 0) {
        dtype = "float32";
      }
      if (numColumns == null) {
        numColumns = numRows;
      }
      var buff = buffer([numRows, numColumns], dtype);
      var n = numRows <= numColumns ? numRows : numColumns;
      for (var i = 0; i < n; ++i) {
        buff.set(1, i, i);
      }
      var out = reshape(buff.toTensor(), [numRows, numColumns]);
      if (batchShape == null) {
        return out;
      } else {
        if (batchShape.length === 1) {
          return tile(expandDims(out, 0), [batchShape[0], 1, 1]);
        } else if (batchShape.length === 2) {
          return tile(expandDims(expandDims(out, 0), 0), [batchShape[0], batchShape[1], 1, 1]);
        } else if (batchShape.length === 3) {
          return tile(expandDims(expandDims(expandDims(out, 0), 0), 0), [
            batchShape[0],
            batchShape[1],
            batchShape[2],
            1,
            1
          ]);
        } else {
          throw new Error("eye() currently supports only 1D and 2D " + // tslint:disable-next-line:no-any
          "batchShapes, but received ".concat(batchShape.length, "D."));
        }
      }
    }
    var eye = /* @__PURE__ */ op({ eye_ });
    function floor_(x) {
      var $x = convertToTensor(x, "x", "floor", "float32");
      var inputs = { x: $x };
      return ENGINE.runKernel(Floor, inputs);
    }
    var floor = /* @__PURE__ */ op({ floor_ });
    function gather_(x, indices, axis, batchDims) {
      if (axis === void 0) {
        axis = 0;
      }
      if (batchDims === void 0) {
        batchDims = 0;
      }
      var $x = convertToTensor(x, "x", "gather");
      var $indices = convertToTensor(indices, "indices", "gather", "int32");
      var inputs = { x: $x, indices: $indices };
      var attrs = { axis, batchDims };
      return ENGINE.runKernel(GatherV2, inputs, attrs);
    }
    var gather = /* @__PURE__ */ op({ gather_ });
    function greater_(a, b) {
      var _a;
      var $a = convertToTensor(a, "a", "greater", "string_or_numeric");
      var $b = convertToTensor(b, "b", "greater", "string_or_numeric");
      _a = __read(makeTypesMatch($a, $b), 2), $a = _a[0], $b = _a[1];
      assertAndGetBroadcastShape($a.shape, $b.shape);
      var inputs = { a: $a, b: $b };
      return ENGINE.runKernel(Greater, inputs);
    }
    var greater = /* @__PURE__ */ op({ greater_ });
    function greaterEqual_(a, b) {
      var _a;
      var $a = convertToTensor(a, "a", "greaterEqual", "string_or_numeric");
      var $b = convertToTensor(b, "b", "greaterEqual", "string_or_numeric");
      _a = __read(makeTypesMatch($a, $b), 2), $a = _a[0], $b = _a[1];
      assertAndGetBroadcastShape($a.shape, $b.shape);
      var inputs = { a: $a, b: $b };
      return ENGINE.runKernel(GreaterEqual, inputs);
    }
    var greaterEqual = /* @__PURE__ */ op({ greaterEqual_ });
    function imag_(input) {
      var $input = convertToTensor(input, "input", "imag");
      var inputs = { input: $input };
      return ENGINE.runKernel(Imag, inputs);
    }
    var imag = /* @__PURE__ */ op({ imag_ });
    function isFinite_(x) {
      var $x = convertToTensor(x, "x", "isFinite");
      var inputs = { x: $x };
      return ENGINE.runKernel(IsFinite, inputs);
    }
    var isFinite$1 = /* @__PURE__ */ op({ isFinite_ });
    function isInf_(x) {
      var $x = convertToTensor(x, "x", "isInf");
      var inputs = { x: $x };
      return ENGINE.runKernel(IsInf, inputs);
    }
    var isInf = /* @__PURE__ */ op({ isInf_ });
    function isNaN_(x) {
      var $x = convertToTensor(x, "x", "isNaN");
      var inputs = { x: $x };
      return ENGINE.runKernel(IsNan, inputs);
    }
    var isNaN$1 = /* @__PURE__ */ op({ isNaN_ });
    function leakyRelu_(x, alpha) {
      if (alpha === void 0) {
        alpha = 0.2;
      }
      var $x = convertToTensor(x, "x", "leakyRelu");
      var inputs = { x: $x };
      var attrs = { alpha };
      return ENGINE.runKernel(LeakyRelu, inputs, attrs);
    }
    var leakyRelu = /* @__PURE__ */ op({ leakyRelu_ });
    function less_(a, b) {
      var _a;
      var $a = convertToTensor(a, "a", "less", "string_or_numeric");
      var $b = convertToTensor(b, "b", "less", "string_or_numeric");
      _a = __read(makeTypesMatch($a, $b), 2), $a = _a[0], $b = _a[1];
      assertAndGetBroadcastShape($a.shape, $b.shape);
      var inputs = { a: $a, b: $b };
      return ENGINE.runKernel(Less, inputs);
    }
    var less = /* @__PURE__ */ op({ less_ });
    function lessEqual_(a, b) {
      var _a;
      var $a = convertToTensor(a, "a", "lessEqual", "string_or_numeric");
      var $b = convertToTensor(b, "b", "lessEqual", "string_or_numeric");
      _a = __read(makeTypesMatch($a, $b), 2), $a = _a[0], $b = _a[1];
      assertAndGetBroadcastShape($a.shape, $b.shape);
      var inputs = { a: $a, b: $b };
      return ENGINE.runKernel(LessEqual, inputs);
    }
    var lessEqual = /* @__PURE__ */ op({ lessEqual_ });
    function linspace(start, stop, num) {
      if (num <= 0) {
        throw new Error("The number of values should be positive.");
      }
      var attrs = { start, stop, num };
      return ENGINE.runKernel(LinSpace, {}, attrs);
    }
    function localResponseNormalization_(x, depthRadius, bias, alpha, beta) {
      if (depthRadius === void 0) {
        depthRadius = 5;
      }
      if (bias === void 0) {
        bias = 1;
      }
      if (alpha === void 0) {
        alpha = 1;
      }
      if (beta === void 0) {
        beta = 0.5;
      }
      var $x = convertToTensor(x, "x", "localResponseNormalization");
      assert($x.rank === 4 || $x.rank === 3, function() {
        return "Error in localResponseNormalization: x must be rank 3 or 4 but got\n               rank ".concat($x.rank, ".");
      });
      assert(isInt(depthRadius), function() {
        return "Error in localResponseNormalization: depthRadius must be an " + "integer but got depthRadius ".concat(depthRadius, ".");
      });
      var x4D = $x;
      var reshapedTo4D = false;
      if ($x.rank === 3) {
        reshapedTo4D = true;
        x4D = reshape($x, [1, $x.shape[0], $x.shape[1], $x.shape[2]]);
      }
      var inputs = { x: x4D };
      var attrs = { depthRadius, bias, alpha, beta };
      var res = ENGINE.runKernel(LRN, inputs, attrs);
      if (reshapedTo4D) {
        return reshape(res, [res.shape[1], res.shape[2], res.shape[3]]);
      } else {
        return res;
      }
    }
    var localResponseNormalization = /* @__PURE__ */ op({ localResponseNormalization_ });
    function log_(x) {
      var $x = convertToTensor(x, "x", "log", "float32");
      var inputs = { x: $x };
      return ENGINE.runKernel(Log, inputs);
    }
    var log = /* @__PURE__ */ op({ log_ });
    function log1p_(x) {
      var $x = convertToTensor(x, "x", "log1p");
      var inputs = { x: $x };
      return ENGINE.runKernel(Log1p, inputs);
    }
    var log1p = /* @__PURE__ */ op({ log1p_ });
    function customGrad(f) {
      return ENGINE.customGrad(f);
    }
    function neg_(x) {
      var $x = convertToTensor(x, "x", "neg");
      var inputs = { x: $x };
      return ENGINE.runKernel(Neg, inputs);
    }
    var neg = /* @__PURE__ */ op({ neg_ });
    function softplus_(x) {
      var $x = convertToTensor(x, "x", "softplus");
      var inputs = { x: $x };
      return ENGINE.runKernel(Softplus, inputs);
    }
    var softplus = /* @__PURE__ */ op({ softplus_ });
    function logSigmoid_(x) {
      var $x = convertToTensor(x, "x", "logSigmoid");
      var customOp = customGrad(function(x2) {
        var value = neg(softplus(neg(x2)));
        var gradFunc = function(dy) {
          var derX = mul(dy, sigmoid(neg(x2)));
          return derX;
        };
        return { value, gradFunc };
      });
      return customOp($x);
    }
    var logSigmoid = /* @__PURE__ */ op({ logSigmoid_ });
    function sub_(a, b) {
      var _a;
      var $a = convertToTensor(a, "a", "sub");
      var $b = convertToTensor(b, "b", "sub");
      _a = __read(makeTypesMatch($a, $b), 2), $a = _a[0], $b = _a[1];
      var inputs = { a: $a, b: $b };
      return ENGINE.runKernel(Sub, inputs);
    }
    var sub = /* @__PURE__ */ op({ sub_ });
    function logSoftmax_(logits, axis) {
      if (axis === void 0) {
        axis = -1;
      }
      var $logits = convertToTensor(logits, "logits", "logSoftmax");
      if (axis === -1) {
        axis = $logits.rank - 1;
      }
      if (axis !== $logits.rank - 1) {
        throw Error("Log Softmax along a non-last dimension is not yet supported. " + "Logits was rank ".concat($logits.rank, " and axis was ").concat(axis));
      }
      var customOp = customGrad(function(logits2, save) {
        var keepDims = true;
        var xMax = max(logits2, axis, true);
        var shifted = sub(logits2, xMax);
        var value = sub(cast(shifted, "float32"), log(sum(exp(shifted), axis, keepDims)));
        save([value]);
        var gradFunc = function(dy, saved) {
          var _a = __read(saved, 1), value2 = _a[0];
          var keepDims2 = true;
          var softmax2 = exp(value2);
          return sub(dy, mul(sum(dy, axis, keepDims2), softmax2));
        };
        return { value, gradFunc };
      });
      return customOp($logits);
    }
    var logSoftmax = /* @__PURE__ */ op({ logSoftmax_ });
    function logSumExp_(x, axis, keepDims) {
      if (axis === void 0) {
        axis = null;
      }
      if (keepDims === void 0) {
        keepDims = false;
      }
      var $x = convertToTensor(x, "x", "logSumExp");
      var axes = parseAxisParam(axis, $x.shape);
      var xMax = max(
        $x,
        axes,
        true
        /* keepDims */
      );
      var a = sub($x, xMax);
      var b = exp(a);
      var c = sum(b, axes);
      var d = log(c);
      var res = add(reshape(xMax, d.shape), d);
      if (keepDims) {
        var newShape = expandShapeToKeepDim(res.shape, axes);
        return reshape(res, newShape);
      }
      return res;
    }
    var logSumExp = /* @__PURE__ */ op({ logSumExp_ });
    function logicalAnd_(a, b) {
      var $a = convertToTensor(a, "a", "logicalAnd", "bool");
      var $b = convertToTensor(b, "b", "logicalAnd", "bool");
      assertAndGetBroadcastShape($a.shape, $b.shape);
      var inputs = { a: $a, b: $b };
      return ENGINE.runKernel(LogicalAnd, inputs);
    }
    var logicalAnd = /* @__PURE__ */ op({ logicalAnd_ });
    function logicalNot_(x) {
      var $x = convertToTensor(x, "x", "logicalNot", "bool");
      var inputs = { x: $x };
      return ENGINE.runKernel(LogicalNot, inputs);
    }
    var logicalNot = /* @__PURE__ */ op({ logicalNot_ });
    function logicalOr_(a, b) {
      var $a = convertToTensor(a, "a", "logicalOr", "bool");
      var $b = convertToTensor(b, "b", "logicalOr", "bool");
      assertAndGetBroadcastShape($a.shape, $b.shape);
      var inputs = { a: $a, b: $b };
      return ENGINE.runKernel(LogicalOr, inputs);
    }
    var logicalOr = /* @__PURE__ */ op({ logicalOr_ });
    function logicalXor_(a, b) {
      var $a = convertToTensor(a, "a", "logicalXor", "bool");
      var $b = convertToTensor(b, "b", "logicalXor", "bool");
      assertAndGetBroadcastShape($a.shape, $b.shape);
      return logicalAnd(logicalOr(a, b), logicalNot(logicalAnd(a, b)));
    }
    var logicalXor = /* @__PURE__ */ op({ logicalXor_ });
    var INT32_MAX = 2147483648;
    function searchSorted_(sortedSequence, values, side) {
      if (side === void 0) {
        side = "left";
      }
      var $sortedSequence = convertToTensor(sortedSequence, "sortedSequence", "searchSorted");
      var $values = convertToTensor(values, "values", "searchSorted");
      var sequenceSize = $sortedSequence.shape[$sortedSequence.shape.length - 1];
      var valuesSize = $values.shape[$values.shape.length - 1];
      var $sortedSequence2D = reshape($sortedSequence, [-1, sequenceSize]);
      var $values2D = reshape($values, [-1, valuesSize]);
      if ($sortedSequence2D.rank < 2) {
        throw new Error("Sorted input argument must be at least 2-dimensional");
      }
      if ($sortedSequence2D.shape[0] !== $values2D.shape[0]) {
        throw new Error("Leading dimension of 'sortedSequence' and 'values' must match.");
      }
      if (sizeFromShape($values2D.shape) >= INT32_MAX) {
        throw new Error("values tensor size must less than ".concat(INT32_MAX));
      }
      if ($sortedSequence2D.shape[1] >= INT32_MAX) {
        throw new Error("trailing dim_size must less than ".concat(INT32_MAX, " for int32 output type, was ").concat($sortedSequence2D.shape[1]));
      }
      var inputs = {
        sortedSequence: $sortedSequence2D,
        values: $values2D
      };
      var attrs = { side };
      return ENGINE.runKernel(SearchSorted, inputs, attrs);
    }
    var searchSorted = /* @__PURE__ */ op({ searchSorted_ });
    function lowerBound(sortedSequence, values) {
      return searchSorted(sortedSequence, values, "left");
    }
    function maxPool_(x, filterSize, strides, pad2, dimRoundingMode) {
      var $x = convertToTensor(x, "x", "maxPool");
      var dilations = 1;
      var x4D = $x;
      var reshapedTo4D = false;
      if ($x.rank === 3) {
        reshapedTo4D = true;
        x4D = reshape($x, [1, $x.shape[0], $x.shape[1], $x.shape[2]]);
      }
      assert(x4D.rank === 4, function() {
        return "Error in maxPool: input must be rank 4 but got rank ".concat(x4D.rank, ".");
      });
      assert(eitherStridesOrDilationsAreOne(strides, dilations), function() {
        return "Error in maxPool: Either strides or dilations must be 1. " + "Got strides ".concat(strides, " and dilations '").concat(dilations, "'");
      });
      checkPadOnDimRoundingMode("maxPool", pad2, dimRoundingMode);
      var inputs = { x: x4D };
      var attrs = { filterSize, strides, pad: pad2, dimRoundingMode };
      var res = ENGINE.runKernel(MaxPool, inputs, attrs);
      if (reshapedTo4D) {
        return reshape(res, [res.shape[1], res.shape[2], res.shape[3]]);
      }
      return res;
    }
    var maxPool = /* @__PURE__ */ op({ maxPool_ });
    function maxPool3d_(x, filterSize, strides, pad2, dimRoundingMode, dataFormat) {
      if (filterSize === void 0) {
        filterSize = [1, 1, 1];
      }
      if (dataFormat === void 0) {
        dataFormat = "NDHWC";
      }
      var $x = convertToTensor(x, "x", "maxPool3d");
      var x5D = $x;
      var reshapedTo5D = false;
      if ($x.rank === 4) {
        reshapedTo5D = true;
        x5D = reshape($x, [1, $x.shape[0], $x.shape[1], $x.shape[2], $x.shape[3]]);
      }
      assert(x5D.rank === 5, function() {
        return "Error in maxPool3d: x must be rank 5 but got rank ".concat(x5D.rank, ".");
      });
      assert(dataFormat === "NDHWC", function() {
        return "Error in maxPool3d: Only NDHWC is currently supported, " + "but got dataFormat of ".concat(dataFormat);
      });
      checkPadOnDimRoundingMode("maxPool3d", pad2, dimRoundingMode);
      var inputs = { x: x5D };
      var attrs = { filterSize, strides, pad: pad2, dimRoundingMode, dataFormat };
      var res = ENGINE.runKernel(MaxPool3D, inputs, attrs);
      if (reshapedTo5D) {
        return reshape(res, [res.shape[1], res.shape[2], res.shape[3], res.shape[4]]);
      }
      return res;
    }
    var maxPool3d = /* @__PURE__ */ op({ maxPool3d_ });
    function maxPoolWithArgmax_(x, filterSize, strides, pad2, includeBatchInIndex) {
      if (includeBatchInIndex === void 0) {
        includeBatchInIndex = false;
      }
      var $x = convertToTensor(x, "x", "maxPoolWithArgmax");
      var inputs = { x: $x };
      var attrs = { filterSize, strides, pad: pad2, includeBatchInIndex };
      var result = ENGINE.runKernel(MaxPoolWithArgmax, inputs, attrs);
      return { result: result[0], indexes: result[1] };
    }
    var maxPoolWithArgmax = /* @__PURE__ */ op({ maxPoolWithArgmax_ });
    function maximum_(a, b) {
      var _a;
      var $a = convertToTensor(a, "a", "maximum");
      var $b = convertToTensor(b, "b", "maximum");
      _a = __read(makeTypesMatch($a, $b), 2), $a = _a[0], $b = _a[1];
      if ($a.dtype === "bool") {
        $a = cast($a, "int32");
        $b = cast($b, "int32");
      }
      assertAndGetBroadcastShape($a.shape, $b.shape);
      var inputs = { a: $a, b: $b };
      return ENGINE.runKernel(Maximum, inputs);
    }
    var maximum = /* @__PURE__ */ op({ maximum_ });
    function mean_(x, axis, keepDims) {
      if (axis === void 0) {
        axis = null;
      }
      if (keepDims === void 0) {
        keepDims = false;
      }
      var $x = convertToTensor(x, "x", "mean");
      var inputs = { x: $x };
      var attrs = { axis, keepDims };
      return ENGINE.runKernel(Mean, inputs, attrs);
    }
    var mean = /* @__PURE__ */ op({ mean_ });
    function zeros(shape, dtype) {
      if (dtype === void 0) {
        dtype = "float32";
      }
      assertNonNegativeIntegerDimensions(shape);
      if (dtype === "complex64") {
        var real2 = zeros(shape, "float32");
        var imag2 = zeros(shape, "float32");
        return complex(real2, imag2);
      }
      var values = makeZerosTypedArray(sizeFromShape(shape), dtype);
      return ENGINE.makeTensor(values, shape, dtype);
    }
    function ones(shape, dtype) {
      if (dtype === void 0) {
        dtype = "float32";
      }
      assertNonNegativeIntegerDimensions(shape);
      if (dtype === "complex64") {
        var real2 = ones(shape, "float32");
        var imag2 = zeros(shape, "float32");
        return complex(real2, imag2);
      }
      var values = makeOnesTypedArray(sizeFromShape(shape), dtype);
      return ENGINE.makeTensor(values, shape, dtype);
    }
    function meshgrid(x, y, _a) {
      var _b = _a === void 0 ? {} : _a, _c = _b.indexing, indexing = _c === void 0 ? "xy" : _c;
      if (indexing !== "xy" && indexing !== "ij") {
        throw new TypeError("".concat(indexing, " is not a valid third argument to meshgrid"));
      }
      if (x === void 0) {
        return [];
      }
      var $x = convertToTensor(x, "x", "meshgrid", x instanceof Tensor ? x.dtype : "float32");
      if (y === void 0) {
        return [$x];
      }
      var $y = convertToTensor(y, "y", "meshgrid", y instanceof Tensor ? y.dtype : "float32");
      var w = sizeFromShape($x.shape);
      var h = sizeFromShape($y.shape);
      if (indexing === "xy") {
        $x = reshape($x, [1, -1]);
        $y = reshape($y, [-1, 1]);
        return [
          matMul$1(ones([h, 1], $x.dtype), $x),
          matMul$1($y, ones([1, w], $y.dtype))
        ];
      }
      $x = reshape($x, [-1, 1]);
      $y = reshape($y, [1, -1]);
      return [
        matMul$1($x, ones([1, h], $x.dtype)),
        matMul$1(ones([w, 1], $y.dtype), $y)
      ];
    }
    function minimum_(a, b) {
      var _a;
      var $a = convertToTensor(a, "a", "minimum");
      var $b = convertToTensor(b, "b", "minimum");
      _a = __read(makeTypesMatch($a, $b), 2), $a = _a[0], $b = _a[1];
      if ($a.dtype === "bool") {
        $a = cast($a, "int32");
        $b = cast($b, "int32");
      }
      assertAndGetBroadcastShape($a.shape, $b.shape);
      var inputs = { a: $a, b: $b };
      return ENGINE.runKernel(Minimum, inputs);
    }
    var minimum = /* @__PURE__ */ op({ minimum_ });
    function mirrorPad_(x, paddings, mode) {
      assert(mode === "reflect" || mode === "symmetric", function() {
        return "Invalid mode. Mode must be either reflect or symmetric. " + "Got ".concat(mode, ".");
      });
      var $x = convertToTensor(x, "x", "mirrorPad");
      if ($x.rank === 0) {
        throw new Error("mirrorPad(scalar) is not defined. Pass non-scalar to mirrorPad");
      }
      assert(paddings.length === $x.rank, function() {
        return "Padding doesn't match input. Must be ".concat($x.rank, ". ") + "Got ".concat(paddings.length, ".");
      });
      var shapeOffset = mode === "reflect" ? 1 : 0;
      var _loop_1 = function(i2) {
        assert(paddings[i2].length === 2, function() {
          return "Invalid number of paddings. Must be length of 2 each.";
        });
        assert(paddings[i2][0] >= 0 && paddings[i2][0] <= $x.shape[i2] - shapeOffset && paddings[i2][1] >= 0 && paddings[i2][1] <= $x.shape[i2] - shapeOffset, function() {
          return "Padding in dimension ".concat(i2, " cannot be greater than or equal ") + "to ".concat($x.shape[i2] - shapeOffset, " or less than 0 for input of ") + "shape ".concat($x.shape);
        });
      };
      for (var i = 0; i < $x.rank; i++) {
        _loop_1(i);
      }
      var attrs = { paddings, mode };
      var inputs = { x: $x };
      return ENGINE.runKernel(MirrorPad, inputs, attrs);
    }
    var mirrorPad = /* @__PURE__ */ op({ mirrorPad_ });
    function mod_(a, b) {
      var _a;
      var $a = convertToTensor(a, "a", "mod");
      var $b = convertToTensor(b, "b", "mod");
      _a = __read(makeTypesMatch($a, $b), 2), $a = _a[0], $b = _a[1];
      var inputs = { a: $a, b: $b };
      return ENGINE.runKernel(Mod, inputs);
    }
    var mod = /* @__PURE__ */ op({ mod_ });
    function moments_(x, axis, keepDims) {
      if (axis === void 0) {
        axis = null;
      }
      if (keepDims === void 0) {
        keepDims = false;
      }
      x = convertToTensor(x, "x", "moments");
      var axes = parseAxisParam(axis, x.shape);
      var xMean = mean(x, axes, keepDims);
      var keepDimsShape = xMean.shape;
      if (!keepDims) {
        keepDimsShape = expandShapeToKeepDim(xMean.shape, axes);
      }
      var devSquared = square(sub(cast(x, "float32"), reshape(xMean, keepDimsShape)));
      var variance = mean(devSquared, axes, keepDims);
      return { mean: xMean, variance };
    }
    var moments = /* @__PURE__ */ op({ moments_ });
    function multiRNNCell_(lstmCells, data, c, h) {
      var $data = convertToTensor(data, "data", "multiRNNCell");
      var $c = convertToTensorArray(c, "c", "multiRNNCell");
      var $h = convertToTensorArray(h, "h", "multiRNNCell");
      var input = $data;
      var newStates = [];
      for (var i = 0; i < lstmCells.length; i++) {
        var output = lstmCells[i](input, $c[i], $h[i]);
        newStates.push(output[0]);
        newStates.push(output[1]);
        input = output[1];
      }
      var newC = [];
      var newH = [];
      for (var i = 0; i < newStates.length; i += 2) {
        newC.push(newStates[i]);
        newH.push(newStates[i + 1]);
      }
      return [newC, newH];
    }
    var multiRNNCell = /* @__PURE__ */ op({ multiRNNCell_ });
    function multinomial_(logits, numSamples, seed, normalized) {
      if (normalized === void 0) {
        normalized = false;
      }
      var $logits = convertToTensor(logits, "logits", "multinomial");
      var numOutcomes = $logits.size;
      var origRank = $logits.rank;
      if (numOutcomes < 2) {
        throw new Error("Error in multinomial: you need at least 2 outcomes, but got " + "".concat(numOutcomes, "."));
      }
      if (origRank > 2) {
        throw new Error("Rank of probabilities must be 1 or 2, but is ".concat(origRank));
      }
      seed = seed || Math.random();
      var logits2D = origRank === 1 ? reshape($logits, [1, -1]) : $logits;
      var inputs = { logits: logits2D };
      var attrs = { numSamples, seed, normalized };
      var res = ENGINE.runKernel(Multinomial, inputs, attrs);
      return origRank === 1 ? reshape(res, [res.size]) : res;
    }
    var multinomial = /* @__PURE__ */ op({ multinomial_ });
    function notEqual_(a, b) {
      var _a;
      var $a = convertToTensor(a, "a", "notEqual", "string_or_numeric");
      var $b = convertToTensor(b, "b", "notEqual", "string_or_numeric");
      _a = __read(makeTypesMatch($a, $b), 2), $a = _a[0], $b = _a[1];
      assertAndGetBroadcastShape($a.shape, $b.shape);
      var inputs = { a: $a, b: $b };
      return ENGINE.runKernel(NotEqual, inputs);
    }
    var notEqual = /* @__PURE__ */ op({ notEqual_ });
    function oneHot_(indices, depth, onValue, offValue, dtype) {
      if (onValue === void 0) {
        onValue = 1;
      }
      if (offValue === void 0) {
        offValue = 0;
      }
      if (dtype === void 0) {
        dtype = "int32";
      }
      if (depth < 2) {
        throw new Error("Error in oneHot: depth must be >=2, but it is ".concat(depth));
      }
      var $indices = convertToTensor(indices, "indices", "oneHot", "int32");
      var inputs = { indices: $indices };
      var attrs = { dtype, depth, onValue, offValue };
      return ENGINE.runKernel(OneHot, inputs, attrs);
    }
    var oneHot = /* @__PURE__ */ op({ oneHot_ });
    function onesLike_(x) {
      var $x = convertToTensor(x, "x", "onesLike");
      var inputs = { x: $x };
      return ENGINE.runKernel(OnesLike, inputs);
    }
    var onesLike = /* @__PURE__ */ op({ onesLike_ });
    function outerProduct_(v1, v2) {
      var $v1 = convertToTensor(v1, "v1", "outerProduct");
      var $v2 = convertToTensor(v2, "v2", "outerProduct");
      assert($v1.rank === 1 && $v2.rank === 1, function() {
        return "Error in outerProduct: inputs must be rank 1, but got ranks " + "".concat($v1.rank, " and ").concat($v2.rank, ".");
      });
      var v12D = reshape($v1, [-1, 1]);
      var v22D = reshape($v2, [1, -1]);
      return matMul$1(v12D, v22D);
    }
    var outerProduct = /* @__PURE__ */ op({ outerProduct_ });
    function pad_(x, paddings, constantValue) {
      if (constantValue === void 0) {
        constantValue = 0;
      }
      var $x = convertToTensor(x, "x", "pad");
      if ($x.rank === 0) {
        throw new Error("pad(scalar) is not defined. Pass non-scalar to pad");
      }
      var attrs = { paddings, constantValue };
      var inputs = { x: $x };
      return ENGINE.runKernel(PadV2, inputs, attrs);
    }
    var pad = /* @__PURE__ */ op({ pad_ });
    function pad1d_(x, paddings, constantValue) {
      if (constantValue === void 0) {
        constantValue = 0;
      }
      assert(paddings.length === 2, function() {
        return "Invalid number of paddings. Must be length of 2.";
      });
      return pad(x, [paddings], constantValue);
    }
    var pad1d = /* @__PURE__ */ op({ pad1d_ });
    function pad2d_(x, paddings, constantValue) {
      if (constantValue === void 0) {
        constantValue = 0;
      }
      assert(paddings.length === 2 && paddings[0].length === 2 && paddings[1].length === 2, function() {
        return "Invalid number of paddings. Must be length of 2 each.";
      });
      return pad(x, paddings, constantValue);
    }
    var pad2d = /* @__PURE__ */ op({ pad2d_ });
    function pad3d_(x, paddings, constantValue) {
      if (constantValue === void 0) {
        constantValue = 0;
      }
      assert(paddings.length === 3 && paddings[0].length === 2 && paddings[1].length === 2 && paddings[2].length === 2, function() {
        return "Invalid number of paddings. Must be length of 2 each.";
      });
      return pad(x, paddings, constantValue);
    }
    var pad3d = /* @__PURE__ */ op({ pad3d_ });
    function pad4d_(x, paddings, constantValue) {
      if (constantValue === void 0) {
        constantValue = 0;
      }
      assert(paddings.length === 4 && paddings[0].length === 2 && paddings[1].length === 2 && paddings[2].length === 2 && paddings[3].length === 2, function() {
        return "Invalid number of paddings. Must be length of 2 each.";
      });
      return pad(x, paddings, constantValue);
    }
    var pad4d = /* @__PURE__ */ op({ pad4d_ });
    function spaceToBatchND_(x, blockShape, paddings) {
      var $x = convertToTensor(x, "x", "spaceToBatchND");
      assert($x.rank >= 1 + blockShape.length, function() {
        return "input rank ".concat($x.rank, " should be > than [blockShape] ").concat(blockShape.length);
      });
      assert(paddings.length === blockShape.length, function() {
        return "paddings.shape[0] ".concat(paddings.length, " must be equal to [blockShape] ").concat(blockShape.length);
      });
      assert($x.shape.reduce(function(a, b, i) {
        if (i > 0 && i <= blockShape.length) {
          return a && (b + paddings[i - 1][0] + paddings[i - 1][1]) % blockShape[i - 1] === 0;
        }
        return a;
      }, true), function() {
        return "input spatial dimensions ".concat($x.shape.slice(1), " with paddings ").concat(paddings.toString(), " must be divisible by blockShapes ").concat(blockShape.toString());
      });
      var inputs = { x: $x };
      var attrs = { blockShape, paddings };
      return ENGINE.runKernel(SpaceToBatchND, inputs, attrs);
    }
    var spaceToBatchND = /* @__PURE__ */ op({ spaceToBatchND_ });
    function pool_(input, windowShape, poolingType, pad2, dilations, strides, dimRoundingMode) {
      if (dilations == null) {
        dilations = [1, 1];
      }
      if (strides == null) {
        strides = 1;
      }
      if (pad2 === 0) {
        pad2 = "valid";
      }
      var $x = convertToTensor(input, "x", "maxPool");
      var x4D = $x;
      var reshapedTo4D = false;
      if ($x.rank === 3) {
        reshapedTo4D = true;
        x4D = reshape($x, [1, $x.shape[0], $x.shape[1], $x.shape[2]]);
      }
      assert(eitherStridesOrDilationsAreOne(strides, dilations), function() {
        return "Error in pool: Either strides or dilations must be 1. " + "Got strides ".concat(strides, " and dilations '").concat(dilations, "'");
      });
      var convInfo = computePool2DInfo(x4D.shape, windowShape, strides, dilations, pad2);
      var dilation = [convInfo.dilationHeight, convInfo.dilationWidth];
      var basePadding;
      if (pad2 === "same") {
        basePadding = withSpaceToBatchBasePaddings([convInfo.filterHeight, convInfo.filterWidth], dilation);
      } else {
        basePadding = [[0, 0], [0, 0]];
      }
      var isDilationOne = dilation[0] === 1 && dilation[1] === 1;
      var _a = __read(requiredSpaceToBatchPaddings([convInfo.inHeight, convInfo.inWidth], dilation, basePadding), 2), adjustedPadding = _a[0], adjustedCrops = _a[1];
      var convertedPad = isDilationOne ? pad2 : "valid";
      var convertedX = isDilationOne ? x4D : spaceToBatchND(x4D, dilation, adjustedPadding);
      var forwardOp = poolingType === "avg" ? function() {
        return avgPool(convertedX, windowShape, strides, convertedPad, dimRoundingMode);
      } : function() {
        return maxPool(convertedX, windowShape, strides, convertedPad, dimRoundingMode);
      };
      var y = forwardOp();
      var res = isDilationOne ? y : batchToSpaceND(y, dilation, adjustedCrops);
      if (reshapedTo4D) {
        return reshape(res, [res.shape[1], res.shape[2], res.shape[3]]);
      }
      return res;
    }
    function requiredSpaceToBatchPaddings(inputShape, blockShape, basePadding) {
      var padStart = basePadding.map(function(b) {
        return b[0];
      });
      var origPadEnd = basePadding.map(function(b) {
        return b[1];
      });
      var fullInputShape = inputShape.concat(padStart, origPadEnd);
      var padEndExtra = blockShape.map(function(b, i) {
        return (b - fullInputShape[i] % b) % b;
      });
      var padEnd = origPadEnd.map(function(s, i) {
        return s + padEndExtra[i];
      });
      var paddings = blockShape.map(function(_, i) {
        return [padStart[i], padEnd[i]];
      });
      var crops = blockShape.map(function(_, i) {
        return [0, padEndExtra[i]];
      });
      return [paddings, crops];
    }
    function withSpaceToBatchBasePaddings(filterShape, dilation) {
      var dilatedFilterShape = filterShape.map(function(s, i) {
        return s + (s - 1) * (dilation[i] - 1);
      });
      var padExtraShape = dilatedFilterShape.map(function(s) {
        return s - 1;
      });
      var padExtraStart = padExtraShape.map(function(s) {
        return Math.floor(s / 2);
      });
      var padExtraEnd = padExtraShape.map(function(s, i) {
        return s - padExtraStart[i];
      });
      return padExtraShape.map(function(_, i) {
        return [padExtraStart[i], padExtraEnd[i]];
      });
    }
    var pool = /* @__PURE__ */ op({ pool_ });
    function prelu_(x, alpha) {
      var $x = convertToTensor(x, "x", "prelu");
      var $alpha = convertToTensor(alpha, "alpha", "prelu");
      var inputs = { x: $x, alpha: $alpha };
      return ENGINE.runKernel(Prelu, inputs);
    }
    var prelu = /* @__PURE__ */ op({ prelu_ });
    function print(x, verbose) {
      if (verbose === void 0) {
        verbose = false;
      }
      console.log(x.toString(verbose));
    }
    function prod_(x, axis, keepDims) {
      if (axis === void 0) {
        axis = null;
      }
      if (keepDims === void 0) {
        keepDims = false;
      }
      var $x = convertToTensor(x, "x", "prod");
      if ($x.dtype === "bool") {
        $x = cast($x, "int32");
      }
      var inputs = { x: $x };
      var attrs = { axis, keepDims };
      return ENGINE.runKernel(Prod, inputs, attrs);
    }
    var prod = /* @__PURE__ */ op({ prod_ });
    function raggedGather_(paramsNestedSplits, paramsDenseValues, indices, outputRaggedRank) {
      var $paramsNestedSplits = paramsNestedSplits.map(function(t, i) {
        return convertToTensor(t, "tensors".concat(i), "raggedGather", "int32");
      });
      var $paramsDenseValues = convertToTensor(paramsDenseValues, "paramsDenseValues", "raggedGather");
      var $indices = convertToTensor(indices, "indices", "raggedGather", "int32");
      var inputs = {
        paramsNestedSplits: $paramsNestedSplits,
        paramsDenseValues: $paramsDenseValues,
        indices: $indices
      };
      var attrs = { outputRaggedRank };
      var result = ENGINE.runKernel(RaggedGather, inputs, attrs);
      return {
        outputNestedSplits: result.slice(0, result.length - 1),
        outputDenseValues: result[result.length - 1]
      };
    }
    var raggedGather = /* @__PURE__ */ op({ raggedGather_ });
    function raggedRange_(starts, limits, deltas) {
      var $starts = convertToTensor(starts, "starts", "raggedRange");
      var $limits = convertToTensor(limits, "limits", "raggedRange", $starts.dtype);
      var $deltas = convertToTensor(deltas, "deltas", "raggedRange", $starts.dtype);
      var inputs = {
        starts: $starts,
        limits: $limits,
        deltas: $deltas
      };
      var result = ENGINE.runKernel(RaggedRange, inputs);
      return {
        rtNestedSplits: result[0],
        rtDenseValues: result[1]
      };
    }
    var raggedRange = /* @__PURE__ */ op({ raggedRange_ });
    function raggedTensorToTensor_(shape, values, defaultValue, rowPartitionTensors, rowPartitionTypes) {
      var $shape = convertToTensor(shape, "shape", "raggedTensorToTensor", "int32");
      var $values = convertToTensor(values, "values", "raggedTensorToTensor");
      var $defaultValue = convertToTensor(defaultValue, "defaultValue", "raggedTensorToTensor", $values.dtype);
      var $rowPartitionTensors = rowPartitionTensors.map(function(t, i) {
        return convertToTensor(t, "tensors".concat(i), "raggedTensorToTensor", "int32");
      });
      var inputs = {
        shape: $shape,
        values: $values,
        defaultValue: $defaultValue,
        rowPartitionTensors: $rowPartitionTensors
      };
      var attrs = { rowPartitionTypes };
      return ENGINE.runKernel(RaggedTensorToTensor, inputs, attrs);
    }
    var raggedTensorToTensor = /* @__PURE__ */ op({ raggedTensorToTensor_ });
    function rand_(shape, randFunction, dtype) {
      assertNonNegativeIntegerDimensions(shape);
      var size = sizeFromShape(shape);
      var values = null;
      if (dtype == null || dtype === "float32") {
        values = new Float32Array(size);
      } else if (dtype === "int32") {
        values = new Int32Array(size);
      } else if (dtype === "bool") {
        values = new Uint8Array(size);
      } else {
        throw new Error("Unknown data type ".concat(dtype));
      }
      for (var i = 0; i < size; i++) {
        values[i] = randFunction();
      }
      return ENGINE.makeTensor(values, shape, dtype);
    }
    var rand = /* @__PURE__ */ op({ rand_ });
    var alea$1 = { exports: {} };
    (function(module3) {
      (function(global2, module4, define) {
        function Alea(seed) {
          var me = this, mash = Mash();
          me.next = function() {
            var t = 2091639 * me.s0 + me.c * 23283064365386963e-26;
            me.s0 = me.s1;
            me.s1 = me.s2;
            return me.s2 = t - (me.c = t | 0);
          };
          me.c = 1;
          me.s0 = mash(" ");
          me.s1 = mash(" ");
          me.s2 = mash(" ");
          me.s0 -= mash(seed);
          if (me.s0 < 0) {
            me.s0 += 1;
          }
          me.s1 -= mash(seed);
          if (me.s1 < 0) {
            me.s1 += 1;
          }
          me.s2 -= mash(seed);
          if (me.s2 < 0) {
            me.s2 += 1;
          }
          mash = null;
        }
        function copy(f, t) {
          t.c = f.c;
          t.s0 = f.s0;
          t.s1 = f.s1;
          t.s2 = f.s2;
          return t;
        }
        function impl(seed, opts) {
          var xg = new Alea(seed), state = opts && opts.state, prng = xg.next;
          prng.int32 = function() {
            return xg.next() * 4294967296 | 0;
          };
          prng.double = function() {
            return prng() + (prng() * 2097152 | 0) * 11102230246251565e-32;
          };
          prng.quick = prng;
          if (state) {
            if (typeof state == "object")
              copy(state, xg);
            prng.state = function() {
              return copy(xg, {});
            };
          }
          return prng;
        }
        function Mash() {
          var n = 4022871197;
          var mash = function(data) {
            data = String(data);
            for (var i = 0; i < data.length; i++) {
              n += data.charCodeAt(i);
              var h = 0.02519603282416938 * n;
              n = h >>> 0;
              h -= n;
              h *= n;
              n = h >>> 0;
              h -= n;
              n += h * 4294967296;
            }
            return (n >>> 0) * 23283064365386963e-26;
          };
          return mash;
        }
        if (module4 && module4.exports) {
          module4.exports = impl;
        } else if (define && define.amd) {
          define(function() {
            return impl;
          });
        } else {
          this.alea = impl;
        }
      })(
        commonjsGlobal,
        module3,
        // present in node.js
        false
        // present with an AMD loader
      );
    })(alea$1);
    var aleaExports = alea$1.exports;
    var xor128$1 = { exports: {} };
    (function(module3) {
      (function(global2, module4, define) {
        function XorGen(seed) {
          var me = this, strseed = "";
          me.x = 0;
          me.y = 0;
          me.z = 0;
          me.w = 0;
          me.next = function() {
            var t = me.x ^ me.x << 11;
            me.x = me.y;
            me.y = me.z;
            me.z = me.w;
            return me.w ^= me.w >>> 19 ^ t ^ t >>> 8;
          };
          if (seed === (seed | 0)) {
            me.x = seed;
          } else {
            strseed += seed;
          }
          for (var k = 0; k < strseed.length + 64; k++) {
            me.x ^= strseed.charCodeAt(k) | 0;
            me.next();
          }
        }
        function copy(f, t) {
          t.x = f.x;
          t.y = f.y;
          t.z = f.z;
          t.w = f.w;
          return t;
        }
        function impl(seed, opts) {
          var xg = new XorGen(seed), state = opts && opts.state, prng = function() {
            return (xg.next() >>> 0) / 4294967296;
          };
          prng.double = function() {
            do {
              var top = xg.next() >>> 11, bot = (xg.next() >>> 0) / 4294967296, result = (top + bot) / (1 << 21);
            } while (result === 0);
            return result;
          };
          prng.int32 = xg.next;
          prng.quick = prng;
          if (state) {
            if (typeof state == "object")
              copy(state, xg);
            prng.state = function() {
              return copy(xg, {});
            };
          }
          return prng;
        }
        if (module4 && module4.exports) {
          module4.exports = impl;
        } else if (define && define.amd) {
          define(function() {
            return impl;
          });
        } else {
          this.xor128 = impl;
        }
      })(
        commonjsGlobal,
        module3,
        // present in node.js
        false
        // present with an AMD loader
      );
    })(xor128$1);
    var xor128Exports = xor128$1.exports;
    var xorwow$1 = { exports: {} };
    (function(module3) {
      (function(global2, module4, define) {
        function XorGen(seed) {
          var me = this, strseed = "";
          me.next = function() {
            var t = me.x ^ me.x >>> 2;
            me.x = me.y;
            me.y = me.z;
            me.z = me.w;
            me.w = me.v;
            return (me.d = me.d + 362437 | 0) + (me.v = me.v ^ me.v << 4 ^ (t ^ t << 1)) | 0;
          };
          me.x = 0;
          me.y = 0;
          me.z = 0;
          me.w = 0;
          me.v = 0;
          if (seed === (seed | 0)) {
            me.x = seed;
          } else {
            strseed += seed;
          }
          for (var k = 0; k < strseed.length + 64; k++) {
            me.x ^= strseed.charCodeAt(k) | 0;
            if (k == strseed.length) {
              me.d = me.x << 10 ^ me.x >>> 4;
            }
            me.next();
          }
        }
        function copy(f, t) {
          t.x = f.x;
          t.y = f.y;
          t.z = f.z;
          t.w = f.w;
          t.v = f.v;
          t.d = f.d;
          return t;
        }
        function impl(seed, opts) {
          var xg = new XorGen(seed), state = opts && opts.state, prng = function() {
            return (xg.next() >>> 0) / 4294967296;
          };
          prng.double = function() {
            do {
              var top = xg.next() >>> 11, bot = (xg.next() >>> 0) / 4294967296, result = (top + bot) / (1 << 21);
            } while (result === 0);
            return result;
          };
          prng.int32 = xg.next;
          prng.quick = prng;
          if (state) {
            if (typeof state == "object")
              copy(state, xg);
            prng.state = function() {
              return copy(xg, {});
            };
          }
          return prng;
        }
        if (module4 && module4.exports) {
          module4.exports = impl;
        } else if (define && define.amd) {
          define(function() {
            return impl;
          });
        } else {
          this.xorwow = impl;
        }
      })(
        commonjsGlobal,
        module3,
        // present in node.js
        false
        // present with an AMD loader
      );
    })(xorwow$1);
    var xorwowExports = xorwow$1.exports;
    var xorshift7$1 = { exports: {} };
    (function(module3) {
      (function(global2, module4, define) {
        function XorGen(seed) {
          var me = this;
          me.next = function() {
            var X = me.x, i = me.i, t, v;
            t = X[i];
            t ^= t >>> 7;
            v = t ^ t << 24;
            t = X[i + 1 & 7];
            v ^= t ^ t >>> 10;
            t = X[i + 3 & 7];
            v ^= t ^ t >>> 3;
            t = X[i + 4 & 7];
            v ^= t ^ t << 7;
            t = X[i + 7 & 7];
            t = t ^ t << 13;
            v ^= t ^ t << 9;
            X[i] = v;
            me.i = i + 1 & 7;
            return v;
          };
          function init(me2, seed2) {
            var j, X = [];
            if (seed2 === (seed2 | 0)) {
              X[0] = seed2;
            } else {
              seed2 = "" + seed2;
              for (j = 0; j < seed2.length; ++j) {
                X[j & 7] = X[j & 7] << 15 ^ seed2.charCodeAt(j) + X[j + 1 & 7] << 13;
              }
            }
            while (X.length < 8)
              X.push(0);
            for (j = 0; j < 8 && X[j] === 0; ++j)
              ;
            if (j == 8)
              X[7] = -1;
            else
              X[j];
            me2.x = X;
            me2.i = 0;
            for (j = 256; j > 0; --j) {
              me2.next();
            }
          }
          init(me, seed);
        }
        function copy(f, t) {
          t.x = f.x.slice();
          t.i = f.i;
          return t;
        }
        function impl(seed, opts) {
          if (seed == null)
            seed = +/* @__PURE__ */ new Date();
          var xg = new XorGen(seed), state = opts && opts.state, prng = function() {
            return (xg.next() >>> 0) / 4294967296;
          };
          prng.double = function() {
            do {
              var top = xg.next() >>> 11, bot = (xg.next() >>> 0) / 4294967296, result = (top + bot) / (1 << 21);
            } while (result === 0);
            return result;
          };
          prng.int32 = xg.next;
          prng.quick = prng;
          if (state) {
            if (state.x)
              copy(state, xg);
            prng.state = function() {
              return copy(xg, {});
            };
          }
          return prng;
        }
        if (module4 && module4.exports) {
          module4.exports = impl;
        } else if (define && define.amd) {
          define(function() {
            return impl;
          });
        } else {
          this.xorshift7 = impl;
        }
      })(
        commonjsGlobal,
        module3,
        // present in node.js
        false
        // present with an AMD loader
      );
    })(xorshift7$1);
    var xorshift7Exports = xorshift7$1.exports;
    var xor4096$1 = { exports: {} };
    (function(module3) {
      (function(global2, module4, define) {
        function XorGen(seed) {
          var me = this;
          me.next = function() {
            var w = me.w, X = me.X, i = me.i, t, v;
            me.w = w = w + 1640531527 | 0;
            v = X[i + 34 & 127];
            t = X[i = i + 1 & 127];
            v ^= v << 13;
            t ^= t << 17;
            v ^= v >>> 15;
            t ^= t >>> 12;
            v = X[i] = v ^ t;
            me.i = i;
            return v + (w ^ w >>> 16) | 0;
          };
          function init(me2, seed2) {
            var t, v, i, j, w, X = [], limit = 128;
            if (seed2 === (seed2 | 0)) {
              v = seed2;
              seed2 = null;
            } else {
              seed2 = seed2 + "\0";
              v = 0;
              limit = Math.max(limit, seed2.length);
            }
            for (i = 0, j = -32; j < limit; ++j) {
              if (seed2)
                v ^= seed2.charCodeAt((j + 32) % seed2.length);
              if (j === 0)
                w = v;
              v ^= v << 10;
              v ^= v >>> 15;
              v ^= v << 4;
              v ^= v >>> 13;
              if (j >= 0) {
                w = w + 1640531527 | 0;
                t = X[j & 127] ^= v + w;
                i = 0 == t ? i + 1 : 0;
              }
            }
            if (i >= 128) {
              X[(seed2 && seed2.length || 0) & 127] = -1;
            }
            i = 127;
            for (j = 4 * 128; j > 0; --j) {
              v = X[i + 34 & 127];
              t = X[i = i + 1 & 127];
              v ^= v << 13;
              t ^= t << 17;
              v ^= v >>> 15;
              t ^= t >>> 12;
              X[i] = v ^ t;
            }
            me2.w = w;
            me2.X = X;
            me2.i = i;
          }
          init(me, seed);
        }
        function copy(f, t) {
          t.i = f.i;
          t.w = f.w;
          t.X = f.X.slice();
          return t;
        }
        function impl(seed, opts) {
          if (seed == null)
            seed = +/* @__PURE__ */ new Date();
          var xg = new XorGen(seed), state = opts && opts.state, prng = function() {
            return (xg.next() >>> 0) / 4294967296;
          };
          prng.double = function() {
            do {
              var top = xg.next() >>> 11, bot = (xg.next() >>> 0) / 4294967296, result = (top + bot) / (1 << 21);
            } while (result === 0);
            return result;
          };
          prng.int32 = xg.next;
          prng.quick = prng;
          if (state) {
            if (state.X)
              copy(state, xg);
            prng.state = function() {
              return copy(xg, {});
            };
          }
          return prng;
        }
        if (module4 && module4.exports) {
          module4.exports = impl;
        } else if (define && define.amd) {
          define(function() {
            return impl;
          });
        } else {
          this.xor4096 = impl;
        }
      })(
        commonjsGlobal,
        // window object or global
        module3,
        // present in node.js
        false
        // present with an AMD loader
      );
    })(xor4096$1);
    var xor4096Exports = xor4096$1.exports;
    var tychei$1 = { exports: {} };
    (function(module3) {
      (function(global2, module4, define) {
        function XorGen(seed) {
          var me = this, strseed = "";
          me.next = function() {
            var b = me.b, c = me.c, d = me.d, a = me.a;
            b = b << 25 ^ b >>> 7 ^ c;
            c = c - d | 0;
            d = d << 24 ^ d >>> 8 ^ a;
            a = a - b | 0;
            me.b = b = b << 20 ^ b >>> 12 ^ c;
            me.c = c = c - d | 0;
            me.d = d << 16 ^ c >>> 16 ^ a;
            return me.a = a - b | 0;
          };
          me.a = 0;
          me.b = 0;
          me.c = 2654435769 | 0;
          me.d = 1367130551;
          if (seed === Math.floor(seed)) {
            me.a = seed / 4294967296 | 0;
            me.b = seed | 0;
          } else {
            strseed += seed;
          }
          for (var k = 0; k < strseed.length + 20; k++) {
            me.b ^= strseed.charCodeAt(k) | 0;
            me.next();
          }
        }
        function copy(f, t) {
          t.a = f.a;
          t.b = f.b;
          t.c = f.c;
          t.d = f.d;
          return t;
        }
        function impl(seed, opts) {
          var xg = new XorGen(seed), state = opts && opts.state, prng = function() {
            return (xg.next() >>> 0) / 4294967296;
          };
          prng.double = function() {
            do {
              var top = xg.next() >>> 11, bot = (xg.next() >>> 0) / 4294967296, result = (top + bot) / (1 << 21);
            } while (result === 0);
            return result;
          };
          prng.int32 = xg.next;
          prng.quick = prng;
          if (state) {
            if (typeof state == "object")
              copy(state, xg);
            prng.state = function() {
              return copy(xg, {});
            };
          }
          return prng;
        }
        if (module4 && module4.exports) {
          module4.exports = impl;
        } else if (define && define.amd) {
          define(function() {
            return impl;
          });
        } else {
          this.tychei = impl;
        }
      })(
        commonjsGlobal,
        module3,
        // present in node.js
        false
        // present with an AMD loader
      );
    })(tychei$1);
    var tycheiExports = tychei$1.exports;
    var seedrandom$1 = { exports: {} };
    var _nodeResolve_empty = {};
    var _nodeResolve_empty$1 = {
      __proto__: null,
      default: _nodeResolve_empty
    };
    var require$$0 = /* @__PURE__ */ getAugmentedNamespace(_nodeResolve_empty$1);
    (function(module3) {
      (function(global2, pool2, math) {
        var width = 256, chunks = 6, digits = 52, rngname = "random", startdenom = math.pow(width, chunks), significance = math.pow(2, digits), overflow = significance * 2, mask = width - 1, nodecrypto;
        function seedrandom2(seed, options, callback) {
          var key = [];
          options = options == true ? { entropy: true } : options || {};
          var shortseed = mixkey(flatten2(options.entropy ? [seed, tostring(pool2)] : seed == null ? autoseed() : seed, 3), key);
          var arc4 = new ARC4(key);
          var prng = function() {
            var n = arc4.g(chunks), d = startdenom, x = 0;
            while (n < significance) {
              n = (n + x) * width;
              d *= width;
              x = arc4.g(1);
            }
            while (n >= overflow) {
              n /= 2;
              d /= 2;
              x >>>= 1;
            }
            return (n + x) / d;
          };
          prng.int32 = function() {
            return arc4.g(4) | 0;
          };
          prng.quick = function() {
            return arc4.g(4) / 4294967296;
          };
          prng.double = prng;
          mixkey(tostring(arc4.S), pool2);
          return (options.pass || callback || function(prng2, seed2, is_math_call, state) {
            if (state) {
              if (state.S) {
                copy(state, arc4);
              }
              prng2.state = function() {
                return copy(arc4, {});
              };
            }
            if (is_math_call) {
              math[rngname] = prng2;
              return seed2;
            } else
              return prng2;
          })(prng, shortseed, "global" in options ? options.global : this == math, options.state);
        }
        function ARC4(key) {
          var t, keylen = key.length, me = this, i = 0, j = me.i = me.j = 0, s = me.S = [];
          if (!keylen) {
            key = [keylen++];
          }
          while (i < width) {
            s[i] = i++;
          }
          for (i = 0; i < width; i++) {
            s[i] = s[j = mask & j + key[i % keylen] + (t = s[i])];
            s[j] = t;
          }
          (me.g = function(count) {
            var t2, r = 0, i2 = me.i, j2 = me.j, s2 = me.S;
            while (count--) {
              t2 = s2[i2 = mask & i2 + 1];
              r = r * width + s2[mask & (s2[i2] = s2[j2 = mask & j2 + t2]) + (s2[j2] = t2)];
            }
            me.i = i2;
            me.j = j2;
            return r;
          })(width);
        }
        function copy(f, t) {
          t.i = f.i;
          t.j = f.j;
          t.S = f.S.slice();
          return t;
        }
        function flatten2(obj, depth) {
          var result = [], typ = typeof obj, prop;
          if (depth && typ == "object") {
            for (prop in obj) {
              try {
                result.push(flatten2(obj[prop], depth - 1));
              } catch (e) {
              }
            }
          }
          return result.length ? result : typ == "string" ? obj : obj + "\0";
        }
        function mixkey(seed, key) {
          var stringseed = seed + "", smear, j = 0;
          while (j < stringseed.length) {
            key[mask & j] = mask & (smear ^= key[mask & j] * 19) + stringseed.charCodeAt(j++);
          }
          return tostring(key);
        }
        function autoseed() {
          try {
            var out;
            if (nodecrypto && (out = nodecrypto.randomBytes)) {
              out = out(width);
            } else {
              out = new Uint8Array(width);
              (global2.crypto || global2.msCrypto).getRandomValues(out);
            }
            return tostring(out);
          } catch (e) {
            var browser = global2.navigator, plugins = browser && browser.plugins;
            return [+/* @__PURE__ */ new Date(), global2, plugins, global2.screen, tostring(pool2)];
          }
        }
        function tostring(a) {
          return String.fromCharCode.apply(0, a);
        }
        mixkey(math.random(), pool2);
        if (module3.exports) {
          module3.exports = seedrandom2;
          try {
            nodecrypto = require$$0;
          } catch (ex) {
          }
        } else {
          math["seed" + rngname] = seedrandom2;
        }
      })(
        // global: `self` in browsers (including strict mode and web workers),
        // otherwise `this` in Node and other environments
        typeof self !== "undefined" ? self : commonjsGlobal,
        [],
        // pool: entropy pool starts empty
        Math
        // math: package containing random, pow, and seedrandom
      );
    })(seedrandom$1);
    var seedrandomExports = seedrandom$1.exports;
    var alea = aleaExports;
    var xor128 = xor128Exports;
    var xorwow = xorwowExports;
    var xorshift7 = xorshift7Exports;
    var xor4096 = xor4096Exports;
    var tychei = tycheiExports;
    var sr = seedrandomExports;
    sr.alea = alea;
    sr.xor128 = xor128;
    sr.xorwow = xorwow;
    sr.xorshift7 = xorshift7;
    sr.xor4096 = xor4096;
    sr.tychei = tychei;
    var seedrandom = sr;
    var MPRandGauss = (
      /** @class */
      function() {
        function MPRandGauss2(mean2, stdDeviation, dtype, truncated, seed) {
          this.mean = mean2;
          this.stdDev = stdDeviation;
          this.dtype = dtype;
          this.nextVal = NaN;
          this.truncated = truncated;
          if (this.truncated) {
            this.upper = this.mean + this.stdDev * 2;
            this.lower = this.mean - this.stdDev * 2;
          }
          var seedValue = seed ? seed : Math.random();
          this.random = seedrandom.alea(seedValue.toString());
        }
        MPRandGauss2.prototype.nextValue = function() {
          if (!isNaN(this.nextVal)) {
            var value = this.nextVal;
            this.nextVal = NaN;
            return value;
          }
          var resultX, resultY;
          var isValid = false;
          while (!isValid) {
            var v1 = void 0, v2 = void 0, s = void 0;
            do {
              v1 = 2 * this.random() - 1;
              v2 = 2 * this.random() - 1;
              s = v1 * v1 + v2 * v2;
            } while (s >= 1 || s === 0);
            var mul2 = Math.sqrt(-2 * Math.log(s) / s);
            resultX = this.mean + this.stdDev * v1 * mul2;
            resultY = this.mean + this.stdDev * v2 * mul2;
            if (!this.truncated || this.isValidTruncated(resultX)) {
              isValid = true;
            }
          }
          if (!this.truncated || this.isValidTruncated(resultY)) {
            this.nextVal = this.convertValue(resultY);
          }
          return this.convertValue(resultX);
        };
        MPRandGauss2.prototype.convertValue = function(value) {
          if (this.dtype == null || this.dtype === "float32") {
            return value;
          }
          return Math.round(value);
        };
        MPRandGauss2.prototype.isValidTruncated = function(value) {
          return value <= this.upper && value >= this.lower;
        };
        return MPRandGauss2;
      }()
    );
    var RandGamma = (
      /** @class */
      function() {
        function RandGamma2(alpha, beta, dtype, seed) {
          this.alpha = alpha;
          this.beta = 1 / beta;
          this.dtype = dtype;
          var seedValue = seed ? seed : Math.random();
          this.randu = seedrandom.alea(seedValue.toString());
          this.randn = new MPRandGauss(0, 1, dtype, false, this.randu());
          if (alpha < 1) {
            this.d = alpha + 2 / 3;
          } else {
            this.d = alpha - 1 / 3;
          }
          this.c = 1 / Math.sqrt(9 * this.d);
        }
        RandGamma2.prototype.nextValue = function() {
          var x2, v0, v1, x, u, v;
          while (true) {
            do {
              x = this.randn.nextValue();
              v = 1 + this.c * x;
            } while (v <= 0);
            v *= v * v;
            x2 = x * x;
            v0 = 1 - 0.331 * x2 * x2;
            v1 = 0.5 * x2 + this.d * (1 - v + Math.log(v));
            u = this.randu();
            if (u < v0 || Math.log(u) < v1) {
              break;
            }
          }
          v = 1 / this.beta * this.d * v;
          if (this.alpha < 1) {
            v *= Math.pow(this.randu(), 1 / this.alpha);
          }
          return this.convertValue(v);
        };
        RandGamma2.prototype.convertValue = function(value) {
          if (this.dtype === "float32") {
            return value;
          }
          return Math.round(value);
        };
        return RandGamma2;
      }()
    );
    var UniformRandom = (
      /** @class */
      function() {
        function UniformRandom2(min2, max2, dtype, seed) {
          if (min2 === void 0) {
            min2 = 0;
          }
          if (max2 === void 0) {
            max2 = 1;
          }
          var _this = this;
          this.canReturnFloat = function() {
            return _this.dtype == null || _this.dtype === "float32";
          };
          this.min = min2;
          this.range = max2 - min2;
          this.dtype = dtype;
          if (seed == null) {
            seed = Math.random();
          }
          if (typeof seed === "number") {
            seed = seed.toString();
          }
          if (!this.canReturnFloat() && this.range <= 1) {
            throw new Error("The difference between ".concat(min2, " - ").concat(max2, " <= 1 and dtype is not float"));
          }
          this.random = seedrandom.alea(seed);
        }
        UniformRandom2.prototype.convertValue = function(value) {
          if (this.canReturnFloat()) {
            return value;
          }
          return Math.round(value);
        };
        UniformRandom2.prototype.nextValue = function() {
          return this.convertValue(this.min + this.range * this.random());
        };
        return UniformRandom2;
      }()
    );
    function randomGamma_(shape, alpha, beta, dtype, seed) {
      if (beta === void 0) {
        beta = 1;
      }
      if (dtype === void 0) {
        dtype = "float32";
      }
      assertNonNegativeIntegerDimensions(shape);
      if (beta == null) {
        beta = 1;
      }
      if (dtype == null) {
        dtype = "float32";
      }
      if (dtype !== "float32" && dtype !== "int32") {
        throw new Error("Unsupported data type ".concat(dtype));
      }
      var rgamma = new RandGamma(alpha, beta, dtype, seed);
      var res = buffer(shape, dtype);
      for (var i = 0; i < res.values.length; i++) {
        res.values[i] = rgamma.nextValue();
      }
      return res.toTensor();
    }
    var randomGamma = /* @__PURE__ */ op({ randomGamma_ });
    function randomNormal_(shape, mean2, stdDev, dtype, seed) {
      if (mean2 === void 0) {
        mean2 = 0;
      }
      if (stdDev === void 0) {
        stdDev = 1;
      }
      assertNonNegativeIntegerDimensions(shape);
      if (dtype != null && dtype === "bool") {
        throw new Error("Unsupported data type ".concat(dtype));
      }
      var randGauss = new MPRandGauss(mean2, stdDev, dtype, false, seed);
      var res = buffer(shape, dtype);
      for (var i = 0; i < res.values.length; i++) {
        res.values[i] = randGauss.nextValue();
      }
      return res.toTensor();
    }
    var randomNormal = /* @__PURE__ */ op({ randomNormal_ });
    function randomStandardNormal_(shape, dtype, seed) {
      if (dtype != null && dtype === "bool") {
        throw new Error("Unsupported data type ".concat(dtype));
      }
      return randomNormal(shape, 0, 1, dtype, seed);
    }
    var randomStandardNormal = /* @__PURE__ */ op({ randomStandardNormal_ });
    function randomUniform_(shape, minval, maxval, dtype, seed) {
      if (minval === void 0) {
        minval = 0;
      }
      if (maxval === void 0) {
        maxval = 1;
      }
      if (dtype === void 0) {
        dtype = "float32";
      }
      assertNonNegativeIntegerDimensions(shape);
      var res = buffer(shape, dtype);
      var random = new UniformRandom(minval, maxval, null, seed);
      for (var i = 0; i < res.values.length; i++) {
        res.values[i] = random.nextValue();
      }
      return res.toTensor();
    }
    var randomUniform = /* @__PURE__ */ op({ randomUniform_ });
    function randomUniformInt_(shape, minval, maxval, seed) {
      return randomUniform(shape, minval, maxval, "int32", seed);
    }
    var randomUniformInt = /* @__PURE__ */ op({ randomUniformInt_ });
    function range(start, stop, step2, dtype) {
      if (step2 === void 0) {
        step2 = 1;
      }
      if (dtype === void 0) {
        dtype = "float32";
      }
      if (step2 === 0) {
        throw new Error("Cannot have a step of zero");
      }
      var attrs = { start, stop, step: step2, dtype };
      return ENGINE.runKernel(Range, {}, attrs);
    }
    function real_(input) {
      var $input = convertToTensor(input, "input", "real");
      var inputs = { input: $input };
      return ENGINE.runKernel(Real, inputs);
    }
    var real = /* @__PURE__ */ op({ real_ });
    function reciprocal_(x) {
      var $x = convertToTensor(x, "x", "reciprocal");
      var inputs = { x: $x };
      return ENGINE.runKernel(Reciprocal, inputs);
    }
    var reciprocal = /* @__PURE__ */ op({ reciprocal_ });
    function relu_(x) {
      var $x = convertToTensor(x, "x", "relu");
      var inputs = { x: $x };
      return ENGINE.runKernel(Relu, inputs);
    }
    var relu = /* @__PURE__ */ op({ relu_ });
    function relu6_(x) {
      var $x = convertToTensor(x, "x", "relu6");
      var inputs = { x: $x };
      return ENGINE.runKernel(Relu6, inputs);
    }
    var relu6 = /* @__PURE__ */ op({ relu6_ });
    function reverse_(x, axis) {
      var $x = convertToTensor(x, "x", "reverse");
      var inputs = { x: $x };
      var attrs = { dims: axis };
      return ENGINE.runKernel(Reverse, inputs, attrs);
    }
    var reverse = /* @__PURE__ */ op({ reverse_ });
    function reverse1d_(x) {
      var $x = convertToTensor(x, "x", "reverse");
      assert($x.rank === 1, function() {
        return "Error in reverse1D: x must be rank 1 but got rank ".concat($x.rank, ".");
      });
      return reverse($x, 0);
    }
    var reverse1d = /* @__PURE__ */ op({ reverse1d_ });
    function reverse2d_(x, axis) {
      var $x = convertToTensor(x, "x", "reverse");
      assert($x.rank === 2, function() {
        return "Error in reverse2D: x must be rank 2 but got rank ".concat($x.rank, ".");
      });
      return reverse($x, axis);
    }
    var reverse2d = /* @__PURE__ */ op({ reverse2d_ });
    function reverse3d_(x, axis) {
      var $x = convertToTensor(x, "x", "reverse");
      assert($x.rank === 3, function() {
        return "Error in reverse3D: x must be rank 3 but got rank ".concat($x.rank, ".");
      });
      return reverse($x, axis);
    }
    var reverse3d = /* @__PURE__ */ op({ reverse3d_ });
    function reverse4d_(x, axis) {
      var $x = convertToTensor(x, "x", "reverse");
      assert($x.rank === 4, function() {
        return "Error in reverse4D: x must be rank 4 but got rank ".concat($x.rank, ".");
      });
      return reverse($x, axis);
    }
    var reverse4d = /* @__PURE__ */ op({ reverse4d_ });
    function round_(x) {
      var $x = convertToTensor(x, "x", "round");
      var inputs = { x: $x };
      return ENGINE.runKernel(Round, inputs);
    }
    var round = /* @__PURE__ */ op({ round_ });
    function rsqrt_(x) {
      var $x = convertToTensor(x, "x", "rsqrt", "float32");
      var inputs = { x: $x };
      return ENGINE.runKernel(Rsqrt, inputs);
    }
    var rsqrt = /* @__PURE__ */ op({ rsqrt_ });
    function selu_(x) {
      var $x = convertToTensor(x, "x", "selu");
      var inputs = { x: $x };
      return ENGINE.runKernel(Selu, inputs);
    }
    var selu = /* @__PURE__ */ op({ selu_ });
    function separableConv2d_(x, depthwiseFilter, pointwiseFilter, strides, pad2, dilation, dataFormat) {
      if (dilation === void 0) {
        dilation = [1, 1];
      }
      if (dataFormat === void 0) {
        dataFormat = "NHWC";
      }
      var $x = convertToTensor(x, "x", "separableConv2d");
      var $depthwiseFilter = convertToTensor(depthwiseFilter, "depthwiseFilter", "separableConv2d");
      var $pointwiseFilter = convertToTensor(pointwiseFilter, "pointwiseFilter", "separableConv2d");
      var x4D = $x;
      var reshapedTo4D = false;
      if ($x.rank === 3) {
        reshapedTo4D = true;
        x4D = reshape($x, [1, $x.shape[0], $x.shape[1], $x.shape[2]]);
      }
      if (dataFormat === "NCHW") {
        throw new Error("separableConv2d currently does not support dataFormat NCHW; only NHWC is supported");
      }
      assert(x4D.rank === 4, function() {
        return "Error in separableConv2d: input must be rank 4, but got " + "rank ".concat(x4D.rank, ".");
      });
      assert($depthwiseFilter.rank === 4, function() {
        return "Error in separableConv2d: depthwise filter must be rank 4, but " + "got rank ".concat($depthwiseFilter.rank, ".");
      });
      assert($pointwiseFilter.rank === 4, function() {
        return "Error in separableConv2d: pointwise filter must be rank 4, but " + "got rank ".concat($depthwiseFilter.rank, ".");
      });
      assert($pointwiseFilter.shape[0] === 1, function() {
        return "Error in separableConv2d: the first dimension of pointwise filter " + " must be 1, but got ".concat($pointwiseFilter.shape[0], ".");
      });
      assert($pointwiseFilter.shape[1] === 1, function() {
        return "Error in separableConv2d: the second dimension of pointwise " + "filter must be 1, but got ".concat($pointwiseFilter.shape[1], ".");
      });
      var inChannels = $depthwiseFilter.shape[2];
      var channelMultiplier = $depthwiseFilter.shape[3];
      assert($pointwiseFilter.shape[2] === inChannels * channelMultiplier, function() {
        return "Error in separableConv2d: the third dimension of pointwise filter " + "must be ".concat(inChannels * channelMultiplier, ", ") + "but got ".concat($pointwiseFilter.shape[2], ".");
      });
      var depthwise = depthwiseConv2d$1(x4D, $depthwiseFilter, strides, pad2, dataFormat, dilation);
      var pointwiseStride = 1;
      var res = conv2d$1(depthwise, $pointwiseFilter, pointwiseStride, "valid", dataFormat);
      if (reshapedTo4D) {
        return reshape(res, [res.shape[1], res.shape[2], res.shape[3]]);
      }
      return res;
    }
    var separableConv2d = /* @__PURE__ */ op({ separableConv2d_ });
    function setdiff1dAsync_(x, y) {
      return __awaiter(this, void 0, void 0, function() {
        var $x, $y, xVals, yVals, ySet, outputSize, i, buffer2, indices, i, p;
        return __generator(this, function(_a) {
          switch (_a.label) {
            case 0:
              $x = convertToTensor(x, "x", "setdiff1d");
              $y = convertToTensor(y, "y", "setdiff1d");
              assert($x.dtype === $y.dtype, function() {
                return "x and y should have the same dtype, but got x (".concat($x.dtype, ") and y (").concat($y.dtype, ").");
              });
              assert($x.rank === 1, function() {
                return "x should be 1D tensor, but got x (".concat($x.shape, ").");
              });
              assert($y.rank === 1, function() {
                return "y should be 1D tensor, but got y (".concat($y.shape, ").");
              });
              return [4, $x.data()];
            case 1:
              xVals = _a.sent();
              return [4, $y.data()];
            case 2:
              yVals = _a.sent();
              ySet = new Set(yVals);
              outputSize = 0;
              for (i = 0; i < xVals.length; i++) {
                if (!ySet.has(xVals[i])) {
                  outputSize++;
                }
              }
              buffer2 = new TensorBuffer([outputSize], $x.dtype);
              indices = new TensorBuffer([outputSize], "int32");
              for (i = 0, p = 0; i < xVals.length; i++) {
                if (!ySet.has(xVals[i])) {
                  buffer2.values[p] = xVals[i];
                  indices.values[p] = i;
                  p++;
                }
              }
              return [2, [buffer2.toTensor(), indices.toTensor()]];
          }
        });
      });
    }
    var setdiff1dAsync = setdiff1dAsync_;
    function sign_(x) {
      var $x = convertToTensor(x, "x", "sign");
      var inputs = { x: $x };
      return ENGINE.runKernel(Sign, inputs);
    }
    var sign = /* @__PURE__ */ op({ sign_ });
    function sin_(x) {
      var $x = convertToTensor(x, "x", "sin", "float32");
      var inputs = { x: $x };
      return ENGINE.runKernel(Sin, inputs);
    }
    var sin = /* @__PURE__ */ op({ sin_ });
    function sinh_(x) {
      var $x = convertToTensor(x, "x", "sinh");
      var inputs = { x: $x };
      return ENGINE.runKernel(Sinh, inputs);
    }
    var sinh = /* @__PURE__ */ op({ sinh_ });
    function slice1d_(x, begin, size) {
      var $x = convertToTensor(x, "x", "slice1d");
      assert($x.rank === 1, function() {
        return "slice1d expects a rank-1 tensor, but got a rank-".concat($x.rank, " tensor");
      });
      return slice($x, [begin], [size]);
    }
    var slice1d = /* @__PURE__ */ op({ slice1d_ });
    function slice2d_(x, begin, size) {
      var $x = convertToTensor(x, "x", "slice2d");
      assert($x.rank === 2, function() {
        return "slice2d expects a rank-2 tensor, but got a rank-".concat($x.rank, " tensor");
      });
      return slice($x, begin, size);
    }
    var slice2d = /* @__PURE__ */ op({ slice2d_ });
    function slice3d_(x, begin, size) {
      var $x = convertToTensor(x, "x", "slice3d");
      assert($x.rank === 3, function() {
        return "slice3d expects a rank-3 tensor, but got a rank-".concat($x.rank, " tensor");
      });
      return slice($x, begin, size);
    }
    var slice3d = /* @__PURE__ */ op({ slice3d_ });
    function slice4d_(x, begin, size) {
      var $x = convertToTensor(x, "x", "slice4d");
      assert($x.rank === 4, function() {
        return "slice4d expects a rank-4 tensor, but got a rank-".concat($x.rank, " tensor");
      });
      return slice($x, begin, size);
    }
    var slice4d = /* @__PURE__ */ op({ slice4d_ });
    function softmax_(logits, dim) {
      if (dim === void 0) {
        dim = -1;
      }
      var $logits = convertToTensor(logits, "logits", "softmax", "float32");
      if (dim === -1) {
        dim = $logits.rank - 1;
      }
      if (dim !== $logits.rank - 1) {
        throw Error("Softmax along a non-last dimension is not yet supported. " + "Logits was rank ".concat($logits.rank, " and dim was ").concat(dim));
      }
      var inputs = { logits: $logits };
      var attrs = { dim };
      return ENGINE.runKernel(Softmax, inputs, attrs);
    }
    var softmax = /* @__PURE__ */ op({ softmax_ });
    function fft_(input) {
      assert(input.dtype === "complex64", function() {
        return "The dtype for tf.spectral.fft() must be complex64 " + "but got ".concat(input.dtype, ".");
      });
      var inputs = { input };
      return ENGINE.runKernel(FFT, inputs);
    }
    var fft = /* @__PURE__ */ op({ fft_ });
    function ifft_(input) {
      assert(input.dtype === "complex64", function() {
        return "The dtype for tf.spectral.ifft() must be complex64 " + "but got ".concat(input.dtype, ".");
      });
      var inputs = { input };
      return ENGINE.runKernel(IFFT, inputs);
    }
    var ifft = /* @__PURE__ */ op({ ifft_ });
    function irfft_(input) {
      var innerDimensionSize = input.shape[input.shape.length - 1];
      var batch = input.size / innerDimensionSize;
      var ret;
      if (innerDimensionSize <= 2) {
        var complexInput = reshape(input, [batch, innerDimensionSize]);
        ret = ifft(complexInput);
      } else {
        var outputShape = [batch, 2 * (innerDimensionSize - 1)];
        var realInput = reshape(real(input), [batch, innerDimensionSize]);
        var imagInput = reshape(imag(input), [batch, innerDimensionSize]);
        var realConjugate = reverse(slice(realInput, [0, 1], [batch, innerDimensionSize - 2]), 1);
        var imagConjugate = mul(reverse(slice(imagInput, [0, 1], [batch, innerDimensionSize - 2]), 1), scalar(-1));
        var r = concat([realInput, realConjugate], 1);
        var i = concat([imagInput, imagConjugate], 1);
        var complexInput = reshape(complex(r, i), [outputShape[0], outputShape[1]]);
        ret = ifft(complexInput);
      }
      ret = real(ret);
      if (input.rank === 3 && input.shape[0] !== 0) {
        var temp = ret;
        var batch_1 = input.shape[0];
        ret = reshape(ret, [batch_1, ret.shape[0] / batch_1, ret.shape[1]]);
        temp.dispose();
      }
      return ret;
    }
    var irfft = /* @__PURE__ */ op({ irfft_ });
    function split_(x, numOrSizeSplits, axis) {
      if (axis === void 0) {
        axis = 0;
      }
      var $x = convertToTensor(x, "x", "split");
      var inputs = { x: $x };
      var attr = { numOrSizeSplits, axis };
      return ENGINE.runKernel(SplitV, inputs, attr);
    }
    var split$1 = /* @__PURE__ */ op({ split_ });
    function rfft_(input, fftLength) {
      assert(input.dtype === "float32", function() {
        return "The dtype for rfft() must be real value but got ".concat(input.dtype);
      });
      var innerDimensionSize = input.shape[input.shape.length - 1];
      var batch = input.size / innerDimensionSize;
      var adjustedInput;
      if (fftLength != null && fftLength < innerDimensionSize) {
        var begin = input.shape.map(function(v) {
          return 0;
        });
        var size = input.shape.map(function(v) {
          return v;
        });
        size[input.shape.length - 1] = fftLength;
        adjustedInput = slice(input, begin, size);
        innerDimensionSize = fftLength;
      } else if (fftLength != null && fftLength > innerDimensionSize) {
        var zerosShape = input.shape.map(function(v) {
          return v;
        });
        zerosShape[input.shape.length - 1] = fftLength - innerDimensionSize;
        adjustedInput = concat([input, zeros(zerosShape)], input.shape.length - 1);
        innerDimensionSize = fftLength;
      } else {
        adjustedInput = input;
      }
      var zerosInput = zerosLike(adjustedInput);
      var complexInput = reshape(complex(adjustedInput, zerosInput), [batch, innerDimensionSize]);
      var ret = fft(complexInput);
      var half = Math.floor(innerDimensionSize / 2) + 1;
      var realValues = real(ret);
      var imagValues = imag(ret);
      var realComplexConjugate = split$1(realValues, [half, innerDimensionSize - half], realValues.shape.length - 1);
      var imagComplexConjugate = split$1(imagValues, [half, innerDimensionSize - half], imagValues.shape.length - 1);
      var outputShape = adjustedInput.shape.slice();
      outputShape[adjustedInput.shape.length - 1] = half;
      return reshape(complex(realComplexConjugate[0], imagComplexConjugate[0]), outputShape);
    }
    var rfft = /* @__PURE__ */ op({ rfft_ });
    function squaredDifference_(a, b) {
      var _a;
      var $a = convertToTensor(a, "a", "squaredDifference");
      var $b = convertToTensor(b, "b", "squaredDifference");
      _a = __read(makeTypesMatch($a, $b), 2), $a = _a[0], $b = _a[1];
      assertAndGetBroadcastShape($a.shape, $b.shape);
      var inputs = { a: $a, b: $b };
      var attrs = {};
      return ENGINE.runKernel(SquaredDifference, inputs, attrs);
    }
    var squaredDifference = /* @__PURE__ */ op({ squaredDifference_ });
    function squeeze_(x, axis) {
      var $x = convertToTensor(x, "x", "squeeze", "string_or_numeric");
      return reshape($x, squeezeShape($x.shape, axis).newShape);
    }
    var squeeze = /* @__PURE__ */ op({ squeeze_ });
    function stack_(tensors, axis) {
      if (axis === void 0) {
        axis = 0;
      }
      var $tensors = convertToTensorArray(tensors, "tensors", "stack", "string_or_numeric");
      assert($tensors.length >= 1, function() {
        return "Pass at least one tensor to tf.stack";
      });
      if ($tensors.length > 0) {
        assert(axis <= $tensors[0].rank, function() {
          return "Axis must be <= rank of the tensor";
        });
      }
      var inputs = $tensors;
      var attrs = { axis };
      return ENGINE.runKernel(Pack, inputs, attrs);
    }
    var stack = /* @__PURE__ */ op({ stack_ });
    function step_(x, alpha) {
      if (alpha === void 0) {
        alpha = 0;
      }
      var $x = convertToTensor(x, "x", "step");
      var inputs = { x: $x };
      var attrs = { alpha };
      return ENGINE.runKernel(Step, inputs, attrs);
    }
    var step = /* @__PURE__ */ op({ step_ });
    function stridedSlice_(x, begin, end, strides, beginMask, endMask, ellipsisMask, newAxisMask, shrinkAxisMask) {
      if (beginMask === void 0) {
        beginMask = 0;
      }
      if (endMask === void 0) {
        endMask = 0;
      }
      if (ellipsisMask === void 0) {
        ellipsisMask = 0;
      }
      if (newAxisMask === void 0) {
        newAxisMask = 0;
      }
      if (shrinkAxisMask === void 0) {
        shrinkAxisMask = 0;
      }
      var $x = convertToTensor(x, "x", "stridedSlice", "string_or_numeric");
      var inputs = { x: $x };
      var attrs = {
        begin,
        end,
        strides,
        beginMask,
        endMask,
        ellipsisMask,
        newAxisMask,
        shrinkAxisMask
      };
      return ENGINE.runKernel(StridedSlice, inputs, attrs);
    }
    var stridedSlice = /* @__PURE__ */ op({ stridedSlice_ });
    function tan_(x) {
      var $x = convertToTensor(x, "x", "tan", "float32");
      var inputs = { x: $x };
      return ENGINE.runKernel(Tan, inputs);
    }
    var tan = /* @__PURE__ */ op({ tan_ });
    function tensor(values, shape, dtype) {
      var inferredShape = inferShape(values, dtype);
      return makeTensor(values, shape, inferredShape, dtype);
    }
    function tensor1d(values, dtype) {
      assertNonNull(values);
      var inferredShape = inferShape(values, dtype);
      if (inferredShape.length !== 1) {
        throw new Error("tensor1d() requires values to be a flat/TypedArray");
      }
      var shape = null;
      return makeTensor(values, shape, inferredShape, dtype);
    }
    function tensor2d(values, shape, dtype) {
      assertNonNull(values);
      if (shape != null && shape.length !== 2) {
        throw new Error("tensor2d() requires shape to have two numbers");
      }
      var inferredShape = inferShape(values, dtype);
      if (inferredShape.length !== 2 && inferredShape.length !== 1) {
        throw new Error("tensor2d() requires values to be number[][] or flat/TypedArray");
      }
      if (inferredShape.length === 1 && shape == null) {
        throw new Error("tensor2d() requires shape to be provided when `values` are a flat/TypedArray");
      }
      return makeTensor(values, shape, inferredShape, dtype);
    }
    function tensor3d(values, shape, dtype) {
      assertNonNull(values);
      if (shape != null && shape.length !== 3) {
        throw new Error("tensor3d() requires shape to have three numbers");
      }
      var inferredShape = inferShape(values, dtype);
      if (inferredShape.length !== 3 && inferredShape.length !== 1) {
        throw new Error("tensor3d() requires values to be number[][][] or flat/TypedArray");
      }
      if (inferredShape.length === 1 && shape == null) {
        throw new Error("tensor3d() requires shape to be provided when `values` are a flat array");
      }
      return makeTensor(values, shape, inferredShape, dtype);
    }
    function tensor4d(values, shape, dtype) {
      assertNonNull(values);
      if (shape != null && shape.length !== 4) {
        throw new Error("tensor4d() requires shape to have four numbers");
      }
      var inferredShape = inferShape(values, dtype);
      if (inferredShape.length !== 4 && inferredShape.length !== 1) {
        throw new Error("tensor4d() requires values to be number[][][][] or flat/TypedArray");
      }
      if (inferredShape.length === 1 && shape == null) {
        throw new Error("tensor4d() requires shape to be provided when `values` are a flat array");
      }
      return makeTensor(values, shape, inferredShape, dtype);
    }
    function tensor5d(values, shape, dtype) {
      assertNonNull(values);
      if (shape != null && shape.length !== 5) {
        throw new Error("tensor5d() requires shape to have five numbers");
      }
      var inferredShape = inferShape(values, dtype);
      if (inferredShape.length !== 5 && inferredShape.length !== 1) {
        throw new Error("tensor5d() requires values to be number[][][][][] or flat/TypedArray");
      }
      if (inferredShape.length === 1 && shape == null) {
        throw new Error("tensor5d() requires shape to be provided when `values` are a flat array");
      }
      return makeTensor(values, shape, inferredShape, dtype);
    }
    function tensor6d(values, shape, dtype) {
      assertNonNull(values);
      if (shape != null && shape.length !== 6) {
        throw new Error("tensor6d() requires shape to have six numbers");
      }
      var inferredShape = inferShape(values, dtype);
      if (inferredShape.length !== 6 && inferredShape.length !== 1) {
        throw new Error("tensor6d() requires values to be number[][][][][][] or flat/TypedArray");
      }
      if (inferredShape.length === 1 && shape == null) {
        throw new Error("tensor6d() requires shape to be provided when `values` are a flat array");
      }
      shape = shape || inferredShape;
      return makeTensor(values, shape, inferredShape, dtype);
    }
    function validateUpdateShape(shape, indices, updates) {
      var sliceDim = indices.rank > 1 ? indices.shape[indices.rank - 1] : 1;
      var batchDim = indices.rank > 1 ? indices.rank - 1 : 1;
      var shapeError = "Must have updates.shape = indices.shape[:batchDim] + " + "shape[sliceDim:], got updates.shape: ".concat(updates.shape) + ", indices.shape: ".concat(indices.shape, ", shape: ").concat(shape) + ", sliceDim: ".concat(sliceDim, ", and batchDim: ").concat(batchDim, ".");
      if (updates.rank < batchDim) {
        throw new Error(shapeError + " update.rank < ".concat(batchDim, ". "));
      }
      if (shape.length < sliceDim + (updates.rank - batchDim)) {
        throw new Error(shapeError + " Output shape length < ".concat(sliceDim + (updates.rank - batchDim)));
      }
      if (updates.rank !== batchDim + shape.length - sliceDim) {
        throw new Error(shapeError + " update.rank != ".concat(batchDim + shape.length - sliceDim));
      }
      for (var d = 0; d < batchDim; ++d) {
        if (updates.shape[d] !== indices.shape[d]) {
          throw new Error(shapeError + " updates.shape[".concat(d, "] (").concat(updates.shape[d], ") != indices.shape[").concat(d, "] (").concat(indices.shape[d], ")."));
        }
      }
      for (var d = 0; d < updates.rank - batchDim; ++d) {
        if (updates.shape[d + batchDim] !== shape[d + sliceDim]) {
          throw new Error(shapeError + " updates.shape[".concat(d + batchDim, "] (").concat(updates.shape[d + batchDim], ") != shape[").concat(d + batchDim, "] (").concat(shape[d + batchDim], ")"));
        }
      }
    }
    function validateInput$1(updates, indices, shape) {
      if (indices.rank < 1) {
        throw new Error("tf.scatterND() expects the indices to be rank 1 or higher," + " but the rank was ".concat(indices.rank, "."));
      }
      if (updates.rank < 1) {
        throw new Error("tf.scatterND() expects the updates to be rank 1 or higher," + " but the rank was ".concat(updates.rank, "."));
      }
      if (indices.dtype !== "int32") {
        throw new Error("The dtype of 'indices' should be int32, but got dtype: ".concat(indices.dtype));
      }
      if (shape.length < 1) {
        throw new Error("Output rank must be greater or equal to 1, but got shape: ".concat(shape));
      }
      if (shape.length === 0) {
        if (indices.size === 0) {
          throw new Error("Indices specified for empty output. indices shape: ".concat(indices.shape));
        }
        if (updates.size === 0) {
          throw new Error("Updates specified for empty output. updates shape: ".concat(updates.shape));
        }
      }
      validateUpdateShape(shape, indices, updates);
    }
    function tensorScatterUpdate_(tensor2, indices, updates) {
      var $tensor = convertToTensor(tensor2, "tensor", "tensorScatterupdate");
      var $indices = convertToTensor(indices, "indices", "tensorScatterupdate", "int32");
      var $updates = convertToTensor(updates, "updates", "tensorScatterupdate");
      validateInput$1($updates, $indices, $tensor.shape);
      if ($tensor.dtype !== $updates.dtype) {
        throw new Error("tensor and updates must have the same dtype, instead they are ".concat($tensor.dtype, " and ").concat($updates.dtype, "."));
      }
      var inputs = {
        tensor: $tensor,
        indices: $indices,
        updates: $updates
      };
      var attrs = {};
      return ENGINE.runKernel(TensorScatterUpdate, inputs, attrs);
    }
    var tensorScatterUpdate = op({ tensorScatterUpdate_ });
    function topk_(x, k, sorted) {
      if (k === void 0) {
        k = 1;
      }
      if (sorted === void 0) {
        sorted = true;
      }
      var $x = convertToTensor(x, "x", "topk");
      if ($x.rank === 0) {
        throw new Error("topk() expects the input to be of rank 1 or higher");
      }
      var lastDim = $x.shape[$x.shape.length - 1];
      if (k < 0) {
        throw new Error("'k' passed to topk() must be >= 0 but got ".concat(k));
      }
      if (k > lastDim) {
        throw new Error("'k' passed to topk() must be <= the last dimension (".concat(lastDim, ") ") + "but got ".concat(k));
      }
      var inputs = { x: $x };
      var attrs = { k, sorted };
      var _a = __read(ENGINE.runKernel(TopK, inputs, attrs), 2), values = _a[0], indices = _a[1];
      return { values, indices };
    }
    var topk = /* @__PURE__ */ op({ topk_ });
    function truncatedNormal_(shape, mean2, stdDev, dtype, seed) {
      if (mean2 === void 0) {
        mean2 = 0;
      }
      if (stdDev === void 0) {
        stdDev = 1;
      }
      assertNonNegativeIntegerDimensions(shape);
      if (dtype != null && dtype === "bool") {
        throw new Error("Unsupported data type $ { dtype }");
      }
      var randGauss = new MPRandGauss(mean2, stdDev, dtype, true, seed);
      var res = buffer(shape, dtype);
      for (var i = 0; i < res.values.length; i++) {
        res.values[i] = randGauss.nextValue();
      }
      return res.toTensor();
    }
    var truncatedNormal = /* @__PURE__ */ op({ truncatedNormal_ });
    function unique_(x, axis) {
      if (axis === void 0) {
        axis = 0;
      }
      var $x = convertToTensor(x, "x", "unique", "string_or_numeric");
      assert($x.rank > 0, function() {
        return "The input tensor must be at least 1D";
      });
      var inputs = { x: $x };
      var attrs = { axis };
      var _a = __read(ENGINE.runKernel(Unique, inputs, attrs), 2), values = _a[0], indices = _a[1];
      return { values, indices };
    }
    var unique = /* @__PURE__ */ op({ unique_ });
    function unsortedSegmentSum_(x, segmentIds, numSegments) {
      var $x = convertToTensor(x, "x", "unsortedSegmentSum");
      var $segmentIds = convertToTensor(segmentIds, "segmentIds", "unsortedSegmentSum", "int32");
      assert(isInt(numSegments), function() {
        return "numSegments must be of dtype int";
      });
      var inputs = { x: $x, segmentIds: $segmentIds };
      var attrs = { numSegments };
      return ENGINE.runKernel(UnsortedSegmentSum, inputs, attrs);
    }
    var unsortedSegmentSum = /* @__PURE__ */ op({ unsortedSegmentSum_ });
    function unstack_(x, axis) {
      if (axis === void 0) {
        axis = 0;
      }
      var $x = convertToTensor(x, "x", "unstack", "string_or_numeric");
      assert(axis >= -$x.shape.length && axis < $x.shape.length, function() {
        return "Axis = ".concat(axis, " is not in [-").concat($x.shape.length, ", ").concat($x.shape.length, ")");
      });
      var inputs = { value: $x };
      var attrs = { axis };
      return ENGINE.runKernel(Unpack, inputs, attrs);
    }
    var unstack = /* @__PURE__ */ op({ unstack_ });
    function upperBound(sortedSequence, values) {
      return searchSorted(sortedSequence, values, "right");
    }
    function variable(initialValue, trainable, name, dtype) {
      if (trainable === void 0) {
        trainable = true;
      }
      return ENGINE.makeVariable(initialValue, trainable, name, dtype);
    }
    function whereImpl(condShape, condVals) {
      var indices = [];
      for (var i = 0; i < condVals.length; i++) {
        if (condVals[i]) {
          indices.push(i);
        }
      }
      var inBuffer = buffer(condShape, "int32");
      var out = buffer([indices.length, condShape.length], "int32");
      for (var i = 0; i < indices.length; i++) {
        var loc = inBuffer.indexToLoc(indices[i]);
        var offset = i * condShape.length;
        out.values.set(loc, offset);
      }
      return out.toTensor();
    }
    function whereAsync_(condition) {
      return __awaiter(this, void 0, void 0, function() {
        var $condition, vals, res;
        return __generator(this, function(_a) {
          switch (_a.label) {
            case 0:
              $condition = convertToTensor(condition, "condition", "whereAsync", "bool");
              return [4, $condition.data()];
            case 1:
              vals = _a.sent();
              res = whereImpl($condition.shape, vals);
              if (condition !== $condition) {
                $condition.dispose();
              }
              return [2, res];
          }
        });
      });
    }
    var whereAsync = whereAsync_;
    function booleanMaskAsync_(tensor2, mask, axis) {
      return __awaiter(this, void 0, void 0, function() {
        var $tensor, $mask, axisFrom, maskDim, tensorShape, leadingSize, i, targetTensorShape, reshapedTensor, reshapedMask, positivePositions, indices, res;
        return __generator(this, function(_a) {
          switch (_a.label) {
            case 0:
              $tensor = convertToTensor(tensor2, "tensor", "boolMask");
              $mask = convertToTensor(mask, "mask", "boolMask", "bool");
              axisFrom = axis == null ? 0 : axis;
              maskDim = $mask.rank;
              tensorShape = $tensor.shape;
              assert(maskDim > 0, function() {
                return "mask cannot be scalar";
              });
              assertShapesMatch(tensorShape.slice(axisFrom, axisFrom + maskDim), $mask.shape, "mask's shape must match the first K dimensions of tensor's shape,");
              leadingSize = 1;
              for (i = axisFrom; i < axisFrom + maskDim; i++) {
                leadingSize *= tensorShape[i];
              }
              targetTensorShape = tensorShape.slice(0, axisFrom).concat([leadingSize], tensorShape.slice(axisFrom + maskDim));
              reshapedTensor = reshape($tensor, targetTensorShape);
              reshapedMask = reshape($mask, [-1]);
              return [4, whereAsync(reshapedMask)];
            case 1:
              positivePositions = _a.sent();
              indices = squeeze(positivePositions, [1]);
              res = gather(reshapedTensor, indices, axisFrom);
              if (tensor2 !== $tensor) {
                $tensor.dispose();
              }
              if (mask !== $mask) {
                $mask.dispose();
              }
              indices.dispose();
              reshapedTensor.dispose();
              reshapedMask.dispose();
              positivePositions.dispose();
              return [2, res];
          }
        });
      });
    }
    var booleanMaskAsync = booleanMaskAsync_;
    function tidy(nameOrFn, fn) {
      return ENGINE.tidy(nameOrFn, fn);
    }
    function dispose(container) {
      var tensors = getTensorsInContainer(container);
      tensors.forEach(function(tensor2) {
        return tensor2.dispose();
      });
    }
    function transpose_(x, perm, conjugate) {
      var $x = convertToTensor(x, "x", "transpose");
      if (perm == null) {
        perm = $x.shape.map(function(s, i) {
          return i;
        }).reverse();
      }
      assert($x.rank === perm.length, function() {
        return "Error in transpose: rank of input ".concat($x.rank, " ") + "must match length of perm ".concat(perm, ".");
      });
      perm.forEach(function(axis) {
        assert(axis >= 0 && axis < $x.rank, function() {
          return "All entries in 'perm' must be between 0 and ".concat($x.rank - 1) + " but got ".concat(perm);
        });
      });
      if ($x.rank <= 1) {
        return $x.clone();
      }
      var inputs = { x: $x };
      var attrs = { perm };
      if ($x.dtype === "complex64") {
        return tidy(function() {
          var $real = real($x);
          var $imag = imag($x);
          $real = ENGINE.runKernel(Transpose, { x: $real }, attrs);
          $imag = ENGINE.runKernel(Transpose, { x: $imag }, attrs);
          if (conjugate) {
            $imag = neg($imag);
          }
          return complex($real, $imag);
        });
      }
      return ENGINE.runKernel(Transpose, inputs, attrs);
    }
    var transpose = /* @__PURE__ */ op({ transpose_ });
    function movingAverage_(v, x, decay, step2, zeroDebias) {
      if (zeroDebias === void 0) {
        zeroDebias = true;
      }
      var $v = convertToTensor(v, "v", "movingAverage");
      var $x = convertToTensor(x, "x", "movingAverage");
      var $decay = convertToTensor(decay, "decay", "movingAverage");
      assertTypesMatch($v, $x);
      assert(arraysEqual($v.shape, $x.shape), function() {
        return "Shape mismatch in v and x";
      });
      var one = scalar(1);
      var oneMinusDecay = sub(one, $decay);
      var update = mul(sub($x, $v), oneMinusDecay);
      if (zeroDebias) {
        assert(step2 != null, function() {
          return "When using zeroDebias: true, step is required.";
        });
        var $step = convertToTensor(step2, "step", "movingAverage");
        update = div(update, sub(one, pow($decay, $step)));
      }
      return add($v, update);
    }
    var movingAverage = /* @__PURE__ */ op({ movingAverage_ });
    function scatterND_(indices, updates, shape) {
      assertNonNegativeIntegerDimensions(shape);
      var $indices = convertToTensor(indices, "indices", "scatterND", "int32");
      var $updates = convertToTensor(updates, "updates", "scatterND");
      validateInput$1($updates, $indices, shape);
      var inputs = { indices: $indices, updates: $updates };
      var attrs = { shape };
      return ENGINE.runKernel(ScatterNd, inputs, attrs);
    }
    var scatterND = /* @__PURE__ */ op({ scatterND_ });
    function validateInput(sparseIndices, sparseValues, outputShape, defaultValues) {
      if (sparseIndices.dtype !== "int32") {
        throw new Error("tf.sparseToDense() expects the indices to be int32 type," + " but the dtype was ".concat(sparseIndices.dtype, "."));
      }
      if (sparseIndices.rank > 2) {
        throw new Error("sparseIndices should be a scalar, vector, or matrix," + " but got shape ".concat(sparseIndices.shape, "."));
      }
      var numElems = sparseIndices.rank > 0 ? sparseIndices.shape[0] : 1;
      var numDims = sparseIndices.rank > 1 ? sparseIndices.shape[1] : 1;
      if (outputShape.length !== numDims) {
        throw new Error("outputShape has incorrect number of elements:," + " ".concat(outputShape.length, ", should be: ").concat(numDims, "."));
      }
      var numValues = sparseValues.size;
      if (!(sparseValues.rank === 0 || sparseValues.rank === 1 && numValues === numElems)) {
        throw new Error("sparseValues has incorrect shape " + "".concat(sparseValues.shape, ", should be [] or [").concat(numElems, "]"));
      }
      if (sparseValues.dtype !== defaultValues.dtype) {
        throw new Error("sparseValues.dtype must match defaultValues.dtype");
      }
    }
    function sparseToDense_(sparseIndices, sparseValues, outputShape, defaultValue) {
      if (defaultValue === void 0) {
        defaultValue = 0;
      }
      assertNonNegativeIntegerDimensions(outputShape);
      var $sparseIndices = convertToTensor(sparseIndices, "sparseIndices", "sparseToDense", "int32");
      var $sparseValues = convertToTensor(sparseValues, "sparseValues", "sparseToDense", "string_or_numeric");
      var $defaultValue = convertToTensor(defaultValue, "defaultValue", "sparseToDense", $sparseValues.dtype);
      validateInput($sparseIndices, $sparseValues, outputShape, $defaultValue);
      var inputs = {
        sparseIndices: $sparseIndices,
        sparseValues: $sparseValues,
        defaultValue: $defaultValue
      };
      var attrs = { outputShape };
      return ENGINE.runKernel(SparseToDense, inputs, attrs);
    }
    var sparseToDense = /* @__PURE__ */ op({ sparseToDense_ });
    function gatherND_(x, indices) {
      var $indices = convertToTensor(indices, "indices", "gatherND", "int32");
      var $x = convertToTensor(x, "x", "gatherND", "string_or_numeric");
      var inputs = { params: $x, indices: $indices };
      return ENGINE.runKernel(GatherNd, inputs);
    }
    var gatherND = /* @__PURE__ */ op({ gatherND_ });
    function getNoiseShape(x, noiseShape) {
      if (noiseShape == null) {
        return x.shape.slice();
      }
      if (arraysEqual(x.shape, noiseShape)) {
        return noiseShape;
      }
      if (x.shape.length === noiseShape.length) {
        var newDimension = [];
        for (var i = 0; i < x.shape.length; i++) {
          if (noiseShape[i] == null && x.shape[i] != null) {
            newDimension.push(x.shape[i]);
          } else {
            newDimension.push(noiseShape[i]);
          }
        }
        return newDimension;
      }
      return noiseShape;
    }
    function dropout_(x, rate, noiseShape, seed) {
      var $x = convertToTensor(x, "x", "dropout");
      assert($x.dtype === "float32", function() {
        return "x has to be a floating point tensor since it's going to be " + "scaled, but got a ".concat($x.dtype, " tensor instead.");
      });
      assert(rate >= 0 && rate < 1, function() {
        return "rate must be a float in the range [0, 1), but got ".concat(rate, ".");
      });
      if (rate === 0) {
        return x instanceof Tensor ? $x.clone() : $x;
      }
      var $noiseShape = getNoiseShape($x, noiseShape);
      var keepProb = 1 - rate;
      var multiplier = div(floor(add(randomUniform($noiseShape, 0, 1, "float32", seed), keepProb)), keepProb);
      return mul($x, multiplier);
    }
    var dropout = /* @__PURE__ */ op({ dropout_ });
    function enclosingPowerOfTwo(value) {
      return Math.floor(Math.pow(2, Math.ceil(Math.log(value) / Math.log(2))));
    }
    function cosineWindow(windowLength, a, b) {
      var even = 1 - windowLength % 2;
      var newValues = new Float32Array(windowLength);
      for (var i = 0; i < windowLength; ++i) {
        var cosArg = 2 * Math.PI * i / (windowLength + even - 1);
        newValues[i] = a - b * Math.cos(cosArg);
      }
      return tensor1d(newValues, "float32");
    }
    function inTopKAsync_(predictions, targets, k) {
      if (k === void 0) {
        k = 1;
      }
      return __awaiter(this, void 0, void 0, function() {
        var $predictions, $targets, lastDim, predictionsVals, targetsVals, _a, batch, size, precision, b, offset, vals, valAndInd, i, i;
        return __generator(this, function(_b) {
          switch (_b.label) {
            case 0:
              $predictions = convertToTensor(predictions, "predictions", "inTopK");
              $targets = convertToTensor(targets, "targets", "inTopK");
              assert($predictions.rank > 1, function() {
                return "inTopK() expects the predictions to be of rank 2 or higher, " + "but got ".concat($predictions.rank);
              });
              assert($predictions.rank - 1 === $targets.rank, function() {
                return "predictions rank should be 1 larger than targets rank, but got predictions rank " + "".concat($predictions.rank, " and targets rank ").concat($targets.rank);
              });
              assertShapesMatch($predictions.shape.slice(0, $predictions.shape.length - 1), $targets.shape, "predictions's shape should be align with the targets' shape, except the last dimension.");
              lastDim = $predictions.shape[$predictions.shape.length - 1];
              assert(k > 0 && k <= lastDim, function() {
                return "'k' passed to inTopK() must be > 0 && <= the predictions last " + "dimension (".concat(lastDim, "), but got ").concat(k);
              });
              return [4, $predictions.data()];
            case 1:
              predictionsVals = _b.sent();
              return [4, $targets.data()];
            case 2:
              targetsVals = _b.sent();
              _a = __read([predictionsVals.length / lastDim, lastDim], 2), batch = _a[0], size = _a[1];
              precision = getTypedArrayFromDType("bool", batch);
              for (b = 0; b < batch; b++) {
                offset = b * size;
                vals = predictionsVals.subarray(offset, offset + size);
                valAndInd = [];
                for (i = 0; i < vals.length; i++) {
                  valAndInd.push({ value: vals[i], index: i });
                }
                valAndInd.sort(function(a, b2) {
                  return b2.value - a.value;
                });
                precision[b] = 0;
                for (i = 0; i < k; i++) {
                  if (valAndInd[i].index === targetsVals[b]) {
                    precision[b] = 1;
                    break;
                  }
                }
              }
              if (predictions !== $predictions) {
                $predictions.dispose();
              }
              if (targets !== $targets) {
                $targets.dispose();
              }
              return [2, tensor(precision, $targets.shape, "bool")];
          }
        });
      });
    }
    var inTopKAsync = inTopKAsync_;
    function conv2DBackpropFilter_(x, dy, filterShape, strides, pad2, dataFormat, dimRoundingMode) {
      if (dataFormat === void 0) {
        dataFormat = "NHWC";
      }
      var x4D = x;
      if (x.rank === 3) {
        x4D = reshape(x, [1, x.shape[0], x.shape[1], x.shape[2]]);
      }
      var dy4D = dy;
      if (dy4D.rank === 3) {
        dy4D = reshape(dy, [1, dy.shape[0], dy.shape[1], dy.shape[2]]);
      }
      assert(x4D.rank === 4, function() {
        return "Error in conv2dDerFilter: input must be rank 4, but got shape " + "".concat(x4D.shape, ".");
      });
      assert(dy4D.rank === 4, function() {
        return "Error in conv2dDerFilter: dy must be rank 4, but got shape " + "".concat(dy4D.shape, ".");
      });
      assert(filterShape.length === 4, function() {
        return "Error in conv2dDerFilter: filterShape must be length 4, but got " + "".concat(filterShape, ".");
      });
      var inDepth = dataFormat === "NHWC" ? x4D.shape[3] : x4D.shape[1];
      var outDepth = dataFormat === "NHWC" ? dy4D.shape[3] : dy4D.shape[1];
      assert(inDepth === filterShape[2], function() {
        return "Error in conv2dDerFilter: depth of input ".concat(inDepth, ") must ") + "match input depth in filter (".concat(filterShape[2], ".");
      });
      assert(outDepth === filterShape[3], function() {
        return "Error in conv2dDerFilter: depth of dy (".concat(outDepth, ") must ") + "match output depth for filter (".concat(filterShape[3], ").");
      });
      checkPadOnDimRoundingMode("conv2dDerFilter", pad2, dimRoundingMode);
      var inputs = { x: x4D, dy: dy4D };
      var attrs = { strides, pad: pad2, dataFormat, dimRoundingMode, filterShape };
      return ENGINE.runKernel(Conv2DBackpropFilter, inputs, attrs);
    }
    var conv2DBackpropFilter = /* @__PURE__ */ op({ conv2DBackpropFilter_ });
    function getFusedDyActivation(dy, y, activation) {
      if (activation == null || activation === "linear") {
        return dy;
      }
      if (activation === "relu") {
        return mul(dy, step(y));
      }
      throw new Error("Cannot compute gradient for fused activation ".concat(activation, "."));
    }
    function getFusedBiasGradient(bias, dyActivation) {
      var res = dyActivation;
      var reduceAxes = getReductionAxes(bias.shape, dyActivation.shape);
      if (reduceAxes.length > 0) {
        res = sum(res, reduceAxes);
      }
      return reshape(res, bias.shape);
    }
    function applyActivation(x, activation, preluActivationWeights, leakyreluAlpha) {
      if (activation === "linear") {
        return x;
      } else if (activation === "relu") {
        return relu(x);
      } else if (activation === "elu") {
        return elu(x);
      } else if (activation === "relu6") {
        return relu6(x);
      } else if (activation === "prelu") {
        return prelu(x, preluActivationWeights);
      } else if (activation === "leakyrelu") {
        return leakyRelu(x, leakyreluAlpha);
      } else if (activation === "sigmoid") {
        return sigmoid(x);
      }
      throw new Error("Unknown fused activation ".concat(activation, "."));
    }
    var shouldFuse = function(gradientDepth, activation) {
      var gradientMode = gradientDepth > 0;
      return !gradientMode || activation === "linear";
    };
    function fusedConv2d_(_a) {
      var _b;
      var x = _a.x, filter = _a.filter, strides = _a.strides, pad2 = _a.pad, _c = _a.dataFormat, dataFormat = _c === void 0 ? "NHWC" : _c, _d = _a.dilations, dilations = _d === void 0 ? [1, 1] : _d, dimRoundingMode = _a.dimRoundingMode, bias = _a.bias, _e = _a.activation, activation = _e === void 0 ? "linear" : _e, preluActivationWeights = _a.preluActivationWeights, leakyreluAlpha = _a.leakyreluAlpha;
      activation = activation || "linear";
      if (shouldFuse(ENGINE.state.gradientDepth, activation) === false) {
        assert(dataFormat === "NHWC", function() {
          return "Error in fused conv2d: got dataFormat of ".concat(dataFormat, " but ") + "only NHWC is currently supported for the case of gradient depth is 0 and the activation is not linear.";
        });
        var result = conv2d$1(x, filter, strides, pad2, dataFormat, dilations, dimRoundingMode);
        if (bias != null) {
          result = add(result, bias);
        }
        return applyActivation(result, activation, preluActivationWeights, leakyreluAlpha);
      }
      var $x = convertToTensor(x, "x", "conv2d", "float32");
      var $filter = convertToTensor(filter, "filter", "conv2d", "float32");
      var x4D = $x;
      var reshapedTo4D = false;
      if ($x.rank === 3) {
        reshapedTo4D = true;
        x4D = reshape($x, [1, $x.shape[0], $x.shape[1], $x.shape[2]]);
      }
      assert(x4D.rank === 4, function() {
        return "Error in fused conv2d: input must be rank 4, but got rank " + "".concat(x4D.rank, ".");
      });
      assert($filter.rank === 4, function() {
        return "Error in fused conv2d: filter must be rank 4, but got rank " + "".concat($filter.rank, ".");
      });
      checkPadOnDimRoundingMode("fused conv2d", pad2, dimRoundingMode);
      var inputChannels = dataFormat === "NHWC" ? x4D.shape[3] : x4D.shape[1];
      assert($filter.shape[2] === inputChannels, function() {
        return "Error in conv2d: depth of input (".concat(inputChannels, ") must match ") + "input depth for filter ".concat($filter.shape[2], ".");
      });
      assert(eitherStridesOrDilationsAreOne(strides, dilations), function() {
        return "Error in conv2D: Either strides or dilations must be 1. " + "Got strides ".concat(strides, " and dilations '").concat(dilations, "'");
      });
      var convInfo = computeConv2DInfo(x4D.shape, $filter.shape, strides, dilations, pad2, dimRoundingMode);
      var $bias;
      if (bias != null) {
        $bias = convertToTensor(bias, "bias", "fused conv2d");
        _b = __read(makeTypesMatch($bias, $x), 1), $bias = _b[0];
        if (dataFormat === "NHWC") {
          assertAndGetBroadcastShape(convInfo.outShape, $bias.shape);
        } else {
          assert($bias.shape.length <= 1, function() {
            return "Error in fused conv2d: only supports scalar or 1-D Tensor bias for NCHW format but got the bias of " + "rank-".concat($bias.shape.length, ".");
          });
          assert($bias.shape.length === 0 || $bias.shape[0] === convInfo.outChannels || $bias.shape[0] === 1, function() {
            return "Error in fused conv2d: bias shape (".concat($bias.shape, ") is not ") + "compatible with the number of output channels " + "(".concat(convInfo.outChannels, ")");
          });
        }
      }
      var $preluActivationWeights;
      if (preluActivationWeights != null) {
        var alphaShape_1 = preluActivationWeights.shape;
        assert(alphaShape_1.length <= 1 || alphaShape_1.length === 3, function() {
          return "Error in fused conv2d: only supports scalar, 1-D Tensor or 3-D Tensor PReLU activation weights but got a tensor of " + "rank-".concat(alphaShape_1.length, ".");
        });
        if (alphaShape_1.length === 1) {
          assert(alphaShape_1[0] === 1 || alphaShape_1[0] === convInfo.outChannels, function() {
            return "Error in fused conv2d: PReLU activation weights " + "(".concat(alphaShape_1, ") is not compatible with the number of output ") + "channels (".concat(convInfo.outChannels, ").");
          });
        } else if (alphaShape_1.length === 3) {
          try {
            assertAndGetBroadcastShape(alphaShape_1, convInfo.outShape);
          } catch (e) {
            var errMsg = "Error in fused conv2d: PReLU activation weights (".concat(alphaShape_1, ") ") + "is not compatible with the output shape of the conv2d " + "(".concat(convInfo.outShape, ").");
            throw Error(errMsg);
          }
        }
        $preluActivationWeights = convertToTensor(preluActivationWeights, "prelu weights", "fused conv2d");
      }
      var grad = function(dy, saved) {
        assert(dataFormat === "NHWC", function() {
          return "Error in gradient of fused conv2D: got dataFormat of ".concat(dataFormat, " but only NHWC is currently supported.");
        });
        var _a2 = __read(saved, 4), $filter2 = _a2[0], x4D2 = _a2[1], y = _a2[2], $bias2 = _a2[3];
        var dyActivation = getFusedDyActivation(dy, y, activation);
        assert(tupleValuesAreOne(dilations), function() {
          return "Error in gradient of fused conv2D: dilation rates greater than 1 " + "are not yet supported in gradients. Got dilations '".concat(dilations, "'");
        });
        var xDer = conv2DBackpropInput(x4D2.shape, dyActivation, $filter2, strides, pad2);
        var filterDer = conv2DBackpropFilter(x4D2, dyActivation, $filter2.shape, strides, pad2);
        var der = [xDer, filterDer];
        if ($bias2 != null) {
          var biasDer = getFusedBiasGradient($bias2, dyActivation);
          der.push(biasDer);
        }
        return der;
      };
      var inputs = {
        x: x4D,
        filter: $filter,
        bias: $bias,
        preluActivationWeights: $preluActivationWeights
      };
      var attrs = {
        strides,
        pad: pad2,
        dataFormat,
        dilations,
        dimRoundingMode,
        activation,
        leakyreluAlpha
      };
      if (bias == null) {
        var customOp = customGrad(function(x4D2, filter2, save) {
          var res = (
            // tslint:disable-next-line: no-unnecessary-type-assertion
            ENGINE.runKernel(FusedConv2D, inputs, attrs)
          );
          save([filter2, x4D2, res]);
          if (reshapedTo4D) {
            res = reshape(res, [res.shape[1], res.shape[2], res.shape[3]]);
          }
          return { value: res, gradFunc: grad };
        });
        return customOp(x4D, $filter);
      } else {
        var customOpWithBias = customGrad(function(x4D2, filter2, bias2, save) {
          var res = ENGINE.runKernel(FusedConv2D, inputs, attrs);
          save([filter2, x4D2, res, bias2]);
          if (reshapedTo4D) {
            res = reshape(res, [res.shape[1], res.shape[2], res.shape[3]]);
          }
          return { value: res, gradFunc: grad };
        });
        return customOpWithBias(x4D, $filter, $bias);
      }
    }
    var conv2d = /* @__PURE__ */ op({ fusedConv2d_ });
    function depthwiseConv2dNativeBackpropFilter_(x, dy, filterShape, strides, pad2, dilations, dimRoundingMode) {
      if (dilations === void 0) {
        dilations = [1, 1];
      }
      var x4D = x;
      if (x.rank === 3) {
        x4D = reshape(x, [1, x.shape[0], x.shape[1], x.shape[2]]);
      }
      var dy4D = dy;
      if (dy4D.rank === 3) {
        dy4D = reshape(dy, [1, dy.shape[0], dy.shape[1], dy.shape[2]]);
      }
      var inputs = { x: x4D, dy: dy4D };
      var attrs = { strides, pad: pad2, dimRoundingMode, dilations, filterShape };
      return ENGINE.runKernel(DepthwiseConv2dNativeBackpropFilter, inputs, attrs);
    }
    var depthwiseConv2dNativeBackpropFilter = op({ depthwiseConv2dNativeBackpropFilter_ });
    function depthwiseConv2dNativeBackpropInput_(xShape, dy, filter, strides, pad2, dilations, dimRoundingMode) {
      if (dilations === void 0) {
        dilations = [1, 1];
      }
      var dy4D = dy;
      var reshapedTo4D = false;
      if (dy.rank === 3) {
        reshapedTo4D = true;
        dy4D = reshape(dy, [1, dy.shape[0], dy.shape[1], dy.shape[2]]);
      }
      var inputs = { dy: dy4D, filter };
      var attrs = { strides, pad: pad2, dimRoundingMode, dilations, inputShape: xShape };
      var res = (
        // tslint:disable-next-line: no-unnecessary-type-assertion
        ENGINE.runKernel(DepthwiseConv2dNativeBackpropInput, inputs, attrs)
      );
      if (reshapedTo4D) {
        return reshape(res, [res.shape[1], res.shape[2], res.shape[3]]);
      }
      return res;
    }
    var depthwiseConv2dNativeBackpropInput = op({ depthwiseConv2dNativeBackpropInput_ });
    function fusedDepthwiseConv2d_(_a) {
      var _b;
      var x = _a.x, filter = _a.filter, strides = _a.strides, pad2 = _a.pad, _c = _a.dataFormat, dataFormat = _c === void 0 ? "NHWC" : _c, _d = _a.dilations, dilations = _d === void 0 ? [1, 1] : _d, dimRoundingMode = _a.dimRoundingMode, bias = _a.bias, _e = _a.activation, activation = _e === void 0 ? "linear" : _e, preluActivationWeights = _a.preluActivationWeights, leakyreluAlpha = _a.leakyreluAlpha;
      if (shouldFuse(ENGINE.state.gradientDepth, activation) === false) {
        var result = depthwiseConv2d$1(x, filter, strides, pad2, dataFormat, dilations, dimRoundingMode);
        if (bias != null) {
          result = add(result, bias);
        }
        return applyActivation(result, activation, preluActivationWeights, leakyreluAlpha);
      }
      var $x = convertToTensor(x, "x", "depthwiseConv2d", "float32");
      var $filter = convertToTensor(filter, "filter", "depthwiseConv2d", "float32");
      var x4D = $x;
      var reshapedTo4D = false;
      if ($x.rank === 3) {
        reshapedTo4D = true;
        x4D = reshape($x, [1, $x.shape[0], $x.shape[1], $x.shape[2]]);
      }
      assert(x4D.rank === 4, function() {
        return "Error in fused depthwiseConv2d: input must be rank 4, but got " + "rank ".concat(x4D.rank, ".");
      });
      assert($filter.rank === 4, function() {
        return "Error in fused depthwiseConv2d: filter must be rank 4, " + "but got rank ".concat($filter.rank, ".");
      });
      assert(x4D.shape[3] === $filter.shape[2], function() {
        return "Error in fused depthwiseConv2d: number of input channels " + "(".concat(x4D.shape[3], ") must match the inChannels dimension in ") + "filter ".concat($filter.shape[2], ".");
      });
      if (dilations == null) {
        dilations = [1, 1];
      }
      assert(eitherStridesOrDilationsAreOne(strides, dilations), function() {
        return "Error in fused depthwiseConv2d: Either strides or dilations must " + "be 1. Got strides ".concat(strides, " and dilations '").concat(dilations, "'");
      });
      checkPadOnDimRoundingMode("fused depthwiseConv2d", pad2, dimRoundingMode);
      var convInfo = computeConv2DInfo(
        x4D.shape,
        $filter.shape,
        strides,
        dilations,
        pad2,
        dimRoundingMode,
        true
        /* depthwise */
      );
      var $bias;
      if (bias != null) {
        $bias = convertToTensor(bias, "bias", "fused conv2d");
        _b = __read(makeTypesMatch($bias, $x), 1), $bias = _b[0];
        assertAndGetBroadcastShape(convInfo.outShape, $bias.shape);
      }
      var $preluActivationWeights;
      if (preluActivationWeights != null) {
        $preluActivationWeights = convertToTensor(preluActivationWeights, "prelu weights", "fused depthwiseConv2d");
      }
      var grad = function(dy, saved) {
        assert(tupleValuesAreOne(dilations), function() {
          return "Error in gradient of fused depthwiseConv2d: dilation rates greater than 1 are not yet supported. Got dilations " + "'".concat(dilations, "'");
        });
        var _a2 = __read(saved, 4), $filter2 = _a2[0], x4D2 = _a2[1], y = _a2[2], bias2 = _a2[3];
        var dyActivation = getFusedDyActivation(dy, y, activation);
        var xDer = depthwiseConv2dNativeBackpropInput(x4D2.shape, dyActivation, $filter2, strides, pad2, dilations, dimRoundingMode);
        var filterDer = depthwiseConv2dNativeBackpropFilter(x4D2, dyActivation, $filter2.shape, strides, pad2, dilations, dimRoundingMode);
        if (bias2 != null) {
          var biasDer = getFusedBiasGradient($bias, dyActivation);
          return [xDer, filterDer, biasDer];
        }
        return [xDer, filterDer];
      };
      var inputs = {
        x: x4D,
        filter: $filter,
        bias: $bias,
        preluActivationWeights: $preluActivationWeights
      };
      var attrs = {
        strides,
        pad: pad2,
        dataFormat,
        dilations,
        dimRoundingMode,
        activation,
        leakyreluAlpha
      };
      if (bias == null) {
        var customOp = customGrad(function(x4D2, filter2, save) {
          var res = ENGINE.runKernel(FusedDepthwiseConv2D, inputs, attrs);
          save([filter2, x4D2, res]);
          if (reshapedTo4D) {
            res = reshape(res, [res.shape[1], res.shape[2], res.shape[3]]);
          }
          return { value: res, gradFunc: grad };
        });
        return customOp(x4D, $filter);
      } else {
        var customOpWithBias = customGrad(function(x4D2, filter2, bias2, save) {
          var res = ENGINE.runKernel(FusedDepthwiseConv2D, inputs, attrs);
          save([filter2, x4D2, res, bias2]);
          if (reshapedTo4D) {
            res = reshape(res, [res.shape[1], res.shape[2], res.shape[3]]);
          }
          return { value: res, gradFunc: grad };
        });
        return customOpWithBias(x4D, $filter, $bias);
      }
    }
    var depthwiseConv2d = /* @__PURE__ */ op({ fusedDepthwiseConv2d_ });
    function fusedMatMul_(_a) {
      var _b, _c;
      var a = _a.a, b = _a.b, _d = _a.transposeA, transposeA = _d === void 0 ? false : _d, _e = _a.transposeB, transposeB = _e === void 0 ? false : _e, bias = _a.bias, _f = _a.activation, activation = _f === void 0 ? "linear" : _f, preluActivationWeights = _a.preluActivationWeights, _g = _a.leakyreluAlpha, leakyreluAlpha = _g === void 0 ? 0.2 : _g;
      if (shouldFuse(ENGINE.state.gradientDepth, activation) === false) {
        var result = matMul$1(a, b, transposeA, transposeB);
        if (bias != null) {
          result = add(result, bias);
        }
        return applyActivation(result, activation, preluActivationWeights, leakyreluAlpha);
      }
      var $a = convertToTensor(a, "a", "fused matMul");
      var $b = convertToTensor(b, "b", "fused matMul");
      _b = __read(makeTypesMatch($a, $b), 2), $a = _b[0], $b = _b[1];
      var innerShapeA = transposeA ? $a.shape[$a.rank - 2] : $a.shape[$a.rank - 1];
      var innerShapeB = transposeB ? $b.shape[$b.rank - 1] : $b.shape[$b.rank - 2];
      var outerShapeA = transposeA ? $a.shape[$a.rank - 1] : $a.shape[$a.rank - 2];
      var outerShapeB = transposeB ? $b.shape[$b.rank - 2] : $b.shape[$b.rank - 1];
      var outerDimsA = $a.shape.slice(0, -2);
      var outerDimsB = $b.shape.slice(0, -2);
      var batchDimA = sizeFromShape(outerDimsA);
      var batchDimB = sizeFromShape(outerDimsB);
      assert(innerShapeA === innerShapeB, function() {
        return "Error in fused matMul: inner shapes (".concat(innerShapeA, ") and (") + "".concat(innerShapeB, ") of Tensors with shapes ").concat($a.shape, " and ") + "".concat($b.shape, " and transposeA=").concat(transposeA) + " and transposeB=".concat(transposeB, " must match.");
      });
      var outShapeOuterDims = assertAndGetBroadcastShape($a.shape.slice(0, -2), $b.shape.slice(0, -2));
      var outShape = outShapeOuterDims.concat([outerShapeA, outerShapeB]);
      var a3D = transposeA ? reshape($a, [batchDimA, innerShapeA, outerShapeA]) : reshape($a, [batchDimA, outerShapeA, innerShapeA]);
      var b3D = transposeB ? reshape($b, [batchDimB, outerShapeB, innerShapeB]) : reshape($b, [batchDimB, innerShapeB, outerShapeB]);
      var $bias;
      if (bias != null) {
        $bias = convertToTensor(bias, "bias", "fused matMul");
        _c = __read(makeTypesMatch($bias, $a), 1), $bias = _c[0];
        assertAndGetBroadcastShape(outShape, $bias.shape);
      }
      var $preluActivationWeights;
      if (preluActivationWeights != null) {
        $preluActivationWeights = convertToTensor(preluActivationWeights, "prelu weights", "fused matMul");
      }
      var grad = function(dy, saved) {
        var _a2 = __read(saved, 4), a3D2 = _a2[0], b3D2 = _a2[1], y = _a2[2], $bias2 = _a2[3];
        var dyActivation = getFusedDyActivation(reshape(dy, y.shape), y, activation);
        var aDer;
        var bDer;
        if (!transposeA && !transposeB) {
          aDer = matMul$1(dyActivation, b3D2, false, true);
          bDer = matMul$1(a3D2, dyActivation, true, false);
        } else if (!transposeA && transposeB) {
          aDer = matMul$1(dyActivation, b3D2, false, false);
          bDer = matMul$1(dyActivation, a3D2, true, false);
        } else if (transposeA && !transposeB) {
          aDer = matMul$1(b3D2, dyActivation, false, true);
          bDer = matMul$1(a3D2, dyActivation, false, false);
        } else {
          aDer = matMul$1(b3D2, dyActivation, true, true);
          bDer = matMul$1(dyActivation, a3D2, true, true);
        }
        if (bias != null) {
          var biasDer = getFusedBiasGradient($bias2, dyActivation);
          return [aDer, bDer, biasDer];
        } else {
          return [aDer, bDer];
        }
      };
      var inputs = {
        a: a3D,
        b: b3D,
        bias: $bias,
        preluActivationWeights: $preluActivationWeights
      };
      var attrs = { transposeA, transposeB, activation, leakyreluAlpha };
      if (bias == null) {
        var customOp = customGrad(function(a3D2, b3D2, save) {
          var res = (
            // tslint:disable-next-line: no-unnecessary-type-assertion
            ENGINE.runKernel(_FusedMatMul, inputs, attrs)
          );
          save([a3D2, b3D2, res]);
          return { value: reshape(res, outShape), gradFunc: grad };
        });
        return customOp(a3D, b3D);
      } else {
        var customOpWithBias = customGrad(function(a3D2, b3D2, $bias2, save) {
          var res = (
            // tslint:disable-next-line: no-unnecessary-type-assertion
            ENGINE.runKernel(_FusedMatMul, inputs, attrs)
          );
          save([a3D2, b3D2, res, $bias2]);
          return { value: reshape(res, outShape), gradFunc: grad };
        });
        return customOpWithBias(a3D, b3D, $bias);
      }
    }
    var matMul = /* @__PURE__ */ op({ fusedMatMul_ });
    var fused_ops = {
      __proto__: null,
      conv2d,
      depthwiseConv2d,
      matMul
    };
    function hammingWindow_(windowLength) {
      return cosineWindow(windowLength, 0.54, 0.46);
    }
    var hammingWindow = /* @__PURE__ */ op({ hammingWindow_ });
    function hannWindow_(windowLength) {
      return cosineWindow(windowLength, 0.5, 0.5);
    }
    var hannWindow = /* @__PURE__ */ op({ hannWindow_ });
    function frame_(signal2, frameLength, frameStep, padEnd, padValue) {
      if (padEnd === void 0) {
        padEnd = false;
      }
      if (padValue === void 0) {
        padValue = 0;
      }
      var start = 0;
      var output = [];
      while (start + frameLength <= signal2.size) {
        output.push(slice(signal2, start, frameLength));
        start += frameStep;
      }
      if (padEnd) {
        while (start < signal2.size) {
          var padLen = start + frameLength - signal2.size;
          var pad2 = concat([
            slice(signal2, start, frameLength - padLen),
            fill([padLen], padValue)
          ]);
          output.push(pad2);
          start += frameStep;
        }
      }
      if (output.length === 0) {
        return tensor2d([], [0, frameLength]);
      }
      return reshape(concat(output), [output.length, frameLength]);
    }
    var frame = /* @__PURE__ */ op({ frame_ });
    function stft_(signal2, frameLength, frameStep, fftLength, windowFn) {
      if (windowFn === void 0) {
        windowFn = hannWindow;
      }
      if (fftLength == null) {
        fftLength = enclosingPowerOfTwo(frameLength);
      }
      var framedSignal = frame(signal2, frameLength, frameStep);
      var windowedSignal = mul(framedSignal, windowFn(frameLength));
      return rfft(windowedSignal, fftLength);
    }
    var stft = /* @__PURE__ */ op({ stft_ });
    function cropAndResize_(image2, boxes, boxInd, cropSize, method, extrapolationValue) {
      if (method === void 0) {
        method = "bilinear";
      }
      if (extrapolationValue === void 0) {
        extrapolationValue = 0;
      }
      var $image = convertToTensor(image2, "image", "cropAndResize");
      var $boxes = convertToTensor(boxes, "boxes", "cropAndResize", "float32");
      var $boxInd = convertToTensor(boxInd, "boxInd", "cropAndResize", "int32");
      var numBoxes = $boxes.shape[0];
      assert($image.rank === 4, function() {
        return "Error in cropAndResize: image must be rank 4," + "but got rank ".concat($image.rank, ".");
      });
      assert($boxes.rank === 2 && $boxes.shape[1] === 4, function() {
        return "Error in cropAndResize: boxes must be have size [".concat(numBoxes, ",4] ") + "but had shape ".concat($boxes.shape, ".");
      });
      assert($boxInd.rank === 1 && $boxInd.shape[0] === numBoxes, function() {
        return "Error in cropAndResize: boxInd must be have size [".concat(numBoxes, "] ") + "but had shape ".concat($boxes.shape, ".");
      });
      assert(cropSize.length === 2, function() {
        return "Error in cropAndResize: cropSize must be of length 2, but got " + "length ".concat(cropSize.length, ".");
      });
      assert(cropSize[0] >= 1 && cropSize[1] >= 1, function() {
        return "cropSize must be atleast [1,1], but was ".concat(cropSize);
      });
      assert(method === "bilinear" || method === "nearest", function() {
        return "method must be bilinear or nearest, but was ".concat(method);
      });
      var inputs = { image: $image, boxes: $boxes, boxInd: $boxInd };
      var attrs = { method, extrapolationValue, cropSize };
      var res = ENGINE.runKernel(CropAndResize, inputs, attrs);
      return res;
    }
    var cropAndResize = /* @__PURE__ */ op({ cropAndResize_ });
    function flipLeftRight_(image2) {
      var $image = convertToTensor(image2, "image", "flipLeftRight", "float32");
      assert($image.rank === 4, function() {
        return "Error in flipLeftRight: image must be rank 4," + "but got rank ".concat($image.rank, ".");
      });
      var inputs = { image: $image };
      var res = ENGINE.runKernel(FlipLeftRight, inputs, {});
      return res;
    }
    var flipLeftRight = /* @__PURE__ */ op({ flipLeftRight_ });
    function grayscaleToRGB_(image2) {
      var $image = convertToTensor(image2, "image", "grayscaleToRGB");
      var lastDimsIdx = $image.rank - 1;
      var lastDims = $image.shape[lastDimsIdx];
      assert($image.rank >= 2, function() {
        return "Error in grayscaleToRGB: images must be at least rank 2, " + "but got rank ".concat($image.rank, ".");
      });
      assert(lastDims === 1, function() {
        return "Error in grayscaleToRGB: last dimension of a grayscale image " + "should be size 1, but got size ".concat(lastDims, ".");
      });
      var reps = new Array($image.rank);
      reps.fill(1, 0, lastDimsIdx);
      reps[lastDimsIdx] = 3;
      return tile($image, reps);
    }
    var grayscaleToRGB = /* @__PURE__ */ op({ grayscaleToRGB_ });
    function rotateWithOffset_(image2, radians, fillValue, center) {
      if (fillValue === void 0) {
        fillValue = 0;
      }
      if (center === void 0) {
        center = 0.5;
      }
      var $image = convertToTensor(image2, "image", "rotateWithOffset", "float32");
      assert($image.rank === 4, function() {
        return "Error in rotateWithOffset: image must be rank 4," + "but got rank ".concat($image.rank, ".");
      });
      var inputs = { image: $image };
      var attrs = { radians, fillValue, center };
      var res = ENGINE.runKernel(RotateWithOffset, inputs, attrs);
      return res;
    }
    var rotateWithOffset = /* @__PURE__ */ op({ rotateWithOffset_ });
    function nonMaxSuppSanityCheck(boxes, scores, maxOutputSize, iouThreshold, scoreThreshold, softNmsSigma) {
      if (iouThreshold == null) {
        iouThreshold = 0.5;
      }
      if (scoreThreshold == null) {
        scoreThreshold = Number.NEGATIVE_INFINITY;
      }
      if (softNmsSigma == null) {
        softNmsSigma = 0;
      }
      var numBoxes = boxes.shape[0];
      maxOutputSize = Math.min(maxOutputSize, numBoxes);
      assert(0 <= iouThreshold && iouThreshold <= 1, function() {
        return "iouThreshold must be in [0, 1], but was '".concat(iouThreshold, "'");
      });
      assert(boxes.rank === 2, function() {
        return "boxes must be a 2D tensor, but was of rank '".concat(boxes.rank, "'");
      });
      assert(boxes.shape[1] === 4, function() {
        return "boxes must have 4 columns, but 2nd dimension was ".concat(boxes.shape[1]);
      });
      assert(scores.rank === 1, function() {
        return "scores must be a 1D tensor";
      });
      assert(scores.shape[0] === numBoxes, function() {
        return "scores has incompatible shape with boxes. Expected ".concat(numBoxes, ", ") + "but was ".concat(scores.shape[0]);
      });
      assert(0 <= softNmsSigma && softNmsSigma <= 1, function() {
        return "softNmsSigma must be in [0, 1], but was '".concat(softNmsSigma, "'");
      });
      return { maxOutputSize, iouThreshold, scoreThreshold, softNmsSigma };
    }
    function nonMaxSuppression_(boxes, scores, maxOutputSize, iouThreshold, scoreThreshold) {
      if (iouThreshold === void 0) {
        iouThreshold = 0.5;
      }
      if (scoreThreshold === void 0) {
        scoreThreshold = Number.NEGATIVE_INFINITY;
      }
      var $boxes = convertToTensor(boxes, "boxes", "nonMaxSuppression", "float32");
      var $scores = convertToTensor(scores, "scores", "nonMaxSuppression", "float32");
      var inputs = nonMaxSuppSanityCheck($boxes, $scores, maxOutputSize, iouThreshold, scoreThreshold);
      maxOutputSize = inputs.maxOutputSize;
      iouThreshold = inputs.iouThreshold;
      scoreThreshold = inputs.scoreThreshold;
      var attrs = { maxOutputSize, iouThreshold, scoreThreshold };
      return ENGINE.runKernel(NonMaxSuppressionV3, { boxes: $boxes, scores: $scores }, attrs);
    }
    var nonMaxSuppression = /* @__PURE__ */ op({ nonMaxSuppression_ });
    function binaryInsert(arr, element, comparator) {
      var index = binarySearch(arr, element, comparator);
      var insertionPoint = index < 0 ? -(index + 1) : index;
      arr.splice(insertionPoint, 0, element);
    }
    function binarySearch(arr, target, comparator) {
      return binarySearch_(arr, target, comparator || defaultComparator);
    }
    function defaultComparator(a, b) {
      return a > b ? 1 : a < b ? -1 : 0;
    }
    function binarySearch_(arr, target, comparator) {
      var left = 0;
      var right = arr.length;
      var middle = 0;
      var found = false;
      while (left < right) {
        middle = left + (right - left >>> 1);
        var compareResult = comparator(target, arr[middle]);
        if (compareResult > 0) {
          left = middle + 1;
        } else {
          right = middle;
          found = !compareResult;
        }
      }
      return found ? left : -left - 1;
    }
    function nonMaxSuppressionV3Impl(boxes, scores, maxOutputSize, iouThreshold, scoreThreshold) {
      return nonMaxSuppressionImpl_(
        boxes,
        scores,
        maxOutputSize,
        iouThreshold,
        scoreThreshold,
        0
        /* softNmsSigma */
      );
    }
    function nonMaxSuppressionV4Impl(boxes, scores, maxOutputSize, iouThreshold, scoreThreshold, padToMaxOutputSize) {
      return nonMaxSuppressionImpl_(
        boxes,
        scores,
        maxOutputSize,
        iouThreshold,
        scoreThreshold,
        0,
        false,
        padToMaxOutputSize,
        true
        /* returnValidOutputs */
      );
    }
    function nonMaxSuppressionV5Impl(boxes, scores, maxOutputSize, iouThreshold, scoreThreshold, softNmsSigma) {
      return nonMaxSuppressionImpl_(
        boxes,
        scores,
        maxOutputSize,
        iouThreshold,
        scoreThreshold,
        softNmsSigma,
        true
        /* returnScoresTensor */
      );
    }
    function nonMaxSuppressionImpl_(boxes, scores, maxOutputSize, iouThreshold, scoreThreshold, softNmsSigma, returnScoresTensor, padToMaxOutputSize, returnValidOutputs) {
      if (returnScoresTensor === void 0) {
        returnScoresTensor = false;
      }
      if (padToMaxOutputSize === void 0) {
        padToMaxOutputSize = false;
      }
      if (returnValidOutputs === void 0) {
        returnValidOutputs = false;
      }
      var candidates = [];
      for (var i = 0; i < scores.length; i++) {
        if (scores[i] > scoreThreshold) {
          candidates.push({ score: scores[i], boxIndex: i, suppressBeginIndex: 0 });
        }
      }
      candidates.sort(ascendingComparator);
      var scale = softNmsSigma > 0 ? -0.5 / softNmsSigma : 0;
      var selectedIndices = [];
      var selectedScores = [];
      while (selectedIndices.length < maxOutputSize && candidates.length > 0) {
        var candidate = candidates.pop();
        var originalScore = candidate.score, boxIndex = candidate.boxIndex, suppressBeginIndex = candidate.suppressBeginIndex;
        if (originalScore < scoreThreshold) {
          break;
        }
        var ignoreCandidate = false;
        for (var j = selectedIndices.length - 1; j >= suppressBeginIndex; --j) {
          var iou = intersectionOverUnion(boxes, boxIndex, selectedIndices[j]);
          if (iou >= iouThreshold) {
            ignoreCandidate = true;
            break;
          }
          candidate.score = candidate.score * suppressWeight(iouThreshold, scale, iou);
          if (candidate.score <= scoreThreshold) {
            break;
          }
        }
        candidate.suppressBeginIndex = selectedIndices.length;
        if (!ignoreCandidate) {
          if (candidate.score === originalScore) {
            selectedIndices.push(boxIndex);
            selectedScores.push(candidate.score);
          } else if (candidate.score > scoreThreshold) {
            binaryInsert(candidates, candidate, ascendingComparator);
          }
        }
      }
      var validOutputs = selectedIndices.length;
      var elemsToPad = maxOutputSize - validOutputs;
      if (padToMaxOutputSize && elemsToPad > 0) {
        selectedIndices.push.apply(selectedIndices, __spreadArray([], __read(new Array(elemsToPad).fill(0)), false));
        selectedScores.push.apply(selectedScores, __spreadArray([], __read(new Array(elemsToPad).fill(0)), false));
      }
      var result = { selectedIndices };
      if (returnScoresTensor) {
        result["selectedScores"] = selectedScores;
      }
      if (returnValidOutputs) {
        result["validOutputs"] = validOutputs;
      }
      return result;
    }
    function intersectionOverUnion(boxes, i, j) {
      var iCoord = boxes.subarray(i * 4, i * 4 + 4);
      var jCoord = boxes.subarray(j * 4, j * 4 + 4);
      var yminI = Math.min(iCoord[0], iCoord[2]);
      var xminI = Math.min(iCoord[1], iCoord[3]);
      var ymaxI = Math.max(iCoord[0], iCoord[2]);
      var xmaxI = Math.max(iCoord[1], iCoord[3]);
      var yminJ = Math.min(jCoord[0], jCoord[2]);
      var xminJ = Math.min(jCoord[1], jCoord[3]);
      var ymaxJ = Math.max(jCoord[0], jCoord[2]);
      var xmaxJ = Math.max(jCoord[1], jCoord[3]);
      var areaI = (ymaxI - yminI) * (xmaxI - xminI);
      var areaJ = (ymaxJ - yminJ) * (xmaxJ - xminJ);
      if (areaI <= 0 || areaJ <= 0) {
        return 0;
      }
      var intersectionYmin = Math.max(yminI, yminJ);
      var intersectionXmin = Math.max(xminI, xminJ);
      var intersectionYmax = Math.min(ymaxI, ymaxJ);
      var intersectionXmax = Math.min(xmaxI, xmaxJ);
      var intersectionArea = Math.max(intersectionYmax - intersectionYmin, 0) * Math.max(intersectionXmax - intersectionXmin, 0);
      return intersectionArea / (areaI + areaJ - intersectionArea);
    }
    function suppressWeight(iouThreshold, scale, iou) {
      var weight = Math.exp(scale * iou * iou);
      return iou <= iouThreshold ? weight : 0;
    }
    function ascendingComparator(c1, c2) {
      return c1.score - c2.score || c1.score === c2.score && c2.boxIndex - c1.boxIndex;
    }
    function nonMaxSuppressionAsync_(boxes, scores, maxOutputSize, iouThreshold, scoreThreshold) {
      if (iouThreshold === void 0) {
        iouThreshold = 0.5;
      }
      if (scoreThreshold === void 0) {
        scoreThreshold = Number.NEGATIVE_INFINITY;
      }
      return __awaiter(this, void 0, void 0, function() {
        var $boxes, $scores, inputs, boxesAndScores, boxesVals, scoresVals, selectedIndices;
        return __generator(this, function(_a) {
          switch (_a.label) {
            case 0:
              $boxes = convertToTensor(boxes, "boxes", "nonMaxSuppressionAsync");
              $scores = convertToTensor(scores, "scores", "nonMaxSuppressionAsync");
              inputs = nonMaxSuppSanityCheck($boxes, $scores, maxOutputSize, iouThreshold, scoreThreshold);
              maxOutputSize = inputs.maxOutputSize;
              iouThreshold = inputs.iouThreshold;
              scoreThreshold = inputs.scoreThreshold;
              return [4, Promise.all([$boxes.data(), $scores.data()])];
            case 1:
              boxesAndScores = _a.sent();
              boxesVals = boxesAndScores[0];
              scoresVals = boxesAndScores[1];
              selectedIndices = nonMaxSuppressionV3Impl(boxesVals, scoresVals, maxOutputSize, iouThreshold, scoreThreshold).selectedIndices;
              if ($boxes !== boxes) {
                $boxes.dispose();
              }
              if ($scores !== scores) {
                $scores.dispose();
              }
              return [2, tensor1d(selectedIndices, "int32")];
          }
        });
      });
    }
    var nonMaxSuppressionAsync = nonMaxSuppressionAsync_;
    function nonMaxSuppressionWithScore_(boxes, scores, maxOutputSize, iouThreshold, scoreThreshold, softNmsSigma) {
      if (iouThreshold === void 0) {
        iouThreshold = 0.5;
      }
      if (scoreThreshold === void 0) {
        scoreThreshold = Number.NEGATIVE_INFINITY;
      }
      if (softNmsSigma === void 0) {
        softNmsSigma = 0;
      }
      var $boxes = convertToTensor(boxes, "boxes", "nonMaxSuppression");
      var $scores = convertToTensor(scores, "scores", "nonMaxSuppression");
      var params = nonMaxSuppSanityCheck($boxes, $scores, maxOutputSize, iouThreshold, scoreThreshold, softNmsSigma);
      maxOutputSize = params.maxOutputSize;
      iouThreshold = params.iouThreshold;
      scoreThreshold = params.scoreThreshold;
      softNmsSigma = params.softNmsSigma;
      var inputs = { boxes: $boxes, scores: $scores };
      var attrs = { maxOutputSize, iouThreshold, scoreThreshold, softNmsSigma };
      var result = ENGINE.runKernel(NonMaxSuppressionV5, inputs, attrs);
      return { selectedIndices: result[0], selectedScores: result[1] };
    }
    var nonMaxSuppressionWithScore = /* @__PURE__ */ op({ nonMaxSuppressionWithScore_ });
    function nonMaxSuppressionWithScoreAsync_(boxes, scores, maxOutputSize, iouThreshold, scoreThreshold, softNmsSigma) {
      if (iouThreshold === void 0) {
        iouThreshold = 0.5;
      }
      if (scoreThreshold === void 0) {
        scoreThreshold = Number.NEGATIVE_INFINITY;
      }
      if (softNmsSigma === void 0) {
        softNmsSigma = 0;
      }
      return __awaiter(this, void 0, void 0, function() {
        var $boxes, $scores, params, boxesAndScores, boxesVals, scoresVals, _a, selectedIndices, selectedScores;
        return __generator(this, function(_b) {
          switch (_b.label) {
            case 0:
              $boxes = convertToTensor(boxes, "boxes", "nonMaxSuppressionAsync");
              $scores = convertToTensor(scores, "scores", "nonMaxSuppressionAsync");
              params = nonMaxSuppSanityCheck($boxes, $scores, maxOutputSize, iouThreshold, scoreThreshold, softNmsSigma);
              maxOutputSize = params.maxOutputSize;
              iouThreshold = params.iouThreshold;
              scoreThreshold = params.scoreThreshold;
              softNmsSigma = params.softNmsSigma;
              return [4, Promise.all([$boxes.data(), $scores.data()])];
            case 1:
              boxesAndScores = _b.sent();
              boxesVals = boxesAndScores[0];
              scoresVals = boxesAndScores[1];
              _a = nonMaxSuppressionV5Impl(boxesVals, scoresVals, maxOutputSize, iouThreshold, scoreThreshold, softNmsSigma), selectedIndices = _a.selectedIndices, selectedScores = _a.selectedScores;
              if ($boxes !== boxes) {
                $boxes.dispose();
              }
              if ($scores !== scores) {
                $scores.dispose();
              }
              return [2, {
                selectedIndices: tensor1d(selectedIndices, "int32"),
                selectedScores: tensor1d(selectedScores)
              }];
          }
        });
      });
    }
    var nonMaxSuppressionWithScoreAsync = nonMaxSuppressionWithScoreAsync_;
    function nonMaxSuppressionPadded_(boxes, scores, maxOutputSize, iouThreshold, scoreThreshold, padToMaxOutputSize) {
      if (iouThreshold === void 0) {
        iouThreshold = 0.5;
      }
      if (scoreThreshold === void 0) {
        scoreThreshold = Number.NEGATIVE_INFINITY;
      }
      if (padToMaxOutputSize === void 0) {
        padToMaxOutputSize = false;
      }
      var $boxes = convertToTensor(boxes, "boxes", "nonMaxSuppression");
      var $scores = convertToTensor(scores, "scores", "nonMaxSuppression");
      var params = nonMaxSuppSanityCheck(
        $boxes,
        $scores,
        maxOutputSize,
        iouThreshold,
        scoreThreshold,
        null
        /* softNmsSigma */
      );
      var $maxOutputSize = params.maxOutputSize;
      var $iouThreshold = params.iouThreshold;
      var $scoreThreshold = params.scoreThreshold;
      var inputs = { boxes: $boxes, scores: $scores };
      var attrs = {
        maxOutputSize: $maxOutputSize,
        iouThreshold: $iouThreshold,
        scoreThreshold: $scoreThreshold,
        padToMaxOutputSize
      };
      var result = ENGINE.runKernel(NonMaxSuppressionV4, inputs, attrs);
      return { selectedIndices: result[0], validOutputs: result[1] };
    }
    var nonMaxSuppressionPadded = /* @__PURE__ */ op({ nonMaxSuppressionPadded_ });
    function nonMaxSuppressionPaddedAsync_(boxes, scores, maxOutputSize, iouThreshold, scoreThreshold, padToMaxOutputSize) {
      if (iouThreshold === void 0) {
        iouThreshold = 0.5;
      }
      if (scoreThreshold === void 0) {
        scoreThreshold = Number.NEGATIVE_INFINITY;
      }
      if (padToMaxOutputSize === void 0) {
        padToMaxOutputSize = false;
      }
      return __awaiter(this, void 0, void 0, function() {
        var $boxes, $scores, params, $maxOutputSize, $iouThreshold, $scoreThreshold, _a, boxesVals, scoresVals, _b, selectedIndices, validOutputs;
        return __generator(this, function(_c) {
          switch (_c.label) {
            case 0:
              $boxes = convertToTensor(boxes, "boxes", "nonMaxSuppressionAsync");
              $scores = convertToTensor(scores, "scores", "nonMaxSuppressionAsync");
              params = nonMaxSuppSanityCheck(
                $boxes,
                $scores,
                maxOutputSize,
                iouThreshold,
                scoreThreshold,
                null
                /* softNmsSigma */
              );
              $maxOutputSize = params.maxOutputSize;
              $iouThreshold = params.iouThreshold;
              $scoreThreshold = params.scoreThreshold;
              return [4, Promise.all([$boxes.data(), $scores.data()])];
            case 1:
              _a = __read.apply(void 0, [_c.sent(), 2]), boxesVals = _a[0], scoresVals = _a[1];
              _b = nonMaxSuppressionV4Impl(boxesVals, scoresVals, $maxOutputSize, $iouThreshold, $scoreThreshold, padToMaxOutputSize), selectedIndices = _b.selectedIndices, validOutputs = _b.validOutputs;
              if ($boxes !== boxes) {
                $boxes.dispose();
              }
              if ($scores !== scores) {
                $scores.dispose();
              }
              return [2, {
                selectedIndices: tensor1d(selectedIndices, "int32"),
                validOutputs: scalar(validOutputs, "int32")
              }];
          }
        });
      });
    }
    var nonMaxSuppressionPaddedAsync = nonMaxSuppressionPaddedAsync_;
    function resizeBilinear_(images, size, alignCorners, halfPixelCenters) {
      if (alignCorners === void 0) {
        alignCorners = false;
      }
      if (halfPixelCenters === void 0) {
        halfPixelCenters = false;
      }
      var $images = convertToTensor(images, "images", "resizeBilinear");
      assert($images.rank === 3 || $images.rank === 4, function() {
        return "Error in resizeBilinear: x must be rank 3 or 4, but got " + "rank ".concat($images.rank, ".");
      });
      assert(size.length === 2, function() {
        return "Error in resizeBilinear: new shape must 2D, but got shape " + "".concat(size, ".");
      });
      assert(halfPixelCenters === false || alignCorners === false, function() {
        return "Error in resizeBilinear: If halfPixelCenters is true, alignCorners must be false.";
      });
      var batchImages = $images;
      var reshapedTo4D = false;
      if ($images.rank === 3) {
        reshapedTo4D = true;
        batchImages = reshape($images, [1, $images.shape[0], $images.shape[1], $images.shape[2]]);
      }
      __read(size, 0);
      var inputs = { images: batchImages };
      var attrs = { alignCorners, halfPixelCenters, size };
      var res = ENGINE.runKernel(ResizeBilinear, inputs, attrs);
      if (reshapedTo4D) {
        return reshape(res, [res.shape[1], res.shape[2], res.shape[3]]);
      }
      return res;
    }
    var resizeBilinear = /* @__PURE__ */ op({ resizeBilinear_ });
    function resizeNearestNeighbor_(images, size, alignCorners, halfPixelCenters) {
      if (alignCorners === void 0) {
        alignCorners = false;
      }
      if (halfPixelCenters === void 0) {
        halfPixelCenters = false;
      }
      var $images = convertToTensor(images, "images", "resizeNearestNeighbor");
      assert($images.rank === 3 || $images.rank === 4, function() {
        return "Error in resizeNearestNeighbor: x must be rank 3 or 4, but got " + "rank ".concat($images.rank, ".");
      });
      assert(size.length === 2, function() {
        return "Error in resizeNearestNeighbor: new shape must 2D, but got shape " + "".concat(size, ".");
      });
      assert($images.dtype === "float32" || $images.dtype === "int32", function() {
        return "`images` must have `int32` or `float32` as dtype";
      });
      assert(halfPixelCenters === false || alignCorners === false, function() {
        return "Error in resizeNearestNeighbor: If halfPixelCenters is true, alignCorners must be false.";
      });
      var batchImages = $images;
      var reshapedTo4D = false;
      if ($images.rank === 3) {
        reshapedTo4D = true;
        batchImages = reshape($images, [1, $images.shape[0], $images.shape[1], $images.shape[2]]);
      }
      __read(size, 0);
      var inputs = { images: batchImages };
      var attrs = { alignCorners, halfPixelCenters, size };
      var res = ENGINE.runKernel(ResizeNearestNeighbor, inputs, attrs);
      if (reshapedTo4D) {
        return reshape(res, [res.shape[1], res.shape[2], res.shape[3]]);
      }
      return res;
    }
    var resizeNearestNeighbor = /* @__PURE__ */ op({ resizeNearestNeighbor_ });
    function threshold_(image2, method, inverted, threshValue) {
      var _a;
      if (method === void 0) {
        method = "binary";
      }
      if (inverted === void 0) {
        inverted = false;
      }
      if (threshValue === void 0) {
        threshValue = 0.5;
      }
      var $image = convertToTensor(image2, "image", "threshold");
      var RED_INTENCITY_COEF = 0.2989;
      var GREEN_INTENCITY_COEF = 0.587;
      var BLUE_INTENCITY_COEF = 0.114;
      var totalPixelsInImage = $image.shape[0] * $image.shape[1];
      var $threshold = mul(tensor1d([threshValue]), 255);
      var r, g, b, grayscale;
      assert($image.rank === 3, function() {
        return "Error in threshold: image must be rank 3," + "but got rank ".concat($image.rank, ".");
      });
      assert($image.shape[2] === 3 || $image.shape[2] === 1, function() {
        return "Error in threshold: image color channel must be equal to 3 or 1" + "but got ".concat($image.shape[2], ".");
      });
      assert($image.dtype === "int32" || $image.dtype === "float32", function() {
        return "Error in dtype: image dtype must be int32 or float32," + "but got dtype ".concat($image.dtype, ".");
      });
      assert(method === "otsu" || method === "binary", function() {
        return "Method must be binary or otsu, but was ".concat(method);
      });
      if ($image.shape[2] === 3) {
        _a = __read(split$1($image, [1, 1, 1], -1), 3), r = _a[0], g = _a[1], b = _a[2];
        var $r = mul(r, RED_INTENCITY_COEF);
        var $g = mul(g, GREEN_INTENCITY_COEF);
        var $b = mul(b, BLUE_INTENCITY_COEF);
        grayscale = add(add($r, $g), $b);
      } else {
        grayscale = image2;
      }
      if (method === "otsu") {
        var $histogram = bincount(cast(round(grayscale), "int32"), tensor([]), 256);
        $threshold = otsu($histogram, totalPixelsInImage);
      }
      var invCondition = inverted ? lessEqual(grayscale, $threshold) : greater(grayscale, $threshold);
      var result = cast(mul(invCondition, 255), "int32");
      return result;
    }
    function otsu(histogram, total) {
      var bestThresh = tensor1d([-1]);
      var bestInBetVar = tensor1d([0]);
      var cInBetVar = tensor1d([0]);
      var classFirst, classSecond, meanFirst, meanSec, weightForeground, weightBack;
      for (var index = 0; index < histogram.size - 1; index++) {
        classFirst = slice(histogram, 0, index + 1);
        classSecond = slice(histogram, index + 1);
        weightForeground = div(sum(classFirst), total);
        weightBack = div(sum(classSecond), total);
        var meanFirstDivA = sum(mul(classFirst, range(0, classFirst.size)));
        meanFirst = div(meanFirstDivA, sum(classFirst));
        var meanSecFill = fill(classSecond.shape, classFirst.size);
        var meanSecAdd = add(range(0, classSecond.size), meanSecFill);
        var meanSecMul = mul(classSecond, meanSecAdd);
        meanSec = div(sum(meanSecMul), sum(classSecond));
        var cInBetVarSubA = sub(meanFirst, meanSec);
        var cInBetVarSubB = sub(meanFirst, meanSec);
        var cInBetVarMul = mul(weightForeground, weightBack);
        cInBetVar = mul(mul(cInBetVarMul, cInBetVarSubA), cInBetVarSubB);
        var condition = greater(cInBetVar, bestInBetVar);
        bestInBetVar = where(condition, cInBetVar, bestInBetVar);
        bestThresh = where(condition, tensor1d([index]), bestThresh);
      }
      return bestThresh;
    }
    var threshold = /* @__PURE__ */ op({ threshold_ });
    function transform_(image2, transforms, interpolation, fillMode, fillValue, outputShape) {
      if (interpolation === void 0) {
        interpolation = "nearest";
      }
      if (fillMode === void 0) {
        fillMode = "constant";
      }
      if (fillValue === void 0) {
        fillValue = 0;
      }
      var $image = convertToTensor(image2, "image", "transform", "float32");
      var $transforms = convertToTensor(transforms, "transforms", "transform", "float32");
      assert($image.rank === 4, function() {
        return "Error in transform: image must be rank 4," + "but got rank ".concat($image.rank, ".");
      });
      assert($transforms.rank === 2 && ($transforms.shape[0] === $image.shape[0] || $transforms.shape[0] === 1) && $transforms.shape[1] === 8, function() {
        return "Error in transform: Input transform should be batch x 8 or 1 x 8";
      });
      assert(outputShape == null || outputShape.length === 2, function() {
        return "Error in transform: outputShape must be [height, width] or null, " + "but got ".concat(outputShape, ".");
      });
      var inputs = { image: $image, transforms: $transforms };
      var attrs = { interpolation, fillMode, fillValue, outputShape };
      return ENGINE.runKernel(Transform, inputs, attrs);
    }
    var transform = /* @__PURE__ */ op({ transform_ });
    function bandPart_(a, numLower, numUpper) {
      var $a = convertToTensor(a, "a", "bandPart");
      assert($a.rank >= 2, function() {
        return "bandPart(): Rank must be at least 2, got ".concat($a.rank, ".");
      });
      var shape = $a.shape;
      var _a = __read($a.shape.slice(-2), 2), M = _a[0], N = _a[1];
      var $numLower;
      var $numUpper;
      if (typeof numLower === "number") {
        assert(numLower % 1 === 0, function() {
          return "bandPart(): numLower must be an integer, got ".concat(numLower, ".");
        });
        assert(numLower <= M, function() {
          return "bandPart(): numLower (".concat(numLower, ")") + " must not be greater than the number of rows (".concat(M, ").");
        });
        $numLower = convertToTensor(numLower < 0 ? M : numLower, "numLower", "bandPart");
      } else {
        assert(numLower.dtype === "int32", function() {
          return "bandPart(): numLower's dtype must be an int32.";
        });
        $numLower = where(less(numLower, 0), M, minimum(numLower, M));
      }
      if (typeof numUpper === "number") {
        assert(numUpper % 1 === 0, function() {
          return "bandPart(): numUpper must be an integer, got ".concat(numUpper, ".");
        });
        assert(numUpper <= N, function() {
          return "bandPart(): numUpper (".concat(numUpper, ")") + " must not be greater than the number of columns (".concat(N, ").");
        });
        $numUpper = convertToTensor(numUpper < 0 ? N : numUpper, "numUpper", "bandPart");
      } else {
        assert(numUpper.dtype === "int32", function() {
          return "bandPart(): numUpper's dtype must be an int32.";
        });
        $numUpper = where(less(numUpper, 0), N, minimum(numUpper, N));
      }
      var i = reshape(range(0, M, 1, "int32"), [-1, 1]);
      var j = range(0, N, 1, "int32");
      var ij = sub(i, j);
      var inBand = logicalAnd(lessEqual(ij, $numLower), greaterEqual(ij, neg($numUpper)));
      var zero = zeros([M, N], $a.dtype);
      return reshape(stack(unstack(reshape($a, [-1, M, N])).map(function(mat) {
        return where(inBand, mat, zero);
      })), shape);
    }
    var bandPart = /* @__PURE__ */ op({ bandPart_ });
    function gramSchmidt_(xs) {
      var inputIsTensor2D;
      if (Array.isArray(xs)) {
        inputIsTensor2D = false;
        assert(xs != null && xs.length > 0, function() {
          return "Gram-Schmidt process: input must not be null, undefined, or empty";
        });
        var dim_1 = xs[0].shape[0];
        var _loop_1 = function(i2) {
          assert(xs[i2].shape[0] === dim_1, function() {
            return "Gram-Schmidt: Non-unique lengths found in the input vectors: " + "(".concat(xs[i2].shape[0], " vs. ").concat(dim_1, ")");
          });
        };
        for (var i = 1; i < xs.length; ++i) {
          _loop_1(i);
        }
      } else {
        inputIsTensor2D = true;
        xs = split$1(xs, xs.shape[0], 0).map(function(x) {
          return squeeze(x, [0]);
        });
      }
      assert(xs.length <= xs[0].shape[0], function() {
        return "Gram-Schmidt: Number of vectors (".concat(xs.length, ") exceeds ") + "number of dimensions (".concat(xs[0].shape[0], ").");
      });
      var ys = [];
      var xs1d = xs;
      var _loop_2 = function(i2) {
        ys.push(ENGINE.tidy(function() {
          var x = xs1d[i2];
          if (i2 > 0) {
            for (var j = 0; j < i2; ++j) {
              var proj = mul(sum(mul(ys[j], x)), ys[j]);
              x = sub(x, proj);
            }
          }
          return div(x, norm(x, "euclidean"));
        }));
      };
      for (var i = 0; i < xs.length; ++i) {
        _loop_2(i);
      }
      if (inputIsTensor2D) {
        return stack(ys, 0);
      } else {
        return ys;
      }
    }
    var gramSchmidt = /* @__PURE__ */ op({ gramSchmidt_ });
    function qr_(x, fullMatrices) {
      if (fullMatrices === void 0) {
        fullMatrices = false;
      }
      assert(x.rank >= 2, function() {
        return "qr() requires input tensor to have a rank >= 2, but got rank ".concat(x.rank);
      });
      if (x.rank === 2) {
        return qr2d(x, fullMatrices);
      } else {
        var outerDimsProd = x.shape.slice(0, x.shape.length - 2).reduce(function(value, prev) {
          return value * prev;
        });
        var x2ds = unstack(reshape(x, [
          outerDimsProd,
          x.shape[x.shape.length - 2],
          x.shape[x.shape.length - 1]
        ]), 0);
        var q2ds_1 = [];
        var r2ds_1 = [];
        x2ds.forEach(function(x2d) {
          var _a = __read(qr2d(x2d, fullMatrices), 2), q2d = _a[0], r2d = _a[1];
          q2ds_1.push(q2d);
          r2ds_1.push(r2d);
        });
        var q = reshape(stack(q2ds_1, 0), x.shape);
        var r = reshape(stack(r2ds_1, 0), x.shape);
        return [q, r];
      }
    }
    function qr2d(x, fullMatrices) {
      if (fullMatrices === void 0) {
        fullMatrices = false;
      }
      return ENGINE.tidy(function() {
        assert(x.shape.length === 2, function() {
          return "qr2d() requires a 2D Tensor, but got a ".concat(x.shape.length, "D Tensor.");
        });
        var m = x.shape[0];
        var n = x.shape[1];
        var q = eye(m);
        var r = clone(x);
        var one2D = tensor2d([[1]], [1, 1]);
        var w = clone(one2D);
        var iters = m >= n ? n : m;
        var _loop_1 = function(j2) {
          var _a;
          var rTemp = r;
          var wTemp = w;
          var qTemp = q;
          _a = __read(ENGINE.tidy(function() {
            var rjEnd1 = slice(r, [j2, j2], [m - j2, 1]);
            var normX = norm(rjEnd1);
            var rjj = slice(r, [j2, j2], [1, 1]);
            var s = where(greater(rjj, 0), tensor2d([[-1]]), tensor2d([[1]]));
            var u1 = sub(rjj, mul(s, normX));
            var wPre = div(rjEnd1, u1);
            if (wPre.shape[0] === 1) {
              w = clone(one2D);
            } else {
              w = concat([
                one2D,
                slice(wPre, [1, 0], [wPre.shape[0] - 1, wPre.shape[1]])
              ], 0);
            }
            var tau = neg(div(matMul$1(s, u1), normX));
            var rjEndAll = slice(r, [j2, 0], [m - j2, n]);
            var tauTimesW = mul(tau, w);
            var wT = transpose(w);
            if (j2 === 0) {
              r = sub(rjEndAll, matMul$1(tauTimesW, matMul$1(wT, rjEndAll)));
            } else {
              var rTimesTau = sub(rjEndAll, matMul$1(tauTimesW, matMul$1(wT, rjEndAll)));
              r = concat([slice(r, [0, 0], [j2, n]), rTimesTau], 0);
            }
            var tawTimesWT = transpose(tauTimesW);
            var qAllJEnd = slice(q, [0, j2], [m, q.shape[1] - j2]);
            if (j2 === 0) {
              q = sub(qAllJEnd, matMul$1(matMul$1(qAllJEnd, w), tawTimesWT));
            } else {
              var qTimesTau = sub(qAllJEnd, matMul$1(matMul$1(qAllJEnd, w), tawTimesWT));
              q = concat([slice(q, [0, 0], [m, j2]), qTimesTau], 1);
            }
            return [w, r, q];
          }), 3), w = _a[0], r = _a[1], q = _a[2];
          dispose([rTemp, wTemp, qTemp]);
        };
        for (var j = 0; j < iters; ++j) {
          _loop_1(j);
        }
        if (!fullMatrices && m > n) {
          q = slice(q, [0, 0], [m, n]);
          r = slice(r, [0, 0], [n, n]);
        }
        return [q, r];
      });
    }
    var qr = /* @__PURE__ */ op({ qr_ });
    var Reduction;
    (function(Reduction2) {
      Reduction2[Reduction2["NONE"] = 0] = "NONE";
      Reduction2[Reduction2["MEAN"] = 1] = "MEAN";
      Reduction2[Reduction2["SUM"] = 2] = "SUM";
      Reduction2[Reduction2["SUM_BY_NONZERO_WEIGHTS"] = 3] = "SUM_BY_NONZERO_WEIGHTS";
    })(Reduction || (Reduction = {}));
    function computeWeightedLoss_(losses2, weights, reduction2) {
      if (reduction2 === void 0) {
        reduction2 = Reduction.SUM_BY_NONZERO_WEIGHTS;
      }
      var $losses = convertToTensor(losses2, "losses", "computeWeightedLoss");
      var $weights = null;
      if (weights != null) {
        $weights = convertToTensor(weights, "weights", "computeWeightedLoss");
      }
      var weightedLoss = $weights == null ? $losses : mul($losses, $weights);
      if (reduction2 === Reduction.NONE) {
        return weightedLoss;
      }
      if (reduction2 === Reduction.SUM) {
        return sum(weightedLoss);
      }
      if (reduction2 === Reduction.MEAN) {
        if ($weights == null) {
          return mean(weightedLoss);
        } else {
          var broadcastFactor = $losses.size / $weights.size;
          var result = div(sum(weightedLoss), sum($weights));
          return broadcastFactor > 1 ? div(result, scalar(broadcastFactor)) : result;
        }
      }
      if (reduction2 === Reduction.SUM_BY_NONZERO_WEIGHTS) {
        if ($weights == null) {
          return div(sum(weightedLoss), scalar($losses.size));
        } else {
          var broadcastedWeights = mul($weights, ones($losses.shape));
          var numNonZeros = cast(sum(notEqual(broadcastedWeights, scalar(0))), "float32");
          return div(sum(weightedLoss), numNonZeros);
        }
      }
      throw Error("Unknown reduction: ".concat(reduction2));
    }
    var computeWeightedLoss = /* @__PURE__ */ op({ computeWeightedLoss_ });
    function absoluteDifference_(labels, predictions, weights, reduction2) {
      if (reduction2 === void 0) {
        reduction2 = Reduction.SUM_BY_NONZERO_WEIGHTS;
      }
      var $labels = convertToTensor(labels, "labels", "absoluteDifference");
      var $predictions = convertToTensor(predictions, "predictions", "absoluteDifference");
      var $weights = null;
      if (weights != null) {
        $weights = convertToTensor(weights, "weights", "absoluteDifference");
      }
      assertShapesMatch($labels.shape, $predictions.shape, "Error in absoluteDifference: ");
      var losses2 = abs(sub($labels, $predictions));
      return computeWeightedLoss(losses2, $weights, reduction2);
    }
    var absoluteDifference = /* @__PURE__ */ op({ absoluteDifference_ });
    function cosineDistance_(labels, predictions, axis, weights, reduction2) {
      if (reduction2 === void 0) {
        reduction2 = Reduction.SUM_BY_NONZERO_WEIGHTS;
      }
      var $labels = convertToTensor(labels, "labels", "cosineDistance");
      var $predictions = convertToTensor(predictions, "predictions", "cosineDistance");
      var $weights = null;
      if (weights != null) {
        $weights = convertToTensor(weights, "weights", "cosineDistance");
      }
      assertShapesMatch($labels.shape, $predictions.shape, "Error in cosineDistance: ");
      var one = scalar(1);
      var losses2 = sub(one, sum(mul($labels, $predictions), axis, true));
      return computeWeightedLoss(losses2, $weights, reduction2);
    }
    var cosineDistance = /* @__PURE__ */ op({ cosineDistance_ });
    function hingeLoss_(labels, predictions, weights, reduction2) {
      if (reduction2 === void 0) {
        reduction2 = Reduction.SUM_BY_NONZERO_WEIGHTS;
      }
      var $labels = convertToTensor(labels, "labels", "hingeLoss");
      var $predictions = convertToTensor(predictions, "predictions", "hingeLoss");
      var $weights = null;
      if (weights != null) {
        $weights = convertToTensor(weights, "weights", "hingeLoss");
      }
      assertShapesMatch($labels.shape, $predictions.shape, "Error in hingeLoss: ");
      var one = scalar(1);
      $labels = sub(mul(scalar(2), $labels), one);
      var losses2 = relu(sub(one, mul($labels, $predictions)));
      return computeWeightedLoss(losses2, $weights, reduction2);
    }
    var hingeLoss = /* @__PURE__ */ op({ hingeLoss_ });
    function huberLoss_(labels, predictions, weights, delta, reduction2) {
      if (delta === void 0) {
        delta = 1;
      }
      if (reduction2 === void 0) {
        reduction2 = Reduction.SUM_BY_NONZERO_WEIGHTS;
      }
      var $labels = convertToTensor(labels, "labels", "huberLoss");
      var $predictions = convertToTensor(predictions, "predictions", "huberLoss");
      var $weights = null;
      if (weights != null) {
        $weights = convertToTensor(weights, "weights", "huberLoss");
      }
      assertShapesMatch($labels.shape, $predictions.shape, "Error in huberLoss: ");
      var deltaScalar = scalar(delta);
      var error = abs(sub($predictions, $labels));
      var quadratic = minimum(error, deltaScalar);
      var linear = sub(error, quadratic);
      var losses2 = add(mul(scalar(0.5), square(quadratic)), mul(deltaScalar, linear));
      return computeWeightedLoss(losses2, $weights, reduction2);
    }
    var huberLoss = /* @__PURE__ */ op({ huberLoss_ });
    function logLoss_(labels, predictions, weights, epsilon, reduction2) {
      if (epsilon === void 0) {
        epsilon = 1e-7;
      }
      if (reduction2 === void 0) {
        reduction2 = Reduction.SUM_BY_NONZERO_WEIGHTS;
      }
      var $labels = convertToTensor(labels, "labels", "logLoss");
      var $predictions = convertToTensor(predictions, "predictions", "logLoss");
      var $weights = null;
      if (weights != null) {
        $weights = convertToTensor(weights, "weights", "logLoss");
      }
      assertShapesMatch($labels.shape, $predictions.shape, "Error in logLoss: ");
      var one = scalar(1);
      var epsilonScalar = scalar(epsilon);
      var l1 = neg(mul($labels, log(add($predictions, epsilonScalar))));
      var l2 = mul(sub(one, $labels), log(add(sub(one, $predictions), epsilonScalar)));
      var losses2 = sub(l1, l2);
      return computeWeightedLoss(losses2, $weights, reduction2);
    }
    var logLoss = /* @__PURE__ */ op({ logLoss_ });
    function meanSquaredError_(labels, predictions, weights, reduction2) {
      if (reduction2 === void 0) {
        reduction2 = Reduction.SUM_BY_NONZERO_WEIGHTS;
      }
      var $labels = convertToTensor(labels, "labels", "meanSquaredError");
      var $predictions = convertToTensor(predictions, "predictions", "meanSquaredError");
      var $weights = null;
      if (weights != null) {
        $weights = convertToTensor(weights, "weights", "meanSquaredError");
      }
      assertShapesMatch($labels.shape, $predictions.shape, "Error in meanSquaredError: ");
      var losses2 = squaredDifference($labels, $predictions);
      return computeWeightedLoss(losses2, $weights, reduction2);
    }
    var meanSquaredError = /* @__PURE__ */ op({ meanSquaredError_ });
    function sigmoidCrossEntropyWithLogits_(labels, logits) {
      var $labels = convertToTensor(labels, "labels", "sigmoidCrossEntropyWithLogits");
      var $logits = convertToTensor(logits, "logits", "sigmoidCrossEntropyWithLogits");
      assertShapesMatch($labels.shape, $logits.shape, "Error in sigmoidCrossEntropyWithLogits: ");
      var maxOutput = relu($logits);
      var outputXTarget = mul($logits, $labels);
      var sigmoidOutput = log1p(exp(neg(abs($logits))));
      return add(sub(maxOutput, outputXTarget), sigmoidOutput);
    }
    function sigmoidCrossEntropy_(multiClassLabels, logits, weights, labelSmoothing, reduction2) {
      if (labelSmoothing === void 0) {
        labelSmoothing = 0;
      }
      if (reduction2 === void 0) {
        reduction2 = Reduction.SUM_BY_NONZERO_WEIGHTS;
      }
      var $multiClassLabels = convertToTensor(multiClassLabels, "multiClassLabels", "sigmoidCrossEntropy");
      var $logits = convertToTensor(logits, "logits", "sigmoidCrossEntropy");
      var $weights = null;
      if (weights != null) {
        $weights = convertToTensor(weights, "weights", "sigmoidCrossEntropy");
      }
      assertShapesMatch($multiClassLabels.shape, $logits.shape, "Error in sigmoidCrossEntropy: ");
      if (labelSmoothing > 0) {
        var labelSmoothingScalar = scalar(labelSmoothing);
        var one = scalar(1);
        var half = scalar(0.5);
        $multiClassLabels = add(mul($multiClassLabels, sub(one, labelSmoothingScalar)), mul(half, labelSmoothingScalar));
      }
      var losses2 = sigmoidCrossEntropyWithLogits_($multiClassLabels, $logits);
      return computeWeightedLoss(losses2, $weights, reduction2);
    }
    var sigmoidCrossEntropy = /* @__PURE__ */ op({ sigmoidCrossEntropy_ });
    function softmaxCrossEntropyWithLogits_(labels, logits, dim) {
      if (dim === void 0) {
        dim = -1;
      }
      if (dim === -1) {
        dim = logits.rank - 1;
      }
      if (dim !== logits.rank - 1) {
        throw Error("Softmax cross entropy along a non-last dimension is not yet " + "supported. Labels / logits was rank ".concat(logits.rank, " ") + "and dim was ".concat(dim));
      }
      var customOp = customGrad(function(labels2, logits2, save) {
        var keepDims = true;
        var lse = logSumExp(logits2, [dim], keepDims);
        var logResult = sub(cast(logits2, "float32"), lse);
        save([labels2, logResult]);
        var costVector = neg(mul(logResult, labels2));
        var value = sum(costVector, [dim]);
        var gradFunc = function(dy, saved) {
          var _a = __read(saved, 2), labels3 = _a[0], logResult2 = _a[1];
          var dyShape = expandShapeToKeepDim(dy.shape, [dim]);
          return [
            mul(reshape(dy, dyShape), sub(cast(labels3, "float32"), exp(logResult2))),
            mul(reshape(dy, dyShape), sub(exp(logResult2), cast(labels3, "float32")))
          ];
        };
        return { value, gradFunc };
      });
      return customOp(labels, logits);
    }
    function softmaxCrossEntropy_(onehotLabels, logits, weights, labelSmoothing, reduction2) {
      if (labelSmoothing === void 0) {
        labelSmoothing = 0;
      }
      if (reduction2 === void 0) {
        reduction2 = Reduction.SUM_BY_NONZERO_WEIGHTS;
      }
      var $onehotLabels = convertToTensor(onehotLabels, "onehotLabels", "softmaxCrossEntropy");
      var $logits = convertToTensor(logits, "logits", "softmaxCrossEntropy");
      var $weights = null;
      if (weights != null) {
        $weights = convertToTensor(weights, "weights", "softmaxCrossEntropy");
      }
      assertShapesMatch($onehotLabels.shape, $logits.shape, "Error in softmaxCrossEntropy: ");
      if (labelSmoothing > 0) {
        var labelSmoothingScalar = scalar(labelSmoothing);
        var one = scalar(1);
        var numClasses = scalar($onehotLabels.shape[1]);
        $onehotLabels = add(mul($onehotLabels, sub(one, labelSmoothingScalar)), div(labelSmoothingScalar, numClasses));
      }
      var losses2 = softmaxCrossEntropyWithLogits_($onehotLabels, $logits);
      return computeWeightedLoss(losses2, $weights, reduction2);
    }
    var softmaxCrossEntropy = /* @__PURE__ */ op({ softmaxCrossEntropy_ });
    function sparseFillEmptyRows_(indices, values, denseShape, defaultValue) {
      var $indices = convertToTensor(indices, "indices", "sparseFillEmptyRows", "int32");
      var $values = convertToTensor(values, "values", "sparseFillEmptyRows");
      var $denseShape = convertToTensor(denseShape, "denseShape", "sparseFillEmptyRows", "int32");
      var $defaultValue = convertToTensor(defaultValue, "defaultValue", "sparseFillEmptyRows", $values.dtype);
      if ($indices.rank !== 2) {
        throw new Error("Indices should be Tensor2D but received shape\n        ".concat($indices.shape));
      }
      if ($values.rank !== 1) {
        throw new Error("Values should be Tensor1D but received shape ".concat($values.shape));
      }
      if ($denseShape.rank !== 1) {
        throw new Error("Dense shape should be Tensor1D but received shape ".concat($denseShape.shape));
      }
      if ($defaultValue.rank !== 0) {
        throw new Error("Default value should be a scalar but received shape ".concat($defaultValue.shape));
      }
      var inputs = {
        indices: $indices,
        values: $values,
        denseShape: $denseShape,
        defaultValue: $defaultValue
      };
      var result = ENGINE.runKernel(SparseFillEmptyRows, inputs);
      return {
        outputIndices: result[0],
        outputValues: result[1],
        emptyRowIndicator: result[2],
        reverseIndexMap: result[3]
      };
    }
    var sparseFillEmptyRows = /* @__PURE__ */ op({ sparseFillEmptyRows_ });
    function sparseReshape_(inputIndices, inputShape, newShape) {
      var $inputIndices = convertToTensor(inputIndices, "inputIndices", "sparseReshape", "int32");
      var $inputShape = convertToTensor(inputShape, "inputShape", "sparseReshape", "int32");
      var $newShape = convertToTensor(newShape, "newShape", "sparseReshape", "int32");
      if ($inputIndices.rank !== 2) {
        throw new Error("Input indices should be Tensor2D but received shape\n        ".concat($inputIndices.shape));
      }
      if ($inputShape.rank !== 1) {
        throw new Error("Input shape should be Tensor1D but received shape ".concat($inputShape.shape));
      }
      if ($newShape.rank !== 1) {
        throw new Error("New shape should be Tensor1D but received shape ".concat($newShape.shape));
      }
      var inputs = {
        inputIndices: $inputIndices,
        inputShape: $inputShape,
        newShape: $newShape
      };
      var result = ENGINE.runKernel(SparseReshape, inputs);
      return { outputIndices: result[0], outputShape: result[1] };
    }
    var sparseReshape = /* @__PURE__ */ op({ sparseReshape_ });
    function sparseSegmentMean_(data, indices, segmentIds) {
      var $data = convertToTensor(data, "data", "sparseSegmentMean");
      var $indices = convertToTensor(indices, "indices", "sparseSegmentMean", "int32");
      var $segmentIds = convertToTensor(segmentIds, "segmentIds", "sparseSegmentMean", "int32");
      if ($data.rank < 1) {
        throw new Error("Data should be at least 1 dimensional but received scalar");
      }
      if ($indices.rank !== 1) {
        throw new Error("Indices should be Tensor1D but received shape\n          ".concat($indices.shape));
      }
      if ($segmentIds.rank !== 1) {
        throw new Error("Segment ids should be Tensor1D but received shape\n          ".concat($segmentIds.shape));
      }
      var inputs = {
        data: $data,
        indices: $indices,
        segmentIds: $segmentIds
      };
      return ENGINE.runKernel(SparseSegmentMean, inputs);
    }
    var sparseSegmentMean = /* @__PURE__ */ op({ sparseSegmentMean_ });
    function sparseSegmentSum_(data, indices, segmentIds) {
      var $data = convertToTensor(data, "data", "sparseSegmentSum");
      var $indices = convertToTensor(indices, "indices", "sparseSegmentSum", "int32");
      var $segmentIds = convertToTensor(segmentIds, "segmentIds", "sparseSegmentSum", "int32");
      if ($data.rank < 1) {
        throw new Error("Data should be at least 1 dimensional but received scalar");
      }
      if ($indices.rank !== 1) {
        throw new Error("Indices should be Tensor1D but received shape\n         ".concat($indices.shape));
      }
      if ($segmentIds.rank !== 1) {
        throw new Error("Segment ids should be Tensor1D but received shape\n         ".concat($segmentIds.shape));
      }
      var inputs = {
        data: $data,
        indices: $indices,
        segmentIds: $segmentIds
      };
      return ENGINE.runKernel(SparseSegmentSum, inputs);
    }
    var sparseSegmentSum = /* @__PURE__ */ op({ sparseSegmentSum_ });
    function stringNGrams_(data, dataSplits, separator, nGramWidths, leftPad, rightPad2, padWidth, preserveShortSequences) {
      var $data = convertToTensor(data, "data", "stringNGrams", "string");
      if ($data.dtype !== "string") {
        throw new Error("Data must be of datatype string");
      }
      if ($data.shape.length !== 1) {
        throw new Error("Data must be a vector, saw: ".concat($data.shape));
      }
      var $dataSplits = convertToTensor(dataSplits, "dataSplits", "stringNGrams");
      if ($dataSplits.dtype !== "int32") {
        throw new Error("Data splits must be of datatype int32");
      }
      var attrs = {
        separator,
        nGramWidths,
        leftPad,
        rightPad: rightPad2,
        padWidth,
        preserveShortSequences
      };
      var inputs = { data: $data, dataSplits: $dataSplits };
      var result = ENGINE.runKernel(StringNGrams, inputs, attrs);
      return { nGrams: result[0], nGramsSplits: result[1] };
    }
    var stringNGrams = /* @__PURE__ */ op({ stringNGrams_ });
    function stringSplit_(input, delimiter, skipEmpty) {
      if (skipEmpty === void 0) {
        skipEmpty = true;
      }
      var $input = convertToTensor(input, "input", "stringSplit", "string");
      var $delimiter = convertToTensor(delimiter, "delimiter", "stringSplit", "string");
      if ($input.rank !== 1) {
        throw new Error("Input should be Tensor1D but received shape ".concat($input.shape));
      }
      if ($delimiter.rank !== 0) {
        throw new Error("Delimiter should be a scalar but received shape ".concat($delimiter.shape));
      }
      var attrs = { skipEmpty };
      var inputs = { input: $input, delimiter: $delimiter };
      var result = ENGINE.runKernel(StringSplit, inputs, attrs);
      return { indices: result[0], values: result[1], shape: result[2] };
    }
    var stringSplit = /* @__PURE__ */ op({ stringSplit_ });
    function stringToHashBucketFast_(input, numBuckets) {
      var $input = convertToTensor(input, "input", "stringToHashBucketFast", "string");
      var attrs = { numBuckets };
      if (numBuckets <= 0) {
        throw new Error("Number of buckets must be at least 1");
      }
      var inputs = { input: $input };
      return ENGINE.runKernel(StringToHashBucketFast, inputs, attrs);
    }
    var stringToHashBucketFast = /* @__PURE__ */ op({ stringToHashBucketFast_ });
    function staticRegexReplace_(input, pattern, rewrite, replaceGlobal) {
      if (replaceGlobal === void 0) {
        replaceGlobal = true;
      }
      var $input = convertToTensor(input, "input", "staticRegexReplace", "string");
      var attrs = { pattern, rewrite, replaceGlobal };
      return ENGINE.runKernel(StaticRegexReplace, { x: $input }, attrs);
    }
    var staticRegexReplace = /* @__PURE__ */ op({ staticRegexReplace_ });
    var spectral = {
      fft,
      ifft,
      rfft,
      irfft
    };
    var signal = {
      hammingWindow,
      hannWindow,
      frame,
      stft
    };
    var image = {
      flipLeftRight,
      grayscaleToRGB,
      resizeNearestNeighbor,
      resizeBilinear,
      rotateWithOffset,
      cropAndResize,
      nonMaxSuppression,
      nonMaxSuppressionAsync,
      nonMaxSuppressionWithScore,
      nonMaxSuppressionWithScoreAsync,
      nonMaxSuppressionPadded,
      nonMaxSuppressionPaddedAsync,
      threshold,
      transform
    };
    var linalg = {
      bandPart,
      gramSchmidt,
      qr
    };
    var losses = {
      absoluteDifference,
      computeWeightedLoss,
      cosineDistance,
      hingeLoss,
      huberLoss,
      logLoss,
      meanSquaredError,
      sigmoidCrossEntropy,
      softmaxCrossEntropy
    };
    var sparse = {
      sparseFillEmptyRows,
      sparseReshape,
      sparseSegmentMean,
      sparseSegmentSum
    };
    var string = {
      stringNGrams,
      stringSplit,
      stringToHashBucketFast,
      staticRegexReplace
    };
    var tfOps = {
      __proto__: null,
      OP_SCOPE_SUFFIX,
      abs,
      acos,
      acosh,
      add,
      addN,
      all,
      any,
      argMax,
      argMin,
      asin,
      asinh,
      atan,
      atan2,
      atanh,
      avgPool,
      avgPool3d,
      basicLSTMCell,
      batchNorm,
      batchNorm2d,
      batchNorm3d,
      batchNorm4d,
      batchToSpaceND,
      bincount,
      bitwiseAnd,
      booleanMaskAsync,
      broadcastArgs,
      broadcastTo,
      buffer,
      cast,
      ceil,
      clipByValue,
      clone,
      complex,
      concat,
      concat1d,
      concat2d,
      concat3d,
      concat4d,
      conv1d,
      conv2d: conv2d$1,
      conv2dTranspose,
      conv3d,
      conv3dTranspose,
      cos,
      cosh,
      cosineWindow,
      cumprod,
      cumsum,
      denseBincount,
      depthToSpace,
      depthwiseConv2d: depthwiseConv2d$1,
      diag,
      dilation2d,
      div,
      divNoNan,
      dot,
      dropout,
      einsum,
      elu,
      enclosingPowerOfTwo,
      ensureShape,
      equal,
      erf,
      euclideanNorm,
      exp,
      expandDims,
      expm1,
      eye,
      fft,
      fill,
      floor,
      floorDiv,
      fused: fused_ops,
      gather,
      gatherND,
      greater,
      greaterEqual,
      ifft,
      imag,
      image,
      inTopKAsync,
      irfft,
      isFinite: isFinite$1,
      isInf,
      isNaN: isNaN$1,
      leakyRelu,
      less,
      lessEqual,
      linalg,
      linspace,
      localResponseNormalization,
      log,
      log1p,
      logSigmoid,
      logSoftmax,
      logSumExp,
      logicalAnd,
      logicalNot,
      logicalOr,
      logicalXor,
      losses,
      lowerBound,
      matMul: matMul$1,
      max,
      maxPool,
      maxPool3d,
      maxPoolWithArgmax,
      maximum,
      mean,
      meshgrid,
      min,
      minimum,
      mirrorPad,
      mod,
      moments,
      movingAverage,
      mul,
      multiRNNCell,
      multinomial,
      neg,
      norm,
      notEqual,
      oneHot,
      ones,
      onesLike,
      op,
      outerProduct,
      pad,
      pad1d,
      pad2d,
      pad3d,
      pad4d,
      pool,
      pow,
      prelu,
      print,
      prod,
      raggedGather,
      raggedRange,
      raggedTensorToTensor,
      rand,
      randomGamma,
      randomNormal,
      randomStandardNormal,
      randomUniform,
      randomUniformInt,
      range,
      real,
      reciprocal,
      relu,
      relu6,
      reshape,
      reverse,
      reverse1d,
      reverse2d,
      reverse3d,
      reverse4d,
      rfft,
      round,
      rsqrt,
      scalar,
      scatterND,
      searchSorted,
      selu,
      separableConv2d,
      setdiff1dAsync,
      sigmoid,
      sign,
      signal,
      sin,
      sinh,
      slice,
      slice1d,
      slice2d,
      slice3d,
      slice4d,
      softmax,
      softplus,
      spaceToBatchND,
      sparse,
      sparseToDense,
      spectral,
      split: split$1,
      sqrt,
      square,
      squaredDifference,
      squeeze,
      stack,
      step,
      stridedSlice,
      string,
      sub,
      sum,
      tan,
      tanh,
      tensor,
      tensor1d,
      tensor2d,
      tensor3d,
      tensor4d,
      tensor5d,
      tensor6d,
      tensorScatterUpdate,
      tile,
      topk,
      transpose,
      truncatedNormal,
      unique,
      unsortedSegmentSum,
      unstack,
      upperBound,
      variable,
      where,
      whereAsync,
      zeros,
      zerosLike
    };
    var executeOp$k = function(node, tensorMap, context, ops) {
      if (ops === void 0) {
        ops = tfOps;
      }
      switch (node.op) {
        case "BiasAdd":
        case "AddV2":
        case "Add": {
          return [ops.add(getParamValue("a", node, tensorMap, context), getParamValue("b", node, tensorMap, context))];
        }
        case "AddN": {
          return [ops.addN(getParamValue("tensors", node, tensorMap, context))];
        }
        case "FloorMod":
        case "Mod":
          return [ops.mod(getParamValue("a", node, tensorMap, context), getParamValue("b", node, tensorMap, context))];
        case "Mul":
          return [ops.mul(getParamValue("a", node, tensorMap, context), getParamValue("b", node, tensorMap, context))];
        case "RealDiv":
        case "Div": {
          return [ops.div(getParamValue("a", node, tensorMap, context), getParamValue("b", node, tensorMap, context))];
        }
        case "DivNoNan": {
          return [ops.divNoNan(getParamValue("a", node, tensorMap, context), getParamValue("b", node, tensorMap, context))];
        }
        case "FloorDiv": {
          return [ops.floorDiv(getParamValue("a", node, tensorMap, context), getParamValue("b", node, tensorMap, context))];
        }
        case "Sub": {
          return [ops.sub(getParamValue("a", node, tensorMap, context), getParamValue("b", node, tensorMap, context))];
        }
        case "Minimum": {
          return [ops.minimum(getParamValue("a", node, tensorMap, context), getParamValue("b", node, tensorMap, context))];
        }
        case "Maximum": {
          return [ops.maximum(getParamValue("a", node, tensorMap, context), getParamValue("b", node, tensorMap, context))];
        }
        case "Pow": {
          return [ops.pow(getParamValue("a", node, tensorMap, context), getParamValue("b", node, tensorMap, context))];
        }
        case "SquaredDifference": {
          return [ops.squaredDifference(getParamValue("a", node, tensorMap, context), getParamValue("b", node, tensorMap, context))];
        }
        default:
          throw TypeError("Node type ".concat(node.op, " is not implemented"));
      }
    };
    var executeOp$j = function(node, tensorMap, context, ops) {
      if (ops === void 0) {
        ops = tfOps;
      }
      switch (node.op) {
        case "Abs":
        case "ComplexAbs":
          return [ops.abs(getParamValue("x", node, tensorMap, context))];
        case "Acos":
          return [ops.acos(getParamValue("x", node, tensorMap, context))];
        case "Acosh":
          return [ops.acosh(getParamValue("x", node, tensorMap, context))];
        case "Asin":
          return [ops.asin(getParamValue("x", node, tensorMap, context))];
        case "Asinh":
          return [ops.asinh(getParamValue("x", node, tensorMap, context))];
        case "Atan":
          return [ops.atan(getParamValue("x", node, tensorMap, context))];
        case "Atan2":
          return [ops.atan2(getParamValue("x", node, tensorMap, context), getParamValue("y", node, tensorMap, context))];
        case "Atanh":
          return [ops.atanh(getParamValue("x", node, tensorMap, context))];
        case "Ceil":
          return [ops.ceil(getParamValue("x", node, tensorMap, context))];
        case "Complex":
          return [ops.complex(getParamValue("real", node, tensorMap, context), getParamValue("imag", node, tensorMap, context))];
        case "Cos":
          return [ops.cos(getParamValue("x", node, tensorMap, context))];
        case "Cosh":
          return [ops.cosh(getParamValue("x", node, tensorMap, context))];
        case "Elu":
          return [ops.elu(getParamValue("x", node, tensorMap, context))];
        case "Erf":
          return [ops.erf(getParamValue("x", node, tensorMap, context))];
        case "Exp":
          return [ops.exp(getParamValue("x", node, tensorMap, context))];
        case "Expm1": {
          return [ops.expm1(getParamValue("x", node, tensorMap, context))];
        }
        case "Floor":
          return [ops.floor(getParamValue("x", node, tensorMap, context))];
        case "Log":
          return [ops.log(getParamValue("x", node, tensorMap, context))];
        case "Log1p": {
          return [ops.log1p(getParamValue("x", node, tensorMap, context))];
        }
        case "Imag":
          return [ops.imag(getParamValue("x", node, tensorMap, context))];
        case "Neg":
          return [ops.neg(getParamValue("x", node, tensorMap, context))];
        case "Reciprocal": {
          return [ops.reciprocal(getParamValue("x", node, tensorMap, context))];
        }
        case "Real":
          return [ops.real(getParamValue("x", node, tensorMap, context))];
        case "Relu":
          return [ops.relu(getParamValue("x", node, tensorMap, context))];
        case "Round": {
          return [ops.round(getParamValue("x", node, tensorMap, context))];
        }
        case "Selu":
          return [ops.selu(getParamValue("x", node, tensorMap, context))];
        case "Sigmoid":
          return [ops.sigmoid(getParamValue("x", node, tensorMap, context))];
        case "Sin":
          return [ops.sin(getParamValue("x", node, tensorMap, context))];
        case "Sign": {
          return [ops.sign(getParamValue("x", node, tensorMap, context))];
        }
        case "Sinh": {
          return [ops.sinh(getParamValue("x", node, tensorMap, context))];
        }
        case "Softplus": {
          return [ops.softplus(getParamValue("x", node, tensorMap, context))];
        }
        case "Sqrt": {
          return [ops.sqrt(getParamValue("x", node, tensorMap, context))];
        }
        case "Square": {
          return [ops.square(getParamValue("x", node, tensorMap, context))];
        }
        case "Tanh": {
          return [ops.tanh(getParamValue("x", node, tensorMap, context))];
        }
        case "Tan":
          return [ops.tan(getParamValue("x", node, tensorMap, context))];
        case "ClipByValue":
          return [ops.clipByValue(getParamValue("x", node, tensorMap, context), getParamValue("clipValueMin", node, tensorMap, context), getParamValue("clipValueMax", node, tensorMap, context))];
        case "Relu6":
          return [ops.relu6(getParamValue("x", node, tensorMap, context))];
        case "Rsqrt":
          return [ops.rsqrt(getTensor(node.inputNames[0], tensorMap, context))];
        case "LeakyRelu":
          return [ops.leakyRelu(getParamValue("x", node, tensorMap, context), getParamValue("alpha", node, tensorMap, context))];
        case "Prelu":
          return [ops.prelu(getParamValue("x", node, tensorMap, context), getParamValue("alpha", node, tensorMap, context))];
        case "IsNan":
          return [ops.isNaN(getTensor(node.inputNames[0], tensorMap, context))];
        case "IsInf":
          return [ops.isInf(getTensor(node.inputNames[0], tensorMap, context))];
        case "IsFinite":
          return [ops.isFinite(getTensor(node.inputNames[0], tensorMap, context))];
        default:
          throw TypeError("Node type ".concat(node.op, " is not implemented"));
      }
    };
    function assertShapesMatchAllowUndefinedSize(shapeA, shapeB, errorMessagePrefix) {
      if (errorMessagePrefix === void 0) {
        errorMessagePrefix = "";
      }
      if (typeof shapeA === "number" || typeof shapeB === "number") {
        return;
      }
      tfc.util.assert(shapeA.length === shapeB.length, function() {
        return errorMessagePrefix + " Shapes ".concat(shapeA, " and ").concat(shapeB, " must match");
      });
      for (var i = 0; i < shapeA.length; i++) {
        var dim0 = shapeA[i];
        var dim1 = shapeB[i];
        tfc.util.assert(dim0 < 0 || dim1 < 0 || dim0 === dim1, function() {
          return errorMessagePrefix + " Shapes ".concat(shapeA, " and ").concat(shapeB, " must match");
        });
      }
    }
    function fullDefinedShape(elementShape) {
      if (typeof elementShape === "number" || elementShape.some(function(dim) {
        return dim < 0;
      })) {
        return false;
      }
      return true;
    }
    function inferElementShape(listElementShape, tensors, elementShape) {
      var partialShape = mergeElementShape(listElementShape, elementShape);
      var notfullDefinedShape = !fullDefinedShape(partialShape);
      if (notfullDefinedShape && tensors.length === 0) {
        throw new Error("Tried to calculate elements of an empty list" + " with non-fully-defined elementShape: ".concat(partialShape));
      }
      if (notfullDefinedShape) {
        tensors.forEach(function(tensor2) {
          partialShape = mergeElementShape(tensor2.shape, partialShape);
        });
      }
      if (!fullDefinedShape(partialShape)) {
        throw new Error("Non-fully-defined elementShape: ".concat(partialShape));
      }
      return partialShape;
    }
    function mergeElementShape(elementShapeA, elementShapeB) {
      if (typeof elementShapeA === "number") {
        return elementShapeB;
      }
      if (typeof elementShapeB === "number") {
        return elementShapeA;
      }
      if (elementShapeA.length !== elementShapeB.length) {
        throw new Error("Incompatible ranks during merge: ".concat(elementShapeA, " vs. ").concat(elementShapeB));
      }
      var result = [];
      for (var i = 0; i < elementShapeA.length; ++i) {
        var dim0 = elementShapeA[i];
        var dim1 = elementShapeB[i];
        if (dim0 >= 0 && dim1 >= 0 && dim0 !== dim1) {
          throw new Error("Incompatible shape during merge: ".concat(elementShapeA, " vs. ").concat(elementShapeB));
        }
        result[i] = dim0 >= 0 ? dim0 : dim1;
      }
      return result;
    }
    var TensorArray = (
      /** @class */
      function() {
        function TensorArray2(name, dtype, maxSize, elementShape, identicalElementShapes, dynamicSize, clearAfterRead) {
          this.name = name;
          this.dtype = dtype;
          this.maxSize = maxSize;
          this.elementShape = elementShape;
          this.identicalElementShapes = identicalElementShapes;
          this.dynamicSize = dynamicSize;
          this.clearAfterRead = clearAfterRead;
          this.tensors = [];
          this.closed_ = false;
          this.idTensor = tfc.scalar(0);
          tfc.keep(this.idTensor);
        }
        Object.defineProperty(TensorArray2.prototype, "id", {
          get: function() {
            return this.idTensor.id;
          },
          enumerable: false,
          configurable: true
        });
        Object.defineProperty(TensorArray2.prototype, "closed", {
          get: function() {
            return this.closed_;
          },
          enumerable: false,
          configurable: true
        });
        TensorArray2.prototype.clearAndClose = function(keepIds) {
          this.tensors.forEach(function(tensor2) {
            if (keepIds == null || !keepIds.has(tensor2.tensor.id)) {
              tensor2.tensor.dispose();
            }
          });
          this.tensors = [];
          this.closed_ = true;
          this.idTensor.dispose();
        };
        TensorArray2.prototype.size = function() {
          return this.tensors.length;
        };
        TensorArray2.prototype.read = function(index) {
          if (this.closed_) {
            throw new Error("TensorArray ".concat(this.name, " has already been closed."));
          }
          if (index < 0 || index >= this.size()) {
            throw new Error("Tried to read from index ".concat(index, ", but array size is: ").concat(this.size()));
          }
          var tensorWithState = this.tensors[index];
          if (tensorWithState.cleared) {
            throw new Error("TensorArray ".concat(this.name, ": Could not read index ").concat(index, " twice because it was cleared after a previous read ") + "(perhaps try setting clear_after_read = false?).");
          }
          if (this.clearAfterRead) {
            tensorWithState.cleared = true;
          }
          tensorWithState.read = true;
          return tensorWithState.tensor;
        };
        TensorArray2.prototype.readMany = function(indices) {
          var _this = this;
          return indices.map(function(index) {
            return _this.read(index);
          });
        };
        TensorArray2.prototype.write = function(index, tensor2) {
          if (this.closed_) {
            throw new Error("TensorArray ".concat(this.name, " has already been closed."));
          }
          if (index < 0 || !this.dynamicSize && index >= this.maxSize) {
            throw new Error("Tried to write to index ".concat(index, ", but array is not resizeable and size is: ").concat(this.maxSize));
          }
          var t = this.tensors[index] || {};
          if (tensor2.dtype !== this.dtype) {
            throw new Error("TensorArray ".concat(this.name, ": Could not write to TensorArray index ").concat(index, ",\n          because the value dtype is ").concat(tensor2.dtype, ", but TensorArray dtype is ").concat(this.dtype, "."));
          }
          if (this.size() === 0 && (this.elementShape == null || this.elementShape.length === 0)) {
            this.elementShape = tensor2.shape;
          }
          assertShapesMatchAllowUndefinedSize(this.elementShape, tensor2.shape, "TensorArray ".concat(this.name, ": Could not write to TensorArray index ").concat(index, "."));
          if (t.read) {
            throw new Error("TensorArray ".concat(this.name, ": Could not write to TensorArray index ").concat(index, ", because it has already been read."));
          }
          if (t.written) {
            throw new Error("TensorArray ".concat(this.name, ": Could not write to TensorArray index ").concat(index, ", because it has already been written."));
          }
          t.tensor = tensor2;
          tfc.keep(tensor2);
          t.written = true;
          this.tensors[index] = t;
        };
        TensorArray2.prototype.writeMany = function(indices, tensors) {
          var _this = this;
          if (indices.length !== tensors.length) {
            throw new Error("TensorArray ".concat(this.name, ": could not write multiple tensors,") + "because the index size: ".concat(indices.length, " is not the same as tensors size: ").concat(tensors.length, "."));
          }
          indices.forEach(function(i, index) {
            return _this.write(i, tensors[index]);
          });
        };
        TensorArray2.prototype.gather = function(indices, dtype) {
          if (!!dtype && dtype !== this.dtype) {
            throw new Error("TensorArray dtype is ".concat(this.dtype, " but gather requested dtype ").concat(dtype));
          }
          if (!indices) {
            indices = [];
            for (var i = 0; i < this.size(); i++) {
              indices.push(i);
            }
          } else {
            indices = indices.slice(0, this.size());
          }
          if (indices.length === 0) {
            return tfc.tensor([], [0].concat(this.elementShape));
          }
          var tensors = this.readMany(indices);
          assertShapesMatchAllowUndefinedSize(this.elementShape, tensors[0].shape, "TensorArray shape mismatch: ");
          return tfc.stack(tensors, 0);
        };
        TensorArray2.prototype.concat = function(dtype) {
          if (!!dtype && dtype !== this.dtype) {
            throw new Error("TensorArray dtype is ".concat(this.dtype, " but concat requested dtype ").concat(dtype));
          }
          if (this.size() === 0) {
            return tfc.tensor([], [0].concat(this.elementShape));
          }
          var indices = [];
          for (var i = 0; i < this.size(); i++) {
            indices.push(i);
          }
          var tensors = this.readMany(indices);
          assertShapesMatchAllowUndefinedSize(this.elementShape, tensors[0].shape, "TensorArray shape mismatch: tensor array shape (".concat(this.elementShape, ") vs first tensor shape (").concat(tensors[0].shape, ")"));
          return tfc.concat(tensors, 0);
        };
        TensorArray2.prototype.scatter = function(indices, tensor2) {
          if (tensor2.dtype !== this.dtype) {
            throw new Error("TensorArray dtype is ".concat(this.dtype, " but tensor has dtype ").concat(tensor2.dtype));
          }
          if (indices.length !== tensor2.shape[0]) {
            throw new Error("Expected len(indices) == tensor.shape[0], but saw: ".concat(indices.length, " vs. ").concat(tensor2.shape[0]));
          }
          var maxIndex = Math.max.apply(Math, __spreadArray([], __read(indices), false));
          if (!this.dynamicSize && maxIndex >= this.maxSize) {
            throw new Error("Max index must be < array size (".concat(maxIndex, "  vs. ").concat(this.maxSize, ")"));
          }
          this.writeMany(indices, tfc.unstack(tensor2, 0));
        };
        TensorArray2.prototype.split = function(length, tensor2) {
          var _this = this;
          if (tensor2.dtype !== this.dtype) {
            throw new Error("TensorArray dtype is ".concat(this.dtype, " but tensor has dtype ").concat(tensor2.dtype));
          }
          var totalLength = 0;
          var cumulativeLengths = length.map(function(len) {
            totalLength += len;
            return totalLength;
          });
          if (totalLength !== tensor2.shape[0]) {
            throw new Error("Expected sum of lengths to be equal to\n          tensor.shape[0], but sum of lengths is\n        ".concat(totalLength, ", and tensor's shape is: ").concat(tensor2.shape));
          }
          if (!this.dynamicSize && length.length !== this.maxSize) {
            throw new Error("TensorArray's size is not equal to the size of lengths (".concat(this.maxSize, " vs. ").concat(length.length, "), ") + "and the TensorArray is not marked as dynamically resizeable");
          }
          var elementPerRow = totalLength === 0 ? 0 : tensor2.size / totalLength;
          var tensors = [];
          tfc.tidy(function() {
            tensor2 = tfc.reshape(tensor2, [1, totalLength, elementPerRow]);
            for (var i2 = 0; i2 < length.length; ++i2) {
              var previousLength = i2 === 0 ? 0 : cumulativeLengths[i2 - 1];
              var indices_1 = [0, previousLength, 0];
              var sizes = [1, length[i2], elementPerRow];
              tensors[i2] = tfc.reshape(tfc.slice(tensor2, indices_1, sizes), _this.elementShape);
            }
            return tensors;
          });
          var indices = [];
          for (var i = 0; i < length.length; i++) {
            indices[i] = i;
          }
          this.writeMany(indices, tensors);
        };
        return TensorArray2;
      }()
    );
    var TensorList = (
      /** @class */
      function() {
        function TensorList2(tensors, elementShape, elementDtype, maxNumElements) {
          if (maxNumElements === void 0) {
            maxNumElements = -1;
          }
          this.tensors = tensors;
          this.elementShape = elementShape;
          this.elementDtype = elementDtype;
          if (tensors != null) {
            tensors.forEach(function(tensor2) {
              if (elementDtype !== tensor2.dtype) {
                throw new Error("Invalid data types; op elements ".concat(elementDtype, ", but list elements ").concat(tensor2.dtype));
              }
              assertShapesMatchAllowUndefinedSize(elementShape, tensor2.shape, "TensorList shape mismatch: ");
              tfc.keep(tensor2);
            });
          }
          this.idTensor = tfc.scalar(0);
          this.maxNumElements = maxNumElements;
          tfc.keep(this.idTensor);
        }
        Object.defineProperty(TensorList2.prototype, "id", {
          get: function() {
            return this.idTensor.id;
          },
          enumerable: false,
          configurable: true
        });
        TensorList2.prototype.copy = function() {
          return new TensorList2(__spreadArray([], __read(this.tensors), false), this.elementShape, this.elementDtype);
        };
        TensorList2.prototype.clearAndClose = function(keepIds) {
          this.tensors.forEach(function(tensor2) {
            if (keepIds == null || !keepIds.has(tensor2.id)) {
              tensor2.dispose();
            }
          });
          this.tensors.length = 0;
          this.idTensor.dispose();
        };
        TensorList2.prototype.size = function() {
          return this.tensors.length;
        };
        TensorList2.prototype.stack = function(elementShape, elementDtype, numElements) {
          var _this = this;
          if (numElements === void 0) {
            numElements = -1;
          }
          if (elementDtype !== this.elementDtype) {
            throw new Error("Invalid data types; op elements ".concat(elementDtype, ", but list elements ").concat(this.elementDtype));
          }
          if (numElements !== -1 && this.tensors.length !== numElements) {
            throw new Error("Operation expected a list with ".concat(numElements, " elements but got a list with ").concat(this.tensors.length, " elements."));
          }
          assertShapesMatchAllowUndefinedSize(elementShape, this.elementShape, "TensorList shape mismatch: ");
          var outputElementShape = inferElementShape(this.elementShape, this.tensors, elementShape);
          return tfc.tidy(function() {
            var reshapedTensors = _this.tensors.map(function(tensor2) {
              return tfc.reshape(tensor2, outputElementShape);
            });
            return tfc.stack(reshapedTensors, 0);
          });
        };
        TensorList2.prototype.popBack = function(elementShape, elementDtype) {
          if (elementDtype !== this.elementDtype) {
            throw new Error("Invalid data types; op elements ".concat(elementDtype, ", but list elements ").concat(this.elementDtype));
          }
          if (this.size() === 0) {
            throw new Error("Trying to pop from an empty list.");
          }
          var outputElementShape = inferElementShape(this.elementShape, this.tensors, elementShape);
          var tensor2 = this.tensors.pop();
          tensor2.kept = false;
          assertShapesMatchAllowUndefinedSize(tensor2.shape, elementShape, "TensorList shape mismatch: ");
          return tfc.reshape(tensor2, outputElementShape);
        };
        TensorList2.prototype.pushBack = function(tensor2) {
          if (tensor2.dtype !== this.elementDtype) {
            throw new Error("Invalid data types; op elements ".concat(tensor2.dtype, ", but list elements ").concat(this.elementDtype));
          }
          assertShapesMatchAllowUndefinedSize(tensor2.shape, this.elementShape, "TensorList shape mismatch: ");
          if (this.maxNumElements === this.size()) {
            throw new Error("Trying to push element into a full list.");
          }
          tfc.keep(tensor2);
          this.tensors.push(tensor2);
        };
        TensorList2.prototype.resize = function(size) {
          if (size < 0) {
            throw new Error("TensorListResize expects size to be non-negative. Got: ".concat(size));
          }
          if (this.maxNumElements !== -1 && size > this.maxNumElements) {
            throw new Error("TensorListResize input size ".concat(size, " is greater maxNumElement ").concat(this.maxNumElements, "."));
          }
          var destTensorList = new TensorList2([], this.elementShape, this.elementDtype, this.maxNumElements);
          destTensorList.tensors.length = size;
          for (var i = 0; i < Math.min(this.tensors.length, size); ++i) {
            destTensorList.tensors[i] = this.tensors[i];
          }
          return destTensorList;
        };
        TensorList2.prototype.getItem = function(elementIndex, elementShape, elementDtype) {
          if (elementDtype !== this.elementDtype) {
            throw new Error("Invalid data types; op elements ".concat(elementDtype, ", but list elements ").concat(this.elementDtype));
          }
          if (elementIndex < 0 || elementIndex > this.tensors.length) {
            throw new Error("Trying to access element ".concat(elementIndex, " in a list with ").concat(this.tensors.length, " elements."));
          }
          if (this.tensors[elementIndex] == null) {
            throw new Error("element at index ".concat(elementIndex, " is null."));
          }
          assertShapesMatchAllowUndefinedSize(this.tensors[elementIndex].shape, elementShape, "TensorList shape mismatch: ");
          var outputElementShape = inferElementShape(this.elementShape, this.tensors, elementShape);
          return tfc.reshape(this.tensors[elementIndex], outputElementShape);
        };
        TensorList2.prototype.setItem = function(elementIndex, tensor2) {
          if (tensor2.dtype !== this.elementDtype) {
            throw new Error("Invalid data types; op elements ".concat(tensor2.dtype, ", but list elements ").concat(this.elementDtype));
          }
          if (elementIndex < 0 || this.maxNumElements !== -1 && elementIndex >= this.maxNumElements) {
            throw new Error("Trying to set element ".concat(elementIndex, " in a list with max ").concat(this.maxNumElements, " elements."));
          }
          assertShapesMatchAllowUndefinedSize(this.elementShape, tensor2.shape, "TensorList shape mismatch: ");
          tfc.keep(tensor2);
          if (this.tensors[elementIndex] != null) {
            this.tensors[elementIndex].kept = false;
          }
          this.tensors[elementIndex] = tensor2;
        };
        TensorList2.prototype.gather = function(indices, elementDtype, elementShape) {
          var _this = this;
          if (elementDtype !== this.elementDtype) {
            throw new Error("Invalid data types; op elements ".concat(elementDtype, ", but list elements ").concat(this.elementDtype));
          }
          assertShapesMatchAllowUndefinedSize(this.elementShape, elementShape, "TensorList shape mismatch: ");
          indices = indices.slice(0, this.size());
          var outputElementShape = inferElementShape(this.elementShape, this.tensors, elementShape);
          if (indices.length === 0) {
            return tfc.tensor([], [0].concat(outputElementShape));
          }
          return tfc.tidy(function() {
            var tensors = indices.map(function(i) {
              return tfc.reshape(_this.tensors[i], outputElementShape);
            });
            return tfc.stack(tensors, 0);
          });
        };
        TensorList2.prototype.concat = function(elementDtype, elementShape) {
          var _this = this;
          if (!!elementDtype && elementDtype !== this.elementDtype) {
            throw new Error("TensorList dtype is ".concat(this.elementDtype, " but concat requested dtype ").concat(elementDtype));
          }
          assertShapesMatchAllowUndefinedSize(this.elementShape, elementShape, "TensorList shape mismatch: ");
          var outputElementShape = inferElementShape(this.elementShape, this.tensors, elementShape);
          if (this.size() === 0) {
            return tfc.tensor([], [0].concat(outputElementShape));
          }
          return tfc.tidy(function() {
            var tensors = _this.tensors.map(function(t) {
              return tfc.reshape(t, outputElementShape);
            });
            return tfc.concat(tensors, 0);
          });
        };
        return TensorList2;
      }()
    );
    function fromTensor(tensor2, elementShape, elementDtype) {
      var dtype = tensor2.dtype;
      if (tensor2.shape.length < 1) {
        throw new Error("Tensor must be at least a vector, but saw shape: ".concat(tensor2.shape));
      }
      if (tensor2.dtype !== elementDtype) {
        throw new Error("Invalid data types; op elements ".concat(tensor2.dtype, ", but list elements ").concat(elementDtype));
      }
      var tensorElementShape = tensor2.shape.slice(1);
      assertShapesMatchAllowUndefinedSize(tensorElementShape, elementShape, "TensorList shape mismatch: ");
      var tensorList = tfc.unstack(tensor2);
      return new TensorList(tensorList, elementShape, dtype);
    }
    function reserve(elementShape, elementDtype, numElements, maxNumElements) {
      return new TensorList([], elementShape, elementDtype, maxNumElements);
    }
    function scatter(tensor2, indices, elementShape, numElements) {
      if (indices.length !== tensor2.shape[0]) {
        throw new Error("Expected len(indices) == tensor.shape[0], but saw: ".concat(indices.length, " vs. ").concat(tensor2.shape[0]));
      }
      var maxIndex = Math.max.apply(Math, __spreadArray([], __read(indices), false));
      if (numElements != null && numElements !== -1 && maxIndex >= numElements) {
        throw new Error("Max index must be < array size (".concat(maxIndex, "  vs. ").concat(numElements, ")"));
      }
      var list = new TensorList([], elementShape, tensor2.dtype, numElements);
      var tensors = tfc.unstack(tensor2, 0);
      indices.forEach(function(value, index) {
        list.setItem(value, tensors[index]);
      });
      return list;
    }
    function split(tensor2, length, elementShape) {
      var totalLength = 0;
      var cumulativeLengths = length.map(function(len) {
        totalLength += len;
        return totalLength;
      });
      if (totalLength !== tensor2.shape[0]) {
        throw new Error("Expected sum of lengths to be equal to\n          tensor.shape[0], but sum of lengths is\n        ".concat(totalLength, ", and tensor's shape is: ").concat(tensor2.shape));
      }
      var shapeWithoutFirstDim = tensor2.shape.slice(1);
      var outputElementShape = mergeElementShape(shapeWithoutFirstDim, elementShape);
      var elementPerRow = totalLength === 0 ? 0 : tensor2.size / totalLength;
      var tensors = tfc.tidy(function() {
        var tensors2 = [];
        tensor2 = tfc.reshape(tensor2, [1, totalLength, elementPerRow]);
        for (var i2 = 0; i2 < length.length; ++i2) {
          var previousLength = i2 === 0 ? 0 : cumulativeLengths[i2 - 1];
          var indices = [0, previousLength, 0];
          var sizes = [1, length[i2], elementPerRow];
          tensors2[i2] = tfc.reshape(tfc.slice(tensor2, indices, sizes), outputElementShape);
        }
        tensor2.dispose();
        return tensors2;
      });
      var list = new TensorList([], elementShape, tensor2.dtype, length.length);
      for (var i = 0; i < tensors.length; i++) {
        list.setItem(i, tensors[i]);
      }
      return list;
    }
    var executeOp$i = function(node, tensorMap, context) {
      return __awaiter(void 0, void 0, void 0, function() {
        var _a, thenFunc, elseFunc, cond, args, condValue, bodyFunc, condFunc, args, condResult, argIds_1, condValue, result, _loop_1, pred, pred, data, inputName, data, frameId, data, data, data, size, dtype, elementShape, dynamicSize, clearAfterRead, identicalElementShapes, name, tensorArray, id, index, writeTensor, writeTensorArray, readId, readIndex, readTensorArray, gatherId, gatherIndices, gatherDtype, gatherTensorArray, scatterId, scatterIndices, scatterTensor, scatterTensorArray, concatId, concatTensorArray, concatDtype, splitId, splitTensor, lengths, splitTensorArray, sizeId, sizeTensorArray, closeId, closeTensorArray, idTensor, index, writeTensor, tensorList, idTensor, readIndex, elementShape, elementDType, tensorList, scatterIndices, scatterTensor, elementShape, numElements, tensorList, elementShape, elementDtype, numElementsParam, numElements, maxNumElements, tensorList, gatherId, gatherIndices, elementShape, elementDtype, tensorList, idTensor, elementShape, elementDtype, numElements, tensorList, tensor2, elementShape, elementDtype, tensorList, concatId, tensorList, concatDtype, elementShape, idTensor, writeTensor, tensorList, idTensor, elementShape, elementDType, tensorList, splitTensor, elementShape, lengths, tensorList, idTensor, tensorList, idTensor, size, srcTensorList, destTensorList;
        return __generator(this, function(_b) {
          switch (_b.label) {
            case 0:
              _a = node.op;
              switch (_a) {
                case "If":
                  return [3, 1];
                case "StatelessIf":
                  return [3, 1];
                case "While":
                  return [3, 3];
                case "StatelessWhile":
                  return [3, 3];
                case "LoopCond":
                  return [3, 9];
                case "Switch":
                  return [3, 10];
                case "Merge":
                  return [3, 12];
                case "Enter":
                  return [3, 13];
                case "Exit":
                  return [3, 14];
                case "NextIteration":
                  return [3, 15];
                case "TensorArrayV3":
                  return [3, 16];
                case "TensorArrayWriteV3":
                  return [3, 17];
                case "TensorArrayReadV3":
                  return [3, 18];
                case "TensorArrayGatherV3":
                  return [3, 19];
                case "TensorArrayScatterV3":
                  return [3, 20];
                case "TensorArrayConcatV3":
                  return [3, 21];
                case "TensorArraySplitV3":
                  return [3, 22];
                case "TensorArraySizeV3":
                  return [3, 23];
                case "TensorArrayCloseV3":
                  return [3, 24];
                case "TensorListSetItem":
                  return [3, 25];
                case "TensorListGetItem":
                  return [3, 26];
                case "TensorListScatterV2":
                  return [3, 27];
                case "TensorListScatter":
                  return [3, 27];
                case "TensorListReserve":
                  return [3, 28];
                case "EmptyTensorList":
                  return [3, 28];
                case "TensorListGather":
                  return [3, 29];
                case "TensorListStack":
                  return [3, 30];
                case "TensorListFromTensor":
                  return [3, 31];
                case "TensorListConcat":
                  return [3, 32];
                case "TensorListConcatV2":
                  return [3, 32];
                case "TensorListPushBack":
                  return [3, 33];
                case "TensorListPopBack":
                  return [3, 34];
                case "TensorListSplit":
                  return [3, 35];
                case "TensorListLength":
                  return [3, 36];
                case "TensorListResize":
                  return [3, 37];
              }
              return [3, 38];
            case 1:
              thenFunc = getParamValue("thenBranch", node, tensorMap, context);
              elseFunc = getParamValue("elseBranch", node, tensorMap, context);
              cond = getParamValue("cond", node, tensorMap, context);
              args = getParamValue("args", node, tensorMap, context);
              return [4, cond.data()];
            case 2:
              condValue = _b.sent();
              if (condValue[0]) {
                return [2, context.functionMap[thenFunc].executeFunctionAsync(args, context.tensorArrayMap, context.tensorListMap)];
              } else {
                return [2, context.functionMap[elseFunc].executeFunctionAsync(args, context.tensorArrayMap, context.tensorListMap)];
              }
            case 3:
              bodyFunc = getParamValue("body", node, tensorMap, context);
              condFunc = getParamValue("cond", node, tensorMap, context);
              args = getParamValue("args", node, tensorMap, context);
              return [4, context.functionMap[condFunc].executeFunctionAsync(args, context.tensorArrayMap, context.tensorListMap)];
            case 4:
              condResult = _b.sent();
              argIds_1 = args.map(function(tensor3) {
                return tensor3.id;
              });
              return [4, condResult[0].data()];
            case 5:
              condValue = _b.sent();
              condResult.forEach(function(tensor3) {
                if (!tensor3.kept && argIds_1.indexOf(tensor3.id) === -1) {
                  tensor3.dispose();
                }
              });
              result = args;
              _loop_1 = function() {
                var origResult, resultIds, condResult_1;
                return __generator(this, function(_c) {
                  switch (_c.label) {
                    case 0:
                      origResult = result;
                      return [4, context.functionMap[bodyFunc].executeFunctionAsync(result, context.tensorArrayMap, context.tensorListMap)];
                    case 1:
                      result = _c.sent();
                      resultIds = result.map(function(tensor3) {
                        return tensor3.id;
                      });
                      origResult.forEach(function(tensor3) {
                        if (!tensor3.kept && argIds_1.indexOf(tensor3.id) === -1 && resultIds.indexOf(tensor3.id) === -1) {
                          tensor3.dispose();
                        }
                      });
                      return [4, context.functionMap[condFunc].executeFunctionAsync(result, context.tensorArrayMap, context.tensorListMap)];
                    case 2:
                      condResult_1 = _c.sent();
                      return [4, condResult_1[0].data()];
                    case 3:
                      condValue = _c.sent();
                      condResult_1.forEach(function(tensor3) {
                        if (!tensor3.kept && argIds_1.indexOf(tensor3.id) === -1 && resultIds.indexOf(tensor3.id) === -1) {
                          tensor3.dispose();
                        }
                      });
                      return [
                        2
                        /*return*/
                      ];
                  }
                });
              };
              _b.label = 6;
            case 6:
              if (!condValue[0])
                return [3, 8];
              return [5, _loop_1()];
            case 7:
              _b.sent();
              return [3, 6];
            case 8:
              return [2, result];
            case 9: {
              pred = getParamValue("pred", node, tensorMap, context);
              return [2, [cloneTensor(pred)]];
            }
            case 10:
              pred = getParamValue("pred", node, tensorMap, context);
              data = getParamValue("data", node, tensorMap, context);
              if (!data.kept) {
                data = cloneTensor(data);
              }
              return [4, pred.data()];
            case 11:
              return [2, _b.sent()[0] ? [void 0, data] : [data, void 0]];
            case 12: {
              inputName = node.inputNames.find(function(name2) {
                return getTensor(name2, tensorMap, context) !== void 0;
              });
              if (inputName) {
                data = getTensor(inputName, tensorMap, context);
                return [2, [cloneTensor(data)]];
              }
              return [2, void 0];
            }
            case 13: {
              frameId = getParamValue("frameName", node, tensorMap, context);
              data = getParamValue("tensor", node, tensorMap, context);
              context.enterFrame(frameId);
              return [2, [cloneTensor(data)]];
            }
            case 14: {
              data = getParamValue("tensor", node, tensorMap, context);
              context.exitFrame();
              return [2, [cloneTensor(data)]];
            }
            case 15: {
              data = getParamValue("tensor", node, tensorMap, context);
              context.nextIteration();
              return [2, [cloneTensor(data)]];
            }
            case 16: {
              size = getParamValue("size", node, tensorMap, context);
              dtype = getParamValue("dtype", node, tensorMap, context);
              elementShape = getParamValue("elementShape", node, tensorMap, context);
              dynamicSize = getParamValue("dynamicSize", node, tensorMap, context);
              clearAfterRead = getParamValue("clearAfterRead", node, tensorMap, context);
              identicalElementShapes = getParamValue("identicalElementShapes", node, tensorMap, context);
              name = getParamValue("name", node, tensorMap, context);
              tensorArray = new TensorArray(name, dtype, size, elementShape, identicalElementShapes, dynamicSize, clearAfterRead);
              context.addTensorArray(tensorArray);
              return [2, [tensorArray.idTensor, tfc.scalar(1)]];
            }
            case 17: {
              id = getParamValue("tensorArrayId", node, tensorMap, context);
              index = getParamValue("index", node, tensorMap, context);
              writeTensor = getParamValue("tensor", node, tensorMap, context);
              writeTensorArray = context.getTensorArray(id.id);
              writeTensorArray.write(index, writeTensor);
              return [2, [writeTensorArray.idTensor]];
            }
            case 18: {
              readId = getParamValue("tensorArrayId", node, tensorMap, context);
              readIndex = getParamValue("index", node, tensorMap, context);
              readTensorArray = context.getTensorArray(readId.id);
              return [2, [readTensorArray.read(readIndex)]];
            }
            case 19: {
              gatherId = getParamValue("tensorArrayId", node, tensorMap, context);
              gatherIndices = getParamValue("indices", node, tensorMap, context);
              gatherDtype = getParamValue("dtype", node, tensorMap, context);
              gatherTensorArray = context.getTensorArray(gatherId.id);
              return [2, [gatherTensorArray.gather(gatherIndices, gatherDtype)]];
            }
            case 20: {
              scatterId = getParamValue("tensorArrayId", node, tensorMap, context);
              scatterIndices = getParamValue("indices", node, tensorMap, context);
              scatterTensor = getParamValue("tensor", node, tensorMap, context);
              scatterTensorArray = context.getTensorArray(scatterId.id);
              scatterTensorArray.scatter(scatterIndices, scatterTensor);
              return [2, [scatterTensorArray.idTensor]];
            }
            case 21: {
              concatId = getParamValue("tensorArrayId", node, tensorMap, context);
              concatTensorArray = context.getTensorArray(concatId.id);
              concatDtype = getParamValue("dtype", node, tensorMap, context);
              return [2, [concatTensorArray.concat(concatDtype)]];
            }
            case 22: {
              splitId = getParamValue("tensorArrayId", node, tensorMap, context);
              splitTensor = getParamValue("tensor", node, tensorMap, context);
              lengths = getParamValue("lengths", node, tensorMap, context);
              splitTensorArray = context.getTensorArray(splitId.id);
              splitTensorArray.split(lengths, splitTensor);
              return [2, [splitTensorArray.idTensor]];
            }
            case 23: {
              sizeId = getParamValue("tensorArrayId", node, tensorMap, context);
              sizeTensorArray = context.getTensorArray(sizeId.id);
              return [2, [tfc.scalar(sizeTensorArray.size(), "int32")]];
            }
            case 24: {
              closeId = getParamValue("tensorArrayId", node, tensorMap, context);
              closeTensorArray = context.getTensorArray(closeId.id);
              closeTensorArray.clearAndClose();
              return [2, [closeTensorArray.idTensor]];
            }
            case 25: {
              idTensor = getParamValue("tensorListId", node, tensorMap, context);
              index = getParamValue("index", node, tensorMap, context);
              writeTensor = getParamValue("tensor", node, tensorMap, context);
              tensorList = context.getTensorList(idTensor.id);
              tensorList.setItem(index, writeTensor);
              return [2, [tensorList.idTensor]];
            }
            case 26: {
              idTensor = getParamValue("tensorListId", node, tensorMap, context);
              readIndex = getParamValue("index", node, tensorMap, context);
              elementShape = getParamValue("elementShape", node, tensorMap, context);
              elementDType = getParamValue("elementDType", node, tensorMap, context);
              tensorList = context.getTensorList(idTensor.id);
              return [2, [tensorList.getItem(readIndex, elementShape, elementDType)]];
            }
            case 27: {
              scatterIndices = getParamValue("indices", node, tensorMap, context);
              scatterTensor = getParamValue("tensor", node, tensorMap, context);
              elementShape = getParamValue("elementShape", node, tensorMap, context);
              numElements = getParamValue("numElements", node, tensorMap, context);
              tensorList = scatter(scatterTensor, scatterIndices, elementShape, numElements);
              context.addTensorList(tensorList);
              return [2, [tensorList.idTensor]];
            }
            case 28: {
              elementShape = getParamValue("elementShape", node, tensorMap, context);
              elementDtype = getParamValue("elementDType", node, tensorMap, context);
              numElementsParam = void 0;
              if (node.op === "TensorListReserve") {
                numElementsParam = "numElements";
              } else {
                numElementsParam = "maxNumElements";
              }
              numElements = getParamValue(numElementsParam, node, tensorMap, context);
              maxNumElements = node.op === "TensorListReserve" ? -1 : numElements;
              tensorList = reserve(elementShape, elementDtype, numElements, maxNumElements);
              context.addTensorList(tensorList);
              return [2, [tensorList.idTensor]];
            }
            case 29: {
              gatherId = getParamValue("tensorListId", node, tensorMap, context);
              gatherIndices = getParamValue("indices", node, tensorMap, context);
              elementShape = getParamValue("elementShape", node, tensorMap, context);
              elementDtype = getParamValue("elementDType", node, tensorMap, context);
              tensorList = context.getTensorList(gatherId.id);
              return [2, [tensorList.gather(gatherIndices, elementDtype, elementShape)]];
            }
            case 30: {
              idTensor = getParamValue("tensorListId", node, tensorMap, context);
              elementShape = getParamValue("elementShape", node, tensorMap, context);
              elementDtype = getParamValue("elementDType", node, tensorMap, context);
              numElements = getParamValue("numElements", node, tensorMap, context);
              tensorList = context.getTensorList(idTensor.id);
              return [2, [tensorList.stack(elementShape, elementDtype, numElements)]];
            }
            case 31: {
              tensor2 = getParamValue("tensor", node, tensorMap, context);
              elementShape = getParamValue("elementShape", node, tensorMap, context);
              elementDtype = getParamValue("elementDType", node, tensorMap, context);
              tensorList = fromTensor(tensor2, elementShape, elementDtype);
              context.addTensorList(tensorList);
              return [2, [tensorList.idTensor]];
            }
            case 32: {
              concatId = getParamValue("tensorListId", node, tensorMap, context);
              tensorList = context.getTensorList(concatId.id);
              concatDtype = getParamValue("dtype", node, tensorMap, context);
              elementShape = getParamValue("elementShape", node, tensorMap, context);
              return [2, [tensorList.concat(concatDtype, elementShape)]];
            }
            case 33: {
              idTensor = getParamValue("tensorListId", node, tensorMap, context);
              writeTensor = getParamValue("tensor", node, tensorMap, context);
              tensorList = context.getTensorList(idTensor.id);
              tensorList.pushBack(writeTensor);
              return [2, [tensorList.idTensor]];
            }
            case 34: {
              idTensor = getParamValue("tensorListId", node, tensorMap, context);
              elementShape = getParamValue("elementShape", node, tensorMap, context);
              elementDType = getParamValue("elementDType", node, tensorMap, context);
              tensorList = context.getTensorList(idTensor.id);
              return [2, [tensorList.popBack(elementShape, elementDType)]];
            }
            case 35: {
              splitTensor = getParamValue("tensor", node, tensorMap, context);
              elementShape = getParamValue("elementShape", node, tensorMap, context);
              lengths = getParamValue("lengths", node, tensorMap, context);
              tensorList = split(splitTensor, lengths, elementShape);
              context.addTensorList(tensorList);
              return [2, [tensorList.idTensor]];
            }
            case 36: {
              idTensor = getParamValue("tensorListId", node, tensorMap, context);
              tensorList = context.getTensorList(idTensor.id);
              return [2, [tfc.scalar(tensorList.size(), "int32")]];
            }
            case 37: {
              idTensor = getParamValue("tensorListId", node, tensorMap, context);
              size = getParamValue("size", node, tensorMap, context);
              srcTensorList = context.getTensorList(idTensor.id);
              destTensorList = srcTensorList.resize(size);
              context.addTensorList(destTensorList);
              return [2, [destTensorList.idTensor]];
            }
            case 38:
              throw TypeError("Node type ".concat(node.op, " is not implemented"));
          }
        });
      });
    };
    function fusedConvAndDepthWiseParams(node, tensorMap, context) {
      var _a = __read(getParamValue("fusedOps", node, tensorMap, context), 2), extraOp = _a[0], activationFunc = _a[1];
      var isBiasAdd = extraOp === "biasadd";
      var noBiasAdd = !isBiasAdd;
      var isPrelu = activationFunc === "prelu";
      var isBatchNorm = extraOp === "fusedbatchnorm";
      var numArgs = getParamValue("numArgs", node, tensorMap, context);
      if (isBiasAdd) {
        if (isPrelu && numArgs !== 2) {
          throw new Error("FusedConv2d and DepthwiseConv2d with BiasAdd and Prelu must have two extra arguments: bias and alpha.");
        }
        if (!isPrelu && isBiasAdd && numArgs !== 1) {
          throw new Error("FusedConv2d and DepthwiseConv2d with BiasAdd must have one extra argument: bias.");
        }
      }
      if (isBatchNorm) {
        throw new Error("FusedConv2d and DepthwiseConv2d with FusedBatchNorm is not supported");
      }
      var stride = getParamValue("strides", node, tensorMap, context);
      var pad2 = getPadding(node, tensorMap, context);
      var dataFormat = getParamValue("dataFormat", node, tensorMap, context).toUpperCase();
      var dilations = getParamValue("dilations", node, tensorMap, context);
      var _b = __read(getParamValue("args", node, tensorMap, context), 2), biasArg = _b[0], preluArg = _b[1];
      if (noBiasAdd) {
        preluArg = biasArg;
        biasArg = void 0;
      }
      var leakyreluAlpha = getParamValue("leakyreluAlpha", node, tensorMap, context);
      return {
        stride,
        pad: pad2,
        dataFormat,
        dilations,
        biasArg,
        preluArg,
        activationFunc,
        leakyreluAlpha
      };
    }
    var executeOp$h = function(node, tensorMap, context, ops) {
      if (ops === void 0) {
        ops = tfOps;
      }
      switch (node.op) {
        case "Conv1D": {
          var stride = getParamValue("stride", node, tensorMap, context);
          var pad2 = getParamValue("pad", node, tensorMap, context);
          var dataFormat = getParamValue("dataFormat", node, tensorMap, context).toUpperCase();
          var dilation = getParamValue("dilation", node, tensorMap, context);
          return [ops.conv1d(getParamValue("x", node, tensorMap, context), getParamValue("filter", node, tensorMap, context), stride, pad2, dataFormat, dilation)];
        }
        case "Conv2D": {
          var stride = getParamValue("strides", node, tensorMap, context);
          var pad2 = getPadding(node, tensorMap, context);
          var dataFormat = getParamValue("dataFormat", node, tensorMap, context).toUpperCase();
          var dilations = getParamValue("dilations", node, tensorMap, context);
          return [ops.conv2d(getParamValue("x", node, tensorMap, context), getParamValue("filter", node, tensorMap, context), [stride[1], stride[2]], pad2, dataFormat, [dilations[1], dilations[2]])];
        }
        case "_FusedConv2D": {
          var _a = fusedConvAndDepthWiseParams(node, tensorMap, context), stride = _a.stride, pad2 = _a.pad, dataFormat = _a.dataFormat, dilations = _a.dilations, biasArg = _a.biasArg, preluArg = _a.preluArg, activationFunc = _a.activationFunc, leakyreluAlpha = _a.leakyreluAlpha;
          return [ops.fused.conv2d({
            x: getParamValue("x", node, tensorMap, context),
            filter: getParamValue("filter", node, tensorMap, context),
            strides: [stride[1], stride[2]],
            pad: pad2,
            dataFormat,
            dilations: [dilations[1], dilations[2]],
            bias: biasArg,
            activation: activationFunc,
            preluActivationWeights: preluArg,
            leakyreluAlpha
          })];
        }
        case "FusedDepthwiseConv2dNative": {
          var _b = fusedConvAndDepthWiseParams(node, tensorMap, context), stride = _b.stride, pad2 = _b.pad, dataFormat = _b.dataFormat, dilations = _b.dilations, biasArg = _b.biasArg, preluArg = _b.preluArg, activationFunc = _b.activationFunc, leakyreluAlpha = _b.leakyreluAlpha;
          return [ops.fused.depthwiseConv2d({
            x: getParamValue("x", node, tensorMap, context),
            filter: getParamValue("filter", node, tensorMap, context),
            strides: [stride[1], stride[2]],
            pad: pad2,
            dataFormat,
            dilations: [dilations[1], dilations[2]],
            bias: biasArg,
            activation: activationFunc,
            preluActivationWeights: preluArg,
            leakyreluAlpha
          })];
        }
        case "Conv2DBackpropInput":
        case "Conv2dTranspose": {
          var shape = getParamValue("outputShape", node, tensorMap, context);
          var stride = getParamValue("strides", node, tensorMap, context);
          var pad2 = getPadding(node, tensorMap, context);
          return [ops.conv2dTranspose(getParamValue("x", node, tensorMap, context), getParamValue("filter", node, tensorMap, context), shape, [stride[1], stride[2]], pad2)];
        }
        case "DepthwiseConv2dNative":
        case "DepthwiseConv2d": {
          var stride = getParamValue("strides", node, tensorMap, context);
          var pad2 = getPadding(node, tensorMap, context);
          var dilations = getParamValue("dilations", node, tensorMap, context);
          var dataFormat = getParamValue("dataFormat", node, tensorMap, context).toUpperCase();
          return [ops.depthwiseConv2d(getParamValue("input", node, tensorMap, context), getParamValue("filter", node, tensorMap, context), [stride[1], stride[2]], pad2, dataFormat, [dilations[1], dilations[2]])];
        }
        case "Conv3D": {
          var stride = getParamValue("strides", node, tensorMap, context);
          var pad2 = getParamValue("pad", node, tensorMap, context);
          var dataFormat = getParamValue("dataFormat", node, tensorMap, context).toUpperCase();
          var dilations = getParamValue("dilations", node, tensorMap, context);
          return [ops.conv3d(getParamValue("x", node, tensorMap, context), getParamValue("filter", node, tensorMap, context), [stride[1], stride[2], stride[3]], pad2, dataFormat, [dilations[1], dilations[2], dilations[3]])];
        }
        case "AvgPool": {
          var stride = getParamValue("strides", node, tensorMap, context);
          var pad2 = getParamValue("pad", node, tensorMap, context);
          var kernelSize = getParamValue("kernelSize", node, tensorMap, context);
          return [ops.avgPool(getParamValue("x", node, tensorMap, context), [kernelSize[1], kernelSize[2]], [stride[1], stride[2]], pad2)];
        }
        case "MaxPool": {
          var stride = getParamValue("strides", node, tensorMap, context);
          var pad2 = getParamValue("pad", node, tensorMap, context);
          var kernelSize = getParamValue("kernelSize", node, tensorMap, context);
          return [ops.maxPool(getParamValue("x", node, tensorMap, context), [kernelSize[1], kernelSize[2]], [stride[1], stride[2]], pad2)];
        }
        case "MaxPoolWithArgmax": {
          var stride = getParamValue("strides", node, tensorMap, context);
          var pad2 = getParamValue("pad", node, tensorMap, context);
          var kernelSize = getParamValue("kernelSize", node, tensorMap, context);
          var includeBatchInIndex = getParamValue("includeBatchInIndex", node, tensorMap, context);
          var _c = ops.maxPoolWithArgmax(getParamValue("x", node, tensorMap, context), [kernelSize[1], kernelSize[2]], [stride[1], stride[2]], pad2, includeBatchInIndex), result = _c.result, indexes = _c.indexes;
          return [result, indexes];
        }
        case "AvgPool3D": {
          var stride = getParamValue("strides", node, tensorMap, context);
          var pad2 = getParamValue("pad", node, tensorMap, context);
          var kernelSize = getParamValue("kernelSize", node, tensorMap, context);
          return [ops.avgPool3d(getParamValue("x", node, tensorMap, context), [kernelSize[1], kernelSize[2], kernelSize[3]], [stride[1], stride[2], stride[3]], pad2)];
        }
        case "MaxPool3D": {
          var stride = getParamValue("strides", node, tensorMap, context);
          var pad2 = getParamValue("pad", node, tensorMap, context);
          var kernelSize = getParamValue("kernelSize", node, tensorMap, context);
          return [ops.maxPool3d(getParamValue("x", node, tensorMap, context), [kernelSize[1], kernelSize[2], kernelSize[3]], [stride[1], stride[2], stride[3]], pad2)];
        }
        case "Dilation2D": {
          var strides = getParamValue("strides", node, tensorMap, context);
          var pad2 = getParamValue("pad", node, tensorMap, context);
          var dilations = getParamValue("dilations", node, tensorMap, context);
          var strideHeight = strides[1];
          var strideWidth = strides[2];
          var dilationHeight = dilations[1];
          var dilationWidth = dilations[2];
          return [ops.dilation2d(
            getParamValue("x", node, tensorMap, context),
            getParamValue("filter", node, tensorMap, context),
            [strideHeight, strideWidth],
            pad2,
            [dilationHeight, dilationWidth],
            "NHWC"
            /* dataFormat */
          )];
        }
        default:
          throw TypeError("Node type ".concat(node.op, " is not implemented"));
      }
    };
    var executeOp$g = function(node, tensorMap, context, ops) {
      if (ops === void 0) {
        ops = tfOps;
      }
      switch (node.op) {
        case "Fill": {
          var shape = getParamValue("shape", node, tensorMap, context);
          var dtype = getParamValue("dtype", node, tensorMap, context);
          var value = getParamValue("value", node, tensorMap, context);
          return [ops.fill(shape, value, dtype)];
        }
        case "LinSpace": {
          var start = getParamValue("start", node, tensorMap, context);
          var stop = getParamValue("stop", node, tensorMap, context);
          var num = getParamValue("num", node, tensorMap, context);
          return [ops.linspace(start, stop, num)];
        }
        case "Multinomial": {
          var logits = getParamValue("logits", node, tensorMap, context);
          var numSamples = getParamValue("numSamples", node, tensorMap, context);
          var seed = getParamValue("seed", node, tensorMap, context);
          return [ops.multinomial(logits, numSamples, seed)];
        }
        case "OneHot": {
          var indices = getParamValue("indices", node, tensorMap, context);
          var depth = getParamValue("depth", node, tensorMap, context);
          var onValue = getParamValue("onValue", node, tensorMap, context);
          var offValue = getParamValue("offValue", node, tensorMap, context);
          var dtype = getParamValue("dtype", node, tensorMap, context);
          return [ops.oneHot(indices, depth, onValue, offValue, dtype)];
        }
        case "Ones": {
          return [ops.ones(getParamValue("shape", node, tensorMap, context), getParamValue("dtype", node, tensorMap, context))];
        }
        case "OnesLike": {
          return [ops.onesLike(getParamValue("x", node, tensorMap, context))];
        }
        case "RandomStandardNormal": {
          return [ops.randomStandardNormal(getParamValue("shape", node, tensorMap, context), getParamValue("dtype", node, tensorMap, context), getParamValue("seed", node, tensorMap, context))];
        }
        case "RandomUniform": {
          return [ops.randomUniform(
            // tslint:disable-next-line:no-any
            getParamValue("shape", node, tensorMap, context),
            getParamValue("minval", node, tensorMap, context),
            getParamValue("maxval", node, tensorMap, context),
            getParamValue("dtype", node, tensorMap, context)
          )];
        }
        case "RandomUniformInt": {
          return [ops.randomUniformInt(getParamValue("shape", node, tensorMap, context), getParamValue("minval", node, tensorMap, context), getParamValue("maxval", node, tensorMap, context), getParamValue("seed", node, tensorMap, context))];
        }
        case "Range": {
          var start = getParamValue("start", node, tensorMap, context);
          var stop = getParamValue("stop", node, tensorMap, context);
          var step2 = getParamValue("step", node, tensorMap, context);
          return [ops.range(start, stop, step2, getParamValue("dtype", node, tensorMap, context))];
        }
        case "TruncatedNormal": {
          var shape = getParamValue("shape", node, tensorMap, context);
          var mean2 = getParamValue("mean", node, tensorMap, context);
          var stdDev = getParamValue("stdDev", node, tensorMap, context);
          var seed = getParamValue("seed", node, tensorMap, context);
          return [ops.truncatedNormal(shape, mean2, stdDev, getParamValue("dtype", node, tensorMap, context), seed)];
        }
        case "Zeros": {
          return [ops.zeros(getParamValue("shape", node, tensorMap, context), getParamValue("dtype", node, tensorMap, context))];
        }
        case "ZerosLike": {
          return [ops.zerosLike(getParamValue("x", node, tensorMap, context))];
        }
        default:
          throw TypeError("Node type ".concat(node.op, " is not implemented"));
      }
    };
    function nmsParams(node, tensorMap, context) {
      var boxes = getParamValue("boxes", node, tensorMap, context);
      var scores = getParamValue("scores", node, tensorMap, context);
      var maxOutputSize = getParamValue("maxOutputSize", node, tensorMap, context);
      var iouThreshold = getParamValue("iouThreshold", node, tensorMap, context);
      var scoreThreshold = getParamValue("scoreThreshold", node, tensorMap, context);
      var softNmsSigma = getParamValue("softNmsSigma", node, tensorMap, context);
      return {
        boxes,
        scores,
        maxOutputSize,
        iouThreshold,
        scoreThreshold,
        softNmsSigma
      };
    }
    var executeOp$f = function(node, tensorMap, context, resourceManager, ops) {
      if (ops === void 0) {
        ops = tfOps;
      }
      return __awaiter(void 0, void 0, void 0, function() {
        var _a, _b, boxes, scores, maxOutputSize, iouThreshold, scoreThreshold, softNmsSigma, result, _c, boxes, scores, maxOutputSize, iouThreshold, scoreThreshold, padToMaxOutputSize, result, _d, boxes, scores, maxOutputSize, iouThreshold, scoreThreshold, condition, result;
        return __generator(this, function(_e) {
          switch (_e.label) {
            case 0:
              _a = node.op;
              switch (_a) {
                case "NonMaxSuppressionV5":
                  return [3, 1];
                case "NonMaxSuppressionV4":
                  return [3, 3];
                case "NonMaxSuppressionV3":
                  return [3, 5];
                case "NonMaxSuppressionV2":
                  return [3, 5];
                case "Where":
                  return [3, 7];
                case "ListDiff":
                  return [3, 9];
              }
              return [3, 10];
            case 1:
              _b = nmsParams(node, tensorMap, context), boxes = _b.boxes, scores = _b.scores, maxOutputSize = _b.maxOutputSize, iouThreshold = _b.iouThreshold, scoreThreshold = _b.scoreThreshold, softNmsSigma = _b.softNmsSigma;
              return [4, ops.image.nonMaxSuppressionWithScoreAsync(boxes, scores, maxOutputSize, iouThreshold, scoreThreshold, softNmsSigma)];
            case 2:
              result = _e.sent();
              return [2, [result.selectedIndices, result.selectedScores]];
            case 3:
              _c = nmsParams(node, tensorMap, context), boxes = _c.boxes, scores = _c.scores, maxOutputSize = _c.maxOutputSize, iouThreshold = _c.iouThreshold, scoreThreshold = _c.scoreThreshold;
              padToMaxOutputSize = getParamValue("padToMaxOutputSize", node, tensorMap, context);
              return [4, ops.image.nonMaxSuppressionPaddedAsync(boxes, scores, maxOutputSize, iouThreshold, scoreThreshold, padToMaxOutputSize)];
            case 4:
              result = _e.sent();
              return [2, [result.selectedIndices, result.validOutputs]];
            case 5:
              _d = nmsParams(node, tensorMap, context), boxes = _d.boxes, scores = _d.scores, maxOutputSize = _d.maxOutputSize, iouThreshold = _d.iouThreshold, scoreThreshold = _d.scoreThreshold;
              return [4, ops.image.nonMaxSuppressionAsync(boxes, scores, maxOutputSize, iouThreshold, scoreThreshold)];
            case 6:
              return [2, [_e.sent()]];
            case 7:
              condition = ops.cast(getParamValue("condition", node, tensorMap, context), "bool");
              return [4, ops.whereAsync(condition)];
            case 8:
              result = [_e.sent()];
              condition.dispose();
              return [2, result];
            case 9: {
              return [2, ops.setdiff1dAsync(getParamValue("x", node, tensorMap, context), getParamValue("y", node, tensorMap, context))];
            }
            case 10:
              throw TypeError("Node type ".concat(node.op, " is not implemented"));
          }
        });
      });
    };
    var executeOp$e = function(node, tensorMap, context, ops) {
      if (ops === void 0) {
        ops = tfOps;
      }
      switch (node.op) {
        case "LowerBound": {
          var sortedSequence = getParamValue("sortedSequence", node, tensorMap, context);
          var values = getParamValue("values", node, tensorMap, context);
          return [ops.lowerBound(sortedSequence, values)];
        }
        case "TopKV2": {
          var x = getParamValue("x", node, tensorMap, context);
          var k = getParamValue("k", node, tensorMap, context);
          var sorted = getParamValue("sorted", node, tensorMap, context);
          var result = ops.topk(x, k, sorted);
          return [result.values, result.indices];
        }
        case "UpperBound": {
          var sortedSequence = getParamValue("sortedSequence", node, tensorMap, context);
          var values = getParamValue("values", node, tensorMap, context);
          return [ops.upperBound(sortedSequence, values)];
        }
        case "Unique": {
          var x = getParamValue("x", node, tensorMap, context);
          var result = ops.unique(x);
          return [result.values, result.indices];
        }
        case "UniqueV2": {
          var x = getParamValue("x", node, tensorMap, context);
          var axis = getParamValue("axis", node, tensorMap, context);
          var result = ops.unique(x, axis);
          return [result.values, result.indices];
        }
        default:
          throw TypeError("Node type ".concat(node.op, " is not implemented"));
      }
    };
    var executeOp$d = function(node, tensorMap, context, ops) {
      if (ops === void 0) {
        ops = tfOps;
      }
      switch (node.op) {
        case "Const": {
          return tensorMap[node.name];
        }
        case "PlaceholderWithDefault":
          var def = getParamValue("default", node, tensorMap, context);
          return [getTensor(node.name, tensorMap, context) || def];
        case "Placeholder":
          return [getTensor(node.name, tensorMap, context)];
        case "Identity":
        case "StopGradient":
        case "FakeQuantWithMinMaxVars": {
          var data_1 = getParamValue("x", node, tensorMap, context);
          return [cloneTensor(data_1)];
        }
        case "IdentityN":
          return getParamValue("x", node, tensorMap, context).map(function(t) {
            return cloneTensor(t);
          });
        case "Snapshot":
          var snapshot = getParamValue("x", node, tensorMap, context);
          return [cloneTensor(snapshot)];
        case "Shape":
          return [ops.tensor1d(getParamValue("x", node, tensorMap, context).shape, "int32")];
        case "ShapeN":
          return getParamValue("x", node, tensorMap, context).map(function(t) {
            return ops.tensor1d(t.shape);
          });
        case "Size":
          return [ops.scalar(getParamValue("x", node, tensorMap, context).size, "int32")];
        case "Rank":
          return [ops.scalar(getParamValue("x", node, tensorMap, context).rank, "int32")];
        case "NoOp":
          return [ops.scalar(1)];
        case "Print":
          var input = getParamValue("x", node, tensorMap, context);
          var data = getParamValue("data", node, tensorMap, context);
          var message = getParamValue("message", node, tensorMap, context);
          var summarize = getParamValue("summarize", node, tensorMap, context);
          console.warn("The graph has a tf.print() operation,usually used for debugging, which slows down performance.");
          console.log(message);
          for (var i = 0; i < data.length; i++) {
            console.log(Array.prototype.slice.call(data[i].dataSync()).slice(0, summarize));
          }
          return [input];
        default:
          throw TypeError("Node type ".concat(node.op, " is not implemented"));
      }
    };
    var HashTable = (
      /** @class */
      function() {
        function HashTable2(keyDType, valueDType) {
          this.keyDType = keyDType;
          this.valueDType = valueDType;
          this.handle = tfc.scalar(0);
          this.tensorMap = /* @__PURE__ */ new Map();
          tfc.keep(this.handle);
        }
        Object.defineProperty(HashTable2.prototype, "id", {
          get: function() {
            return this.handle.id;
          },
          enumerable: false,
          configurable: true
        });
        HashTable2.prototype.clearAndClose = function() {
          this.tensorMap.forEach(function(value) {
            return value.dispose();
          });
          this.tensorMap.clear();
          this.handle.dispose();
        };
        HashTable2.prototype.size = function() {
          return this.tensorMap.size;
        };
        HashTable2.prototype.tensorSize = function() {
          return scalar(this.size(), "int32");
        };
        HashTable2.prototype.import = function(keys, values) {
          return __awaiter(this, void 0, void 0, function() {
            var $keys;
            var _this = this;
            return __generator(this, function(_a) {
              switch (_a.label) {
                case 0:
                  this.checkKeyAndValueTensor(keys, values);
                  return [4, keys.data()];
                case 1:
                  $keys = _a.sent();
                  this.tensorMap.forEach(function(value) {
                    return value.dispose();
                  });
                  this.tensorMap.clear();
                  return [2, tfc.tidy(function() {
                    var $values = tfc.unstack(values);
                    var keysLength = $keys.length;
                    var valuesLength = $values.length;
                    tfc.util.assert(keysLength === valuesLength, function() {
                      return "The number of elements doesn't match, keys has " + "".concat(keysLength, " elements, the values has ").concat(valuesLength, " ") + "elements.";
                    });
                    for (var i = 0; i < keysLength; i++) {
                      var key = $keys[i];
                      var value = $values[i];
                      tfc.keep(value);
                      _this.tensorMap.set(key, value);
                    }
                    return _this.handle;
                  })];
              }
            });
          });
        };
        HashTable2.prototype.find = function(keys, defaultValue) {
          return __awaiter(this, void 0, void 0, function() {
            var $keys;
            var _this = this;
            return __generator(this, function(_a) {
              switch (_a.label) {
                case 0:
                  this.checkKeyAndValueTensor(keys, defaultValue);
                  return [4, keys.data()];
                case 1:
                  $keys = _a.sent();
                  return [2, tfc.tidy(function() {
                    var result = [];
                    for (var i = 0; i < $keys.length; i++) {
                      var key = $keys[i];
                      var value = _this.findWithDefault(key, defaultValue);
                      result.push(value);
                    }
                    return tfc.stack(result);
                  })];
              }
            });
          });
        };
        HashTable2.prototype.findWithDefault = function(key, defaultValue) {
          var result = this.tensorMap.get(key);
          return result != null ? result : defaultValue;
        };
        HashTable2.prototype.checkKeyAndValueTensor = function(key, value) {
          if (key.dtype !== this.keyDType) {
            throw new Error("Expect key dtype ".concat(this.keyDType, ", but got ") + "".concat(key.dtype));
          }
          if (value.dtype !== this.valueDType) {
            throw new Error("Expect value dtype ".concat(this.valueDType, ", but got ") + "".concat(value.dtype));
          }
        };
        return HashTable2;
      }()
    );
    var executeOp$c = function(node, tensorMap, context, resourceManager) {
      return __awaiter(void 0, void 0, void 0, function() {
        var _a, existingTableHandle, keyDType, valueDType, hashTable2, handle, keys, values, hashTable2, handle, keys, defaultValue, hashTable2, handle, hashTable2;
        return __generator(this, function(_b) {
          switch (_b.label) {
            case 0:
              _a = node.op;
              switch (_a) {
                case "HashTable":
                  return [3, 1];
                case "HashTableV2":
                  return [3, 1];
                case "InitializeTable":
                  return [3, 2];
                case "InitializeTableV2":
                  return [3, 2];
                case "LookupTableImport":
                  return [3, 2];
                case "LookupTableImportV2":
                  return [3, 2];
                case "LookupTableFind":
                  return [3, 4];
                case "LookupTableFindV2":
                  return [3, 4];
                case "LookupTableSize":
                  return [3, 6];
                case "LookupTableSizeV2":
                  return [3, 6];
              }
              return [3, 7];
            case 1: {
              existingTableHandle = resourceManager.getHashTableHandleByName(node.name);
              if (existingTableHandle != null) {
                return [2, [existingTableHandle]];
              } else {
                keyDType = getParamValue("keyDType", node, tensorMap, context);
                valueDType = getParamValue("valueDType", node, tensorMap, context);
                hashTable2 = new HashTable(keyDType, valueDType);
                resourceManager.addHashTable(node.name, hashTable2);
                return [2, [hashTable2.handle]];
              }
            }
            case 2:
              handle = getParamValue("tableHandle", node, tensorMap, context, resourceManager);
              keys = getParamValue("keys", node, tensorMap, context);
              values = getParamValue("values", node, tensorMap, context);
              hashTable2 = resourceManager.getHashTableById(handle.id);
              return [4, hashTable2.import(keys, values)];
            case 3:
              return [2, [_b.sent()]];
            case 4:
              handle = getParamValue("tableHandle", node, tensorMap, context, resourceManager);
              keys = getParamValue("keys", node, tensorMap, context);
              defaultValue = getParamValue("defaultValue", node, tensorMap, context);
              hashTable2 = resourceManager.getHashTableById(handle.id);
              return [4, hashTable2.find(keys, defaultValue)];
            case 5:
              return [2, [_b.sent()]];
            case 6: {
              handle = getParamValue("tableHandle", node, tensorMap, context, resourceManager);
              hashTable2 = resourceManager.getHashTableById(handle.id);
              return [2, [hashTable2.tensorSize()]];
            }
            case 7:
              throw TypeError("Node type ".concat(node.op, " is not implemented"));
          }
        });
      });
    };
    var executeOp$b = function(node, tensorMap, context, ops) {
      if (ops === void 0) {
        ops = tfOps;
      }
      switch (node.op) {
        case "ResizeBilinear": {
          var images = getParamValue("images", node, tensorMap, context);
          var size = getParamValue("size", node, tensorMap, context);
          var alignCorners = getParamValue("alignCorners", node, tensorMap, context);
          var halfPixelCenters = getParamValue("halfPixelCenters", node, tensorMap, context);
          return [ops.image.resizeBilinear(images, [size[0], size[1]], alignCorners, halfPixelCenters)];
        }
        case "ResizeNearestNeighbor": {
          var images = getParamValue("images", node, tensorMap, context);
          var size = getParamValue("size", node, tensorMap, context);
          var alignCorners = getParamValue("alignCorners", node, tensorMap, context);
          var halfPixelCenters = getParamValue("halfPixelCenters", node, tensorMap, context);
          return [ops.image.resizeNearestNeighbor(images, [size[0], size[1]], alignCorners, halfPixelCenters)];
        }
        case "CropAndResize": {
          var image2 = getParamValue("image", node, tensorMap, context);
          var boxes = getParamValue("boxes", node, tensorMap, context);
          var boxInd = getParamValue("boxInd", node, tensorMap, context);
          var cropSize = getParamValue("cropSize", node, tensorMap, context);
          var method = getParamValue("method", node, tensorMap, context);
          var extrapolationValue = getParamValue("extrapolationValue", node, tensorMap, context);
          return [ops.image.cropAndResize(image2, boxes, boxInd, cropSize, method, extrapolationValue)];
        }
        case "ImageProjectiveTransformV3": {
          var images = getParamValue("images", node, tensorMap, context);
          var transforms = getParamValue("transforms", node, tensorMap, context);
          var outputShape = getParamValue("outputShape", node, tensorMap, context);
          var fillValue = getParamValue("fillValue", node, tensorMap, context);
          var interpolation = getParamValue("interpolation", node, tensorMap, context);
          var fillMode = getParamValue("fillMode", node, tensorMap, context);
          return [ops.image.transform(images, transforms, interpolation.toLowerCase(), fillMode.toLowerCase(), fillValue, outputShape)];
        }
        default:
          throw TypeError("Node type ".concat(node.op, " is not implemented"));
      }
    };
    var executeOp$a = function(node, tensorMap, context, ops) {
      if (ops === void 0) {
        ops = tfOps;
      }
      switch (node.op) {
        case "Equal": {
          return [ops.equal(getParamValue("a", node, tensorMap, context), getParamValue("b", node, tensorMap, context))];
        }
        case "NotEqual": {
          return [ops.notEqual(getParamValue("a", node, tensorMap, context), getParamValue("b", node, tensorMap, context))];
        }
        case "Greater": {
          return [ops.greater(getParamValue("a", node, tensorMap, context), getParamValue("b", node, tensorMap, context))];
        }
        case "GreaterEqual": {
          return [ops.greaterEqual(getParamValue("a", node, tensorMap, context), getParamValue("b", node, tensorMap, context))];
        }
        case "Less": {
          return [ops.less(getParamValue("a", node, tensorMap, context), getParamValue("b", node, tensorMap, context))];
        }
        case "LessEqual": {
          return [ops.lessEqual(getParamValue("a", node, tensorMap, context), getParamValue("b", node, tensorMap, context))];
        }
        case "LogicalAnd": {
          return [ops.logicalAnd(getParamValue("a", node, tensorMap, context), getParamValue("b", node, tensorMap, context))];
        }
        case "LogicalNot": {
          return [ops.logicalNot(getParamValue("a", node, tensorMap, context))];
        }
        case "LogicalOr": {
          return [ops.logicalOr(getParamValue("a", node, tensorMap, context), getParamValue("b", node, tensorMap, context))];
        }
        case "Select":
        case "SelectV2": {
          return [ops.where(getParamValue("condition", node, tensorMap, context), getParamValue("a", node, tensorMap, context), getParamValue("b", node, tensorMap, context))];
        }
        case "BitwiseAnd": {
          return [ops.bitwiseAnd(getParamValue("a", node, tensorMap, context), getParamValue("b", node, tensorMap, context))];
        }
        default:
          throw TypeError("Node type ".concat(node.op, " is not implemented"));
      }
    };
    var executeOp$9 = function(node, tensorMap, context, ops) {
      if (ops === void 0) {
        ops = tfOps;
      }
      switch (node.op) {
        case "BatchMatMul":
        case "BatchMatMulV2":
        case "MatMul":
          return [ops.matMul(getParamValue("a", node, tensorMap, context), getParamValue("b", node, tensorMap, context), getParamValue("transposeA", node, tensorMap, context), getParamValue("transposeB", node, tensorMap, context))];
        case "Einsum":
          return [ops.einsum.apply(ops, __spreadArray([getParamValue("equation", node, tensorMap, context)], __read(getParamValue("tensors", node, tensorMap, context)), false))];
        case "Transpose":
          return [ops.transpose(getParamValue("x", node, tensorMap, context), getParamValue("perm", node, tensorMap, context))];
        case "_FusedMatMul":
          var _a = __read(getParamValue("fusedOps", node, tensorMap, context), 2), extraOp = _a[0], activationFunc = _a[1];
          var isBiasAdd = extraOp === "biasadd";
          var isPrelu = activationFunc === "prelu";
          var numArgs = getParamValue("numArgs", node, tensorMap, context);
          var leakyreluAlpha = getParamValue("leakyreluAlpha", node, tensorMap, context);
          if (isBiasAdd) {
            if (isPrelu && numArgs !== 2) {
              throw new Error("Fused MatMul with BiasAdd and Prelu must have two extra arguments: bias and alpha.");
            }
            if (!isPrelu && numArgs !== 1) {
              throw new Error("Fused MatMul with BiasAdd must have one extra argument: bias.");
            }
          }
          var _b = __read(getParamValue("args", node, tensorMap, context), 2), biasArg = _b[0], preluArg = _b[1];
          return [ops.fused.matMul({
            a: getParamValue("a", node, tensorMap, context),
            b: getParamValue("b", node, tensorMap, context),
            transposeA: getParamValue("transposeA", node, tensorMap, context),
            transposeB: getParamValue("transposeB", node, tensorMap, context),
            bias: biasArg,
            activation: activationFunc,
            preluActivationWeights: preluArg,
            leakyreluAlpha
          })];
        case "MatrixBandPart":
          return [ops.linalg.bandPart(getParamValue("a", node, tensorMap, context), getParamValue("numLower", node, tensorMap, context), getParamValue("numUpper", node, tensorMap, context))];
        default:
          throw TypeError("Node type ".concat(node.op, " is not implemented"));
      }
    };
    var executeOp$8 = function(node, tensorMap, context, ops) {
      if (ops === void 0) {
        ops = tfOps;
      }
      switch (node.op) {
        case "EuclideanNorm":
          return [ops.euclideanNorm(getParamValue("x", node, tensorMap, context), getParamValue("axis", node, tensorMap, context), getParamValue("keepDims", node, tensorMap, context))];
        case "FusedBatchNorm":
        case "FusedBatchNormV2": {
          return [ops.batchNorm(getParamValue("x", node, tensorMap, context), getParamValue("mean", node, tensorMap, context), getParamValue("variance", node, tensorMap, context), getParamValue("offset", node, tensorMap, context), getParamValue("scale", node, tensorMap, context), getParamValue("epsilon", node, tensorMap, context))];
        }
        case "FusedBatchNormV3": {
          return [ops.batchNorm(getParamValue("x", node, tensorMap, context), getParamValue("mean", node, tensorMap, context), getParamValue("variance", node, tensorMap, context), getParamValue("offset", node, tensorMap, context), getParamValue("scale", node, tensorMap, context), getParamValue("epsilon", node, tensorMap, context))];
        }
        case "LRN": {
          return [ops.localResponseNormalization(getParamValue("x", node, tensorMap, context), getParamValue("radius", node, tensorMap, context), getParamValue("bias", node, tensorMap, context), getParamValue("alpha", node, tensorMap, context), getParamValue("beta", node, tensorMap, context))];
        }
        case "Softmax": {
          return [ops.softmax(getParamValue("x", node, tensorMap, context))];
        }
        case "LogSoftmax": {
          return [ops.logSoftmax(getParamValue("x", node, tensorMap, context))];
        }
        default:
          throw TypeError("Node type ".concat(node.op, " is not implemented"));
      }
    };
    var executeOp$7 = function(node, tensorMap, context, ops) {
      if (ops === void 0) {
        ops = tfOps;
      }
      switch (node.op) {
        case "RaggedGather": {
          var _a = ops.raggedGather(getParamValue("paramsNestedSplits", node, tensorMap, context), getParamValue("paramsDenseValues", node, tensorMap, context), getParamValue("indices", node, tensorMap, context), getParamValue("outputRaggedRank", node, tensorMap, context)), outputNestedSplits = _a.outputNestedSplits, outputDenseValues = _a.outputDenseValues;
          return outputNestedSplits.concat(outputDenseValues);
        }
        case "RaggedRange": {
          var _b = ops.raggedRange(getParamValue("starts", node, tensorMap, context), getParamValue("limits", node, tensorMap, context), getParamValue("splits", node, tensorMap, context)), rtNestedSplits = _b.rtNestedSplits, rtDenseValues = _b.rtDenseValues;
          return [rtNestedSplits, rtDenseValues];
        }
        case "RaggedTensorToTensor": {
          return [ops.raggedTensorToTensor(getParamValue("shape", node, tensorMap, context), getParamValue("values", node, tensorMap, context), getParamValue("defaultValue", node, tensorMap, context), getParamValue("rowPartitionTensors", node, tensorMap, context), getParamValue("rowPartitionTypes", node, tensorMap, context))];
        }
        default:
          throw TypeError("Node type ".concat(node.op, " is not implemented"));
      }
    };
    var executeOp$6 = function(node, tensorMap, context, ops) {
      if (ops === void 0) {
        ops = tfOps;
      }
      switch (node.op) {
        case "Max": {
          var axis = getParamValue("axis", node, tensorMap, context);
          var keepDims = getParamValue("keepDims", node, tensorMap, context);
          return [ops.max(getParamValue("x", node, tensorMap, context), axis, keepDims)];
        }
        case "Mean": {
          var axis = getParamValue("axis", node, tensorMap, context);
          var keepDims = getParamValue("keepDims", node, tensorMap, context);
          return [ops.mean(getParamValue("x", node, tensorMap, context), axis, keepDims)];
        }
        case "Min": {
          var axis = getParamValue("axis", node, tensorMap, context);
          var keepDims = getParamValue("keepDims", node, tensorMap, context);
          return [ops.min(getParamValue("x", node, tensorMap, context), axis, keepDims)];
        }
        case "Sum": {
          var axis = getParamValue("axis", node, tensorMap, context);
          var keepDims = getParamValue("keepDims", node, tensorMap, context);
          return [ops.sum(getParamValue("x", node, tensorMap, context), axis, keepDims)];
        }
        case "All": {
          var axis = getParamValue("axis", node, tensorMap, context);
          var keepDims = getParamValue("keepDims", node, tensorMap, context);
          return [ops.all(getParamValue("x", node, tensorMap, context), axis, keepDims)];
        }
        case "Any": {
          var axis = getParamValue("axis", node, tensorMap, context);
          var keepDims = getParamValue("keepDims", node, tensorMap, context);
          return [ops.any(getParamValue("x", node, tensorMap, context), axis, keepDims)];
        }
        case "ArgMax": {
          var axis = getParamValue("axis", node, tensorMap, context);
          return [ops.argMax(getParamValue("x", node, tensorMap, context), axis)];
        }
        case "ArgMin": {
          var axis = getParamValue("axis", node, tensorMap, context);
          return [ops.argMin(getParamValue("x", node, tensorMap, context), axis)];
        }
        case "Prod": {
          var axis = getParamValue("axis", node, tensorMap, context);
          var keepDims = getParamValue("keepDims", node, tensorMap, context);
          return [ops.prod(getParamValue("x", node, tensorMap, context), axis, keepDims)];
        }
        case "Cumprod": {
          var axis = getParamValue("axis", node, tensorMap, context);
          var exclusive = getParamValue("exclusive", node, tensorMap, context);
          var reverse2 = getParamValue("reverse", node, tensorMap, context);
          return [ops.cumprod(getParamValue("x", node, tensorMap, context), axis, exclusive, reverse2)];
        }
        case "Cumsum": {
          var axis = getParamValue("axis", node, tensorMap, context);
          var exclusive = getParamValue("exclusive", node, tensorMap, context);
          var reverse2 = getParamValue("reverse", node, tensorMap, context);
          return [ops.cumsum(getParamValue("x", node, tensorMap, context), axis, exclusive, reverse2)];
        }
        case "Bincount":
          var x = getParamValue("x", node, tensorMap, context);
          var weights = getParamValue("weights", node, tensorMap, context);
          var size = getParamValue("size", node, tensorMap, context);
          return [ops.bincount(x, weights, size)];
        case "DenseBincount": {
          var x_1 = getParamValue("x", node, tensorMap, context);
          var weights_1 = getParamValue("weights", node, tensorMap, context);
          var size_1 = getParamValue("size", node, tensorMap, context);
          var binaryOutput = getParamValue("binaryOutput", node, tensorMap, context);
          return [ops.denseBincount(x_1, weights_1, size_1, binaryOutput)];
        }
        default:
          throw TypeError("Node type ".concat(node.op, " is not implemented"));
      }
    };
    var executeOp$5 = function(node, tensorMap, context, ops) {
      if (ops === void 0) {
        ops = tfOps;
      }
      switch (node.op) {
        case "ConcatV2":
        case "Concat": {
          var n = getParamValue("n", node, tensorMap, context);
          var axis = getParamValue("axis", node, tensorMap, context);
          var inputs = getParamValue("tensors", node, tensorMap, context);
          inputs = inputs.slice(0, n);
          return [ops.concat(inputs, axis)];
        }
        case "Gather": {
          var input = getParamValue("x", node, tensorMap, context);
          var indices = getParamValue("indices", node, tensorMap, context);
          return [ops.gather(input, ops.cast(indices, "int32"), 0)];
        }
        case "GatherV2": {
          var axis = getParamValue("axis", node, tensorMap, context);
          var batchDims = getParamValue("batchDims", node, tensorMap, context);
          var input = getParamValue("x", node, tensorMap, context);
          var indices = getParamValue("indices", node, tensorMap, context);
          return [ops.gather(input, ops.cast(indices, "int32"), axis, batchDims)];
        }
        case "Reverse": {
          var dims = getParamValue("dims", node, tensorMap, context);
          var axis = [];
          for (var i = 0; i < dims.length; i++) {
            if (dims[i]) {
              axis.push(i);
            }
          }
          var input = getParamValue("x", node, tensorMap, context);
          return [ops.reverse(input, axis)];
        }
        case "ReverseV2": {
          var axis = getParamValue("axis", node, tensorMap, context);
          var input = getParamValue("x", node, tensorMap, context);
          return [ops.reverse(input, axis)];
        }
        case "Slice": {
          var begin = getParamValue("begin", node, tensorMap, context);
          var size = getParamValue("size", node, tensorMap, context);
          return [ops.slice(getParamValue("x", node, tensorMap, context), begin, size)];
        }
        case "StridedSlice": {
          var begin = getParamValue("begin", node, tensorMap, context);
          var end = getParamValue("end", node, tensorMap, context);
          var strides = getParamValue("strides", node, tensorMap, context);
          var beginMask = getParamValue("beginMask", node, tensorMap, context);
          var endMask = getParamValue("endMask", node, tensorMap, context);
          var ellipsisMask = getParamValue("ellipsisMask", node, tensorMap, context);
          var newAxisMask = getParamValue("newAxisMask", node, tensorMap, context);
          var shrinkAxisMask = getParamValue("shrinkAxisMask", node, tensorMap, context);
          var tensor2 = getParamValue("x", node, tensorMap, context);
          return [ops.stridedSlice(tensor2, begin, end, strides, beginMask, endMask, ellipsisMask, newAxisMask, shrinkAxisMask)];
        }
        case "Pack": {
          return tfc.tidy(function() {
            var axis2 = getParamValue("axis", node, tensorMap, context);
            var tensors = getParamValue("tensors", node, tensorMap, context);
            var shape2 = tensors[0].shape;
            var squeezedShape = ops.squeeze(tensors[0]).shape;
            var mapped = tensors.map(function(tensor3) {
              var sameShape = tfc.util.arraysEqual(tensor3.shape, shape2);
              if (!sameShape && !tfc.util.arraysEqual(ops.squeeze(tensor3).shape, squeezedShape)) {
                throw new Error("the input tensors shape does not match");
              }
              return sameShape ? tensor3 : ops.reshape(tensor3, shape2);
            });
            return [ops.stack(mapped, axis2)];
          });
        }
        case "Unpack": {
          var axis = getParamValue("axis", node, tensorMap, context);
          var tensor2 = getParamValue("tensor", node, tensorMap, context);
          return ops.unstack(tensor2, axis);
        }
        case "Tile": {
          var reps = getParamValue("reps", node, tensorMap, context);
          return [ops.tile(getParamValue("x", node, tensorMap, context), reps)];
        }
        case "Split":
        case "SplitV": {
          var axis = getParamValue("axis", node, tensorMap, context);
          var numOrSizeSplits = getParamValue("numOrSizeSplits", node, tensorMap, context);
          var tensor2 = getParamValue("x", node, tensorMap, context);
          return ops.split(tensor2, numOrSizeSplits, axis);
        }
        case "ScatterNd": {
          var indices = getParamValue("indices", node, tensorMap, context);
          var values = getParamValue("values", node, tensorMap, context);
          var shape = getParamValue("shape", node, tensorMap, context);
          return [ops.scatterND(indices, values, shape)];
        }
        case "GatherNd": {
          var x = getParamValue("x", node, tensorMap, context);
          var indices = getParamValue("indices", node, tensorMap, context);
          return [ops.gatherND(x, indices)];
        }
        case "SparseToDense": {
          var indices = getParamValue("sparseIndices", node, tensorMap, context);
          var shape = getParamValue("outputShape", node, tensorMap, context);
          var sparseValues = getParamValue("sparseValues", node, tensorMap, context);
          var defaultValue = getParamValue("defaultValue", node, tensorMap, context);
          return [ops.sparseToDense(indices, sparseValues, shape, sparseValues.dtype === defaultValue.dtype ? defaultValue : ops.cast(defaultValue, sparseValues.dtype))];
        }
        case "TensorScatterUpdate": {
          var indices = getParamValue("indices", node, tensorMap, context);
          var values = getParamValue("values", node, tensorMap, context);
          var tensor2 = getParamValue("tensor", node, tensorMap, context);
          return [ops.tensorScatterUpdate(tensor2, indices, values)];
        }
        default:
          throw TypeError("Node type ".concat(node.op, " is not implemented"));
      }
    };
    var executeOp$4 = function(node, tensorMap, context, ops) {
      if (ops === void 0) {
        ops = tfOps;
      }
      switch (node.op) {
        case "SparseFillEmptyRows": {
          var _a = ops.sparse.sparseFillEmptyRows(getParamValue("indices", node, tensorMap, context), getParamValue("values", node, tensorMap, context), getParamValue("denseShape", node, tensorMap, context), getParamValue("defaultValue", node, tensorMap, context)), outputIndices = _a.outputIndices, outputValues = _a.outputValues, emptyRowIndicator = _a.emptyRowIndicator, reverseIndexMap = _a.reverseIndexMap;
          return [
            outputIndices,
            outputValues,
            emptyRowIndicator,
            reverseIndexMap
          ];
        }
        case "SparseReshape": {
          var _b = ops.sparse.sparseReshape(getParamValue("inputIndices", node, tensorMap, context), getParamValue("inputShape", node, tensorMap, context), getParamValue("newShape", node, tensorMap, context)), outputIndices = _b.outputIndices, outputShape = _b.outputShape;
          return [outputIndices, outputShape];
        }
        case "SparseSegmentMean": {
          var outputData = ops.sparse.sparseSegmentMean(getParamValue("data", node, tensorMap, context), getParamValue("indices", node, tensorMap, context), getParamValue("segmentIds", node, tensorMap, context));
          return [outputData];
        }
        case "SparseSegmentSum": {
          var outputData = ops.sparse.sparseSegmentSum(getParamValue("data", node, tensorMap, context), getParamValue("indices", node, tensorMap, context), getParamValue("segmentIds", node, tensorMap, context));
          return [outputData];
        }
        default:
          throw TypeError("Node type ".concat(node.op, " is not implemented"));
      }
    };
    var executeOp$3 = function(node, tensorMap, context, ops) {
      if (ops === void 0) {
        ops = tfOps;
      }
      switch (node.op) {
        case "FFT": {
          return [ops.fft(getParamValue("x", node, tensorMap, context))];
        }
        case "IFFT": {
          return [ops.ifft(getParamValue("x", node, tensorMap, context))];
        }
        case "RFFT": {
          return [ops.rfft(getParamValue("x", node, tensorMap, context))];
        }
        case "IRFFT": {
          return [ops.irfft(getParamValue("x", node, tensorMap, context))];
        }
        default:
          throw TypeError("Node type ".concat(node.op, " is not implemented"));
      }
    };
    var executeOp$2 = function(node, tensorMap, context, ops) {
      if (ops === void 0) {
        ops = tfOps;
      }
      switch (node.op) {
        case "StaticRegexReplace": {
          return [ops.string.staticRegexReplace(getParamValue("input", node, tensorMap, context), getParamValue("pattern", node, tensorMap, context), getParamValue("rewrite", node, tensorMap, context), getParamValue("replaceGlobal", node, tensorMap, context))];
        }
        case "StringNGrams": {
          var _a = ops.string.stringNGrams(getParamValue("data", node, tensorMap, context), getParamValue("dataSplits", node, tensorMap, context), getParamValue("separator", node, tensorMap, context), getParamValue("nGramWidths", node, tensorMap, context), getParamValue("leftPad", node, tensorMap, context), getParamValue("rightPad", node, tensorMap, context), getParamValue("padWidth", node, tensorMap, context), getParamValue("preserveShortSequences", node, tensorMap, context)), nGrams = _a.nGrams, nGramsSplits = _a.nGramsSplits;
          return [nGrams, nGramsSplits];
        }
        case "StringSplit": {
          var _b = ops.string.stringSplit(getParamValue("input", node, tensorMap, context), getParamValue("delimiter", node, tensorMap, context), getParamValue("skipEmpty", node, tensorMap, context)), indices = _b.indices, values = _b.values, shape = _b.shape;
          return [indices, values, shape];
        }
        case "StringToHashBucketFast": {
          var output = ops.string.stringToHashBucketFast(getParamValue("input", node, tensorMap, context), getParamValue("numBuckets", node, tensorMap, context));
          return [output];
        }
        default:
          throw TypeError("Node type ".concat(node.op, " is not implemented"));
      }
    };
    var executeOp$1 = function(node, tensorMap, context, ops) {
      if (ops === void 0) {
        ops = tfOps;
      }
      switch (node.op) {
        case "Cast": {
          return [ops.cast(getParamValue("x", node, tensorMap, context), getParamValue("dtype", node, tensorMap, context))];
        }
        case "ExpandDims": {
          var axis = getParamValue("axis", node, tensorMap, context);
          return [ops.expandDims(getParamValue("x", node, tensorMap, context), axis)];
        }
        case "Squeeze": {
          var axis = getParamValue("axis", node, tensorMap, context);
          return [ops.squeeze(getParamValue("x", node, tensorMap, context), axis)];
        }
        case "Reshape": {
          return [ops.reshape(getParamValue("x", node, tensorMap, context), getParamValue("shape", node, tensorMap, context))];
        }
        case "EnsureShape": {
          return [ops.ensureShape(getParamValue("x", node, tensorMap, context), getParamValue("shape", node, tensorMap, context))];
        }
        case "MirrorPad": {
          return [ops.mirrorPad(getParamValue("x", node, tensorMap, context), getParamValue("padding", node, tensorMap, context), getParamValue("mode", node, tensorMap, context))];
        }
        case "PadV2":
        case "Pad": {
          return [ops.pad(getParamValue("x", node, tensorMap, context), getParamValue("padding", node, tensorMap, context), getParamValue("constantValue", node, tensorMap, context))];
        }
        case "SpaceToBatchND": {
          var blockShape = getParamValue("blockShape", node, tensorMap, context);
          var paddings = getParamValue("paddings", node, tensorMap, context);
          return [ops.spaceToBatchND(getParamValue("x", node, tensorMap, context), blockShape, paddings)];
        }
        case "BatchToSpaceND": {
          var blockShape = getParamValue("blockShape", node, tensorMap, context);
          var crops = getParamValue("crops", node, tensorMap, context);
          return [ops.batchToSpaceND(getParamValue("x", node, tensorMap, context), blockShape, crops)];
        }
        case "DepthToSpace": {
          var blockSize = getParamValue("blockSize", node, tensorMap, context);
          var dataFormat = getParamValue("dataFormat", node, tensorMap, context).toUpperCase();
          return [ops.depthToSpace(getParamValue("x", node, tensorMap, context), blockSize, dataFormat)];
        }
        case "BroadcastTo": {
          return [ops.broadcastTo(getParamValue("x", node, tensorMap, context), getParamValue("shape", node, tensorMap, context))];
        }
        case "BroadcastArgs": {
          return [ops.broadcastArgs(getParamValue("s0", node, tensorMap, context), getParamValue("s1", node, tensorMap, context))];
        }
        default:
          throw TypeError("Node type ".concat(node.op, " is not implemented"));
      }
    };
    function executeOp(node, tensorMap, context, resourceManager, tidy2) {
      if (tidy2 === void 0) {
        tidy2 = tfc__namespace.tidy;
      }
      var value = function(node2, tensorMap2, context2) {
        switch (node2.category) {
          case "arithmetic":
            return tidy2(function() {
              return executeOp$k(node2, tensorMap2, context2);
            });
          case "basic_math":
            return tidy2(function() {
              return executeOp$j(node2, tensorMap2, context2);
            });
          case "control":
            return executeOp$i(node2, tensorMap2, context2);
          case "convolution":
            return tidy2(function() {
              return executeOp$h(node2, tensorMap2, context2);
            });
          case "creation":
            return tidy2(function() {
              return executeOp$g(node2, tensorMap2, context2);
            });
          case "dynamic":
            return executeOp$f(node2, tensorMap2, context2);
          case "evaluation":
            return tidy2(function() {
              return executeOp$e(node2, tensorMap2, context2);
            });
          case "image":
            return tidy2(function() {
              return executeOp$b(node2, tensorMap2, context2);
            });
          case "graph":
            return tidy2(function() {
              return executeOp$d(node2, tensorMap2, context2);
            });
          case "logical":
            return tidy2(function() {
              return executeOp$a(node2, tensorMap2, context2);
            });
          case "matrices":
            return tidy2(function() {
              return executeOp$9(node2, tensorMap2, context2);
            });
          case "normalization":
            return tidy2(function() {
              return executeOp$8(node2, tensorMap2, context2);
            });
          case "ragged":
            return tidy2(function() {
              return executeOp$7(node2, tensorMap2, context2);
            });
          case "reduction":
            return tidy2(function() {
              return executeOp$6(node2, tensorMap2, context2);
            });
          case "slice_join":
            return tidy2(function() {
              return executeOp$5(node2, tensorMap2, context2);
            });
          case "sparse":
            return tidy2(function() {
              return executeOp$4(node2, tensorMap2, context2);
            });
          case "spectral":
            return tidy2(function() {
              return executeOp$3(node2, tensorMap2, context2);
            });
          case "string":
            return tidy2(function() {
              return executeOp$2(node2, tensorMap2, context2);
            });
          case "transformation":
            return tidy2(function() {
              return executeOp$1(node2, tensorMap2, context2);
            });
          case "hash_table":
            return executeOp$c(node2, tensorMap2, context2, resourceManager);
          case "custom":
            var opMapper = getRegisteredOp(node2.op);
            if (opMapper && opMapper.customExecutor) {
              return opMapper.customExecutor(new NodeValueImpl(node2, tensorMap2, context2));
            } else {
              throw TypeError("Custom op ".concat(node2.op, " is not registered."));
            }
          default:
            throw TypeError("Unknown op '".concat(node2.op, "'. File an issue at ") + "https://github.com/tensorflow/tfjs/issues so we can add it, or register a custom execution with tf.registerOp()");
        }
      }(node, tensorMap, context);
      if (tfc__namespace.util.isPromise(value)) {
        return value.then(function(data) {
          return [].concat(data);
        });
      }
      return [].concat(value);
    }
    var ExecutionContext = (
      /** @class */
      function() {
        function ExecutionContext2(weightMap, tensorArrayMap, tensorListMap, functionMap, parseNodeNameCache) {
          if (weightMap === void 0) {
            weightMap = {};
          }
          if (tensorArrayMap === void 0) {
            tensorArrayMap = {};
          }
          if (tensorListMap === void 0) {
            tensorListMap = {};
          }
          if (functionMap === void 0) {
            functionMap = {};
          }
          this.weightMap = weightMap;
          this.tensorArrayMap = tensorArrayMap;
          this.tensorListMap = tensorListMap;
          this.functionMap = functionMap;
          this.parseNodeNameCache = parseNodeNameCache;
          this.rootContext = { id: 0, frameName: "", iterationId: 0 };
          this.contexts = [this.rootContext];
          this.lastId = 0;
          this.generateCurrentContextIds();
        }
        ExecutionContext2.prototype.newFrame = function(id, frameName) {
          return { id, frameName, iterationId: 0 };
        };
        Object.defineProperty(ExecutionContext2.prototype, "currentContext", {
          get: function() {
            return this.contexts;
          },
          /**
           * Set the current context
           * @param contexts: ExecutionContextInfo[] the current path of execution
           * frames
           */
          set: function(contexts) {
            if (this.contexts !== contexts) {
              this.contexts = contexts;
              this.generateCurrentContextIds();
            }
          },
          enumerable: false,
          configurable: true
        });
        Object.defineProperty(ExecutionContext2.prototype, "currentContextId", {
          /**
           * Returns the current context in string format.
           */
          get: function() {
            return this._currentContextIds[0];
          },
          enumerable: false,
          configurable: true
        });
        Object.defineProperty(ExecutionContext2.prototype, "currentContextIds", {
          /**
           * Returns the current context and all parent contexts in string format.
           * This allow access to the nodes in the current and parent frames.
           */
          get: function() {
            return this._currentContextIds;
          },
          enumerable: false,
          configurable: true
        });
        ExecutionContext2.prototype.generateCurrentContextIds = function() {
          var names = [];
          for (var i = 0; i < this.contexts.length - 1; i++) {
            var contexts = this.contexts.slice(0, this.contexts.length - i);
            names.push(this.contextIdforContexts(contexts));
          }
          names.push("");
          this._currentContextIds = names;
        };
        ExecutionContext2.prototype.contextIdforContexts = function(contexts) {
          return contexts ? contexts.map(function(context) {
            return context.id === 0 && context.iterationId === 0 ? "" : "".concat(context.frameName, "-").concat(context.iterationId);
          }).join("/") : "";
        };
        ExecutionContext2.prototype.enterFrame = function(frameId) {
          if (this.contexts) {
            this.lastId++;
            this.contexts = this.contexts.slice();
            this.contexts.push(this.newFrame(this.lastId, frameId));
            this._currentContextIds.unshift(this.contextIdforContexts(this.contexts));
          }
        };
        ExecutionContext2.prototype.exitFrame = function() {
          if (this.contexts && this.contexts.length > 1) {
            this.contexts = this.contexts.slice();
            this.contexts.splice(-1);
            this.currentContextIds.shift();
          } else {
            throw new Error("Cannot exit frame, the context is empty");
          }
        };
        ExecutionContext2.prototype.nextIteration = function() {
          if (this.contexts && this.contexts.length > 0) {
            this.contexts = this.contexts.slice();
            this.lastId++;
            var context = Object.assign({}, this.contexts[this.contexts.length - 1]);
            context.iterationId += 1;
            context.id = this.lastId;
            this.contexts.splice(-1, 1, context);
            this._currentContextIds.splice(0, 1, this.contextIdforContexts(this.contexts));
          } else {
            throw new Error("Cannot increase frame iteration, the context is empty");
          }
        };
        ExecutionContext2.prototype.getWeight = function(name) {
          return this.weightMap[name];
        };
        ExecutionContext2.prototype.addTensorArray = function(tensorArray) {
          this.tensorArrayMap[tensorArray.id] = tensorArray;
        };
        ExecutionContext2.prototype.getTensorArray = function(id) {
          return this.tensorArrayMap[id];
        };
        ExecutionContext2.prototype.addTensorList = function(tensorList) {
          this.tensorListMap[tensorList.id] = tensorList;
        };
        ExecutionContext2.prototype.getTensorList = function(id) {
          return this.tensorListMap[id];
        };
        ExecutionContext2.prototype.dispose = function(keepIds) {
          for (var key in this.tensorArrayMap) {
            this.tensorArrayMap[key].clearAndClose(keepIds);
          }
          for (var key in this.tensorListMap) {
            this.tensorListMap[key].clearAndClose(keepIds);
          }
        };
        return ExecutionContext2;
      }()
    );
    function getExecutionSubgraph(inputs, outputs, weightMap, initNodes) {
      var usedNodes = /* @__PURE__ */ new Set();
      var missingInputs = [];
      var dynamicNode = null;
      var syncInputs = null;
      var seen = /* @__PURE__ */ new Set();
      var inputNodeNames = new Set(Object.keys(inputs).map(function(name) {
        return parseNodeName(name)[0];
      }));
      initNodes = initNodes || [];
      var initNodeNames = new Set(initNodes.map(function(node2) {
        return parseNodeName(node2.name)[0];
      }));
      var frontier = __spreadArray([], __read(outputs), false);
      while (frontier.length > 0) {
        var node = frontier.pop();
        if (isControlFlow(node) || isDynamicShape(node) || isHashTable(node)) {
          if (dynamicNode == null) {
            dynamicNode = node;
            syncInputs = dynamicNode.children.map(function(child) {
              return child.name;
            }).filter(function(name) {
              return usedNodes.has(name);
            });
          }
        }
        usedNodes.add(node.name);
        if (weightMap[node.name] != null) {
          continue;
        }
        if (inputNodeNames.has(node.name)) {
          continue;
        }
        if (initNodeNames.has(node.name)) {
          continue;
        }
        if (node.inputs.length === 0) {
          missingInputs.push(node.name);
          continue;
        }
        node.inputs.forEach(function(input) {
          if (seen.has(input.name)) {
            return;
          }
          seen.add(input.name);
          frontier.push(input);
        });
      }
      return { inputs, outputs, usedNodes, missingInputs, dynamicNode, syncInputs };
    }
    function getNodesInTopologicalOrder(graph2, executionInfo) {
      var e_1, _a, e_2, _b, e_3, _c;
      var usedNodes = executionInfo.usedNodes, inputs = executionInfo.inputs;
      var inputNodes = Object.keys(inputs).map(function(name) {
        return parseNodeName(name)[0];
      }).map(function(name) {
        return graph2.nodes[name];
      });
      var initNodes = graph2.initNodes || [];
      var isUsed = function(node2) {
        return usedNodes.has(typeof node2 === "string" ? node2 : node2.name);
      };
      function unique2(nodes) {
        return __spreadArray([], __read(new Map(nodes.map(function(node2) {
          return [node2.name, node2];
        })).values()), false);
      }
      var predefinedNodes = unique2(__spreadArray(__spreadArray(__spreadArray([], __read(inputNodes), false), __read(graph2.weights), false), __read(initNodes), false)).filter(isUsed);
      var allNodes = unique2(__spreadArray(__spreadArray([], __read(predefinedNodes), false), __read(Object.values(graph2.nodes)), false)).filter(isUsed);
      var nameToNode = new Map(allNodes.map(function(node2) {
        return [node2.name, node2];
      }));
      var inCounts = {};
      try {
        for (var allNodes_1 = __values(allNodes), allNodes_1_1 = allNodes_1.next(); !allNodes_1_1.done; allNodes_1_1 = allNodes_1.next()) {
          var node = allNodes_1_1.value;
          inCounts[node.name] = inCounts[node.name] || 0;
          try {
            for (var _d = (e_2 = void 0, __values(node.children)), _e = _d.next(); !_e.done; _e = _d.next()) {
              var child = _e.value;
              if (!isUsed(child)) {
                inCounts[child.name] = Number.POSITIVE_INFINITY;
              }
              inCounts[child.name] = (inCounts[child.name] || 0) + 1;
            }
          } catch (e_2_1) {
            e_2 = { error: e_2_1 };
          } finally {
            try {
              if (_e && !_e.done && (_b = _d.return))
                _b.call(_d);
            } finally {
              if (e_2)
                throw e_2.error;
            }
          }
        }
      } catch (e_1_1) {
        e_1 = { error: e_1_1 };
      } finally {
        try {
          if (allNodes_1_1 && !allNodes_1_1.done && (_a = allNodes_1.return))
            _a.call(allNodes_1);
        } finally {
          if (e_1)
            throw e_1.error;
        }
      }
      var frontier = Object.entries(inCounts).filter(function(_a2) {
        var _b2 = __read(_a2, 2), inCount = _b2[1];
        return inCount === 0;
      }).map(function(_a2) {
        var _b2 = __read(_a2, 1), name = _b2[0];
        return name;
      });
      var orderedNodeNames = __spreadArray([], __read(frontier), false);
      while (frontier.length > 0) {
        var nodeName = frontier.pop();
        var node = nameToNode.get(nodeName);
        try {
          for (var _f = (e_3 = void 0, __values(node.children.filter(isUsed))), _g = _f.next(); !_g.done; _g = _f.next()) {
            var child = _g.value;
            if (--inCounts[child.name] === 0) {
              orderedNodeNames.push(child.name);
              frontier.push(child.name);
            }
          }
        } catch (e_3_1) {
          e_3 = { error: e_3_1 };
        } finally {
          try {
            if (_g && !_g.done && (_c = _f.return))
              _c.call(_f);
          } finally {
            if (e_3)
              throw e_3.error;
          }
        }
      }
      var orderedNodes = orderedNodeNames.map(function(name) {
        return nameToNode.get(name);
      });
      var filteredOrderedNodes = filterPredefinedReachableNodes(orderedNodes, predefinedNodes);
      validateNodesExecutionOrder(filteredOrderedNodes, predefinedNodes);
      return filteredOrderedNodes;
    }
    function filterPredefinedReachableNodes(orderedNodes, predefinedNodes) {
      var e_4, _a;
      var nameToNode = new Map(orderedNodes.map(function(node2) {
        return [node2.name, node2];
      }));
      var stack2 = predefinedNodes.map(function(node2) {
        return node2.name;
      });
      var predefinedReachableNodeNames = new Set(stack2);
      while (stack2.length > 0) {
        var nodeName = stack2.pop();
        var node = nameToNode.get(nodeName);
        try {
          for (var _b = (e_4 = void 0, __values(node.children)), _c = _b.next(); !_c.done; _c = _b.next()) {
            var child = _c.value;
            if (!nameToNode.has(child.name) || predefinedReachableNodeNames.has(child.name)) {
              continue;
            }
            predefinedReachableNodeNames.add(child.name);
            stack2.push(child.name);
          }
        } catch (e_4_1) {
          e_4 = { error: e_4_1 };
        } finally {
          try {
            if (_c && !_c.done && (_a = _b.return))
              _a.call(_b);
          } finally {
            if (e_4)
              throw e_4.error;
          }
        }
      }
      var filteredOrderedNodes = orderedNodes.filter(function(node2) {
        return predefinedReachableNodeNames.has(node2.name);
      });
      return filteredOrderedNodes;
    }
    var NodesExecutionOrderError = (
      /** @class */
      function(_super) {
        __extends(NodesExecutionOrderError2, _super);
        function NodesExecutionOrderError2(message) {
          return _super.call(this, "NodesExecutionOrderError: ".concat(message)) || this;
        }
        return NodesExecutionOrderError2;
      }(Error)
    );
    function validateNodesExecutionOrder(orderedNodes, predefinedNodes) {
      var e_5, _a, e_6, _b, e_7, _c;
      var nodeNameToOrder = new Map(orderedNodes.map(function(node2, order) {
        return [node2.name, order];
      }));
      var predefinedNodeNames = new Set(predefinedNodes.map(function(node2) {
        return node2.name;
      }));
      var isPredefined = function(node2) {
        return predefinedNodeNames.has(typeof node2 === "string" ? node2 : node2.name);
      };
      var willBeExecutedNodeNames = new Set(orderedNodes.map(function(node2) {
        return node2.name;
      }));
      var willBeExecuted = function(node2) {
        return willBeExecutedNodeNames.has(typeof node2 === "string" ? node2 : node2.name);
      };
      try {
        for (var orderedNodes_1 = __values(orderedNodes), orderedNodes_1_1 = orderedNodes_1.next(); !orderedNodes_1_1.done; orderedNodes_1_1 = orderedNodes_1.next()) {
          var node = orderedNodes_1_1.value;
          try {
            for (var _d = (e_6 = void 0, __values(node.children.filter(willBeExecuted))), _e = _d.next(); !_e.done; _e = _d.next()) {
              var child = _e.value;
              if (!nodeNameToOrder.has(child.name)) {
                throw new NodesExecutionOrderError("Child ".concat(child.name, " of node ").concat(node.name, " is unreachable."));
              }
              if (nodeNameToOrder.get(node.name) > nodeNameToOrder.get(child.name)) {
                throw new NodesExecutionOrderError("Node ".concat(node.name, " is scheduled to run after its child ").concat(child.name, "."));
              }
            }
          } catch (e_6_1) {
            e_6 = { error: e_6_1 };
          } finally {
            try {
              if (_e && !_e.done && (_b = _d.return))
                _b.call(_d);
            } finally {
              if (e_6)
                throw e_6.error;
            }
          }
          if (!isPredefined(node)) {
            try {
              for (var _f = (e_7 = void 0, __values(node.inputs)), _g = _f.next(); !_g.done; _g = _f.next()) {
                var input = _g.value;
                if (!nodeNameToOrder.has(input.name)) {
                  throw new NodesExecutionOrderError("Input ".concat(input.name, " of node ").concat(node.name, " is unreachable."));
                }
                if (nodeNameToOrder.get(input.name) > nodeNameToOrder.get(node.name)) {
                  throw new NodesExecutionOrderError("Node ".concat(node.name, " is scheduled to run before its input ").concat(input.name, "."));
                }
              }
            } catch (e_7_1) {
              e_7 = { error: e_7_1 };
            } finally {
              try {
                if (_g && !_g.done && (_c = _f.return))
                  _c.call(_f);
              } finally {
                if (e_7)
                  throw e_7.error;
              }
            }
          }
        }
      } catch (e_5_1) {
        e_5 = { error: e_5_1 };
      } finally {
        try {
          if (orderedNodes_1_1 && !orderedNodes_1_1.done && (_a = orderedNodes_1.return))
            _a.call(orderedNodes_1);
        } finally {
          if (e_5)
            throw e_5.error;
        }
      }
    }
    function getNodeLiveUntilMap(orderedNodes) {
      var nodeNameToOrder = new Map(orderedNodes.map(function(node2, order) {
        return [node2.name, order];
      }));
      var INF_LIFE = Number.MAX_SAFE_INTEGER;
      var selfLifespans = orderedNodes.map(function(node2, nodeOrder2) {
        return isControlFlow(node2) ? INF_LIFE : nodeOrder2;
      });
      var getSelfLifeSpan = function(node2) {
        var selfLife = selfLifespans[nodeNameToOrder.get(node2.name)];
        if (selfLife == null) {
          return -1;
        }
        return selfLife;
      };
      var liveUntilOrders = orderedNodes.map(function(node2, nodeOrder2) {
        return node2.children.map(getSelfLifeSpan).reduce(function(a, b) {
          return Math.max(a, b);
        }, selfLifespans[nodeOrder2]);
      });
      var liveUntilMap = /* @__PURE__ */ new Map();
      for (var nodeOrder = 0; nodeOrder < orderedNodes.length; ++nodeOrder) {
        var liveUntilOrder = liveUntilOrders[nodeOrder];
        if (liveUntilOrder === INF_LIFE) {
          continue;
        }
        var node = orderedNodes[nodeOrder];
        var liveUntilNode = orderedNodes[liveUntilOrder];
        if (!liveUntilMap.has(liveUntilNode.name)) {
          liveUntilMap.set(liveUntilNode.name, []);
        }
        liveUntilMap.get(liveUntilNode.name).push(node);
      }
      return liveUntilMap;
    }
    var CONTROL_FLOW_OPS = /* @__PURE__ */ new Set([
      "Switch",
      "Merge",
      "Enter",
      "Exit",
      "NextIteration",
      "StatelessIf",
      "StatelessWhile",
      "if",
      "While"
    ]);
    var DYNAMIC_SHAPE_OPS = /* @__PURE__ */ new Set([
      "NonMaxSuppressionV2",
      "NonMaxSuppressionV3",
      "NonMaxSuppressionV5",
      "Where"
    ]);
    var HASH_TABLE_OPS = /* @__PURE__ */ new Set([
      "HashTable",
      "HashTableV2",
      "LookupTableImport",
      "LookupTableImportV2",
      "LookupTableFind",
      "LookupTableFindV2",
      "LookupTableSize",
      "LookupTableSizeV2"
    ]);
    function isControlFlow(node) {
      return CONTROL_FLOW_OPS.has(node.op);
    }
    function isDynamicShape(node) {
      return DYNAMIC_SHAPE_OPS.has(node.op);
    }
    function isHashTable(node) {
      return HASH_TABLE_OPS.has(node.op);
    }
    var GraphExecutor = (
      /** @class */
      function() {
        function GraphExecutor2(graph2, parent) {
          var _this = this;
          this.graph = graph2;
          this.parent = parent;
          this.compiledMap = /* @__PURE__ */ new Map();
          this.parseNodeNameCache = /* @__PURE__ */ new Map();
          this._weightMap = {};
          this.SEPARATOR = ",";
          this._functions = {};
          this._functionExecutorMap = {};
          this.keepIntermediateTensors = false;
          this._outputs = graph2.outputs;
          this._inputs = graph2.inputs;
          this._initNodes = graph2.initNodes;
          this._signature = graph2.signature;
          this._functions = graph2.functions;
          if (graph2.functions != null) {
            Object.keys(graph2.functions).forEach(function(name) {
              _this._functionExecutorMap[name] = new GraphExecutor2(graph2.functions[name], _this);
            });
          }
        }
        Object.defineProperty(GraphExecutor2.prototype, "weightIds", {
          get: function() {
            return this.parent ? this.parent.weightIds : this._weightIds;
          },
          enumerable: false,
          configurable: true
        });
        Object.defineProperty(GraphExecutor2.prototype, "functionExecutorMap", {
          get: function() {
            return this.parent ? this.parent.functionExecutorMap : this._functionExecutorMap;
          },
          enumerable: false,
          configurable: true
        });
        Object.defineProperty(GraphExecutor2.prototype, "weightMap", {
          get: function() {
            return this.parent ? this.parent.weightMap : this._weightMap;
          },
          set: function(weightMap) {
            var weightIds = Object.keys(weightMap).map(function(key) {
              return weightMap[key].map(function(tensor2) {
                return tensor2.id;
              });
            });
            this._weightIds = [].concat.apply([], __spreadArray([], __read(weightIds), false));
            this._weightMap = weightMap;
          },
          enumerable: false,
          configurable: true
        });
        Object.defineProperty(GraphExecutor2.prototype, "resourceManager", {
          /**
           * Set `ResourceManager` shared by executors of a model.
           * @param resourceManager: `ResourceManager` of the `GraphModel`.
           */
          set: function(resourceManager) {
            this._resourceManager = resourceManager;
          },
          enumerable: false,
          configurable: true
        });
        Object.defineProperty(GraphExecutor2.prototype, "inputs", {
          get: function() {
            return this._inputs.map(function(node) {
              return {
                name: node.name,
                shape: node.attrParams["shape"] ? node.attrParams["shape"].value : void 0,
                dtype: node.attrParams["dtype"] ? node.attrParams["dtype"].value : void 0
              };
            });
          },
          enumerable: false,
          configurable: true
        });
        Object.defineProperty(GraphExecutor2.prototype, "outputs", {
          get: function() {
            return this._outputs.map(function(node) {
              return {
                name: node.name,
                shape: node.attrParams["shape"] ? node.attrParams["shape"].value : void 0,
                dtype: node.attrParams["dtype"] ? node.attrParams["dtype"].value : void 0
              };
            });
          },
          enumerable: false,
          configurable: true
        });
        Object.defineProperty(GraphExecutor2.prototype, "inputNodes", {
          get: function() {
            return this._inputs.map(function(node) {
              return node.signatureKey || node.name;
            });
          },
          enumerable: false,
          configurable: true
        });
        Object.defineProperty(GraphExecutor2.prototype, "outputNodes", {
          get: function() {
            return this._outputs.map(function(node) {
              var name = node.signatureKey || node.name;
              return node.defaultOutput ? "".concat(name, ":").concat(node.defaultOutput) : name;
            });
          },
          enumerable: false,
          configurable: true
        });
        Object.defineProperty(GraphExecutor2.prototype, "functions", {
          get: function() {
            var _this = this;
            return Object.keys(this._functions).reduce(function(map, key) {
              map[key] = _this._functions[key].signature;
              return map;
            }, {});
          },
          enumerable: false,
          configurable: true
        });
        GraphExecutor2.prototype.getCompilationKey = function(inputs, outputs) {
          var sortedInputs = inputs.map(function(node) {
            return node.name;
          }).sort();
          var sortedOutputs = outputs.map(function(node) {
            return node.name;
          }).sort();
          return sortedInputs.join(this.SEPARATOR) + "--" + sortedOutputs.join(this.SEPARATOR);
        };
        GraphExecutor2.prototype.compile = function(inputs, outputs) {
          var executionInfo = getExecutionSubgraph(inputs, outputs, this.weightMap, this._initNodes);
          var missingInputs = executionInfo.missingInputs, dynamicNode = executionInfo.dynamicNode, syncInputs = executionInfo.syncInputs;
          if (dynamicNode != null) {
            throw new Error("This execution contains the node '".concat(dynamicNode.name, "', which has ") + "the dynamic op '".concat(dynamicNode.op, "'. Please use ") + "model.executeAsync() instead. Alternatively, to avoid the " + "dynamic ops, specify the inputs [".concat(syncInputs, "]"));
          }
          if (missingInputs.length > 0) {
            var outNames = outputs.map(function(n) {
              return n.name;
            });
            var inNames = Object.keys(inputs);
            throw new Error("Cannot compute the outputs [".concat(outNames, "] from the provided inputs ") + "[".concat(inNames, "]. Missing the following inputs: [").concat(missingInputs, "]"));
          }
          var orderedNodes = getNodesInTopologicalOrder(this.graph, executionInfo);
          var nodeLiveUntilMap = getNodeLiveUntilMap(orderedNodes);
          return { orderedNodes, nodeLiveUntilMap };
        };
        GraphExecutor2.prototype.cloneAndKeepTensor = function(tensor2) {
          if (tensor2 == null) {
            return null;
          }
          var clone2 = tensor2.clone();
          tfc.keep(clone2);
          return clone2;
        };
        GraphExecutor2.prototype.cloneTensorList = function(tensors) {
          var _this = this;
          if (!tensors) {
            return null;
          }
          var clonedTensor = tensors.map(function(tensor2) {
            return _this.cloneAndKeepTensor(tensor2);
          });
          return clonedTensor;
        };
        GraphExecutor2.prototype.cloneTensorMap = function(tensorsMap) {
          var _this = this;
          return Object.fromEntries(Object.entries(tensorsMap).map(function(_c) {
            var _d = __read(_c, 2), name = _d[0], tensorsList = _d[1];
            return [name, _this.cloneTensorList(tensorsList)];
          }));
        };
        GraphExecutor2.prototype.execute = function(inputs, outputs) {
          var _this = this;
          this.disposeIntermediateTensors();
          inputs = this.mapInputs(inputs);
          var names = Object.keys(inputs).sort();
          this.checkInputs(inputs);
          this.checkInputShapeAndType(inputs);
          outputs = this.mapOutputs(outputs);
          this.checkOutputs(outputs);
          var inputNodes = names.map(function(name) {
            return _this.graph.nodes[parseNodeName(name)[0]];
          });
          var outputNodeNames = outputs.map(function(name) {
            return parseNodeName(name)[0];
          });
          var outputNodeNameSet = new Set(outputNodeNames);
          var outputNodes = outputNodeNames.map(function(name) {
            return _this.graph.nodes[name];
          });
          if (outputNodes.length === 0) {
            outputNodes = this._outputs;
          }
          var compilationKey = this.getCompilationKey(inputNodes, outputNodes);
          var compilation = this.compiledMap.get(compilationKey);
          if (compilation == null) {
            compilation = this.compile(inputs, outputNodes);
            this.compiledMap.set(compilationKey, compilation);
          }
          try {
            this.keepIntermediateTensors = tfc.env().getBool("KEEP_INTERMEDIATE_TENSORS");
          } catch (e) {
            this.keepIntermediateTensors = false;
            console.warn(e.message);
          }
          var tensorArrayMap = {};
          var tensorListMap = {};
          return tfc.tidy(function() {
            var e_1, _c;
            var context = new ExecutionContext(_this.weightMap, tensorArrayMap, tensorListMap, _this.functionExecutorMap, _this.parseNodeNameCache);
            var tensorsMap = Object.assign({}, _this.weightMap);
            if (_this.keepIntermediateTensors) {
              _this.clonedTensorsMap = _this.cloneTensorMap(_this.weightMap);
            }
            Object.keys(inputs).forEach(function(name) {
              var _c2 = __read(parseNodeName(name, context), 2), nodeName = _c2[0], index = _c2[1];
              var tensors2 = [];
              tensors2[index] = inputs[name];
              tensorsMap[nodeName] = tensors2;
              if (_this.keepIntermediateTensors) {
                _this.clonedTensorsMap[nodeName] = _this.cloneTensorList(tensors2);
              }
            });
            var tensorsToKeep = _this.getFrozenTensorIds(tensorsMap);
            var orderedNodes = compilation.orderedNodes, nodeLiveUntilMap = compilation.nodeLiveUntilMap;
            try {
              for (var orderedNodes_1 = __values(orderedNodes), orderedNodes_1_1 = orderedNodes_1.next(); !orderedNodes_1_1.done; orderedNodes_1_1 = orderedNodes_1.next()) {
                var node = orderedNodes_1_1.value;
                if (tensorsMap[node.name]) {
                  continue;
                }
                var tensors = executeOp(node, tensorsMap, context, _this._resourceManager);
                if (tfc.util.isPromise(tensors)) {
                  throw new Error("The execution of the op '".concat(node.op, "' returned a promise. ") + "Please use model.executeAsync() instead.");
                }
                tensorsMap[node.name] = tensors;
                if (_this.keepIntermediateTensors) {
                  _this.clonedTensorsMap[node.name] = _this.cloneTensorList(tensors);
                }
                _this.checkTensorForDisposalWithNodeLiveUntilInfo(node, tensorsMap, context, tensorsToKeep, outputNodeNameSet, nodeLiveUntilMap.get(node.name));
              }
            } catch (e_1_1) {
              e_1 = { error: e_1_1 };
            } finally {
              try {
                if (orderedNodes_1_1 && !orderedNodes_1_1.done && (_c = orderedNodes_1.return))
                  _c.call(orderedNodes_1);
              } finally {
                if (e_1)
                  throw e_1.error;
              }
            }
            if (_this.parent == null) {
              context.dispose(tensorsToKeep);
            }
            return outputs.map(function(name) {
              return getTensor(name, tensorsMap, context);
            });
          });
        };
        GraphExecutor2.prototype.getFrozenTensorIds = function(tensorMap) {
          var ids = [].concat.apply([], Object.keys(tensorMap).map(function(key) {
            return tensorMap[key];
          }).map(function(tensors) {
            return tensors.map(function(tensor2) {
              return tensor2.id;
            });
          }));
          return new Set(ids);
        };
        GraphExecutor2.prototype.checkTensorForDisposal = function(nodeName, node, tensorMap, context, tensorsToKeep, outputNodeNameSet, intermediateTensorConsumerCount) {
          var e_2, _c, e_3, _d, e_4, _e;
          if (isControlFlow(node) || outputNodeNameSet.has(nodeName)) {
            return;
          }
          try {
            for (var _f = __values(tensorMap[nodeName]), _g = _f.next(); !_g.done; _g = _f.next()) {
              var tensor2 = _g.value;
              if (tensor2 == null) {
                continue;
              }
              intermediateTensorConsumerCount[tensor2.id] = (intermediateTensorConsumerCount[tensor2.id] || 0) + node.children.length;
            }
          } catch (e_2_1) {
            e_2 = { error: e_2_1 };
          } finally {
            try {
              if (_g && !_g.done && (_c = _f.return))
                _c.call(_f);
            } finally {
              if (e_2)
                throw e_2.error;
            }
          }
          try {
            for (var _h = __values(node.inputs), _j = _h.next(); !_j.done; _j = _h.next()) {
              var input = _j.value;
              if (isControlFlow(input)) {
                continue;
              }
              var tensors = getTensorsForCurrentContext(input.name, tensorMap, context);
              if (tensors == null) {
                continue;
              }
              try {
                for (var tensors_1 = (e_4 = void 0, __values(tensors)), tensors_1_1 = tensors_1.next(); !tensors_1_1.done; tensors_1_1 = tensors_1.next()) {
                  var tensor2 = tensors_1_1.value;
                  if (!tensor2 || tensor2.kept || tensorsToKeep.has(tensor2.id)) {
                    continue;
                  }
                  var count = intermediateTensorConsumerCount[tensor2.id];
                  if (count === 1) {
                    tensor2.dispose();
                    delete intermediateTensorConsumerCount[tensor2.id];
                  } else if (count != null) {
                    intermediateTensorConsumerCount[tensor2.id]--;
                  }
                }
              } catch (e_4_1) {
                e_4 = { error: e_4_1 };
              } finally {
                try {
                  if (tensors_1_1 && !tensors_1_1.done && (_e = tensors_1.return))
                    _e.call(tensors_1);
                } finally {
                  if (e_4)
                    throw e_4.error;
                }
              }
            }
          } catch (e_3_1) {
            e_3 = { error: e_3_1 };
          } finally {
            try {
              if (_j && !_j.done && (_d = _h.return))
                _d.call(_h);
            } finally {
              if (e_3)
                throw e_3.error;
            }
          }
        };
        GraphExecutor2.prototype.checkTensorForDisposalWithNodeLiveUntilInfo = function(node, tensorMap, context, tensorsToKeep, outputNodeNameSet, liveUntilNodes) {
          var e_5, _c, e_6, _d;
          function isNonDisposableNode(node2) {
            return isControlFlow(node2) || outputNodeNameSet.has(node2.name);
          }
          if (isControlFlow(node) || liveUntilNodes == null) {
            return;
          }
          try {
            for (var liveUntilNodes_1 = __values(liveUntilNodes), liveUntilNodes_1_1 = liveUntilNodes_1.next(); !liveUntilNodes_1_1.done; liveUntilNodes_1_1 = liveUntilNodes_1.next()) {
              var nodeToDispose = liveUntilNodes_1_1.value;
              if (isNonDisposableNode(nodeToDispose)) {
                continue;
              }
              var tensors = getTensorsForCurrentContext(nodeToDispose.name, tensorMap, context);
              try {
                for (var tensors_2 = (e_6 = void 0, __values(tensors)), tensors_2_1 = tensors_2.next(); !tensors_2_1.done; tensors_2_1 = tensors_2.next()) {
                  var tensor2 = tensors_2_1.value;
                  if (!tensor2 || tensor2.kept || tensorsToKeep.has(tensor2.id)) {
                    continue;
                  }
                  tensor2.dispose();
                }
              } catch (e_6_1) {
                e_6 = { error: e_6_1 };
              } finally {
                try {
                  if (tensors_2_1 && !tensors_2_1.done && (_d = tensors_2.return))
                    _d.call(tensors_2);
                } finally {
                  if (e_6)
                    throw e_6.error;
                }
              }
            }
          } catch (e_5_1) {
            e_5 = { error: e_5_1 };
          } finally {
            try {
              if (liveUntilNodes_1_1 && !liveUntilNodes_1_1.done && (_c = liveUntilNodes_1.return))
                _c.call(liveUntilNodes_1);
            } finally {
              if (e_5)
                throw e_5.error;
            }
          }
        };
        GraphExecutor2.prototype.executeAsync = function(inputs, outputs) {
          return __awaiter(this, void 0, void 0, function() {
            return __generator(this, function(_c) {
              return [2, this._executeAsync(inputs, outputs)];
            });
          });
        };
        GraphExecutor2.prototype.disposeIntermediateTensors = function() {
          if (!this.clonedTensorsMap) {
            return;
          }
          Object.values(this.clonedTensorsMap).forEach(function(tensorsList) {
            var e_7, _c;
            try {
              for (var tensorsList_1 = __values(tensorsList), tensorsList_1_1 = tensorsList_1.next(); !tensorsList_1_1.done; tensorsList_1_1 = tensorsList_1.next()) {
                var tensor2 = tensorsList_1_1.value;
                if (tensor2 && !tensor2.isDisposed) {
                  tensor2.dispose();
                }
              }
            } catch (e_7_1) {
              e_7 = { error: e_7_1 };
            } finally {
              try {
                if (tensorsList_1_1 && !tensorsList_1_1.done && (_c = tensorsList_1.return))
                  _c.call(tensorsList_1);
              } finally {
                if (e_7)
                  throw e_7.error;
              }
            }
          });
          this.clonedTensorsMap = null;
        };
        GraphExecutor2.prototype.getIntermediateTensors = function() {
          return this.clonedTensorsMap;
        };
        GraphExecutor2.prototype._executeAsync = function(inputs, outputs, isFunctionExecution, tensorArrayMap, tensorListMap) {
          if (isFunctionExecution === void 0) {
            isFunctionExecution = false;
          }
          if (tensorArrayMap === void 0) {
            tensorArrayMap = {};
          }
          if (tensorListMap === void 0) {
            tensorListMap = {};
          }
          return __awaiter(this, void 0, void 0, function() {
            var context, tensorsMap, results, outputIds, inputIds, keepIds;
            return __generator(this, function(_c) {
              switch (_c.label) {
                case 0:
                  this.disposeIntermediateTensors();
                  if (!isFunctionExecution) {
                    inputs = this.mapInputs(inputs);
                    this.checkInputs(inputs);
                    this.checkInputShapeAndType(inputs);
                    outputs = this.mapOutputs(outputs);
                    this.checkOutputs(outputs);
                  }
                  try {
                    this.keepIntermediateTensors = tfc.env().getBool("KEEP_INTERMEDIATE_TENSORS");
                  } catch (e) {
                    this.keepIntermediateTensors = false;
                    console.warn(e.message);
                  }
                  context = new ExecutionContext(this.weightMap, tensorArrayMap, tensorListMap, this.functionExecutorMap, this.parseNodeNameCache);
                  if (this.keepIntermediateTensors) {
                    this.clonedTensorsMap = this.cloneTensorMap(this.weightMap);
                  }
                  return [4, this.executeWithControlFlow(inputs, context, outputs, isFunctionExecution)];
                case 1:
                  tensorsMap = _c.sent();
                  results = outputs.map(function(name) {
                    return getTensor(name, tensorsMap, context);
                  });
                  outputIds = results.map(function(t) {
                    return t.id;
                  });
                  inputIds = Object.keys(inputs).map(function(name) {
                    return inputs[name].id;
                  });
                  keepIds = new Set(__spreadArray(__spreadArray(__spreadArray([], __read(outputIds), false), __read(inputIds), false), __read(this.weightIds), false));
                  Object.values(tensorsMap).forEach(function(tensorsList) {
                    tensorsList.forEach(function(tensor2) {
                      if (tensor2 && !tensor2.isDisposed && !keepIds.has(tensor2.id)) {
                        tensor2.dispose();
                      }
                    });
                  });
                  if (this.parent == null) {
                    context.dispose(keepIds);
                  }
                  return [2, results];
              }
            });
          });
        };
        GraphExecutor2.prototype.executeFunctionAsync = function(inputs, tensorArrayMap, tensorListMap) {
          return __awaiter(this, void 0, void 0, function() {
            var mappedInputs;
            var _this = this;
            return __generator(this, function(_c) {
              mappedInputs = inputs.reduce(function(map, tensor2, index) {
                map[_this.inputs[index].name] = tensor2;
                return map;
              }, {});
              return [2, this._executeAsync(mappedInputs, this.outputNodes, true, tensorArrayMap, tensorListMap)];
            });
          });
        };
        GraphExecutor2.prototype.executeWithControlFlow = function(inputs, context, outputNames, isFunctionExecution) {
          return __awaiter(this, void 0, void 0, function() {
            var names, inputNodes, outputNodeNames, outputNodeNameSet, outputNodes, _c, usedNodes, missingInputs, dynamicNode, syncInputs, stack2, tensorsMap, intermediateTensorConsumerCount, tensorsToKeep, added, promises, missingOutputs, alternativeMsg;
            var _this = this;
            return __generator(this, function(_d) {
              switch (_d.label) {
                case 0:
                  names = Object.keys(inputs);
                  inputNodes = names.map(function(name) {
                    return _this.graph.nodes[parseNodeName(name)[0]];
                  });
                  outputNodeNames = outputNames.map(function(name) {
                    return parseNodeName(name)[0];
                  });
                  outputNodeNameSet = new Set(outputNodeNames);
                  outputNodes = outputNodeNames.map(function(name) {
                    return _this.graph.nodes[name];
                  });
                  if (outputNodes.length === 0) {
                    outputNodes = this._outputs;
                  }
                  _c = getExecutionSubgraph(inputs, outputNodes, this.weightMap, this._initNodes), usedNodes = _c.usedNodes, missingInputs = _c.missingInputs, dynamicNode = _c.dynamicNode, syncInputs = _c.syncInputs;
                  stack2 = __spreadArray(__spreadArray(__spreadArray([], __read(inputNodes), false), __read(this.graph.weights), false), __read(this._initNodes || []), false).map(function(node) {
                    return { node, contexts: context.currentContext };
                  });
                  tensorsMap = Object.assign({}, this.weightMap);
                  Object.keys(inputs).forEach(function(name) {
                    var _c2 = __read(parseNodeName(name), 2), nodeName = _c2[0], index = _c2[1];
                    var tensors = [];
                    tensors[index] = inputs[name];
                    tensorsMap[nodeName] = tensors;
                  });
                  intermediateTensorConsumerCount = {};
                  tensorsToKeep = this.getFrozenTensorIds(tensorsMap);
                  added = {};
                  _d.label = 1;
                case 1:
                  if (!(stack2.length > 0))
                    return [3, 3];
                  promises = this.processStack(inputNodes, stack2, context, tensorsMap, added, tensorsToKeep, outputNodeNameSet, intermediateTensorConsumerCount, usedNodes);
                  return [4, Promise.all(promises)];
                case 2:
                  _d.sent();
                  return [3, 1];
                case 3:
                  if (dynamicNode == null && !isFunctionExecution) {
                    console.warn("This model execution did not contain any nodes with control flow or dynamic output shapes. You can use model.execute() instead.");
                  }
                  missingOutputs = outputNodes.filter(function(node) {
                    return !isControlFlow(node) && !getTensor(node.name, tensorsMap, context);
                  }).map(function(node) {
                    return node.name;
                  });
                  if (missingOutputs.length > 0) {
                    alternativeMsg = "";
                    if (dynamicNode != null) {
                      alternativeMsg = "Alternatively, to avoid the dynamic ops, use model.execute() " + "and specify the inputs [".concat(syncInputs, "]");
                    }
                    throw new Error("Cannot compute the outputs [".concat(missingOutputs, "] from the provided ") + "inputs [".concat(names, "]. Consider providing the following inputs: ") + "[".concat(missingInputs, "]. ").concat(alternativeMsg));
                  }
                  return [2, tensorsMap];
              }
            });
          });
        };
        GraphExecutor2.prototype.processStack = function(inputNodes, stack2, context, tensorMap, added, tensorsToKeep, outputNodeNameSet, intermediateTensorConsumerCount, usedNodes) {
          var _this = this;
          var promises = [];
          var _loop_1 = function() {
            var _c, _d;
            var item = stack2.pop();
            context.currentContext = item.contexts;
            var nodeName = "";
            if (item.node.op === "Enter" && getParamValue("isConstant", item.node, tensorMap, context)) {
              _c = __read(getNodeNameAndIndex(item.node.name, context), 1), nodeName = _c[0];
            }
            if (tensorMap[item.node.name] == null) {
              var tensors = executeOp(item.node, tensorMap, context, this_1._resourceManager);
              if (!nodeName) {
                _d = __read(getNodeNameAndIndex(item.node.name, context), 1), nodeName = _d[0];
              }
              var currentContext_1 = context.currentContext;
              if (tfc.util.isPromise(tensors)) {
                promises.push(tensors.then(function(t) {
                  tensorMap[nodeName] = t;
                  if (_this.keepIntermediateTensors) {
                    _this.clonedTensorsMap[nodeName] = _this.cloneTensorList(t);
                  }
                  context.currentContext = currentContext_1;
                  _this.checkTensorForDisposal(nodeName, item.node, tensorMap, context, tensorsToKeep, outputNodeNameSet, intermediateTensorConsumerCount);
                  _this.processChildNodes(item.node, stack2, context, tensorMap, added, usedNodes);
                  return t;
                }));
              } else {
                tensorMap[nodeName] = tensors;
                if (this_1.keepIntermediateTensors) {
                  this_1.clonedTensorsMap[nodeName] = this_1.cloneTensorList(tensors);
                }
                this_1.checkTensorForDisposal(nodeName, item.node, tensorMap, context, tensorsToKeep, outputNodeNameSet, intermediateTensorConsumerCount);
                this_1.processChildNodes(item.node, stack2, context, tensorMap, added, usedNodes);
              }
            } else {
              this_1.processChildNodes(item.node, stack2, context, tensorMap, added, usedNodes);
            }
          };
          var this_1 = this;
          while (stack2.length > 0) {
            _loop_1();
          }
          return promises;
        };
        GraphExecutor2.prototype.processChildNodes = function(node, stack2, context, tensorMap, added, usedNodes) {
          node.children.forEach(function(childNode) {
            var _c = __read(getNodeNameAndIndex(childNode.name, context), 1), nodeName = _c[0];
            if (added[nodeName] || !usedNodes.has(childNode.name)) {
              return;
            }
            if (childNode.op === "Merge") {
              if (childNode.inputNames.some(function(name) {
                return !!getTensor(name, tensorMap, context);
              })) {
                added[nodeName] = true;
                stack2.push({ contexts: context.currentContext, node: childNode });
              }
            } else if (childNode.inputNames.every(function(name) {
              return !!getTensor(name, tensorMap, context);
            })) {
              added[nodeName] = true;
              stack2.push({ contexts: context.currentContext, node: childNode });
            }
          });
        };
        GraphExecutor2.prototype.dispose = function() {
          var _this = this;
          Object.keys(this.weightMap).forEach(function(key) {
            return _this.weightMap[key].forEach(function(tensor2) {
              return tensor2.dispose();
            });
          });
        };
        GraphExecutor2.prototype.checkInputShapeAndType = function(inputs) {
          var _this = this;
          Object.keys(inputs).forEach(function(name) {
            var input = inputs[name];
            var _c = __read(parseNodeName(name), 1), nodeName = _c[0];
            var node = _this.graph.nodes[nodeName];
            if (node.attrParams["shape"] && node.attrParams["shape"].value) {
              var shape_1 = node.attrParams["shape"].value;
              var match = shape_1.length === input.shape.length && input.shape.every(function(dim, index) {
                return shape_1[index] === -1 || shape_1[index] === dim;
              });
              tfc.util.assert(match, function() {
                return "The shape of dict['".concat(node.name, "'] provided in ") + "model.execute(dict) must be [".concat(shape_1, "], but was ") + "[".concat(input.shape, "]");
              });
            }
            if (node.attrParams["dtype"] && node.attrParams["dtype"].value) {
              tfc.util.assert(input.dtype === node.attrParams["dtype"].value, function() {
                return "The dtype of dict['".concat(node.name, "'] provided in ") + "model.execute(dict) must be " + "".concat(node.attrParams["dtype"].value, ", but was ").concat(input.dtype);
              });
            }
          });
        };
        GraphExecutor2.prototype.mapInputs = function(inputs) {
          var _a, _b;
          var result = {};
          for (var inputName in inputs) {
            var tensor2 = (_b = (_a = this._signature) === null || _a === void 0 ? void 0 : _a.inputs) === null || _b === void 0 ? void 0 : _b[inputName];
            if (tensor2 != null) {
              result[tensor2.name] = inputs[inputName];
            } else {
              result[inputName] = inputs[inputName];
            }
          }
          return result;
        };
        GraphExecutor2.prototype.checkInputs = function(inputs) {
          var _this = this;
          var notInGraph = Object.keys(inputs).filter(function(name) {
            var _c = __read(parseNodeName(name), 1), nodeName = _c[0];
            return _this.graph.nodes[nodeName] == null;
          });
          if (notInGraph.length > 0) {
            throw new Error("The dict provided in model.execute(dict) has " + "keys: [".concat(notInGraph, "] that are not part of graph"));
          }
        };
        GraphExecutor2.prototype.mapOutputs = function(outputs) {
          var _this = this;
          return outputs.map(function(name) {
            var _a, _b;
            var tensor2 = (_b = (_a = _this._signature) === null || _a === void 0 ? void 0 : _a.outputs) === null || _b === void 0 ? void 0 : _b[name];
            if (tensor2 != null) {
              return tensor2.name;
            }
            return name;
          }, {});
        };
        GraphExecutor2.prototype.checkOutputs = function(outputs) {
          var _this = this;
          outputs.forEach(function(name) {
            var _c = __read(parseNodeName(name), 1), normalizedName = _c[0];
            if (!_this.graph.nodes[normalizedName]) {
              throw new Error("The output '".concat(name, "' is not found in the graph"));
            }
          });
        };
        return GraphExecutor2;
      }()
    );
    var ResourceManager = (
      /** @class */
      function() {
        function ResourceManager2(hashTableNameToHandle, hashTableMap) {
          if (hashTableNameToHandle === void 0) {
            hashTableNameToHandle = {};
          }
          if (hashTableMap === void 0) {
            hashTableMap = {};
          }
          this.hashTableNameToHandle = hashTableNameToHandle;
          this.hashTableMap = hashTableMap;
        }
        ResourceManager2.prototype.addHashTable = function(name, hashTable2) {
          this.hashTableNameToHandle[name] = hashTable2.handle;
          this.hashTableMap[hashTable2.id] = hashTable2;
        };
        ResourceManager2.prototype.getHashTableHandleByName = function(name) {
          return this.hashTableNameToHandle[name];
        };
        ResourceManager2.prototype.getHashTableById = function(id) {
          return this.hashTableMap[id];
        };
        ResourceManager2.prototype.dispose = function() {
          for (var key in this.hashTableMap) {
            this.hashTableMap[key].clearAndClose();
            delete this.hashTableMap[key];
          }
          for (var name in this.hashTableNameToHandle) {
            this.hashTableNameToHandle[name].dispose();
            delete this.hashTableNameToHandle[name];
          }
        };
        return ResourceManager2;
      }()
    );
    var TFHUB_SEARCH_PARAM = "?tfjs-format=file";
    var DEFAULT_MODEL_NAME = "model.json";
    var GraphModel = (
      /** @class */
      function() {
        function GraphModel2(modelUrl, loadOptions, tfio) {
          if (loadOptions === void 0) {
            loadOptions = {};
          }
          if (tfio === void 0) {
            tfio = tfc.io;
          }
          this.modelUrl = modelUrl;
          this.loadOptions = loadOptions;
          this.version = "n/a";
          this.io = tfio;
          if (loadOptions == null) {
            this.loadOptions = {};
          }
          this.resourceManager = new ResourceManager();
        }
        Object.defineProperty(GraphModel2.prototype, "modelVersion", {
          // Returns the version information for the tensorflow model GraphDef.
          get: function() {
            return this.version;
          },
          enumerable: false,
          configurable: true
        });
        Object.defineProperty(GraphModel2.prototype, "inputNodes", {
          get: function() {
            return this.executor.inputNodes;
          },
          enumerable: false,
          configurable: true
        });
        Object.defineProperty(GraphModel2.prototype, "outputNodes", {
          get: function() {
            return this.executor.outputNodes;
          },
          enumerable: false,
          configurable: true
        });
        Object.defineProperty(GraphModel2.prototype, "inputs", {
          get: function() {
            return this.executor.inputs;
          },
          enumerable: false,
          configurable: true
        });
        Object.defineProperty(GraphModel2.prototype, "outputs", {
          get: function() {
            return this.executor.outputs;
          },
          enumerable: false,
          configurable: true
        });
        Object.defineProperty(GraphModel2.prototype, "weights", {
          get: function() {
            return this.executor.weightMap;
          },
          enumerable: false,
          configurable: true
        });
        Object.defineProperty(GraphModel2.prototype, "metadata", {
          get: function() {
            return this.artifacts.userDefinedMetadata;
          },
          enumerable: false,
          configurable: true
        });
        Object.defineProperty(GraphModel2.prototype, "modelSignature", {
          get: function() {
            return this.signature;
          },
          enumerable: false,
          configurable: true
        });
        Object.defineProperty(GraphModel2.prototype, "modelStructuredOutputKeys", {
          get: function() {
            return this.structuredOutputKeys;
          },
          enumerable: false,
          configurable: true
        });
        GraphModel2.prototype.findIOHandler = function() {
          var path = this.modelUrl;
          if (path.load != null) {
            this.handler = path;
          } else if (this.loadOptions.requestInit != null) {
            this.handler = this.io.browserHTTPRequest(path, this.loadOptions);
          } else {
            var handlers = this.io.getLoadHandlers(path, this.loadOptions);
            if (handlers.length === 0) {
              handlers.push(this.io.browserHTTPRequest(path, this.loadOptions));
            } else if (handlers.length > 1) {
              throw new Error("Found more than one (".concat(handlers.length, ") load handlers for ") + "URL '".concat([path], "'"));
            }
            this.handler = handlers[0];
          }
        };
        GraphModel2.prototype.load = function() {
          var _this = this;
          this.findIOHandler();
          if (this.handler.load == null) {
            throw new Error("Cannot proceed with model loading because the IOHandler provided does not have the `load` method implemented.");
          }
          var loadResult = this.handler.load();
          if (tfc.util.isPromise(loadResult)) {
            return loadResult.then(function(artifacts) {
              return _this.loadSync(artifacts);
            });
          }
          return this.loadSync(loadResult);
        };
        GraphModel2.prototype.loadSync = function(artifacts) {
          this.artifacts = artifacts;
          var graph2 = this.artifacts.modelTopology;
          var signature = this.artifacts.signature;
          if (this.artifacts.userDefinedMetadata != null) {
            var metadata = this.artifacts.userDefinedMetadata;
            if (metadata.signature != null) {
              signature = metadata.signature;
            }
            if (metadata.structuredOutputKeys != null) {
              this.structuredOutputKeys = metadata.structuredOutputKeys;
            }
          }
          this.signature = signature;
          this.version = "".concat(graph2.versions.producer, ".").concat(graph2.versions.minConsumer);
          var weightMap = this.io.decodeWeights(this.artifacts.weightData, this.artifacts.weightSpecs);
          this.executor = new GraphExecutor(OperationMapper.Instance.transformGraph(graph2, this.signature));
          this.executor.weightMap = this.convertTensorMapToTensorsMap(weightMap);
          this.executor.resourceManager = this.resourceManager;
          if (artifacts.modelInitializer != null && artifacts.modelInitializer.node != null) {
            var initializer = OperationMapper.Instance.transformGraph(artifacts.modelInitializer);
            this.initializer = new GraphExecutor(initializer);
            this.initializer.weightMap = this.executor.weightMap;
            this.initializer.resourceManager = this.resourceManager;
            this.initializerSignature = artifacts.initializerSignature;
          }
          return true;
        };
        GraphModel2.prototype.save = function(handlerOrURL, config) {
          return __awaiter(this, void 0, void 0, function() {
            var handlers;
            return __generator(this, function(_d) {
              if (typeof handlerOrURL === "string") {
                handlers = this.io.getSaveHandlers(handlerOrURL);
                if (handlers.length === 0) {
                  throw new Error("Cannot find any save handlers for URL '".concat(handlerOrURL, "'"));
                } else if (handlers.length > 1) {
                  throw new Error("Found more than one (".concat(handlers.length, ") save handlers for ") + "URL '".concat(handlerOrURL, "'"));
                }
                handlerOrURL = handlers[0];
              }
              if (handlerOrURL.save == null) {
                throw new Error("GraphModel.save() cannot proceed because the IOHandler provided does not have the `save` attribute defined.");
              }
              return [2, handlerOrURL.save(this.artifacts)];
            });
          });
        };
        GraphModel2.prototype.addStructuredOutputNames = function(outputTensors) {
          var _this = this;
          if (this.structuredOutputKeys) {
            var outputTensorsArray = outputTensors instanceof tfc.Tensor ? [outputTensors] : outputTensors;
            var outputTensorMap_1 = {};
            outputTensorsArray.forEach(function(outputTensor, i) {
              return outputTensorMap_1[_this.structuredOutputKeys[i]] = outputTensor;
            });
            return outputTensorMap_1;
          }
          return outputTensors;
        };
        GraphModel2.prototype.predict = function(inputs, config) {
          var outputTensors = this.execute(inputs, this.outputNodes);
          return this.addStructuredOutputNames(outputTensors);
        };
        GraphModel2.prototype.predictAsync = function(inputs, config) {
          return __awaiter(this, void 0, void 0, function() {
            var outputTensors;
            return __generator(this, function(_d) {
              switch (_d.label) {
                case 0:
                  return [4, this.executeAsync(inputs, this.outputNodes)];
                case 1:
                  outputTensors = _d.sent();
                  return [2, this.addStructuredOutputNames(outputTensors)];
              }
            });
          });
        };
        GraphModel2.prototype.normalizeInputs = function(inputs) {
          var _this = this;
          var _a;
          if (!(inputs instanceof tfc.Tensor) && !Array.isArray(inputs)) {
            var signatureInputs = (_a = this.signature) === null || _a === void 0 ? void 0 : _a.inputs;
            if (signatureInputs != null) {
              for (var input in signatureInputs) {
                var tensor2 = signatureInputs[input];
                if (tensor2.resourceId != null) {
                  inputs[input] = this.resourceIdToCapturedInput[tensor2.resourceId];
                }
              }
            }
            return inputs;
          }
          inputs = Array.isArray(inputs) ? inputs : [inputs];
          var numCapturedInputs = Object.keys(this.resourceIdToCapturedInput).length;
          if (inputs.length + numCapturedInputs !== this.inputNodes.length) {
            throw new Error("Input tensor count mismatch, the graph model has ".concat(this.inputNodes.length - numCapturedInputs, " non-resource placeholders, while there are ").concat(inputs.length, " input tensors provided."));
          }
          var inputIndex = 0;
          return this.inputNodes.reduce(function(map, inputName) {
            var _a2, _b, _c;
            var resourceId = (_c = (_b = (_a2 = _this.signature) === null || _a2 === void 0 ? void 0 : _a2.inputs) === null || _b === void 0 ? void 0 : _b[inputName]) === null || _c === void 0 ? void 0 : _c.resourceId;
            if (resourceId != null) {
              map[inputName] = _this.resourceIdToCapturedInput[resourceId];
            } else {
              map[inputName] = inputs[inputIndex++];
            }
            return map;
          }, {});
        };
        GraphModel2.prototype.normalizeOutputs = function(outputs) {
          outputs = outputs || this.outputNodes;
          return !Array.isArray(outputs) ? [outputs] : outputs;
        };
        GraphModel2.prototype.executeInitializerGraph = function() {
          if (this.initializer == null) {
            return [];
          }
          if (this.initializerSignature == null) {
            return this.initializer.execute({}, []);
          } else {
            return this.initializer.execute({}, Object.keys(this.initializerSignature.outputs));
          }
        };
        GraphModel2.prototype.executeInitializerGraphAsync = function() {
          return __awaiter(this, void 0, void 0, function() {
            return __generator(this, function(_d) {
              if (this.initializer == null) {
                return [2, []];
              }
              if (this.initializerSignature == null) {
                return [2, this.initializer.executeAsync({}, [])];
              } else {
                return [2, this.initializer.executeAsync({}, Object.keys(this.initializerSignature.outputs))];
              }
            });
          });
        };
        GraphModel2.prototype.setResourceIdToCapturedInput = function(outputs) {
          this.resourceIdToCapturedInput = {};
          if (this.initializerSignature) {
            var signatureOutputs = this.initializerSignature.outputs;
            var outputNames = Object.keys(signatureOutputs);
            for (var i = 0; i < outputNames.length; i++) {
              var outputName = outputNames[i];
              var tensorInfo = signatureOutputs[outputName];
              this.resourceIdToCapturedInput[tensorInfo.resourceId] = outputs[i];
            }
          }
        };
        GraphModel2.prototype.execute = function(inputs, outputs) {
          if (this.resourceIdToCapturedInput == null) {
            this.setResourceIdToCapturedInput(this.executeInitializerGraph());
          }
          inputs = this.normalizeInputs(inputs);
          outputs = this.normalizeOutputs(outputs);
          var result = this.executor.execute(inputs, outputs);
          return result.length > 1 ? result : result[0];
        };
        GraphModel2.prototype.executeAsync = function(inputs, outputs) {
          return __awaiter(this, void 0, void 0, function() {
            var _d, result;
            return __generator(this, function(_e) {
              switch (_e.label) {
                case 0:
                  if (!(this.resourceIdToCapturedInput == null))
                    return [3, 2];
                  _d = this.setResourceIdToCapturedInput;
                  return [4, this.executeInitializerGraphAsync()];
                case 1:
                  _d.apply(this, [_e.sent()]);
                  _e.label = 2;
                case 2:
                  inputs = this.normalizeInputs(inputs);
                  outputs = this.normalizeOutputs(outputs);
                  return [4, this.executor.executeAsync(inputs, outputs)];
                case 3:
                  result = _e.sent();
                  return [2, result.length > 1 ? result : result[0]];
              }
            });
          });
        };
        GraphModel2.prototype.getIntermediateTensors = function() {
          return this.executor.getIntermediateTensors();
        };
        GraphModel2.prototype.disposeIntermediateTensors = function() {
          this.executor.disposeIntermediateTensors();
        };
        GraphModel2.prototype.convertTensorMapToTensorsMap = function(map) {
          return Object.keys(map).reduce(function(newMap, key) {
            newMap[key] = [map[key]];
            return newMap;
          }, {});
        };
        GraphModel2.prototype.dispose = function() {
          this.executor.dispose();
          if (this.initializer) {
            this.initializer.dispose();
            if (this.resourceIdToCapturedInput) {
              tfc.dispose(this.resourceIdToCapturedInput);
            }
          }
          this.resourceManager.dispose();
        };
        return GraphModel2;
      }()
    );
    function loadGraphModel(modelUrl, options, tfio) {
      if (options === void 0) {
        options = {};
      }
      if (tfio === void 0) {
        tfio = tfc.io;
      }
      return __awaiter(this, void 0, void 0, function() {
        var model;
        return __generator(this, function(_d) {
          switch (_d.label) {
            case 0:
              if (modelUrl == null) {
                throw new Error("modelUrl in loadGraphModel() cannot be null. Please provide a url or an IOHandler that loads the model");
              }
              if (options == null) {
                options = {};
              }
              if (options.fromTFHub && typeof modelUrl === "string") {
                modelUrl = getTFHubUrl(modelUrl);
              }
              model = new GraphModel(modelUrl, options, tfio);
              return [4, model.load()];
            case 1:
              _d.sent();
              return [2, model];
          }
        });
      });
    }
    function loadGraphModelSync(modelSource) {
      if (modelSource == null) {
        throw new Error("modelUrl in loadGraphModelSync() cannot be null. Please provide model artifacts or an IOHandler that loads the model");
      }
      var ioHandler;
      if (modelSource instanceof Array) {
        var _d = __read(modelSource, 2), modelJSON = _d[0], weights = _d[1];
        if (!modelJSON) {
          throw new Error("modelJSON must be the first element of the array");
        }
        if (!weights || !(weights instanceof ArrayBuffer)) {
          throw new Error("An ArrayBuffer of weights must be the second element of the array");
        }
        if (!("modelTopology" in modelJSON)) {
          throw new Error("Model JSON is missing 'modelTopology'");
        }
        if (!("weightsManifest" in modelJSON)) {
          throw new Error("Model JSON is missing 'weightsManifest'");
        }
        var weightSpecs = tfc.io.getWeightSpecs(modelJSON.weightsManifest);
        var modelArtifacts = tfc.io.getModelArtifactsForJSONSync(modelJSON, weightSpecs, weights);
        ioHandler = tfc.io.fromMemorySync(modelArtifacts);
      } else if ("load" in modelSource) {
        ioHandler = modelSource;
      } else if ("modelTopology" in modelSource && "weightSpecs" in modelSource && "weightData" in modelSource) {
        ioHandler = tfc.io.fromMemorySync(modelSource);
      } else {
        throw new Error("Unknown model format");
      }
      var model = new GraphModel(ioHandler);
      model.load();
      return model;
    }
    function getTFHubUrl(modelUrl) {
      if (!modelUrl.endsWith("/")) {
        modelUrl = modelUrl + "/";
      }
      return "".concat(modelUrl).concat(DEFAULT_MODEL_NAME).concat(TFHUB_SEARCH_PARAM);
    }
    var version2 = "4.5.0";
    exports.GraphModel = GraphModel;
    exports.deregisterOp = deregisterOp;
    exports.loadGraphModel = loadGraphModel;
    exports.loadGraphModelSync = loadGraphModelSync;
    exports.registerOp = registerOp;
    exports.version_converter = version2;
  }
});

// ../../node_modules/@tensorflow/tfjs-backend-wasm/dist/tf-backend-wasm.node.js
var require_tf_backend_wasm_node = __commonJS({
  "../../node_modules/@tensorflow/tfjs-backend-wasm/dist/tf-backend-wasm.node.js"(exports) {
    "use strict";
    var tfjsCore = require_tf_core_node();
    var require$$0 = require("fs");
    var require$$1 = require("path");
    var require$$3 = require("perf_hooks");
    var require$$4 = require("os");
    function _mergeNamespaces(n, m) {
      m.forEach(function(e) {
        e && typeof e !== "string" && !Array.isArray(e) && Object.keys(e).forEach(function(k) {
          if (k !== "default" && !(k in n)) {
            var d = Object.getOwnPropertyDescriptor(e, k);
            Object.defineProperty(n, k, d.get ? d : {
              enumerable: true,
              get: function() {
                return e[k];
              }
            });
          }
        });
      });
      return n;
    }
    var extendStatics = function(d, b) {
      extendStatics = Object.setPrototypeOf || { __proto__: [] } instanceof Array && function(d2, b2) {
        d2.__proto__ = b2;
      } || function(d2, b2) {
        for (var p in b2)
          if (Object.prototype.hasOwnProperty.call(b2, p))
            d2[p] = b2[p];
      };
      return extendStatics(d, b);
    };
    function __extends(d, b) {
      if (typeof b !== "function" && b !== null)
        throw new TypeError("Class extends value " + String(b) + " is not a constructor or null");
      extendStatics(d, b);
      function __() {
        this.constructor = d;
      }
      d.prototype = b === null ? Object.create(b) : (__.prototype = b.prototype, new __());
    }
    function __awaiter(thisArg, _arguments, P, generator) {
      function adopt(value) {
        return value instanceof P ? value : new P(function(resolve2) {
          resolve2(value);
        });
      }
      return new (P || (P = Promise))(function(resolve2, reject) {
        function fulfilled(value) {
          try {
            step2(generator.next(value));
          } catch (e) {
            reject(e);
          }
        }
        function rejected(value) {
          try {
            step2(generator["throw"](value));
          } catch (e) {
            reject(e);
          }
        }
        function step2(result) {
          result.done ? resolve2(result.value) : adopt(result.value).then(fulfilled, rejected);
        }
        step2((generator = generator.apply(thisArg, _arguments || [])).next());
      });
    }
    function __generator(thisArg, body) {
      var _ = { label: 0, sent: function() {
        if (t[0] & 1)
          throw t[1];
        return t[1];
      }, trys: [], ops: [] }, f, y, t, g;
      return g = { next: verb(0), "throw": verb(1), "return": verb(2) }, typeof Symbol === "function" && (g[Symbol.iterator] = function() {
        return this;
      }), g;
      function verb(n) {
        return function(v) {
          return step2([n, v]);
        };
      }
      function step2(op) {
        if (f)
          throw new TypeError("Generator is already executing.");
        while (_)
          try {
            if (f = 1, y && (t = op[0] & 2 ? y["return"] : op[0] ? y["throw"] || ((t = y["return"]) && t.call(y), 0) : y.next) && !(t = t.call(y, op[1])).done)
              return t;
            if (y = 0, t)
              op = [op[0] & 2, t.value];
            switch (op[0]) {
              case 0:
              case 1:
                t = op;
                break;
              case 4:
                _.label++;
                return { value: op[1], done: false };
              case 5:
                _.label++;
                y = op[1];
                op = [0];
                continue;
              case 7:
                op = _.ops.pop();
                _.trys.pop();
                continue;
              default:
                if (!(t = _.trys, t = t.length > 0 && t[t.length - 1]) && (op[0] === 6 || op[0] === 2)) {
                  _ = 0;
                  continue;
                }
                if (op[0] === 3 && (!t || op[1] > t[0] && op[1] < t[3])) {
                  _.label = op[1];
                  break;
                }
                if (op[0] === 6 && _.label < t[1]) {
                  _.label = t[1];
                  t = op;
                  break;
                }
                if (t && _.label < t[2]) {
                  _.label = t[2];
                  _.ops.push(op);
                  break;
                }
                if (t[2])
                  _.ops.pop();
                _.trys.pop();
                continue;
            }
            op = body.call(thisArg, _);
          } catch (e) {
            op = [6, e];
            y = 0;
          } finally {
            f = t = 0;
          }
        if (op[0] & 5)
          throw op[1];
        return { value: op[0] ? op[1] : void 0, done: true };
      }
    }
    function __values(o) {
      var s = typeof Symbol === "function" && Symbol.iterator, m = s && o[s], i = 0;
      if (m)
        return m.call(o);
      if (o && typeof o.length === "number")
        return {
          next: function() {
            if (o && i >= o.length)
              o = void 0;
            return { value: o && o[i++], done: !o };
          }
        };
      throw new TypeError(s ? "Object is not iterable." : "Symbol.iterator is not defined.");
    }
    function __read(o, n) {
      var m = typeof Symbol === "function" && o[Symbol.iterator];
      if (!m)
        return o;
      var i = m.call(o), r, ar = [], e;
      try {
        while ((n === void 0 || n-- > 0) && !(r = i.next()).done)
          ar.push(r.value);
      } catch (error) {
        e = { error };
      } finally {
        try {
          if (r && !r.done && (m = i["return"]))
            m.call(i);
        } finally {
          if (e)
            throw e.error;
        }
      }
      return ar;
    }
    function __spreadArray(to, from, pack2) {
      if (pack2 || arguments.length === 2)
        for (var i = 0, l = from.length, ar; i < l; i++) {
          if (ar || !(i in from)) {
            if (!ar)
              ar = Array.prototype.slice.call(from, 0, i);
            ar[i] = from[i];
          }
        }
      return to.concat(ar || Array.prototype.slice.call(from));
    }
    var CppDType;
    (function(CppDType2) {
      CppDType2[CppDType2["float32"] = 0] = "float32";
      CppDType2[CppDType2["int32"] = 1] = "int32";
      CppDType2[CppDType2["bool"] = 2] = "bool";
      CppDType2[CppDType2["string"] = 3] = "string";
      CppDType2[CppDType2["complex64"] = 4] = "complex64";
    })(CppDType || (CppDType = {}));
    var FusableActivation;
    (function(FusableActivation2) {
      FusableActivation2[FusableActivation2["linear"] = 0] = "linear";
      FusableActivation2[FusableActivation2["relu"] = 1] = "relu";
      FusableActivation2[FusableActivation2["relu6"] = 2] = "relu6";
      FusableActivation2[FusableActivation2["prelu"] = 3] = "prelu";
      FusableActivation2[FusableActivation2["leakyrelu"] = 4] = "leakyrelu";
      FusableActivation2[FusableActivation2["sigmoid"] = 5] = "sigmoid";
      FusableActivation2[FusableActivation2["elu"] = 6] = "elu";
    })(FusableActivation || (FusableActivation = {}));
    var wasmFusedMatMul;
    function setup$17(backend) {
      wasmFusedMatMul = backend.wasm.cwrap(tfjsCore._FusedMatMul, null, [
        "number",
        "array",
        "number",
        "number",
        "array",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number"
        // out_id
      ]);
    }
    function fusedBatchMatMul(args) {
      var inputs = args.inputs, backend = args.backend, attrs = args.attrs;
      var a = inputs.a, b = inputs.b, bias = inputs.bias, preluActivationWeights = inputs.preluActivationWeights;
      if (a.dtype !== "float32" || b.dtype !== "float32") {
        throw new Error("_FusedMatMul for non non-float32 tensors not yet supported.");
      }
      var transposeA = attrs.transposeA, transposeB = attrs.transposeB, activation = attrs.activation, leakyreluAlpha = attrs.leakyreluAlpha;
      var aId = backend.dataIdMap.get(a.dataId).id;
      var bId = backend.dataIdMap.get(b.dataId).id;
      var biasId = 0;
      if (bias != null) {
        var biasData = backend.dataIdMap.get(bias.dataId);
        if (biasData.shape.length !== 1) {
          throw new Error("_FusedMatMul only supports rank-1 bias but got " + "rank ".concat(biasData.shape.length, "."));
        }
        biasId = biasData.id;
      }
      var preluActivationWeightsId = preluActivationWeights == null ? 0 : backend.dataIdMap.get(preluActivationWeights.dataId).id;
      var fusedActivation = FusableActivation[activation];
      if (fusedActivation == null) {
        throw new Error("".concat(activation, " activation not yet supported for FusedConv2D ") + "in the wasm backend.");
      }
      var leftDim = transposeA ? a.shape[2] : a.shape[1];
      var rightDim = transposeB ? b.shape[1] : b.shape[2];
      var batchDims = tfjsCore.broadcast_util.assertAndGetBroadcastShape(a.shape.slice(0, -2), b.shape.slice(0, -2));
      var out = backend.makeOutput(__spreadArray(__spreadArray([], __read(batchDims), false), [leftDim, rightDim], false), a.dtype);
      var outId = backend.dataIdMap.get(out.dataId).id;
      var aShapeBytes = new Uint8Array(new Int32Array(a.shape).buffer);
      var bShapeBytes = new Uint8Array(new Int32Array(b.shape).buffer);
      wasmFusedMatMul(aId, aShapeBytes, a.shape.length, bId, bShapeBytes, b.shape.length, transposeA, transposeB, fusedActivation, biasId, preluActivationWeightsId, leakyreluAlpha || 0, outId);
      return out;
    }
    var _fusedMatMulConfig = {
      kernelName: tfjsCore._FusedMatMul,
      backendName: "wasm",
      setupFunc: setup$17,
      kernelFunc: fusedBatchMatMul
    };
    function createUnaryKernelConfig(kernelName, outType) {
      var wasmFunc2;
      function setupFunc2(backend) {
        wasmFunc2 = backend.wasm.cwrap(kernelName, null, [
          "number",
          "number",
          "number"
          // out_id
        ]);
      }
      function kernelFunc2(args) {
        var backend = args.backend, x = args.inputs.x;
        var xId = backend.dataIdMap.get(x.dataId).id;
        var out = backend.makeOutput(x.shape, outType || x.dtype);
        var outId = backend.dataIdMap.get(out.dataId).id;
        if (tfjsCore.util.sizeFromShape(out.shape) === 0) {
          return out;
        }
        wasmFunc2(xId, CppDType[x.dtype], outId);
        return out;
      }
      return { kernelName, backendName: "wasm", setupFunc: setupFunc2, kernelFunc: kernelFunc2 };
    }
    var absConfig = createUnaryKernelConfig(tfjsCore.Abs);
    var acosConfig = createUnaryKernelConfig(tfjsCore.Acos);
    var acoshConfig = createUnaryKernelConfig(tfjsCore.Acosh);
    function createBinaryKernelConfig(kernelName, supportsFullBroadcast2, dtype) {
      var wasmFunc2;
      function setupFunc2(backend) {
        wasmFunc2 = backend.wasm.cwrap(kernelName, null, [
          "number",
          "array",
          "number",
          "number",
          "array",
          "number",
          "number",
          "number"
          // out_id
        ]);
      }
      function kernelFunc2(args) {
        var backend = args.backend, inputs = args.inputs;
        var a = inputs.a, b = inputs.b;
        var aId = backend.dataIdMap.get(a.dataId).id;
        var bId = backend.dataIdMap.get(b.dataId).id;
        var outputType = dtype != null ? dtype : a.dtype;
        var newShape = tfjsCore.backend_util.assertAndGetBroadcastShape(a.shape, b.shape);
        var out = backend.makeOutput(newShape, outputType);
        if (tfjsCore.util.sizeFromShape(newShape) === 0) {
          return out;
        }
        var aShapeBytes = new Uint8Array(new Int32Array(a.shape).buffer);
        var bShapeBytes = new Uint8Array(new Int32Array(b.shape).buffer);
        var outId = backend.dataIdMap.get(out.dataId).id;
        var kernelFunc3 = function() {
          return wasmFunc2(aId, aShapeBytes, a.shape.length, bId, bShapeBytes, b.shape.length, CppDType[a.dtype], outId);
        };
        kernelFunc3();
        return out;
      }
      return { kernelName, backendName: "wasm", setupFunc: setupFunc2, kernelFunc: kernelFunc2 };
    }
    var addConfig = createBinaryKernelConfig(tfjsCore.Add);
    var wasmFunc$6;
    function setupFunc$1(backend) {
      wasmFunc$6 = backend.wasm.cwrap(tfjsCore.AddN, null, [
        "array",
        "number",
        "number",
        "number"
        // out_id
      ]);
    }
    function addn(args) {
      var inputs = args.inputs, backend = args.backend;
      var out = backend.makeOutput(inputs[0].shape, inputs[0].dtype);
      if (tfjsCore.util.sizeFromShape(out.shape) === 0) {
        return out;
      }
      var inputIds = inputs.map(function(x) {
        return backend.dataIdMap.get(x.dataId).id;
      });
      var inputIdsBytes = new Uint8Array(new Int32Array(inputIds).buffer);
      var outId = backend.dataIdMap.get(out.dataId).id;
      wasmFunc$6(inputIdsBytes, inputIds.length, CppDType[out.dtype], outId);
      return out;
    }
    var addNConfig = {
      kernelName: tfjsCore.AddN,
      backendName: "wasm",
      setupFunc: setupFunc$1,
      kernelFunc: addn
    };
    function identity(args) {
      var x = args.inputs.x, backend = args.backend;
      if (x.dtype === "string") {
        return tfjsCore.tensor(backend.readSync(x.dataId), x.shape, x.dtype);
      }
      var out = backend.makeOutput(x.shape, x.dtype);
      var inVals = backend.typedArrayFromHeap(x);
      var outVals = backend.typedArrayFromHeap(out);
      outVals.set(inVals);
      return out;
    }
    var identityConfig = {
      kernelName: tfjsCore.Identity,
      backendName: "wasm",
      kernelFunc: identity
    };
    var wasmTranspose;
    function setup$16(backend) {
      wasmTranspose = backend.wasm.cwrap(tfjsCore.Transpose, null, [
        "number",
        "array",
        "number",
        "number",
        "number",
        "array",
        "number"
        // perm.length
      ]);
    }
    function transpose(args) {
      var inputs = args.inputs, backend = args.backend, attrs = args.attrs;
      var _a2 = __read(removeOneSizeDims(inputs.x.shape, attrs.perm), 2), reducedShape = _a2[0], perm = _a2[1];
      var permIsNoOp = true;
      for (var i = 0; i < perm.length; i++) {
        if (perm[i] !== i) {
          permIsNoOp = false;
        }
      }
      var outShape = computeOutShape(inputs.x.shape, attrs.perm);
      var x = {
        dataId: inputs.x.dataId,
        shape: reducedShape,
        dtype: inputs.x.dtype
      };
      if (permIsNoOp) {
        var cloned = identity({ inputs, backend });
        cloned.shape = outShape;
        return cloned;
      }
      var out = backend.makeOutput(outShape, x.dtype);
      var xId = backend.dataIdMap.get(x.dataId).id;
      var outId = backend.dataIdMap.get(out.dataId).id;
      var permBytes = new Uint8Array(new Int32Array(perm).buffer);
      var xShapeBytes = new Uint8Array(new Int32Array(x.shape).buffer);
      wasmTranspose(xId, xShapeBytes, x.shape.length, CppDType[x.dtype], outId, permBytes, perm.length);
      return out;
    }
    function computeOutShape(inShape, perm) {
      var outShape = new Array(inShape.length);
      for (var i = 0; i < outShape.length; i++) {
        outShape[i] = inShape[perm[i]];
      }
      return outShape;
    }
    function removeOneSizeDims(shape, perm) {
      var newShape = [];
      var newPerm = [];
      for (var i = 0; i < shape.length; ++i) {
        if (shape[i] !== 1) {
          newShape.push(shape[i]);
        }
        if (shape[perm[i]] !== 1) {
          newPerm.push(perm[i]);
        }
      }
      for (var i = 0; i < newPerm.length; ++i) {
        var minValIdx = -1;
        for (var j = 0; j < newPerm.length; ++j) {
          if (newPerm[j] >= i && (minValIdx === -1 || newPerm[minValIdx] > newPerm[j])) {
            minValIdx = j;
          }
        }
        newPerm[minValIdx] = i;
      }
      return [newShape, newPerm];
    }
    var transposeConfig = {
      kernelName: tfjsCore.Transpose,
      backendName: "wasm",
      kernelFunc: transpose,
      setupFunc: setup$16
    };
    function permuteAxesAndTranspose(x, axis, backend) {
      var xShape = x.shape;
      var xRank = x.shape.length;
      var originalAxes = tfjsCore.util.parseAxisParam(axis, xShape);
      var axes = originalAxes;
      var permutedAxes = tfjsCore.backend_util.getAxesPermutation(axes, xRank);
      var xTransposed = null;
      var inputWasTransposed = false;
      if (permutedAxes != null) {
        var newShape = new Array(xRank);
        for (var i = 0; i < newShape.length; i++) {
          newShape[i] = xShape[permutedAxes[i]];
        }
        axes = tfjsCore.backend_util.getInnerMostAxes(axes.length, xRank);
        xTransposed = transpose({ inputs: { x }, attrs: { perm: permutedAxes }, backend });
        var xId = backend.dataIdMap.get(x.dataId).id;
        var transposedId = backend.dataIdMap.get(xTransposed.dataId).id;
        if (transposedId !== xId) {
          inputWasTransposed = true;
        }
      }
      return { transposed: xTransposed, originalAxes, axes, inputWasTransposed };
    }
    var wasmAll;
    function setup$15(backend) {
      wasmAll = backend.wasm.cwrap(tfjsCore.All, null, ["number, number, number"]);
    }
    function all(args) {
      var backend = args.backend, inputs = args.inputs, attrs = args.attrs;
      var axis = attrs.axis, keepDims = attrs.keepDims;
      var x = inputs.x;
      var xId = backend.dataIdMap.get(x.dataId).id;
      var inputId = xId;
      var input = x;
      var _a2 = permuteAxesAndTranspose(x, axis, backend), transposed = _a2.transposed, axes = _a2.axes, originalAxes = _a2.originalAxes, inputWasTransposed = _a2.inputWasTransposed;
      if (inputWasTransposed) {
        var transposedId = backend.dataIdMap.get(transposed.dataId).id;
        input = transposed;
        inputId = transposedId;
      }
      var inputRank = input.shape.length;
      tfjsCore.backend_util.assertAxesAreInnerMostDims("all", axes, inputRank);
      var _b = __read(tfjsCore.backend_util.computeOutAndReduceShapes(input.shape, axes), 2), outShape = _b[0], reduceShape = _b[1];
      var reduceSize = tfjsCore.util.sizeFromShape(reduceShape);
      var out = backend.makeOutput(outShape, x.dtype);
      if (tfjsCore.util.sizeFromShape(input.shape) !== 0) {
        var outId = backend.dataIdMap.get(out.dataId).id;
        wasmAll(inputId, reduceSize, outId);
      }
      if (inputWasTransposed) {
        backend.disposeData(transposed.dataId);
      }
      if (keepDims) {
        var newShape = tfjsCore.backend_util.expandShapeToKeepDim(out.shape, originalAxes);
        out.shape = newShape;
      }
      return out;
    }
    var allConfig = {
      kernelName: tfjsCore.All,
      backendName: "wasm",
      setupFunc: setup$15,
      kernelFunc: all
    };
    var wasmAny;
    function setup$14(backend) {
      wasmAny = backend.wasm.cwrap(tfjsCore.Any, null, ["number, number, number"]);
    }
    function any(args) {
      var backend = args.backend, inputs = args.inputs, attrs = args.attrs;
      var axis = attrs.axis, keepDims = attrs.keepDims;
      var x = inputs.x;
      var xId = backend.dataIdMap.get(x.dataId).id;
      var inputId = xId;
      var input = x;
      var _a2 = permuteAxesAndTranspose(x, axis, backend), transposed = _a2.transposed, axes = _a2.axes, originalAxes = _a2.originalAxes, inputWasTransposed = _a2.inputWasTransposed;
      if (inputWasTransposed) {
        var transposedId = backend.dataIdMap.get(transposed.dataId).id;
        input = transposed;
        inputId = transposedId;
      }
      var inputRank = input.shape.length;
      tfjsCore.backend_util.assertAxesAreInnerMostDims("any", axes, inputRank);
      var _b = __read(tfjsCore.backend_util.computeOutAndReduceShapes(input.shape, axes), 2), outShape = _b[0], reduceShape = _b[1];
      var reduceSize = tfjsCore.util.sizeFromShape(reduceShape);
      var out = backend.makeOutput(outShape, x.dtype);
      if (tfjsCore.util.sizeFromShape(input.shape) !== 0) {
        var outId = backend.dataIdMap.get(out.dataId).id;
        wasmAny(inputId, reduceSize, outId);
      }
      if (inputWasTransposed) {
        backend.disposeData(transposed.dataId);
      }
      if (keepDims) {
        var newShape = tfjsCore.backend_util.expandShapeToKeepDim(out.shape, originalAxes);
        out.shape = newShape;
      }
      return out;
    }
    var anyConfig = {
      kernelName: tfjsCore.Any,
      backendName: "wasm",
      setupFunc: setup$14,
      kernelFunc: any
    };
    function createArgMinMaxKernelConfig(kernelName) {
      var wasmFunc2;
      function setupFunc2(backend) {
        wasmFunc2 = backend.wasm.cwrap(kernelName, null, [
          "number",
          "number",
          "number",
          "number",
          "number"
          // out_id
        ]);
      }
      function kernelFunc2(args) {
        var backend = args.backend, inputs = args.inputs, attrs = args.attrs;
        var axis = attrs.axis;
        var x = inputs.x;
        var xId = backend.dataIdMap.get(x.dataId).id;
        var inputId = xId;
        var input = x;
        var _a2 = permuteAxesAndTranspose(x, axis, backend), transposed = _a2.transposed, axes = _a2.axes, inputWasTransposed = _a2.inputWasTransposed;
        if (inputWasTransposed) {
          var transposedId = backend.dataIdMap.get(transposed.dataId).id;
          if (transposedId !== xId) {
            input = transposed;
            inputId = transposedId;
          }
        }
        var outShape = input.shape.slice(0, -1);
        var out = backend.makeOutput(outShape, "int32");
        var outId = backend.dataIdMap.get(out.dataId).id;
        var outerSize = tfjsCore.util.sizeFromShape(out.shape);
        var innerSize = input.shape[axes[0]];
        wasmFunc2(inputId, CppDType[input.dtype], outerSize, innerSize, outId);
        if (inputWasTransposed) {
          backend.disposeData(transposed.dataId);
        }
        return out;
      }
      return {
        kernelName,
        backendName: "wasm",
        setupFunc: setupFunc2,
        kernelFunc: kernelFunc2
      };
    }
    var argMaxConfig = createArgMinMaxKernelConfig(tfjsCore.ArgMax);
    var argMinConfig = createArgMinMaxKernelConfig(tfjsCore.ArgMin);
    var asinConfig = createUnaryKernelConfig(tfjsCore.Asin);
    var asinhConfig = createUnaryKernelConfig(tfjsCore.Asinh);
    var atanConfig = createUnaryKernelConfig(tfjsCore.Atan);
    var atan2Config = createBinaryKernelConfig(tfjsCore.Atan2);
    var atanhConfig = createUnaryKernelConfig(tfjsCore.Atanh);
    var wasmAvgPool;
    function setup$13(backend) {
      wasmAvgPool = backend.wasm.cwrap(tfjsCore.AvgPool, null, [
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number"
        // outId
      ]);
    }
    function avgPool(args) {
      var inputs = args.inputs, attrs = args.attrs, backend = args.backend;
      var x = inputs.x;
      var xId = backend.dataIdMap.get(x.dataId).id;
      var filterSize = attrs.filterSize, strides = attrs.strides, pad2 = attrs.pad, dimRoundingMode = attrs.dimRoundingMode;
      var convInfo = tfjsCore.backend_util.computePool2DInfo(x.shape, filterSize, strides, 1, pad2, dimRoundingMode);
      var filterHeight = convInfo.filterHeight;
      var filterWidth = convInfo.filterWidth;
      var padTop = convInfo.padInfo.top;
      var padRight = convInfo.padInfo.right;
      var padBottom = convInfo.padInfo.bottom;
      var padLeft = convInfo.padInfo.left;
      var strideHeight = convInfo.strideHeight;
      var strideWidth = convInfo.strideWidth;
      var channels = convInfo.inChannels;
      if (convInfo.dataFormat !== "channelsLast") {
        throw new Error("wasm backend does not support dataFormat:'" + "".concat(convInfo.dataFormat, "'. Please use 'channelsLast'."));
      }
      if (convInfo.dilationWidth !== 1 || convInfo.dilationHeight !== 1) {
        throw new Error("was backend only supports average pooling with dilation = [1, 1], " + "got [".concat(convInfo.dilationHeight, ", ").concat(convInfo.dilationWidth, "]."));
      }
      var out = backend.makeOutput(convInfo.outShape, "float32");
      var outId = backend.dataIdMap.get(out.dataId).id;
      wasmAvgPool(xId, x.shape[0], x.shape[1], x.shape[2], filterHeight, filterWidth, padTop, padRight, padBottom, padLeft, strideHeight, strideWidth, channels, outId);
      return out;
    }
    var avgPoolConfig = {
      kernelName: tfjsCore.AvgPool,
      backendName: "wasm",
      setupFunc: setup$13,
      kernelFunc: avgPool
    };
    var wasmAvgPool3D;
    function setup$12(backend) {
      wasmAvgPool3D = backend.wasm.cwrap("AvgPool3D", null, [
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number"
        // padLeft
      ]);
    }
    function avgPool3D(args) {
      var inputs = args.inputs, backend = args.backend, attrs = args.attrs;
      var x = inputs.x;
      var filterSize = attrs.filterSize, strides = attrs.strides, pad2 = attrs.pad, dimRoundingMode = attrs.dimRoundingMode, dataFormat = attrs.dataFormat;
      var convInfo = tfjsCore.backend_util.computePool3DInfo(
        x.shape,
        filterSize,
        strides,
        /*dilations=*/
        1,
        pad2,
        dimRoundingMode,
        dataFormat
      );
      var out = backend.makeOutput(convInfo.outShape, x.dtype);
      wasmAvgPool3D(
        backend.dataIdMap.get(x.dataId).id,
        backend.dataIdMap.get(out.dataId).id,
        convInfo.batchSize,
        // Since Pool3D ops (AvgPool3D and MaxPool3D) support 3D filter only, in
        // channels should always equal to out channels.
        /*channelSize=*/
        convInfo.inChannels,
        convInfo.inDepth,
        convInfo.inHeight,
        convInfo.inWidth,
        convInfo.outDepth,
        convInfo.outHeight,
        convInfo.outWidth,
        convInfo.strideDepth,
        convInfo.strideHeight,
        convInfo.strideWidth,
        convInfo.dilationDepth,
        convInfo.dilationHeight,
        convInfo.dilationWidth,
        convInfo.effectiveFilterDepth,
        convInfo.effectiveFilterHeight,
        convInfo.effectiveFilterWidth,
        convInfo.padInfo.front,
        convInfo.padInfo.top,
        convInfo.padInfo.left
      );
      return out;
    }
    var avgPool3DConfig = {
      kernelName: tfjsCore.AvgPool3D,
      backendName: "wasm",
      setupFunc: setup$12,
      kernelFunc: avgPool3D
    };
    var wasmAvgPool3DGrad;
    function setup$11(backend) {
      wasmAvgPool3DGrad = backend.wasm.cwrap("AvgPool3DGrad", null, [
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number"
        // filterWidth
      ]);
    }
    function avgPool3DGrad(args) {
      var inputs = args.inputs, backend = args.backend, attrs = args.attrs;
      var dy = inputs.dy, input = inputs.input;
      var filterSize = attrs.filterSize, strides = attrs.strides, pad2 = attrs.pad, dimRoundingMode = attrs.dimRoundingMode;
      var convInfo = tfjsCore.backend_util.computePool3DInfo(
        input.shape,
        filterSize,
        strides,
        /*dilations=*/
        1,
        pad2,
        dimRoundingMode
      );
      var dx = backend.makeOutput(input.shape, input.dtype);
      wasmAvgPool3DGrad(
        backend.dataIdMap.get(dy.dataId).id,
        backend.dataIdMap.get(dx.dataId).id,
        convInfo.batchSize,
        // Since Pool3D ops (AvgPool3D and MaxPool3D) support 3D filter only, in
        // channels should always equal to out channels.
        /*channelSize=*/
        convInfo.inChannels,
        convInfo.inDepth,
        convInfo.inHeight,
        convInfo.inWidth,
        convInfo.outDepth,
        convInfo.outHeight,
        convInfo.outWidth,
        convInfo.strideDepth,
        convInfo.strideHeight,
        convInfo.strideWidth,
        convInfo.dilationDepth,
        convInfo.dilationHeight,
        convInfo.dilationWidth,
        convInfo.effectiveFilterDepth,
        convInfo.effectiveFilterHeight,
        convInfo.effectiveFilterWidth,
        convInfo.padInfo.front,
        convInfo.padInfo.top,
        convInfo.padInfo.left,
        convInfo.filterDepth,
        convInfo.filterHeight,
        convInfo.filterWidth
      );
      return dx;
    }
    var avgPool3DGradConfig = {
      kernelName: tfjsCore.AvgPool3DGrad,
      backendName: "wasm",
      setupFunc: setup$11,
      kernelFunc: avgPool3DGrad
    };
    function reshape(args) {
      var inputs = args.inputs, attrs = args.attrs;
      var x = inputs.x;
      var shape = attrs.shape;
      var xSize = tfjsCore.util.sizeFromShape(x.shape);
      var $shape = tfjsCore.util.inferFromImplicitShape(shape, xSize);
      tfjsCore.util.assert(xSize === tfjsCore.util.sizeFromShape($shape), function() {
        return "new shape: ".concat($shape, ", old shape: ").concat(x.shape, ". New shape and old ") + "shape must have the same number of elements.";
      });
      args.backend.incRef(x.dataId);
      return { dataId: x.dataId, shape: $shape, dtype: x.dtype };
    }
    var reshapeConfig = {
      kernelName: tfjsCore.Reshape,
      backendName: "wasm",
      kernelFunc: reshape
    };
    var wasmBatchMatMul;
    function setup$10(backend) {
      wasmBatchMatMul = backend.wasm.cwrap(tfjsCore.BatchMatMul, null, [
        "number",
        "array",
        "number",
        "number",
        "array",
        "number",
        "number",
        "number",
        "number"
        // out_id
      ]);
    }
    function batchMatMul(args) {
      var inputs = args.inputs, backend = args.backend, attrs = args.attrs;
      var a = inputs.a, b = inputs.b;
      var transposeA = attrs.transposeA, transposeB = attrs.transposeB;
      if (a.dtype !== "float32" || b.dtype !== "float32") {
        throw new Error("BatchMatMul for non non-float32 tensors not yet supported.");
      }
      var aRank = a.shape.length;
      var bRank = b.shape.length;
      var innerShapeA = transposeA ? a.shape[aRank - 2] : a.shape[aRank - 1];
      var innerShapeB = transposeB ? b.shape[bRank - 1] : b.shape[bRank - 2];
      var outerShapeA = transposeA ? a.shape[aRank - 1] : a.shape[aRank - 2];
      var outerShapeB = transposeB ? b.shape[bRank - 2] : b.shape[bRank - 1];
      var outerDimsA = a.shape.slice(0, -2);
      var outerDimsB = b.shape.slice(0, -2);
      var batchDimA = tfjsCore.util.sizeFromShape(outerDimsA);
      var batchDimB = tfjsCore.util.sizeFromShape(outerDimsB);
      var outShapeOuterDims = tfjsCore.broadcast_util.assertAndGetBroadcastShape(a.shape.slice(0, -2), b.shape.slice(0, -2));
      var outShape = outShapeOuterDims.concat([outerShapeA, outerShapeB]);
      tfjsCore.util.assert(innerShapeA === innerShapeB, function() {
        return "Error in matMul: inner shapes (".concat(innerShapeA, ") and (") + "".concat(innerShapeB, ") of Tensors with shapes ").concat(a.shape, " and ") + "".concat(b.shape, " and transposeA=").concat(transposeA) + " and transposeB=".concat(transposeB, " must match.");
      });
      var a3dShape = transposeA ? [batchDimA, innerShapeA, outerShapeA] : [batchDimA, outerShapeA, innerShapeA];
      var b3dShape = transposeB ? [batchDimB, outerShapeB, innerShapeB] : [batchDimB, innerShapeB, outerShapeB];
      var a3d = reshape({ inputs: { x: a }, backend, attrs: { shape: a3dShape } });
      var b3d = reshape({ inputs: { x: b }, backend, attrs: { shape: b3dShape } });
      var a3dId = backend.dataIdMap.get(a3d.dataId).id;
      var b3dId = backend.dataIdMap.get(b3d.dataId).id;
      var leftDim = transposeA ? a3d.shape[2] : a3d.shape[1];
      var rightDim = transposeB ? b3d.shape[1] : b3d.shape[2];
      var batchDim = Math.max(batchDimA, batchDimB);
      var out = backend.makeOutput([batchDim, leftDim, rightDim], a3d.dtype);
      var outId = backend.dataIdMap.get(out.dataId).id;
      var aShapeBytes = new Uint8Array(new Int32Array(a3d.shape).buffer);
      var bShapeBytes = new Uint8Array(new Int32Array(b3d.shape).buffer);
      wasmBatchMatMul(a3dId, aShapeBytes, a3d.shape.length, b3dId, bShapeBytes, b3d.shape.length, transposeA, transposeB, outId);
      backend.disposeData(a3d.dataId);
      backend.disposeData(b3d.dataId);
      out.shape = outShape;
      return out;
    }
    var batchMatMulConfig = {
      kernelName: tfjsCore.BatchMatMul,
      backendName: "wasm",
      setupFunc: setup$10,
      kernelFunc: batchMatMul
    };
    function concatImpl(inputs, outShape, dtype, simplyConcat) {
      var outVals = tfjsCore.util.getArrayFromDType(dtype, tfjsCore.util.sizeFromShape(outShape));
      if (simplyConcat && dtype !== "string") {
        var offset_1 = 0;
        inputs.forEach(function(input) {
          var size = tfjsCore.util.sizeFromShape(input.shape);
          outVals.set(input.vals, offset_1);
          offset_1 += size;
        });
      } else {
        var colOffset_1 = 0;
        inputs.forEach(function(input) {
          var decodedData = dtype === "string" ? tfjsCore.backend_util.fromUint8ToStringArray(input.vals) : input.vals;
          var tIdx = 0;
          for (var row = 0; row < input.shape[0]; ++row) {
            var resIdx = row * outShape[1] + colOffset_1;
            for (var col = 0; col < input.shape[1]; ++col) {
              outVals[resIdx + col] = decodedData[tIdx++];
            }
          }
          colOffset_1 += input.shape[1];
        });
      }
      return outVals;
    }
    tfjsCore.backend_util.RowPartitionType;
    function rangeImpl(start, stop, step2, dtype) {
      var sameStartStop = start === stop;
      var increasingRangeNegativeStep = start < stop && step2 < 0;
      var decreasingRangePositiveStep = stop < start && step2 > 1;
      if (sameStartStop || increasingRangeNegativeStep || decreasingRangePositiveStep) {
        return tfjsCore.util.makeZerosTypedArray(0, dtype);
      }
      var numElements = Math.abs(Math.ceil((stop - start) / step2));
      var values = tfjsCore.util.makeZerosTypedArray(numElements, dtype);
      if (stop < start && step2 === 1) {
        step2 = -1;
      }
      values[0] = start;
      for (var i = 1; i < values.length; i++) {
        values[i] = values[i - 1] + step2;
      }
      return values;
    }
    function sliceImpl(vals, begin, size, shape, dtype) {
      var isContinous = tfjsCore.slice_util.isSliceContinous(shape, begin, size);
      var length = tfjsCore.util.sizeFromShape(size);
      var xStrides = tfjsCore.util.computeStrides(shape);
      if (isContinous) {
        var flatOffset = tfjsCore.slice_util.computeFlatOffset(begin, xStrides);
        if (dtype === "string") {
          return vals.slice(flatOffset, flatOffset + length);
        }
        return vals.subarray(flatOffset, flatOffset + length);
      }
      var decodedData = dtype === "string" ? tfjsCore.backend_util.fromUint8ToStringArray(vals) : vals;
      var inBuf = tfjsCore.buffer(shape, dtype, decodedData);
      var outBuf = tfjsCore.buffer(size, dtype);
      for (var i = 0; i < outBuf.size; ++i) {
        var outLoc = outBuf.indexToLoc(i);
        var inLoc = outLoc.map(function(idx, j) {
          return idx + begin[j];
        });
        outBuf.set.apply(outBuf, __spreadArray([inBuf.get.apply(inBuf, __spreadArray([], __read(inLoc), false))], __read(outLoc), false));
      }
      if (dtype === "string") {
        return tfjsCore.backend_util.fromStringArrayToUint8(outBuf.values);
      }
      return outBuf.values;
    }
    var StringNGramsOp = (
      /** @class */
      function() {
        function StringNGramsOp2(separator, nGramWidths, leftPad, rightPad, padWidth, preserveShortSequences) {
          this.separator = tfjsCore.util.encodeString(separator);
          this.nGramWidths = nGramWidths;
          this.leftPad = tfjsCore.util.encodeString(leftPad);
          this.rightPad = tfjsCore.util.encodeString(rightPad);
          this.padWidth = padWidth;
          this.preserveShort = preserveShortSequences;
        }
        StringNGramsOp2.prototype.getPadWidth = function(nGramWidth) {
          return Math.min(this.padWidth < 0 ? nGramWidth - 1 : this.padWidth, nGramWidth - 1);
        };
        StringNGramsOp2.prototype.getNumNGrams = function(length, nGramWidth) {
          var padWidth = this.getPadWidth(nGramWidth);
          return Math.max(0, length + 2 * padWidth - nGramWidth + 1);
        };
        StringNGramsOp2.prototype.createNGrams = function(data, splitIndex, output, outputStartIndex, numNGrams, nGramWidth) {
          var _loop_1 = function(nGramIndex2) {
            var padWidth = this_1.getPadWidth(nGramWidth);
            var leftPadding = Math.max(0, padWidth - nGramIndex2);
            var rightPadding = Math.max(0, padWidth - (numNGrams - (nGramIndex2 + 1)));
            var numTokens = nGramWidth - (leftPadding + rightPadding);
            var dataStartIndex = splitIndex + (leftPadding > 0 ? 0 : nGramIndex2 - padWidth);
            var nGramSize = 0;
            nGramSize += leftPadding * this_1.leftPad.length;
            for (var n = 0; n < numTokens; ++n) {
              nGramSize += data[dataStartIndex + n].length;
            }
            nGramSize += rightPadding * this_1.rightPad.length;
            var numSeparators = leftPadding + rightPadding + numTokens - 1;
            nGramSize += numSeparators * this_1.separator.length;
            output[outputStartIndex + nGramIndex2] = new Uint8Array(nGramSize);
            var nGram = output[outputStartIndex + nGramIndex2];
            var nextNGramIndex = 0;
            var appendToNGram = function(str) {
              return str.forEach(function(value) {
                return nGram[nextNGramIndex++] = value;
              });
            };
            for (var n = 0; n < leftPadding; ++n) {
              appendToNGram(this_1.leftPad);
              appendToNGram(this_1.separator);
            }
            for (var n = 0; n < numTokens - 1; ++n) {
              appendToNGram(data[dataStartIndex + n]);
              appendToNGram(this_1.separator);
            }
            if (numTokens > 0) {
              appendToNGram(data[dataStartIndex + numTokens - 1]);
              for (var n = 0; n < rightPadding; ++n) {
                appendToNGram(this_1.separator);
                appendToNGram(this_1.rightPad);
              }
            } else {
              for (var n = 0; n < rightPadding - 1; ++n) {
                appendToNGram(this_1.rightPad);
                appendToNGram(this_1.separator);
              }
              appendToNGram(this_1.rightPad);
            }
          };
          var this_1 = this;
          for (var nGramIndex = 0; nGramIndex < numNGrams; ++nGramIndex) {
            _loop_1(nGramIndex);
          }
        };
        StringNGramsOp2.prototype.compute = function(data, splits) {
          var _this = this;
          var inputDataSize = data.length;
          var splitsSize = splits.length;
          if (splitsSize > 0) {
            var prevSplit = splits[0];
            if (prevSplit !== 0) {
              throw new Error("First split value must be 0, got ".concat(prevSplit));
            }
            for (var i = 1; i < splitsSize; ++i) {
              var validSplits = splits[i] >= prevSplit;
              validSplits = validSplits && splits[i] <= inputDataSize;
              if (!validSplits) {
                throw new Error("Invalid split value ".concat(splits[i], ", must be in [").concat(prevSplit, ", ").concat(inputDataSize, "]"));
              }
              prevSplit = splits[i];
            }
            if (prevSplit !== inputDataSize) {
              throw new Error("Last split value must be data size. Expected ".concat(inputDataSize, ", got ").concat(prevSplit));
            }
          }
          var numBatchItems = splitsSize - 1;
          var nGramsSplits = tfjsCore.util.getArrayFromDType("int32", splitsSize);
          if (inputDataSize === 0 || splitsSize === 0) {
            var empty = new Array(inputDataSize);
            for (var i = 0; i <= numBatchItems; ++i) {
              nGramsSplits[i] = 0;
            }
            return [empty, nGramsSplits];
          }
          nGramsSplits[0] = 0;
          var _loop_2 = function(i2) {
            var length = splits[i2] - splits[i2 - 1];
            var numNGrams = 0;
            this_2.nGramWidths.forEach(function(nGramWidth) {
              numNGrams += _this.getNumNGrams(length, nGramWidth);
            });
            if (this_2.preserveShort && length > 0 && numNGrams === 0) {
              numNGrams = 1;
            }
            nGramsSplits[i2] = nGramsSplits[i2 - 1] + numNGrams;
          };
          var this_2 = this;
          for (var i = 1; i <= numBatchItems; ++i) {
            _loop_2(i);
          }
          var nGrams = new Array(nGramsSplits[numBatchItems]);
          var _loop_3 = function(i2) {
            var splitIndex = splits[i2];
            var outputStartIdx = nGramsSplits[i2];
            this_3.nGramWidths.forEach(function(nGramWidth2) {
              var length = splits[i2 + 1] - splits[i2];
              var numNGrams2 = _this.getNumNGrams(length, nGramWidth2);
              _this.createNGrams(data, splitIndex, nGrams, outputStartIdx, numNGrams2, nGramWidth2);
              outputStartIdx += numNGrams2;
            });
            if (this_3.preserveShort && outputStartIdx === nGramsSplits[i2]) {
              var dataLength = splits[i2 + 1] - splits[i2];
              if (dataLength === 0) {
                return "continue";
              }
              var nGramWidth = dataLength + 2 * this_3.padWidth;
              var numNGrams = 1;
              this_3.createNGrams(data, splitIndex, nGrams, outputStartIdx, numNGrams, nGramWidth);
            }
          };
          var this_3 = this;
          for (var i = 0; i < numBatchItems; ++i) {
            _loop_3(i);
          }
          return [nGrams, nGramsSplits];
        };
        return StringNGramsOp2;
      }()
    );
    function stringNGramsImpl(data, dataSplits, separator, nGramWidths, leftPad, rightPad, padWidth, preserveShortSequences) {
      return new StringNGramsOp(separator, nGramWidths, leftPad, rightPad, padWidth, preserveShortSequences).compute(data, dataSplits);
    }
    function split(str, delimiters, skipEmpty, result) {
      if (!str.length) {
        return;
      }
      if (delimiters.length === 0) {
        for (var i = 0; i < str.length; ++i) {
          result.push(str.subarray(i, i + 1));
        }
        return;
      }
      if (delimiters.length === 1) {
        var delimiter = delimiters[0];
        var f = str.indexOf(delimiter);
        while (f !== -1) {
          var token = str.subarray(0, f);
          if (!skipEmpty || token.length !== 0) {
            result.push(token);
          }
          str = str.subarray(f + 1);
          f = str.indexOf(delimiter);
        }
        if (!skipEmpty || str.length !== 0) {
          result.push(str);
        }
        return;
      }
      var tokenStart = 0;
      for (var i = 0; i < str.length + 1; i++) {
        if (i === str.length || delimiters.indexOf(str[i]) !== -1) {
          var token = str.subarray(tokenStart, i);
          if (!skipEmpty || token.length !== 0) {
            result.push(token);
          }
          tokenStart = i + 1;
        }
      }
    }
    function stringSplitImpl(input, delimiter, skipEmpty) {
      var batchSize = input.length;
      var tokens = [];
      var outputSize = 0;
      var maxNumEntries = 0;
      var numIndices = new Array(batchSize);
      for (var i = 0; i < batchSize; ++i) {
        var prevTokensLength = tokens.length;
        split(input[i], delimiter, skipEmpty, tokens);
        var nEntries = tokens.length - prevTokensLength;
        numIndices[i] = nEntries;
        outputSize += nEntries;
        maxNumEntries = Math.max(maxNumEntries, nEntries);
      }
      var indices = tfjsCore.util.getArrayFromDType("int32", outputSize * 2);
      var values = new Array(outputSize);
      var shape = [batchSize, maxNumEntries];
      var c = 0;
      for (var i = 0; i < batchSize; ++i) {
        for (var j = 0; j < numIndices[i]; ++j) {
          indices[c * 2] = i;
          indices[c * 2 + 1] = j;
          values[c] = tokens[c];
          ++c;
        }
      }
      return [indices, values, shape];
    }
    function stringToHashBucketFastImpl(input, numBuckets) {
      var output = tfjsCore.util.getArrayFromDType("int32", input.length);
      for (var i = 0; i < input.length; ++i) {
        output[i] = tfjsCore.util.fingerPrint64(input[i]).modulo(numBuckets).getLowBitsUnsigned();
      }
      return output;
    }
    function uniqueImpl(values, axis, shape, dtype) {
      var $axis = tfjsCore.util.parseAxisParam(axis, shape)[0];
      var newShape = [1, shape[0], 1];
      for (var i = 0; i < $axis; i++) {
        newShape[0] *= shape[i];
      }
      newShape[1] = shape[$axis];
      for (var i = $axis + 1; i < shape.length; i++) {
        newShape[2] *= shape[i];
      }
      var uniqueElements = /* @__PURE__ */ new Map();
      var indices = new Int32Array(shape[$axis]);
      var inputBuffer = new tfjsCore.TensorBuffer(newShape, dtype, values);
      var uniqueIndices = [];
      var is1DTensor = newShape[0] === 1 && newShape[2] === 1;
      for (var i = 0; i < shape[$axis]; i++) {
        var element = void 0;
        if (is1DTensor) {
          element = values[i].toString();
        } else {
          var axisValues = [];
          for (var m = 0; m < newShape[0]; m++) {
            for (var n = 0; n < newShape[2]; n++) {
              axisValues.push(inputBuffer.get(m, i, n));
            }
          }
          element = axisValues.join(",");
        }
        var existingIndex = uniqueElements.get(element);
        if (existingIndex != null) {
          indices[i] = existingIndex;
        } else {
          var uniqueIndex = uniqueElements.size;
          uniqueElements.set(element, uniqueIndex);
          indices[i] = uniqueIndex;
          uniqueIndices.push(i);
        }
      }
      var outputTmpShape = newShape.slice();
      outputTmpShape[1] = uniqueElements.size;
      var outputBuffer = new tfjsCore.TensorBuffer(outputTmpShape, dtype);
      uniqueIndices.forEach(function(uniqueElementIndex, i2) {
        for (var m2 = 0; m2 < newShape[0]; m2++) {
          for (var n2 = 0; n2 < newShape[2]; n2++) {
            outputBuffer.set(inputBuffer.get(m2, uniqueElementIndex, n2), m2, i2, n2);
          }
        }
      });
      var outputShape = shape.slice();
      outputShape[$axis] = outputTmpShape[1];
      return {
        outputValues: outputBuffer.values,
        outputShape,
        indices
      };
    }
    function slice(args) {
      var x = args.inputs.x, _a2 = args.attrs, begin = _a2.begin, size = _a2.size, backend = args.backend;
      var _b = __read(tfjsCore.slice_util.parseSliceParams(x, begin, size), 2), begin_ = _b[0], size_ = _b[1];
      var isContinous = tfjsCore.slice_util.isSliceContinous(x.shape, begin_, size_);
      var xVals = backend.readSync(x.dataId);
      var out = backend.makeOutput(size_, x.dtype);
      var xStrides = tfjsCore.util.computeStrides(x.shape);
      var outData = backend.dataIdMap.get(out.dataId);
      if (isContinous) {
        var flatOffset = tfjsCore.slice_util.computeFlatOffset(begin_, xStrides);
        if (x.dtype === "string") {
          outData.stringBytes = xVals.slice(flatOffset, flatOffset + tfjsCore.util.sizeFromShape(size_));
        } else {
          var outVals_1 = backend.typedArrayFromHeap(out);
          outVals_1.set(xVals.subarray(flatOffset, flatOffset + tfjsCore.util.sizeFromShape(size_)));
        }
        return out;
      }
      if (x.dtype === "string") {
        var res = sliceImpl(xVals, begin_, size_, x.shape, x.dtype);
        outData.stringBytes = res;
        return out;
      }
      var outVals = backend.typedArrayFromHeap(out);
      var rank = x.shape.length;
      if (rank === 2) {
        slice2d(xVals, xStrides[0], outVals, begin_, size_);
      } else if (rank === 3) {
        slice3d(xVals, xStrides[0], xStrides[1], outVals, begin_, size_);
      } else if (rank === 4) {
        slice4d(xVals, xStrides[0], xStrides[1], xStrides[2], outVals, begin_, size_);
      } else {
        var res = sliceImpl(xVals, begin_, size_, x.shape, x.dtype);
        outVals.set(res);
      }
      return out;
    }
    function slice2d(xVals, xStride, outVals, begin, size) {
      var outOffset = 0;
      var beginI = begin[0];
      var beginJ = begin[1];
      var endI = beginI + size[0];
      for (var i = beginI; i < endI; i++) {
        var xOffset = i * xStride + beginJ;
        outVals.set(xVals.subarray(xOffset, xOffset + size[1]), outOffset);
        outOffset += size[1];
      }
    }
    function slice3d(xVals, xStride1, xStride2, outVals, begin, size) {
      var outOffset = 0;
      var beginI = begin[0];
      var beginJ = begin[1];
      var beginK = begin[2];
      var endI = beginI + size[0];
      var endJ = beginJ + size[1];
      for (var i = beginI; i < endI; i++) {
        for (var j = beginJ; j < endJ; j++) {
          var xOffset = i * xStride1 + j * xStride2 + beginK;
          outVals.set(xVals.subarray(xOffset, xOffset + size[2]), outOffset);
          outOffset += size[2];
        }
      }
    }
    function slice4d(xVals, xStride1, xStride2, xStride3, outVals, begin, size) {
      var outOffset = 0;
      var beginI = begin[0];
      var beginJ = begin[1];
      var beginK = begin[2];
      var endI = beginI + size[0];
      var endJ = beginJ + size[1];
      var endK = beginK + size[2];
      var beginL = begin[3];
      for (var i = beginI; i < endI; i++) {
        for (var j = beginJ; j < endJ; j++) {
          for (var k = beginK; k < endK; k++) {
            var xOffset = i * xStride1 + j * xStride2 + k * xStride3 + beginL;
            outVals.set(xVals.subarray(xOffset, xOffset + size[3]), outOffset);
            outOffset += size[3];
          }
        }
      }
    }
    var sliceConfig = {
      kernelName: tfjsCore.Slice,
      backendName: "wasm",
      kernelFunc: slice
    };
    function batchToSpaceND(args) {
      var inputs = args.inputs, backend = args.backend, attrs = args.attrs;
      var x = inputs.x;
      var blockShape = attrs.blockShape, crops = attrs.crops;
      var prod2 = blockShape.reduce(function(a, b) {
        return a * b;
      });
      var reshaped = tfjsCore.backend_util.getReshaped(x.shape, blockShape, prod2);
      var permuted = tfjsCore.backend_util.getPermuted(reshaped.length, blockShape.length);
      var reshapedPermuted = tfjsCore.backend_util.getReshapedPermuted(x.shape, blockShape, prod2);
      var sliceBeginCoords = tfjsCore.backend_util.getSliceBeginCoords(crops, blockShape.length);
      var sliceSize = tfjsCore.backend_util.getSliceSize(reshapedPermuted, crops, blockShape.length);
      var xReshaped = reshape({ inputs: { x }, backend, attrs: { shape: reshaped } });
      var xTransposed = transpose({ inputs: { x: xReshaped }, backend, attrs: { perm: permuted } });
      var xTransposedReshaped = reshape({ inputs: { x: xTransposed }, backend, attrs: { shape: reshapedPermuted } });
      var result = slice({
        inputs: { x: xTransposedReshaped },
        backend,
        attrs: { begin: sliceBeginCoords, size: sliceSize }
      });
      backend.disposeData(xReshaped.dataId);
      backend.disposeData(xTransposed.dataId);
      backend.disposeData(xReshaped.dataId);
      return result;
    }
    var batchToSpaceNDConfig = {
      kernelName: tfjsCore.BatchToSpaceND,
      backendName: "wasm",
      kernelFunc: batchToSpaceND
    };
    var wasmBincount;
    function setup$$(backend) {
      wasmBincount = backend.wasm.cwrap(tfjsCore.Bincount, null, [
        "number",
        "number",
        "boolean",
        "number",
        "number",
        "number"
        // outId
      ]);
    }
    function bincount(args) {
      var backend = args.backend, inputs = args.inputs, attrs = args.attrs;
      var x = inputs.x, weights = inputs.weights;
      var size = attrs.size;
      var hasWeights = weights.shape.reduce(function(p, v) {
        return p * v;
      }, 1) !== 0;
      var outShape = x.shape.length === 1 ? [size] : [x.shape[0], size];
      var out = backend.makeOutput(outShape, weights.dtype);
      function tensorId(x2) {
        return backend.dataIdMap.get(x2.dataId).id;
      }
      wasmBincount(tensorId(x), size, hasWeights, tensorId(weights), CppDType[weights.dtype], tensorId(out));
      return out;
    }
    var bincountConfig = {
      kernelName: tfjsCore.Bincount,
      backendName: "wasm",
      setupFunc: setup$$,
      kernelFunc: bincount
    };
    function broadcastArgs(args) {
      var inputs = args.inputs, backend = args.backend;
      var s0 = inputs.s0, s1 = inputs.s1;
      var s0Vals = backend.typedArrayFromHeap(s0);
      var s1Vals = backend.typedArrayFromHeap(s1);
      var broadcastShape = tfjsCore.backend_util.assertAndGetBroadcastShape(Array.from(s0Vals), Array.from(s1Vals));
      return backend.makeOutput(
        [broadcastShape.length],
        "int32",
        /*memoryOffset=*/
        void 0,
        /*values=*/
        new Int32Array(broadcastShape)
      );
    }
    var broadcastArgsConfig = {
      kernelName: tfjsCore.BroadcastArgs,
      backendName: "wasm",
      kernelFunc: broadcastArgs
    };
    function cast(args) {
      var x = args.inputs.x, dtype = args.attrs.dtype, backend = args.backend;
      var out = backend.makeOutput(x.shape, dtype);
      var inVals = backend.typedArrayFromHeap(x);
      var outVals = backend.typedArrayFromHeap(out);
      outVals.set(inVals);
      return out;
    }
    var castConfig = {
      kernelName: tfjsCore.Cast,
      backendName: "wasm",
      kernelFunc: cast
    };
    var ceilConfig = createUnaryKernelConfig(tfjsCore.Ceil);
    var wasmClip;
    function setup$_(backend) {
      wasmClip = backend.wasm.cwrap(tfjsCore.ClipByValue, null, [
        "number",
        "number",
        "number",
        "number"
        // out_id
      ]);
    }
    function clip(args) {
      var inputs = args.inputs, backend = args.backend, attrs = args.attrs;
      var x = inputs.x;
      var clipValueMin = attrs.clipValueMin, clipValueMax = attrs.clipValueMax;
      var xId = backend.dataIdMap.get(x.dataId).id;
      var out = backend.makeOutput(x.shape, x.dtype);
      var outId = backend.dataIdMap.get(out.dataId).id;
      wasmClip(xId, clipValueMin, clipValueMax, outId);
      return out;
    }
    var clipByValueConfig = {
      kernelName: tfjsCore.ClipByValue,
      backendName: "wasm",
      setupFunc: setup$_,
      kernelFunc: clip
    };
    function concat(args) {
      var inputs = args.inputs, backend = args.backend;
      var axis = tfjsCore.util.parseAxisParam(args.attrs.axis, inputs[0].shape)[0];
      var shapes = inputs.map(function(t) {
        return t.shape;
      });
      tfjsCore.backend_util.assertParamsConsistent(shapes, axis);
      var outShape = tfjsCore.backend_util.computeOutShape(inputs.map(function(t) {
        return t.shape;
      }), axis);
      var $inputs = inputs.filter(function(t) {
        return tfjsCore.util.sizeFromShape(t.shape) > 0;
      });
      if ($inputs.length === 1) {
        return identity({ inputs: { x: $inputs[0] }, backend });
      }
      var out = backend.makeOutput(outShape, inputs[0].dtype);
      if (tfjsCore.util.sizeFromShape(outShape) === 0) {
        return out;
      }
      if ($inputs[0].dtype === "string") {
        var inputs2D = $inputs.map(function(t) {
          var innerSize = tfjsCore.util.sizeFromShape(t.shape.slice(axis));
          var shape = [-1, innerSize];
          return reshape({ inputs: { x: t }, backend, attrs: { shape } });
        });
        var inputsValShapes = inputs2D.map(function(t) {
          return { vals: backend.readSync(t.dataId), shape: t.shape };
        });
        outShape = tfjsCore.backend_util.computeOutShape(
          inputs2D.map(function(t) {
            return t.shape;
          }),
          1
          /* axis */
        );
        var simplyConcat = inputs2D[0].shape[0] === 1;
        var outVals_1 = concatImpl(inputsValShapes, outShape, inputs[0].dtype, simplyConcat);
        var finalOutShape = tfjsCore.backend_util.computeOutShape($inputs.map(function(t) {
          return t.shape;
        }), axis);
        out.shape = finalOutShape;
        var outData = backend.dataIdMap.get(out.dataId);
        outData.stringBytes = tfjsCore.backend_util.fromStringArrayToUint8(outVals_1);
        inputs2D.forEach(function(t) {
          return backend.disposeData(t.dataId);
        });
        return out;
      }
      var batchDim = tfjsCore.util.sizeFromShape($inputs[0].shape.slice(0, axis));
      var sumInnerDims = 0;
      var innerDims = $inputs.map(function(input) {
        var innerDim2 = tfjsCore.util.sizeFromShape(input.shape.slice(axis));
        sumInnerDims += innerDim2;
        return innerDim2;
      });
      var inVals = $inputs.map(function(input) {
        return backend.typedArrayFromHeap(input);
      });
      var outVals = backend.typedArrayFromHeap(out);
      for (var b = 0; b < batchDim; b++) {
        var outOffset = b * sumInnerDims;
        for (var i = 0; i < inVals.length; i++) {
          var innerDim = innerDims[i];
          var inOffset = b * innerDim;
          var vals = inVals[i].subarray(inOffset, inOffset + innerDim);
          outVals.set(vals, outOffset);
          outOffset += innerDim;
        }
      }
      return out;
    }
    var concatConfig = {
      kernelName: tfjsCore.Concat,
      backendName: "wasm",
      kernelFunc: concat
    };
    var wasmConv2d;
    function setup$Z(backend) {
      wasmConv2d = backend.wasm.cwrap(tfjsCore.Conv2D, null, [
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number"
        // outId
      ]);
    }
    function conv2d(args) {
      var inputs = args.inputs, attrs = args.attrs, backend = args.backend;
      var x = inputs.x, filter = inputs.filter;
      var xId = backend.dataIdMap.get(x.dataId).id;
      var filterId = backend.dataIdMap.get(filter.dataId).id;
      var strides = attrs.strides, dilations = attrs.dilations, pad2 = attrs.pad, dimRoundingMode = attrs.dimRoundingMode, dataFormat = attrs.dataFormat;
      var $dataFormat = tfjsCore.backend_util.convertConv2DDataFormat(dataFormat);
      var convInfo = tfjsCore.backend_util.computeConv2DInfo(x.shape, filter.shape, strides, dilations, pad2, dimRoundingMode, false, $dataFormat);
      var filterHeight = convInfo.filterHeight;
      var filterWidth = convInfo.filterWidth;
      var padTop = convInfo.padInfo.top;
      var padRight = convInfo.padInfo.right;
      var padBottom = convInfo.padInfo.bottom;
      var padLeft = convInfo.padInfo.left;
      var dilationHeight = convInfo.dilationHeight;
      var dilationWidth = convInfo.dilationWidth;
      var strideHeight = convInfo.strideHeight;
      var strideWidth = convInfo.strideWidth;
      var inputChannels = convInfo.inChannels;
      var outputChannels = convInfo.outChannels;
      var isSamePad = convInfo.padInfo.type === "SAME" ? 1 : 0;
      if (convInfo.dataFormat !== "channelsLast") {
        throw new Error("wasm backend Conv2D does not support dataFormat:'" + "".concat(convInfo.dataFormat, "'. Please use 'channelsLast'."));
      }
      var out = backend.makeOutput(convInfo.outShape, "float32");
      var outId = backend.dataIdMap.get(out.dataId).id;
      wasmConv2d(xId, x.shape[0], x.shape[1], x.shape[2], filterId, filterHeight, filterWidth, padTop, padRight, padBottom, padLeft, isSamePad, dilationHeight, dilationWidth, strideHeight, strideWidth, inputChannels, outputChannels, outId);
      return out;
    }
    var conv2DConfig = {
      kernelName: tfjsCore.Conv2D,
      backendName: "wasm",
      setupFunc: setup$Z,
      kernelFunc: conv2d
    };
    var wasmConv2DBackpropInput;
    function setup$Y(backend) {
      wasmConv2DBackpropInput = backend.wasm.cwrap(tfjsCore.Conv2DBackpropInput, null, [
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number"
        // outId
      ]);
    }
    function conv2DBackpropInput(args) {
      var backend = args.backend, inputs = args.inputs, attrs = args.attrs;
      var dy = inputs.dy, filter = inputs.filter;
      var strides = attrs.strides, pad2 = attrs.pad, dataFormat = attrs.dataFormat, dimRoundingMode = attrs.dimRoundingMode, inputShape = attrs.inputShape;
      var dilations = 1;
      var $dataFormat = tfjsCore.backend_util.convertConv2DDataFormat(dataFormat);
      var convInfo = tfjsCore.backend_util.computeConv2DInfo(inputShape, filter.shape, strides, dilations, pad2, dimRoundingMode, false, $dataFormat);
      var batchSize = convInfo.batchSize, filterHeight = convInfo.filterHeight, filterWidth = convInfo.filterWidth, inChannels = convInfo.inChannels, inHeight = convInfo.inHeight, inWidth = convInfo.inWidth, outChannels = convInfo.outChannels, outHeight = convInfo.outHeight, outWidth = convInfo.outWidth, strideHeight = convInfo.strideHeight, strideWidth = convInfo.strideWidth;
      var topPad = filterHeight - 1 - convInfo.padInfo.top;
      var leftPad = filterWidth - 1 - convInfo.padInfo.left;
      var isChannelsLast = convInfo.dataFormat === "channelsLast";
      var dxStrides = tfjsCore.util.computeStrides(convInfo.inShape);
      var dyStrides = tfjsCore.util.computeStrides(dy.shape);
      var _a2 = __read(tfjsCore.util.computeStrides(filter.shape), 3), fltS0 = _a2[0], fltS1 = _a2[1], fltS2 = _a2[2];
      var xBatchStride = dxStrides[0];
      var xRowStride = isChannelsLast ? dxStrides[1] : dxStrides[2];
      var xColStride = isChannelsLast ? dxStrides[2] : 1;
      var xChannelStride = isChannelsLast ? 1 : dxStrides[1];
      var yBatchStride = dyStrides[0];
      var yRowStride = isChannelsLast ? dyStrides[1] : dyStrides[2];
      var yColStride = isChannelsLast ? dyStrides[2] : 1;
      var yChannelStride = isChannelsLast ? 1 : dyStrides[1];
      var out = backend.makeOutput(convInfo.inShape, "float32");
      var outId = backend.dataIdMap.get(out.dataId).id;
      var dyId = backend.dataIdMap.get(dy.dataId).id;
      var filterId = backend.dataIdMap.get(filter.dataId).id;
      wasmConv2DBackpropInput(dyId, filterId, batchSize, filterHeight, filterWidth, inHeight, inWidth, inChannels, outHeight, outWidth, outChannels, strideHeight, strideWidth, topPad, leftPad, fltS0, fltS1, fltS2, xBatchStride, xRowStride, xColStride, xChannelStride, yBatchStride, yRowStride, yColStride, yChannelStride, outId);
      return out;
    }
    var conv2DBackpropInputConfig = {
      kernelName: tfjsCore.Conv2DBackpropInput,
      backendName: "wasm",
      setupFunc: setup$Y,
      kernelFunc: conv2DBackpropInput
    };
    var wasmConv3D;
    function setup$X(backend) {
      wasmConv3D = backend.wasm.cwrap(tfjsCore.Conv3D, null, [
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number"
        // padLeft
      ]);
    }
    function conv3D(args) {
      var inputs = args.inputs, backend = args.backend, attrs = args.attrs;
      var x = inputs.x, filter = inputs.filter;
      var strides = attrs.strides, pad2 = attrs.pad, dilations = attrs.dilations;
      if (x.dtype !== "float32") {
        throw new Error("Tensor x must have dtype float32, got ".concat(x.dtype));
      }
      if (filter.dtype !== "float32") {
        throw new Error("Tensor filter must have dtype float32, got ".concat(filter.dtype));
      }
      var convInfo = tfjsCore.backend_util.computeConv3DInfo(x.shape, filter.shape, strides, dilations, pad2);
      var out = backend.makeOutput(convInfo.outShape, x.dtype);
      wasmConv3D(backend.dataIdMap.get(x.dataId).id, backend.dataIdMap.get(filter.dataId).id, backend.dataIdMap.get(out.dataId).id, convInfo.batchSize, convInfo.inDepth, convInfo.inHeight, convInfo.inWidth, convInfo.inChannels, convInfo.outDepth, convInfo.outHeight, convInfo.outWidth, convInfo.outChannels, convInfo.strideDepth, convInfo.strideHeight, convInfo.strideWidth, convInfo.dilationDepth, convInfo.dilationHeight, convInfo.dilationWidth, convInfo.filterDepth, convInfo.filterHeight, convInfo.filterWidth, convInfo.padInfo.front, convInfo.padInfo.top, convInfo.padInfo.left);
      return out;
    }
    var conv3DConfig = {
      kernelName: tfjsCore.Conv3D,
      backendName: "wasm",
      setupFunc: setup$X,
      kernelFunc: conv3D
    };
    var wasmConv3DBackpropFilterV2;
    function setup$W(backend) {
      wasmConv3DBackpropFilterV2 = backend.wasm.cwrap(tfjsCore.Conv3DBackpropFilterV2, null, [
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number"
        // padLeft
      ]);
    }
    function conv3DBackpropFilterV2(args) {
      var inputs = args.inputs, backend = args.backend, attrs = args.attrs;
      var x = inputs.x, dy = inputs.dy;
      var strides = attrs.strides, pad2 = attrs.pad, filterShape = attrs.filterShape;
      if (x.dtype !== "float32") {
        throw new Error("Tensor dy must have dtype float32, got ".concat(x.dtype));
      }
      if (dy.dtype !== "float32") {
        throw new Error("Tensor filter must have dtype float32, got ".concat(dy.dtype));
      }
      var convInfo = tfjsCore.backend_util.computeConv3DInfo(
        x.shape,
        filterShape,
        strides,
        /*dilations=*/
        1,
        pad2
      );
      var dw = backend.makeOutput(convInfo.filterShape, dy.dtype);
      wasmConv3DBackpropFilterV2(backend.dataIdMap.get(x.dataId).id, backend.dataIdMap.get(dy.dataId).id, backend.dataIdMap.get(dw.dataId).id, convInfo.batchSize, convInfo.inDepth, convInfo.inHeight, convInfo.inWidth, convInfo.inChannels, convInfo.outDepth, convInfo.outHeight, convInfo.outWidth, convInfo.outChannels, convInfo.strideDepth, convInfo.strideHeight, convInfo.strideWidth, convInfo.dilationDepth, convInfo.dilationHeight, convInfo.dilationWidth, convInfo.filterDepth, convInfo.filterHeight, convInfo.filterWidth, convInfo.padInfo.front, convInfo.padInfo.top, convInfo.padInfo.left);
      return dw;
    }
    var conv3DBackpropFilterV2Config = {
      kernelName: tfjsCore.Conv3DBackpropFilterV2,
      backendName: "wasm",
      setupFunc: setup$W,
      kernelFunc: conv3DBackpropFilterV2
    };
    var wasmConv3DBackpropInputV2;
    function setup$V(backend) {
      wasmConv3DBackpropInputV2 = backend.wasm.cwrap(tfjsCore.Conv3DBackpropInputV2, null, [
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number"
        // padLeft
      ]);
    }
    function conv3DBackpropInputV2(args) {
      var inputs = args.inputs, backend = args.backend, attrs = args.attrs;
      var dy = inputs.dy, filter = inputs.filter;
      var pad2 = attrs.pad, strides = attrs.strides, inputShape = attrs.inputShape;
      if (dy.dtype !== "float32") {
        throw new Error("Tensor dy must have dtype float32, got ".concat(dy.dtype));
      }
      if (filter.dtype !== "float32") {
        throw new Error("Tensor filter must have dtype float32, got ".concat(filter.dtype));
      }
      var convInfo = tfjsCore.backend_util.computeConv3DInfo(
        inputShape,
        filter.shape,
        strides,
        /*dilations=*/
        1,
        pad2
      );
      var dx = backend.makeOutput(convInfo.inShape, dy.dtype);
      wasmConv3DBackpropInputV2(backend.dataIdMap.get(filter.dataId).id, backend.dataIdMap.get(dy.dataId).id, backend.dataIdMap.get(dx.dataId).id, convInfo.batchSize, convInfo.inDepth, convInfo.inHeight, convInfo.inWidth, convInfo.inChannels, convInfo.outDepth, convInfo.outHeight, convInfo.outWidth, convInfo.outChannels, convInfo.strideDepth, convInfo.strideHeight, convInfo.strideWidth, convInfo.dilationDepth, convInfo.dilationHeight, convInfo.dilationWidth, convInfo.filterDepth, convInfo.filterHeight, convInfo.filterWidth, convInfo.padInfo.front, convInfo.padInfo.top, convInfo.padInfo.left);
      return dx;
    }
    var conv3DBackpropInputV2Config = {
      kernelName: tfjsCore.Conv3DBackpropInputV2,
      backendName: "wasm",
      setupFunc: setup$V,
      kernelFunc: conv3DBackpropInputV2
    };
    var cosConfig = createUnaryKernelConfig(tfjsCore.Cos);
    var coshConfig = createUnaryKernelConfig(tfjsCore.Cosh);
    var InterpolationMethod;
    (function(InterpolationMethod2) {
      InterpolationMethod2[InterpolationMethod2["bilinear"] = 0] = "bilinear";
      InterpolationMethod2[InterpolationMethod2["nearest"] = 1] = "nearest";
    })(InterpolationMethod || (InterpolationMethod = {}));
    var wasmCropAndResize;
    function setup$U(backend) {
      wasmCropAndResize = backend.wasm.cwrap(tfjsCore.CropAndResize, null, [
        "number",
        "number",
        "number",
        "number",
        "array",
        "number",
        "number",
        "number",
        "number",
        "number"
        // out id
      ]);
    }
    function cropAndResize(args) {
      var backend = args.backend, inputs = args.inputs, attrs = args.attrs;
      var method = attrs.method, extrapolationValue = attrs.extrapolationValue, cropSize = attrs.cropSize;
      var image = inputs.image, boxes = inputs.boxes, boxInd = inputs.boxInd;
      var numBoxes = boxes.shape[0];
      var _a2 = __read(cropSize, 2), cropHeight = _a2[0], cropWidth = _a2[1];
      var outShape = [numBoxes, cropHeight, cropWidth, image.shape[3]];
      var imagesData = backend.dataIdMap.get(image.dataId);
      var castedData;
      if (image.dtype !== "float32") {
        castedData = cast({ backend, inputs: { x: image }, attrs: { dtype: "float32" } });
        imagesData = backend.dataIdMap.get(castedData.dataId);
      }
      var imagesId = imagesData.id;
      var boxesId = backend.dataIdMap.get(boxes.dataId).id;
      var boxIndId = backend.dataIdMap.get(boxInd.dataId).id;
      var out = backend.makeOutput(outShape, "float32");
      var outId = backend.dataIdMap.get(out.dataId).id;
      var imagesShapeBytes = new Uint8Array(new Int32Array(image.shape).buffer);
      wasmCropAndResize(imagesId, boxesId, boxIndId, numBoxes, imagesShapeBytes, cropHeight, cropWidth, InterpolationMethod[method], extrapolationValue, outId);
      if (castedData != null) {
        backend.disposeData(castedData.dataId);
      }
      return out;
    }
    var cropAndResizeConfig = {
      kernelName: tfjsCore.CropAndResize,
      backendName: "wasm",
      setupFunc: setup$U,
      kernelFunc: cropAndResize
    };
    var wasmCumprod;
    function setup$T(backend) {
      wasmCumprod = backend.wasm.cwrap(tfjsCore.Cumprod, null, [
        "number",
        "number",
        "number",
        "number",
        "number",
        "number"
        // dtype
      ]);
    }
    function cumprod(args) {
      var inputs = args.inputs, backend = args.backend, attrs = args.attrs;
      var x = inputs.x;
      var axis = attrs.axis, exclusive = attrs.exclusive, reverse2 = attrs.reverse;
      var xRank = x.shape.length;
      tfjsCore.util.assert(x.dtype === "float32" || x.dtype === "int32", function() {
        return "cumprod does not support ".concat(x.dtype, " tensors in the WASM backend");
      });
      var permutation = tfjsCore.backend_util.getAxesPermutation([axis], xRank);
      var permutedX = x;
      if (permutation !== null) {
        permutedX = transpose({ inputs: { x }, attrs: { perm: permutation }, backend });
      }
      var permutedAxis = tfjsCore.backend_util.getInnerMostAxes(1, xRank)[0];
      tfjsCore.backend_util.assertAxesAreInnerMostDims("cumprod", [permutedAxis], xRank);
      var permutedOut = backend.makeOutput(permutedX.shape, permutedX.dtype);
      var finalDim = permutedX.shape[permutedAxis];
      var permutedXId = backend.dataIdMap.get(permutedX.dataId).id;
      var permutedOutId = backend.dataIdMap.get(permutedOut.dataId).id;
      wasmCumprod(permutedXId, exclusive ? 1 : 0, reverse2 ? 1 : 0, finalDim, permutedOutId, CppDType[x.dtype]);
      var out = permutedOut;
      if (permutation !== null) {
        var undoPermutation = tfjsCore.backend_util.getUndoAxesPermutation(permutation);
        out = transpose({ inputs: { x: permutedOut }, attrs: { perm: undoPermutation }, backend });
        backend.disposeData(permutedX.dataId);
        backend.disposeData(permutedOut.dataId);
      }
      return out;
    }
    var cumprodConfig = {
      kernelName: tfjsCore.Cumprod,
      backendName: "wasm",
      setupFunc: setup$T,
      kernelFunc: cumprod
    };
    var wasmCumsum;
    function setup$S(backend) {
      wasmCumsum = backend.wasm.cwrap(tfjsCore.Cumsum, null, [
        "number",
        "number",
        "number",
        "number",
        "number",
        "number"
        // dtype
      ]);
    }
    function cumsum(args) {
      var inputs = args.inputs, backend = args.backend, attrs = args.attrs;
      var x = inputs.x;
      var axis = attrs.axis, exclusive = attrs.exclusive, reverse2 = attrs.reverse;
      var xRank = x.shape.length;
      tfjsCore.util.assert(x.dtype === "float32" || x.dtype === "int32", function() {
        return "cumsum does not support ".concat(x.dtype, " tensors in the WASM backend");
      });
      var permutation = tfjsCore.backend_util.getAxesPermutation([axis], xRank);
      var permutedX = x;
      if (permutation !== null) {
        permutedX = transpose({ inputs: { x }, attrs: { perm: permutation }, backend });
      }
      var permutedAxis = tfjsCore.backend_util.getInnerMostAxes(1, xRank)[0];
      tfjsCore.backend_util.assertAxesAreInnerMostDims("cumsum", [permutedAxis], xRank);
      var permutedOut = backend.makeOutput(permutedX.shape, permutedX.dtype);
      var finalDim = permutedX.shape[permutedAxis];
      var permutedXId = backend.dataIdMap.get(permutedX.dataId).id;
      var permutedOutId = backend.dataIdMap.get(permutedOut.dataId).id;
      wasmCumsum(permutedXId, exclusive ? 1 : 0, reverse2 ? 1 : 0, finalDim, permutedOutId, CppDType[x.dtype]);
      var out = permutedOut;
      if (permutation !== null) {
        var undoPermutation = tfjsCore.backend_util.getUndoAxesPermutation(permutation);
        out = transpose({ inputs: { x: permutedOut }, attrs: { perm: undoPermutation }, backend });
        backend.disposeData(permutedX.dataId);
        backend.disposeData(permutedOut.dataId);
      }
      return out;
    }
    var cumsumConfig = {
      kernelName: tfjsCore.Cumsum,
      backendName: "wasm",
      setupFunc: setup$S,
      kernelFunc: cumsum
    };
    var wasmDenseBincount;
    function setup$R(backend) {
      wasmDenseBincount = backend.wasm.cwrap("DenseBincount", null, [
        "number",
        "array",
        "number",
        "number",
        "boolean",
        "number",
        "number",
        "boolean",
        "number"
        // outId
      ]);
    }
    function denseBincount(args) {
      var backend = args.backend, inputs = args.inputs, attrs = args.attrs;
      var x = inputs.x, weights = inputs.weights;
      var size = attrs.size, binaryOutput = attrs.binaryOutput;
      var hasWeights = weights.shape.reduce(function(p, v) {
        return p * v;
      }, 1) !== 0;
      var outShape = x.shape.length === 1 ? [size] : [x.shape[0], size];
      var out = backend.makeOutput(outShape, weights.dtype);
      function tensorId(x2) {
        return backend.dataIdMap.get(x2.dataId).id;
      }
      wasmDenseBincount(tensorId(x), new Uint8Array(new Int32Array(x.shape).buffer), x.shape.length, size, hasWeights, tensorId(weights), CppDType[weights.dtype], binaryOutput, tensorId(out));
      return out;
    }
    var denseBincountConfig = {
      kernelName: tfjsCore.DenseBincount,
      backendName: "wasm",
      setupFunc: setup$R,
      kernelFunc: denseBincount
    };
    var wasmDepthToSpace;
    function setup$Q(backend) {
      wasmDepthToSpace = backend.wasm.cwrap(tfjsCore.DepthToSpace, null, [
        "number",
        "number",
        "number",
        "array",
        "number",
        "array",
        "array",
        "number",
        "number"
        // outId
      ]);
    }
    function depthToSpace(args) {
      var backend = args.backend, inputs = args.inputs, attrs = args.attrs;
      var x = inputs.x;
      var blockSize = attrs.blockSize, dataFormat = attrs.dataFormat;
      var batchSize = x.shape[0];
      var inputHeight = dataFormat === "NHWC" ? x.shape[1] : x.shape[2];
      var inputWidth = dataFormat === "NHWC" ? x.shape[2] : x.shape[3];
      var inputDepth = dataFormat === "NHWC" ? x.shape[3] : x.shape[1];
      var outputHeight = inputHeight * blockSize;
      var outputWidth = inputWidth * blockSize;
      var outputDepth = inputDepth / (blockSize * blockSize);
      var outputShape = dataFormat === "NHWC" ? [batchSize, outputHeight, outputWidth, outputDepth] : [batchSize, outputDepth, outputHeight, outputWidth];
      var out = backend.makeOutput(outputShape, "float32");
      var xData = backend.dataIdMap.get(x.dataId);
      var xId = xData.id;
      var xStridesBytes = new Uint8Array(new Int32Array(tfjsCore.util.computeStrides(x.shape)).buffer);
      var outputShapeBytes = new Uint8Array(new Int32Array(outputShape).buffer);
      var outStridesBytes = new Uint8Array(new Int32Array(tfjsCore.util.computeStrides(outputShape)).buffer);
      var outId = backend.dataIdMap.get(out.dataId).id;
      var channelsLast = dataFormat === "NHWC" ? 1 : 0;
      wasmDepthToSpace(xId, blockSize, channelsLast, xStridesBytes, x.shape.length - 1, outputShapeBytes, outStridesBytes, outputShape.length, outId);
      return out;
    }
    var depthToSpaceConfig = {
      kernelName: tfjsCore.DepthToSpace,
      backendName: "wasm",
      setupFunc: setup$Q,
      kernelFunc: depthToSpace
    };
    var wasmDepthwiseConv2d;
    function setup$P(backend) {
      wasmDepthwiseConv2d = backend.wasm.cwrap(tfjsCore.DepthwiseConv2dNative, null, [
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number"
        // outId
      ]);
    }
    function depthwiseConv2d(args) {
      var inputs = args.inputs, attrs = args.attrs, backend = args.backend;
      var x = inputs.x, filter = inputs.filter;
      var xId = backend.dataIdMap.get(x.dataId).id;
      var filterId = backend.dataIdMap.get(filter.dataId).id;
      var strides = attrs.strides, dilations = attrs.dilations, pad2 = attrs.pad, dimRoundingMode = attrs.dimRoundingMode;
      var $dilations = dilations == null ? [1, 1] : dilations;
      var convInfo = tfjsCore.backend_util.computeConv2DInfo(
        x.shape,
        filter.shape,
        strides,
        $dilations,
        pad2,
        dimRoundingMode,
        true
        /* depthwise */
      );
      var filterHeight = convInfo.filterHeight;
      var filterWidth = convInfo.filterWidth;
      var padTop = convInfo.padInfo.top;
      var padRight = convInfo.padInfo.right;
      var padBottom = convInfo.padInfo.bottom;
      var padLeft = convInfo.padInfo.left;
      var dilationHeight = convInfo.dilationHeight;
      var dilationWidth = convInfo.dilationWidth;
      var strideHeight = convInfo.strideHeight;
      var strideWidth = convInfo.strideWidth;
      var inputChannels = convInfo.inChannels;
      var outputChannels = convInfo.outChannels;
      var isSamePad = convInfo.padInfo.type === "SAME" ? 1 : 0;
      if (convInfo.dataFormat !== "channelsLast") {
        throw new Error("wasm backend DepthwiseConv2dNative does not support dataFormat:'" + "".concat(convInfo.dataFormat, "'. Please use 'channelsLast'."));
      }
      var out = backend.makeOutput(convInfo.outShape, "float32");
      var outId = backend.dataIdMap.get(out.dataId).id;
      wasmDepthwiseConv2d(xId, x.shape[0], x.shape[1], x.shape[2], filterId, filterHeight, filterWidth, padTop, padRight, padBottom, padLeft, isSamePad, dilationHeight, dilationWidth, strideHeight, strideWidth, inputChannels, outputChannels, outId);
      return out;
    }
    var depthwiseConv2dNativeConfig = {
      kernelName: tfjsCore.DepthwiseConv2dNative,
      backendName: "wasm",
      setupFunc: setup$P,
      kernelFunc: depthwiseConv2d
    };
    var wasmDiag;
    function setup$O(backend) {
      wasmDiag = backend.wasm.cwrap("Diag", null, [
        "number",
        "number",
        "number",
        "number"
        // outId
      ]);
    }
    function diag(args) {
      var inputs = args.inputs, backend = args.backend;
      var x = inputs.x;
      var xSize = tfjsCore.util.sizeFromShape(x.shape);
      var out = backend.makeOutput(__spreadArray(__spreadArray([], __read(x.shape), false), __read(x.shape), false), x.dtype);
      wasmDiag(backend.dataIdMap.get(x.dataId).id, CppDType[x.dtype], xSize, backend.dataIdMap.get(out.dataId).id);
      return out;
    }
    var diagConfig = {
      kernelName: tfjsCore.Diag,
      backendName: "wasm",
      setupFunc: setup$O,
      kernelFunc: diag
    };
    var wasmDilation2D;
    function setup$N(backend) {
      wasmDilation2D = backend.wasm.cwrap(tfjsCore.Dilation2D, null, [
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number"
        // padLeft
      ]);
    }
    function dilation2D(args) {
      var inputs = args.inputs, backend = args.backend, attrs = args.attrs;
      var x = inputs.x, filter = inputs.filter;
      var strides = attrs.strides, pad2 = attrs.pad, dilations = attrs.dilations;
      if (x.dtype !== filter.dtype) {
        throw new Error("Dilation2D error: x must have the same dtype as filter. Got ".concat(x.dtype, " and ").concat(filter.dtype));
      }
      var dilationInfo = tfjsCore.backend_util.computeDilation2DInfo(
        x.shape,
        filter.shape,
        strides,
        pad2,
        /*dataFormat=*/
        "NHWC",
        dilations
      );
      var out = backend.makeOutput(dilationInfo.outShape, x.dtype);
      wasmDilation2D(
        backend.dataIdMap.get(x.dataId).id,
        backend.dataIdMap.get(filter.dataId).id,
        backend.dataIdMap.get(out.dataId).id,
        CppDType[x.dtype],
        dilationInfo.batchSize,
        /*depth=*/
        dilationInfo.inChannels,
        dilationInfo.inHeight,
        dilationInfo.inWidth,
        dilationInfo.outHeight,
        dilationInfo.outWidth,
        dilationInfo.strideHeight,
        dilationInfo.strideWidth,
        dilationInfo.dilationHeight,
        dilationInfo.dilationWidth,
        dilationInfo.filterHeight,
        dilationInfo.filterWidth,
        dilationInfo.padInfo.top,
        dilationInfo.padInfo.left
      );
      return out;
    }
    var dilation2DConfig = {
      kernelName: tfjsCore.Dilation2D,
      backendName: "wasm",
      setupFunc: setup$N,
      kernelFunc: dilation2D
    };
    var wasmDilation2DBackpropFilter;
    function setup$M(backend) {
      wasmDilation2DBackpropFilter = backend.wasm.cwrap(tfjsCore.Dilation2DBackpropFilter, null, [
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number"
        // padLeft
      ]);
    }
    function dilation2DBackpropFilter(args) {
      var inputs = args.inputs, backend = args.backend, attrs = args.attrs;
      var x = inputs.x, filter = inputs.filter, dy = inputs.dy;
      var strides = attrs.strides, pad2 = attrs.pad, dilations = attrs.dilations;
      if (x.dtype !== filter.dtype || x.dtype !== dy.dtype) {
        throw new Error("Dilation2DBackpropFilter error: x must have the same dtype as filter and dy. Got ".concat(x.dtype, ", ").concat(filter.dtype, ", and ").concat(dy.dtype));
      }
      var dilationInfo = tfjsCore.backend_util.computeDilation2DInfo(
        x.shape,
        filter.shape,
        strides,
        pad2,
        /*dataFormat=*/
        "NHWC",
        dilations
      );
      var gradients = backend.makeOutput(filter.shape, filter.dtype);
      wasmDilation2DBackpropFilter(
        backend.dataIdMap.get(x.dataId).id,
        backend.dataIdMap.get(filter.dataId).id,
        backend.dataIdMap.get(dy.dataId).id,
        backend.dataIdMap.get(gradients.dataId).id,
        CppDType[x.dtype],
        dilationInfo.batchSize,
        /*depth=*/
        dilationInfo.inChannels,
        dilationInfo.inHeight,
        dilationInfo.inWidth,
        dilationInfo.outHeight,
        dilationInfo.outWidth,
        dilationInfo.strideHeight,
        dilationInfo.strideWidth,
        dilationInfo.dilationHeight,
        dilationInfo.dilationWidth,
        dilationInfo.filterHeight,
        dilationInfo.filterWidth,
        dilationInfo.padInfo.top,
        dilationInfo.padInfo.left
      );
      return gradients;
    }
    var dilation2DBackpropFilterConfig = {
      kernelName: tfjsCore.Dilation2DBackpropFilter,
      backendName: "wasm",
      setupFunc: setup$M,
      kernelFunc: dilation2DBackpropFilter
    };
    var wasmDilation2DBackpropInput;
    function setup$L(backend) {
      wasmDilation2DBackpropInput = backend.wasm.cwrap(tfjsCore.Dilation2DBackpropInput, null, [
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number"
        // padLeft
      ]);
    }
    function dilation2DBackpropInput(args) {
      var inputs = args.inputs, backend = args.backend, attrs = args.attrs;
      var x = inputs.x, filter = inputs.filter, dy = inputs.dy;
      var strides = attrs.strides, pad2 = attrs.pad, dilations = attrs.dilations;
      if (x.dtype !== filter.dtype || x.dtype !== dy.dtype) {
        throw new Error("Dilation2DBackpropInput error: x must have the same dtype as filter and dy. Got ".concat(x.dtype, ", ").concat(filter.dtype, ", and ").concat(dy.dtype));
      }
      var dilationInfo = tfjsCore.backend_util.computeDilation2DInfo(
        x.shape,
        filter.shape,
        strides,
        pad2,
        /*dataFormat=*/
        "NHWC",
        dilations
      );
      var gradients = backend.makeOutput(x.shape, x.dtype);
      wasmDilation2DBackpropInput(
        backend.dataIdMap.get(x.dataId).id,
        backend.dataIdMap.get(filter.dataId).id,
        backend.dataIdMap.get(dy.dataId).id,
        backend.dataIdMap.get(gradients.dataId).id,
        CppDType[x.dtype],
        dilationInfo.batchSize,
        /*depth=*/
        dilationInfo.inChannels,
        dilationInfo.inHeight,
        dilationInfo.inWidth,
        dilationInfo.outHeight,
        dilationInfo.outWidth,
        dilationInfo.strideHeight,
        dilationInfo.strideWidth,
        dilationInfo.dilationHeight,
        dilationInfo.dilationWidth,
        dilationInfo.filterHeight,
        dilationInfo.filterWidth,
        dilationInfo.padInfo.top,
        dilationInfo.padInfo.left
      );
      return gradients;
    }
    var dilation2DBackpropInputConfig = {
      kernelName: tfjsCore.Dilation2DBackpropInput,
      backendName: "wasm",
      setupFunc: setup$L,
      kernelFunc: dilation2DBackpropInput
    };
    var eluConfig = createUnaryKernelConfig(tfjsCore.Elu);
    var wasmEluGrad;
    function setup$K(backend) {
      wasmEluGrad = backend.wasm.cwrap(tfjsCore.EluGrad, null, [
        "number",
        "number",
        "number"
        // outId
      ]);
    }
    function eluGrad(args) {
      var inputs = args.inputs, backend = args.backend;
      var dy = inputs.dy, y = inputs.y;
      var out = backend.makeOutput(y.shape, "float32");
      var tensorId = function(x) {
        return backend.dataIdMap.get(x.dataId).id;
      };
      wasmEluGrad(tensorId(y), tensorId(dy), tensorId(out));
      return out;
    }
    var eluGradConfig = {
      kernelName: tfjsCore.EluGrad,
      backendName: "wasm",
      setupFunc: setup$K,
      kernelFunc: eluGrad
    };
    var supportsFullBroadcast$8 = false;
    var equalConfig = createBinaryKernelConfig(tfjsCore.Equal, supportsFullBroadcast$8, "bool");
    var expConfig = createUnaryKernelConfig(tfjsCore.Exp, "float32");
    function expandDims(args) {
      var inputs = args.inputs, attrs = args.attrs, backend = args.backend;
      var input = inputs.input;
      var dim = attrs.dim;
      var inputRank = input.shape.length;
      var newShape = input.shape.slice();
      var $dim = dim;
      if (dim < 0) {
        tfjsCore.util.assert(-(inputRank + 1) <= dim, function() {
          return "Axis must be in the interval [".concat(-(inputRank + 1), ", ").concat(inputRank, "]");
        });
        $dim = inputRank + dim + 1;
      }
      newShape.splice($dim, 0, 1);
      return reshape({ inputs: { x: input }, backend, attrs: { shape: newShape } });
    }
    var expandDimsConfig = {
      kernelName: tfjsCore.ExpandDims,
      backendName: "wasm",
      kernelFunc: expandDims
    };
    var expm1Config = createUnaryKernelConfig(tfjsCore.Expm1, "float32");
    function fill(args) {
      var _a2 = args.attrs, shape = _a2.shape, value = _a2.value, dtype = _a2.dtype, backend = args.backend;
      var out = backend.makeOutput(shape, dtype);
      var outVals = backend.typedArrayFromHeap(out);
      outVals.fill(value);
      return out;
    }
    var fillConfig = {
      kernelName: tfjsCore.Fill,
      backendName: "wasm",
      kernelFunc: fill
    };
    var wasmFlipLeftRight;
    function setup$J(backend) {
      wasmFlipLeftRight = backend.wasm.cwrap(tfjsCore.FlipLeftRight, null, [
        "number",
        "number",
        "number",
        "number",
        "number",
        "number"
        // outId
      ]);
    }
    function flipLeftRight(args) {
      var inputs = args.inputs, backend = args.backend;
      var image = inputs.image;
      var out = backend.makeOutput(image.shape, image.dtype);
      var imageId = backend.dataIdMap.get(image.dataId).id;
      var outId = backend.dataIdMap.get(out.dataId).id;
      var _a2 = __read(image.shape, 4), batch = _a2[0], imageHeight = _a2[1], imageWidth = _a2[2], numChannels = _a2[3];
      wasmFlipLeftRight(imageId, batch, imageHeight, imageWidth, numChannels, outId);
      return out;
    }
    var flipLeftRightConfig = {
      kernelName: tfjsCore.FlipLeftRight,
      backendName: "wasm",
      kernelFunc: flipLeftRight,
      setupFunc: setup$J
    };
    var floorConfig = createUnaryKernelConfig(tfjsCore.Floor);
    var floorDivConfig = createBinaryKernelConfig(tfjsCore.FloorDiv);
    var wasmBatchNorm;
    function setup$I(backend) {
      wasmBatchNorm = backend.wasm.cwrap(tfjsCore.FusedBatchNorm, null, ["number", "number", "number", "number", "number", "number", "number"]);
    }
    function fusedBatchNorm(args) {
      var backend = args.backend, inputs = args.inputs, attrs = args.attrs;
      var varianceEpsilon = attrs.varianceEpsilon;
      var x = inputs.x, mean2 = inputs.mean, variance = inputs.variance, offset = inputs.offset, scale = inputs.scale;
      var xId = backend.dataIdMap.get(x.dataId).id;
      var meanId = backend.dataIdMap.get(mean2.dataId).id;
      var varianceId = backend.dataIdMap.get(variance.dataId).id;
      var offsetId = offset != null ? backend.dataIdMap.get(offset.dataId).id : 0;
      var scaleId = scale != null ? backend.dataIdMap.get(scale.dataId).id : 0;
      var out = backend.makeOutput(x.shape, x.dtype);
      if (tfjsCore.util.sizeFromShape(x.shape) === 0) {
        return out;
      }
      var outId = backend.dataIdMap.get(out.dataId).id;
      wasmBatchNorm(xId, meanId, varianceId, offsetId, scaleId, varianceEpsilon, outId);
      return out;
    }
    var fusedBatchNormConfig = {
      kernelName: tfjsCore.FusedBatchNorm,
      backendName: "wasm",
      setupFunc: setup$I,
      kernelFunc: fusedBatchNorm
    };
    var wasmFusedConv2d;
    function setup$H(backend) {
      wasmFusedConv2d = backend.wasm.cwrap(tfjsCore.FusedConv2D, null, [
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number"
        // outId
      ]);
    }
    function fusedConv2d(args) {
      var inputs = args.inputs, attrs = args.attrs, backend = args.backend;
      var x = inputs.x, filter = inputs.filter, bias = inputs.bias, preluActivationWeights = inputs.preluActivationWeights;
      var strides = attrs.strides, pad2 = attrs.pad, dilations = attrs.dilations, dataFormat = attrs.dataFormat, dimRoundingMode = attrs.dimRoundingMode, activation = attrs.activation, leakyreluAlpha = attrs.leakyreluAlpha;
      var convInfo = tfjsCore.backend_util.computeConv2DInfo(x.shape, filter.shape, strides, dilations, pad2, dimRoundingMode);
      var fusedActivation = FusableActivation[activation];
      if (fusedActivation == null) {
        throw new Error("".concat(activation, " activation not yet supported for FusedConv2D ") + "in the wasm backend.");
      }
      var xId = backend.dataIdMap.get(x.dataId).id;
      var filterId = backend.dataIdMap.get(filter.dataId).id;
      var outputChannels = convInfo.outChannels;
      var biasId = 0;
      if (bias != null) {
        var biasData = backend.dataIdMap.get(bias.dataId);
        if (biasData.shape.length !== 1) {
          throw new Error("FusedConv2D only supports rank-1 bias but got " + "rank ".concat(biasData.shape.length, "."));
        }
        if (biasData.shape[0] !== outputChannels) {
          throw new Error("FusedConv2D bias shape (".concat(biasData.shape, ") does not ") + "match the number of output channels (".concat(outputChannels, ")"));
        }
        biasId = biasData.id;
      }
      var filterHeight = convInfo.filterHeight;
      var filterWidth = convInfo.filterWidth;
      var padTop = convInfo.padInfo.top;
      var padRight = convInfo.padInfo.right;
      var padBottom = convInfo.padInfo.bottom;
      var padLeft = convInfo.padInfo.left;
      var dilationHeight = convInfo.dilationHeight;
      var dilationWidth = convInfo.dilationWidth;
      var strideHeight = convInfo.strideHeight;
      var strideWidth = convInfo.strideWidth;
      var inputChannels = convInfo.inChannels;
      var isSamePad = convInfo.padInfo.type === "SAME" ? 1 : 0;
      var batchSize = convInfo.batchSize;
      var inHeight = convInfo.inHeight;
      var inWidth = convInfo.inWidth;
      if (dataFormat !== "NHWC") {
        throw new Error("wasm backend FusedConv2D does not support dataFormat:'" + "".concat(dataFormat, "'. Please use 'NHWC'."));
      }
      var out = backend.makeOutput(convInfo.outShape, "float32");
      var outId = backend.dataIdMap.get(out.dataId).id;
      var preluActivationWeightsId = preluActivationWeights == null ? 0 : backend.dataIdMap.get(preluActivationWeights.dataId).id;
      wasmFusedConv2d(xId, batchSize, inHeight, inWidth, filterId, filterHeight, filterWidth, biasId, padTop, padRight, padBottom, padLeft, isSamePad, dilationHeight, dilationWidth, strideHeight, strideWidth, inputChannels, outputChannels, fusedActivation, preluActivationWeightsId, leakyreluAlpha || 0, outId);
      return out;
    }
    var fusedConv2DConfig = {
      kernelName: tfjsCore.FusedConv2D,
      backendName: "wasm",
      setupFunc: setup$H,
      kernelFunc: fusedConv2d
    };
    var wasmFusedDepthwiseConv2d;
    function setup$G(backend) {
      wasmFusedDepthwiseConv2d = backend.wasm.cwrap(tfjsCore.FusedDepthwiseConv2D, null, [
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number"
        // outId
      ]);
    }
    function fusedDepthwiseConv2d(args) {
      var inputs = args.inputs, attrs = args.attrs, backend = args.backend;
      var x = inputs.x, filter = inputs.filter, bias = inputs.bias, preluActivationWeights = inputs.preluActivationWeights;
      var strides = attrs.strides, pad2 = attrs.pad, dilations = attrs.dilations, dataFormat = attrs.dataFormat, dimRoundingMode = attrs.dimRoundingMode, activation = attrs.activation, leakyreluAlpha = attrs.leakyreluAlpha;
      var convInfo = tfjsCore.backend_util.computeConv2DInfo(
        x.shape,
        filter.shape,
        strides,
        dilations,
        pad2,
        dimRoundingMode,
        true
        /* depthwise */
      );
      var fusedActivation = FusableActivation[activation];
      if (fusedActivation == null) {
        throw new Error("".concat(activation, " activation not yet supported for FusedDepthwiseConv2D ") + "in the wasm backend.");
      }
      var xId = backend.dataIdMap.get(x.dataId).id;
      var filterId = backend.dataIdMap.get(filter.dataId).id;
      var outputChannels = convInfo.outChannels;
      var biasId = 0;
      if (bias != null) {
        var biasData = backend.dataIdMap.get(bias.dataId);
        if (biasData.shape.length !== 1) {
          throw new Error("FusedDepthwiseConv2D only supports rank-1 bias but got " + "rank ".concat(biasData.shape.length, "."));
        }
        if (biasData.shape[0] !== outputChannels) {
          throw new Error("FusedDepthwiseConv2D bias shape (".concat(biasData.shape, ") does not ") + "match the number of output channels (".concat(outputChannels, ")"));
        }
        biasId = biasData.id;
      }
      var filterHeight = convInfo.filterHeight;
      var filterWidth = convInfo.filterWidth;
      var padTop = convInfo.padInfo.top;
      var padRight = convInfo.padInfo.right;
      var padBottom = convInfo.padInfo.bottom;
      var padLeft = convInfo.padInfo.left;
      var dilationHeight = convInfo.dilationHeight;
      var dilationWidth = convInfo.dilationWidth;
      var strideHeight = convInfo.strideHeight;
      var strideWidth = convInfo.strideWidth;
      var inputChannels = convInfo.inChannels;
      var isSamePad = convInfo.padInfo.type === "SAME" ? 1 : 0;
      var batchSize = convInfo.batchSize;
      var inHeight = convInfo.inHeight;
      var inWidth = convInfo.inWidth;
      if (dataFormat !== "NHWC") {
        throw new Error("wasm backend FusedDepthwiseConv2D does not support dataFormat:'" + "".concat(dataFormat, "'. Please use 'NHWC'."));
      }
      var out = backend.makeOutput(convInfo.outShape, "float32");
      var outId = backend.dataIdMap.get(out.dataId).id;
      var preluActivationWeightsId = preluActivationWeights == null ? 0 : backend.dataIdMap.get(preluActivationWeights.dataId).id;
      wasmFusedDepthwiseConv2d(xId, batchSize, inHeight, inWidth, filterId, filterHeight, filterWidth, biasId, padTop, padRight, padBottom, padLeft, isSamePad, dilationHeight, dilationWidth, strideHeight, strideWidth, inputChannels, outputChannels, fusedActivation, preluActivationWeightsId, leakyreluAlpha || 0, outId);
      return out;
    }
    var fusedDepthwiseConv2DConfig = {
      kernelName: tfjsCore.FusedDepthwiseConv2D,
      backendName: "wasm",
      setupFunc: setup$G,
      kernelFunc: fusedDepthwiseConv2d
    };
    var wasmGatherNd;
    function setup$F(backend) {
      wasmGatherNd = backend.wasm.cwrap(tfjsCore.GatherNd, null, [
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "array",
        "number"
        // outId
      ]);
    }
    function gatherNd(args) {
      var backend = args.backend, inputs = args.inputs;
      var params = inputs.params, indices = inputs.indices;
      var _a2 = __read(tfjsCore.gather_util.prepareAndValidate(params, indices), 4), resultShape = _a2[0], numSlices = _a2[1], sliceSize = _a2[2], strides = _a2[3];
      var out = backend.makeOutput(resultShape, params.dtype);
      if (numSlices === 0) {
        return out;
      }
      var indicesShape = indices.shape;
      var sliceRank = indicesShape[indicesShape.length - 1];
      var xData = backend.dataIdMap.get(params.dataId);
      var xId = xData.id;
      var indicesData = backend.dataIdMap.get(indices.dataId);
      var indicesId = indicesData.id;
      var stridesBytes = new Uint8Array(new Int32Array(strides).buffer);
      var outId = backend.dataIdMap.get(out.dataId).id;
      wasmGatherNd(xId, CppDType[params.dtype], indicesId, numSlices, sliceRank, sliceSize, stridesBytes, outId);
      return out;
    }
    var gatherNdConfig = {
      kernelName: tfjsCore.GatherNd,
      backendName: "wasm",
      setupFunc: setup$F,
      kernelFunc: gatherNd
    };
    var wasmGather;
    function setup$E(backend) {
      wasmGather = backend.wasm.cwrap("Gather", null, [
        "number",
        "number",
        "array",
        "number",
        "number",
        "number",
        "array",
        "number"
        // outId
      ]);
    }
    function gatherV2(args) {
      var backend = args.backend, inputs = args.inputs, attrs = args.attrs;
      var x = inputs.x, indices = inputs.indices;
      var axis = attrs.axis, batchDims = attrs.batchDims;
      var parsedAxis = tfjsCore.util.parseAxisParam(axis, x.shape)[0];
      var indicesVals = backend.readSync(indices.dataId);
      var axisDim = x.shape[parsedAxis];
      var _loop_1 = function(i2) {
        var index = indicesVals[i2];
        tfjsCore.util.assert(index <= axisDim - 1 && index >= 0, function() {
          return "GatherV2: the index value ".concat(index, " is not in [0, ").concat(axisDim - 1, "]");
        });
      };
      for (var i = 0; i < indicesVals.length; ++i) {
        _loop_1(i);
      }
      var shapeInfo = tfjsCore.backend_util.segment_util.collectGatherOpShapeInfo(x, indices, parsedAxis, batchDims);
      var flattenX = reshape({
        inputs: { x },
        attrs: {
          shape: [
            shapeInfo.batchSize,
            shapeInfo.outerSize,
            shapeInfo.dimSize,
            shapeInfo.sliceSize
          ]
        },
        backend
      });
      var indicesSize = tfjsCore.util.sizeFromShape(indices.shape);
      var flattenIndex = reshape({
        inputs: { x: indices },
        attrs: { shape: [shapeInfo.batchSize, indicesSize / shapeInfo.batchSize] },
        backend
      });
      var flattenOutputShape = [
        shapeInfo.batchSize,
        shapeInfo.outerSize,
        indicesSize / shapeInfo.batchSize,
        shapeInfo.sliceSize
      ];
      var out = backend.makeOutput(flattenOutputShape, x.dtype);
      if (tfjsCore.util.sizeFromShape(x.shape) === 0) {
        return out;
      }
      var stridesSize = flattenX.shape.length - 1;
      var xData = backend.dataIdMap.get(flattenX.dataId);
      var xId = xData.id;
      var indicesData = backend.dataIdMap.get(flattenIndex.dataId);
      var indicesId = indicesData.id;
      var outId = backend.dataIdMap.get(out.dataId).id;
      var xStridesBytes = new Uint8Array(new Int32Array(tfjsCore.util.computeStrides(flattenX.shape)).buffer);
      var outStridesBytes = new Uint8Array(new Int32Array(tfjsCore.util.computeStrides(flattenOutputShape)).buffer);
      wasmGather(xId, CppDType[x.dtype], xStridesBytes, stridesSize, indicesId, shapeInfo.batchSize, outStridesBytes, outId);
      backend.disposeData(flattenX.dataId);
      backend.disposeData(flattenIndex.dataId);
      out.shape = shapeInfo.outputShape;
      return out;
    }
    var gatherV2Config = {
      kernelName: tfjsCore.GatherV2,
      backendName: "wasm",
      setupFunc: setup$E,
      kernelFunc: gatherV2
    };
    var supportsFullBroadcast$7 = false;
    var greaterConfig = createBinaryKernelConfig(tfjsCore.Greater, supportsFullBroadcast$7, "bool");
    var supportsFullBroadcast$6 = false;
    var greaterEqualConfig = createBinaryKernelConfig(tfjsCore.GreaterEqual, supportsFullBroadcast$6, "bool");
    var isFiniteConfig = createUnaryKernelConfig(tfjsCore.IsFinite, "bool");
    var isInfConfig = createUnaryKernelConfig(tfjsCore.IsInf, "bool");
    var isNaNConfig = createUnaryKernelConfig(tfjsCore.IsNan, "bool");
    var wasmFunc$5;
    function setupFunc(backend) {
      wasmFunc$5 = backend.wasm.cwrap(tfjsCore.LeakyRelu, null, [
        "number",
        "number",
        "number",
        "number"
        // out_id
      ]);
    }
    function leakyRelu(args) {
      var x = args.inputs.x, alpha = args.attrs.alpha, backend = args.backend;
      var xId = backend.dataIdMap.get(x.dataId).id;
      var out = backend.makeOutput(x.shape, "float32");
      if (tfjsCore.util.sizeFromShape(x.shape) !== 0) {
        var outId = backend.dataIdMap.get(out.dataId).id;
        wasmFunc$5(xId, CppDType[x.dtype], alpha, outId);
      }
      return out;
    }
    var leakyReluConfig = {
      kernelName: tfjsCore.LeakyRelu,
      backendName: "wasm",
      setupFunc,
      kernelFunc: leakyRelu
    };
    var supportsFullBroadcast$5 = false;
    var lessConfig = createBinaryKernelConfig(tfjsCore.Less, supportsFullBroadcast$5, "bool");
    var supportsFullBroadcast$4 = false;
    var lessEqualConfig = createBinaryKernelConfig(tfjsCore.LessEqual, supportsFullBroadcast$4, "bool");
    var wasmLinSpace;
    function setup$D(backend) {
      wasmLinSpace = backend.wasm.cwrap(tfjsCore.LinSpace, null, [
        "number",
        "number",
        "number",
        "number"
        // num
      ]);
    }
    function linSpace(args) {
      var attrs = args.attrs, backend = args.backend;
      var start = attrs.start, stop = attrs.stop, num = attrs.num;
      var numInt = Math.floor(num);
      var out = backend.makeOutput([numInt], "float32");
      wasmLinSpace(backend.dataIdMap.get(out.dataId).id, start, stop, numInt);
      return out;
    }
    var linSpaceConfig = {
      kernelName: tfjsCore.LinSpace,
      backendName: "wasm",
      setupFunc: setup$D,
      kernelFunc: linSpace
    };
    var logConfig = createUnaryKernelConfig(tfjsCore.Log);
    var log1pConfig = createUnaryKernelConfig(tfjsCore.Log1p);
    var supportsFullBroadcast$3 = false;
    var logicalAndConfig = createBinaryKernelConfig(tfjsCore.LogicalAnd, supportsFullBroadcast$3, "bool");
    var logicalNotConfig = createUnaryKernelConfig(tfjsCore.LogicalNot);
    var supportsFullBroadcast$2 = false;
    var logicalOrConfig = createBinaryKernelConfig(tfjsCore.LogicalOr, supportsFullBroadcast$2, "bool");
    var supportsFullBroadcast$1 = false;
    var logicalXorConfig = createBinaryKernelConfig(tfjsCore.LogicalXor, supportsFullBroadcast$1, "bool");
    var wasmLRN;
    function setup$C(backend) {
      wasmLRN = backend.wasm.cwrap(tfjsCore.LRN, null, [
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number"
        // beta
      ]);
    }
    function lrn(args) {
      var inputs = args.inputs, backend = args.backend, attrs = args.attrs;
      var x = inputs.x;
      var depthRadius = attrs.depthRadius, bias = attrs.bias, alpha = attrs.alpha, beta = attrs.beta;
      if (x.dtype !== "float32") {
        throw new Error("LRN error: x must have dtype float32");
      }
      var out = backend.makeOutput(x.shape, x.dtype);
      wasmLRN(
        backend.dataIdMap.get(x.dataId).id,
        backend.dataIdMap.get(out.dataId).id,
        /*channels=*/
        x.shape[3],
        depthRadius,
        bias,
        alpha,
        beta
      );
      return out;
    }
    var lrnConfig = {
      kernelName: tfjsCore.LRN,
      backendName: "wasm",
      setupFunc: setup$C,
      kernelFunc: lrn
    };
    var wasmLRNGrad;
    function setup$B(backend) {
      wasmLRNGrad = backend.wasm.cwrap(tfjsCore.LRNGrad, null, [
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number"
        // beta
      ]);
    }
    function lrnGrad(args) {
      var inputs = args.inputs, backend = args.backend, attrs = args.attrs;
      var x = inputs.x, y = inputs.y, dy = inputs.dy;
      var depthRadius = attrs.depthRadius, bias = attrs.bias, alpha = attrs.alpha, beta = attrs.beta;
      if (x.dtype !== "float32" || y.dtype !== "float32" || dy.dtype !== "float32") {
        throw new Error("LRNGrad error: x, y, and dy must have dtype float32");
      }
      var dx = backend.makeOutput(x.shape, x.dtype);
      wasmLRNGrad(
        backend.dataIdMap.get(x.dataId).id,
        backend.dataIdMap.get(y.dataId).id,
        backend.dataIdMap.get(dy.dataId).id,
        backend.dataIdMap.get(dx.dataId).id,
        /*channels=*/
        dy.shape[3],
        depthRadius,
        bias,
        alpha,
        beta
      );
      return dx;
    }
    var lrnGradConfig = {
      kernelName: tfjsCore.LRNGrad,
      backendName: "wasm",
      setupFunc: setup$B,
      kernelFunc: lrnGrad
    };
    var wasmMax;
    function setup$A(backend) {
      wasmMax = backend.wasm.cwrap(tfjsCore.Max, null, [
        "number",
        "number",
        "number",
        "number"
        // out_id
      ]);
    }
    function max(args) {
      var backend = args.backend, inputs = args.inputs, attrs = args.attrs;
      var axis = attrs.reductionIndices, keepDims = attrs.keepDims;
      var x = inputs.x;
      var xId = backend.dataIdMap.get(x.dataId).id;
      var inputId = xId;
      var input = x;
      var _a2 = permuteAxesAndTranspose(x, axis, backend), transposed = _a2.transposed, axes = _a2.axes, originalAxes = _a2.originalAxes, inputWasTransposed = _a2.inputWasTransposed;
      if (inputWasTransposed) {
        var transposedId = backend.dataIdMap.get(transposed.dataId).id;
        input = transposed;
        inputId = transposedId;
      }
      var inputRank = input.shape.length;
      tfjsCore.backend_util.assertAxesAreInnerMostDims("max", axes, inputRank);
      var _b = __read(tfjsCore.backend_util.computeOutAndReduceShapes(input.shape, axes), 2), outShape = _b[0], reduceShape = _b[1];
      var reduceSize = tfjsCore.util.sizeFromShape(reduceShape);
      var out = backend.makeOutput(outShape, x.dtype);
      if (tfjsCore.util.sizeFromShape(input.shape) !== 0) {
        var outId = backend.dataIdMap.get(out.dataId).id;
        wasmMax(inputId, CppDType[x.dtype], reduceSize, outId);
      }
      if (inputWasTransposed) {
        backend.disposeData(transposed.dataId);
      }
      if (keepDims) {
        var newShape = tfjsCore.backend_util.expandShapeToKeepDim(out.shape, originalAxes);
        out.shape = newShape;
      }
      return out;
    }
    var maxConfig = {
      kernelName: tfjsCore.Max,
      backendName: "wasm",
      setupFunc: setup$A,
      kernelFunc: max
    };
    var maximumConfig = createBinaryKernelConfig(tfjsCore.Maximum);
    var wasmMaxPool;
    function setup$z(backend) {
      wasmMaxPool = backend.wasm.cwrap(tfjsCore.MaxPool, null, [
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number"
        // outId
      ]);
    }
    function maxPool(args) {
      var inputs = args.inputs, attrs = args.attrs, backend = args.backend;
      var x = inputs.x;
      var xId = backend.dataIdMap.get(x.dataId).id;
      tfjsCore.util.assert(x.dtype === "float32", function() {
        return "Error in MaxPool: only float32 input is supported. Got ".concat(x.dtype, ".");
      });
      var filterSize = attrs.filterSize, strides = attrs.strides, pad2 = attrs.pad, dimRoundingMode = attrs.dimRoundingMode;
      var convInfo = tfjsCore.backend_util.computePool2DInfo(x.shape, filterSize, strides, 1, pad2, dimRoundingMode);
      var filterHeight = convInfo.filterHeight;
      var filterWidth = convInfo.filterWidth;
      var padTop = convInfo.padInfo.top;
      var padRight = convInfo.padInfo.right;
      var padBottom = convInfo.padInfo.bottom;
      var padLeft = convInfo.padInfo.left;
      var dilationHeight = convInfo.dilationHeight;
      var dilationWidth = convInfo.dilationWidth;
      var strideHeight = convInfo.strideHeight;
      var strideWidth = convInfo.strideWidth;
      var inputChannels = convInfo.inChannels;
      var outputChannels = convInfo.outChannels;
      if (convInfo.dataFormat !== "channelsLast") {
        throw new Error("wasm backend does not support dataFormat:'" + "".concat(convInfo.dataFormat, "'. Please use 'channelsLast'."));
      }
      var out = backend.makeOutput(convInfo.outShape, "float32");
      var outId = backend.dataIdMap.get(out.dataId).id;
      wasmMaxPool(xId, x.shape[0], x.shape[1], x.shape[2], filterHeight, filterWidth, padTop, padRight, padBottom, padLeft, dilationHeight, dilationWidth, strideHeight, strideWidth, inputChannels, outputChannels, outId);
      return out;
    }
    var maxPoolConfig = {
      kernelName: tfjsCore.MaxPool,
      backendName: "wasm",
      setupFunc: setup$z,
      kernelFunc: maxPool
    };
    var wasmMaxPool3D;
    function setup$y(backend) {
      wasmMaxPool3D = backend.wasm.cwrap("MaxPool3D", null, [
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number"
        // padLeft
      ]);
    }
    function maxPool3D(args) {
      var inputs = args.inputs, backend = args.backend, attrs = args.attrs;
      var x = inputs.x;
      var filterSize = attrs.filterSize, strides = attrs.strides, pad2 = attrs.pad, dimRoundingMode = attrs.dimRoundingMode, dataFormat = attrs.dataFormat;
      var convInfo = tfjsCore.backend_util.computePool3DInfo(
        x.shape,
        filterSize,
        strides,
        /*dilations=*/
        1,
        pad2,
        dimRoundingMode,
        dataFormat
      );
      var out = backend.makeOutput(convInfo.outShape, x.dtype);
      wasmMaxPool3D(
        backend.dataIdMap.get(x.dataId).id,
        backend.dataIdMap.get(out.dataId).id,
        convInfo.batchSize,
        // Since Pool3D ops (AvgPool3D and MaxPool3D) support 3D filter only, in
        // channels should always equal to out channels.
        /*channelSize=*/
        convInfo.inChannels,
        convInfo.inDepth,
        convInfo.inHeight,
        convInfo.inWidth,
        convInfo.outDepth,
        convInfo.outHeight,
        convInfo.outWidth,
        convInfo.strideDepth,
        convInfo.strideHeight,
        convInfo.strideWidth,
        convInfo.dilationDepth,
        convInfo.dilationHeight,
        convInfo.dilationWidth,
        convInfo.effectiveFilterDepth,
        convInfo.effectiveFilterHeight,
        convInfo.effectiveFilterWidth,
        convInfo.padInfo.front,
        convInfo.padInfo.top,
        convInfo.padInfo.left
      );
      return out;
    }
    var maxPool3DConfig = {
      kernelName: tfjsCore.MaxPool3D,
      backendName: "wasm",
      setupFunc: setup$y,
      kernelFunc: maxPool3D
    };
    var wasmMaxPool3DGrad;
    function setup$x(backend) {
      wasmMaxPool3DGrad = backend.wasm.cwrap("MaxPool3DGrad", null, [
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number"
        // padLeft
      ]);
    }
    function maxPool3DGrad(args) {
      var inputs = args.inputs, backend = args.backend, attrs = args.attrs;
      var dy = inputs.dy, input = inputs.input;
      var filterSize = attrs.filterSize, strides = attrs.strides, pad2 = attrs.pad, dimRoundingMode = attrs.dimRoundingMode;
      var convInfo = tfjsCore.backend_util.computePool3DInfo(
        input.shape,
        filterSize,
        strides,
        /*dilations=*/
        1,
        pad2,
        dimRoundingMode
      );
      var dx = backend.makeOutput(input.shape, input.dtype);
      wasmMaxPool3DGrad(
        backend.dataIdMap.get(input.dataId).id,
        backend.dataIdMap.get(dy.dataId).id,
        backend.dataIdMap.get(dx.dataId).id,
        convInfo.batchSize,
        // Since Pool3D ops (MaxPool3D and MaxPool3D) support 3D filter only, in
        // channels should always equal to out channels.
        /*channelSize=*/
        convInfo.inChannels,
        convInfo.inDepth,
        convInfo.inHeight,
        convInfo.inWidth,
        convInfo.outDepth,
        convInfo.outHeight,
        convInfo.outWidth,
        convInfo.strideDepth,
        convInfo.strideHeight,
        convInfo.strideWidth,
        convInfo.dilationDepth,
        convInfo.dilationHeight,
        convInfo.dilationWidth,
        convInfo.effectiveFilterDepth,
        convInfo.effectiveFilterHeight,
        convInfo.effectiveFilterWidth,
        convInfo.padInfo.front,
        convInfo.padInfo.top,
        convInfo.padInfo.left
      );
      return dx;
    }
    var maxPool3DGradConfig = {
      kernelName: tfjsCore.MaxPool3DGrad,
      backendName: "wasm",
      setupFunc: setup$x,
      kernelFunc: maxPool3DGrad
    };
    var wasmMean;
    function setup$w(backend) {
      wasmMean = backend.wasm.cwrap(tfjsCore.Mean, null, ["number, number, number"]);
    }
    function mean(args) {
      var backend = args.backend, inputs = args.inputs, attrs = args.attrs;
      var axis = attrs.axis, keepDims = attrs.keepDims;
      var x = inputs.x;
      var xId = backend.dataIdMap.get(x.dataId).id;
      var inputId = xId;
      var input = x;
      var _a2 = permuteAxesAndTranspose(x, axis, backend), transposed = _a2.transposed, axes = _a2.axes, originalAxes = _a2.originalAxes, inputWasTransposed = _a2.inputWasTransposed;
      var reductionAxes = axes;
      if (inputWasTransposed) {
        var transposedId = backend.dataIdMap.get(transposed.dataId).id;
        if (transposedId !== xId) {
          input = transposed;
          inputId = transposedId;
          reductionAxes = tfjsCore.backend_util.getInnerMostAxes(reductionAxes.length, input.shape.length);
        }
      }
      tfjsCore.backend_util.assertAxesAreInnerMostDims("mean", reductionAxes, input.shape.length);
      var _b = __read(tfjsCore.backend_util.computeOutAndReduceShapes(input.shape, reductionAxes), 2), outShape = _b[0], reduceShape = _b[1];
      var reduceSize = tfjsCore.util.sizeFromShape(reduceShape);
      var castedInput = input;
      if (input.dtype !== "float32") {
        castedInput = cast({ backend, inputs: { x: input }, attrs: { dtype: "float32" } });
        inputId = backend.dataIdMap.get(castedInput.dataId).id;
      }
      var out = backend.makeOutput(outShape, "float32");
      if (tfjsCore.util.sizeFromShape(input.shape) !== 0) {
        var outId = backend.dataIdMap.get(out.dataId).id;
        wasmMean(inputId, reduceSize, outId);
      }
      if (inputWasTransposed) {
        backend.disposeData(transposed.dataId);
      }
      if (keepDims) {
        var newShape = tfjsCore.backend_util.expandShapeToKeepDim(out.shape, originalAxes);
        out.shape = newShape;
      }
      if (input.dtype !== "float32") {
        backend.disposeData(castedInput.dataId);
      }
      return out;
    }
    var meanConfig = {
      kernelName: tfjsCore.Mean,
      backendName: "wasm",
      setupFunc: setup$w,
      kernelFunc: mean
    };
    var wasmMin;
    function setup$v(backend) {
      wasmMin = backend.wasm.cwrap(tfjsCore.Min, null, [
        "number",
        "number",
        "number",
        "number"
        // out_id
      ]);
    }
    function min(args) {
      var backend = args.backend, inputs = args.inputs, attrs = args.attrs;
      var axis = attrs.axis, keepDims = attrs.keepDims;
      var x = inputs.x;
      var xId = backend.dataIdMap.get(x.dataId).id;
      var inputId = xId;
      var input = x;
      var _a2 = permuteAxesAndTranspose(x, axis, backend), transposed = _a2.transposed, axes = _a2.axes, originalAxes = _a2.originalAxes, inputWasTransposed = _a2.inputWasTransposed;
      if (inputWasTransposed) {
        var transposedId = backend.dataIdMap.get(transposed.dataId).id;
        if (transposedId !== xId) {
          input = transposed;
          inputId = transposedId;
        }
      }
      var inputRank = input.shape.length;
      tfjsCore.backend_util.assertAxesAreInnerMostDims("min", axes, inputRank);
      var _b = __read(tfjsCore.backend_util.computeOutAndReduceShapes(input.shape, axes), 2), outShape = _b[0], reduceShape = _b[1];
      var reduceSize = tfjsCore.util.sizeFromShape(reduceShape);
      var out = backend.makeOutput(outShape, input.dtype);
      if (tfjsCore.util.sizeFromShape(input.shape) !== 0) {
        var outId = backend.dataIdMap.get(out.dataId).id;
        wasmMin(inputId, CppDType[x.dtype], reduceSize, outId);
      }
      if (inputWasTransposed) {
        backend.disposeData(transposed.dataId);
      }
      if (keepDims) {
        var newShape = tfjsCore.backend_util.expandShapeToKeepDim(out.shape, originalAxes);
        out.shape = newShape;
      }
      return out;
    }
    var minConfig = {
      kernelName: tfjsCore.Min,
      backendName: "wasm",
      setupFunc: setup$v,
      kernelFunc: min
    };
    var minimumConfig = createBinaryKernelConfig(tfjsCore.Minimum);
    var MirrorPaddingMode;
    (function(MirrorPaddingMode2) {
      MirrorPaddingMode2[MirrorPaddingMode2["reflect"] = 0] = "reflect";
      MirrorPaddingMode2[MirrorPaddingMode2["symmetric"] = 1] = "symmetric";
    })(MirrorPaddingMode || (MirrorPaddingMode = {}));
    var wasmMirrorPad;
    function setup$u(backend) {
      wasmMirrorPad = backend.wasm.cwrap(tfjsCore.MirrorPad, null, [
        "number",
        "array",
        "number",
        "number",
        "array",
        "array",
        "number",
        "number"
        // outId
      ]);
    }
    function mirrorPad(args) {
      var x = args.inputs.x, backend = args.backend, _a2 = args.attrs, paddings = _a2.paddings, mode = _a2.mode;
      var outShape = paddings.map(
        function(p, i) {
          return p[0] + x.shape[i] + p[1];
        }
        /* afterPad */
      );
      var xId = backend.dataIdMap.get(x.dataId).id;
      var out = backend.makeOutput(outShape, x.dtype);
      var outId = backend.dataIdMap.get(out.dataId).id;
      var xShapeBytes = new Uint8Array(new Int32Array(x.shape).buffer);
      var prePaddingsFlat = paddings.map(function(padTuple) {
        return padTuple[0];
      });
      var postPaddingsFlat = paddings.map(function(padTuple) {
        return padTuple[1];
      });
      var prePaddingsBytes = new Uint8Array(new Int32Array(prePaddingsFlat).buffer);
      var postPaddingsBytes = new Uint8Array(new Int32Array(postPaddingsFlat).buffer);
      wasmMirrorPad(xId, xShapeBytes, x.shape.length, CppDType[x.dtype], prePaddingsBytes, postPaddingsBytes, MirrorPaddingMode[mode], outId);
      return out;
    }
    var mirrorPadConfig = {
      kernelName: tfjsCore.MirrorPad,
      backendName: "wasm",
      kernelFunc: mirrorPad,
      setupFunc: setup$u
    };
    var wasmFunc$4;
    function setup$t(backend) {
      wasmFunc$4 = backend.wasm.cwrap(tfjsCore.Softmax, null, [
        "number",
        "number",
        "number",
        "number"
        // batch
      ]);
    }
    function softmax(args) {
      var backend = args.backend, logits = args.inputs.logits, dim = args.attrs.dim;
      var xId = backend.dataIdMap.get(logits.dataId).id;
      var out = backend.makeOutput(logits.shape, logits.dtype);
      var outId = backend.dataIdMap.get(out.dataId).id;
      var channels = logits.shape[dim];
      var batch = tfjsCore.util.sizeFromShape(logits.shape) / channels;
      if (tfjsCore.util.sizeFromShape(out.shape) === 0) {
        return out;
      }
      wasmFunc$4(xId, outId, channels, batch);
      return out;
    }
    var softmaxConfig = {
      kernelName: tfjsCore.Softmax,
      backendName: "wasm",
      setupFunc: setup$t,
      kernelFunc: softmax
    };
    var wasmMultinomial;
    function setup$s(backend) {
      wasmMultinomial = backend.wasm.cwrap(tfjsCore.Multinomial, null, [
        "number",
        "number",
        "number",
        "number",
        "number",
        "number"
        // outId
      ]);
    }
    function multinomial(args) {
      var inputs = args.inputs, backend = args.backend, attrs = args.attrs;
      var logits = inputs.logits;
      var numSamples = attrs.numSamples, seed = attrs.seed, normalized = attrs.normalized;
      if (logits.dtype !== "float32") {
        throw new Error("Tensor logits must have dtype float32, got ".concat(logits.dtype));
      }
      var probabilities = normalized ? logits : softmax({
        inputs: { logits },
        backend,
        attrs: { dim: logits.shape.length - 1 }
      });
      var _a2 = __read(probabilities.shape, 2), batchSize = _a2[0], numEvents = _a2[1];
      var out = backend.makeOutput([batchSize, numSamples], "int32");
      wasmMultinomial(backend.dataIdMap.get(probabilities.dataId).id, batchSize, numEvents, numSamples, seed, backend.dataIdMap.get(out.dataId).id);
      if (!normalized) {
        backend.disposeData(probabilities.dataId);
      }
      return out;
    }
    var multinomialConfig = {
      kernelName: tfjsCore.Multinomial,
      backendName: "wasm",
      setupFunc: setup$s,
      kernelFunc: multinomial
    };
    var multiplyConfig = createBinaryKernelConfig(tfjsCore.Multiply);
    var negConfig = createUnaryKernelConfig(tfjsCore.Neg);
    function parseResultStruct(backend, resOffset) {
      var result = new Int32Array(backend.wasm.HEAPU8.buffer, resOffset, 4);
      var pSelectedIndices = result[0];
      var selectedSize = result[1];
      var pSelectedScores = result[2];
      var pValidOutputs = result[3];
      backend.wasm._free(resOffset);
      return { pSelectedIndices, selectedSize, pSelectedScores, pValidOutputs };
    }
    var wasmFunc$3;
    function setup$r(backend) {
      wasmFunc$3 = backend.wasm.cwrap(
        tfjsCore.NonMaxSuppressionV3,
        "number",
        // Result*
        [
          "number",
          "number",
          "number",
          "number",
          "number"
          // scoreThreshold
        ]
      );
    }
    function kernelFunc$1(args) {
      var backend = args.backend, inputs = args.inputs, attrs = args.attrs;
      var iouThreshold = attrs.iouThreshold, maxOutputSize = attrs.maxOutputSize, scoreThreshold = attrs.scoreThreshold;
      var boxes = inputs.boxes, scores = inputs.scores;
      var boxesId = backend.dataIdMap.get(boxes.dataId).id;
      var scoresId = backend.dataIdMap.get(scores.dataId).id;
      var resOffset = wasmFunc$3(boxesId, scoresId, maxOutputSize, iouThreshold, scoreThreshold);
      var _a2 = parseResultStruct(backend, resOffset), pSelectedIndices = _a2.pSelectedIndices, selectedSize = _a2.selectedSize, pSelectedScores = _a2.pSelectedScores, pValidOutputs = _a2.pValidOutputs;
      backend.wasm._free(pSelectedScores);
      backend.wasm._free(pValidOutputs);
      var selectedIndicesTensor = backend.makeOutput([selectedSize], "int32", pSelectedIndices);
      return selectedIndicesTensor;
    }
    var nonMaxSuppressionV3Config = {
      kernelName: tfjsCore.NonMaxSuppressionV3,
      backendName: "wasm",
      setupFunc: setup$r,
      kernelFunc: kernelFunc$1
    };
    var wasmFunc$2;
    function setup$q(backend) {
      wasmFunc$2 = backend.wasm.cwrap(
        tfjsCore.NonMaxSuppressionV4,
        "number",
        // Result*
        [
          "number",
          "number",
          "number",
          "number",
          "number",
          "bool"
          // padToMaxOutputSize
        ]
      );
    }
    function nonMaxSuppressionV4(args) {
      var backend = args.backend, inputs = args.inputs, attrs = args.attrs;
      var iouThreshold = attrs.iouThreshold, maxOutputSize = attrs.maxOutputSize, scoreThreshold = attrs.scoreThreshold, padToMaxOutputSize = attrs.padToMaxOutputSize;
      var boxes = inputs.boxes, scores = inputs.scores;
      var boxesId = backend.dataIdMap.get(boxes.dataId).id;
      var scoresId = backend.dataIdMap.get(scores.dataId).id;
      var resOffset = wasmFunc$2(boxesId, scoresId, maxOutputSize, iouThreshold, scoreThreshold, padToMaxOutputSize);
      var _a2 = parseResultStruct(backend, resOffset), pSelectedIndices = _a2.pSelectedIndices, selectedSize = _a2.selectedSize, pSelectedScores = _a2.pSelectedScores, pValidOutputs = _a2.pValidOutputs;
      backend.wasm._free(pSelectedScores);
      var selectedIndicesTensor = backend.makeOutput([selectedSize], "int32", pSelectedIndices);
      var validOutputsTensor = backend.makeOutput([], "int32", pValidOutputs);
      return [selectedIndicesTensor, validOutputsTensor];
    }
    var nonMaxSuppressionV4Config = {
      kernelName: tfjsCore.NonMaxSuppressionV4,
      backendName: "wasm",
      setupFunc: setup$q,
      kernelFunc: nonMaxSuppressionV4
    };
    var wasmFunc$1;
    function setup$p(backend) {
      wasmFunc$1 = backend.wasm.cwrap(
        tfjsCore.NonMaxSuppressionV5,
        "number",
        // Result*
        [
          "number",
          "number",
          "number",
          "number",
          "number",
          "number"
          // softNmsSigma
        ]
      );
    }
    function kernelFunc(args) {
      var backend = args.backend, inputs = args.inputs, attrs = args.attrs;
      var iouThreshold = attrs.iouThreshold, maxOutputSize = attrs.maxOutputSize, scoreThreshold = attrs.scoreThreshold, softNmsSigma = attrs.softNmsSigma;
      var boxes = inputs.boxes, scores = inputs.scores;
      var boxesId = backend.dataIdMap.get(boxes.dataId).id;
      var scoresId = backend.dataIdMap.get(scores.dataId).id;
      var resOffset = wasmFunc$1(boxesId, scoresId, maxOutputSize, iouThreshold, scoreThreshold, softNmsSigma);
      var _a2 = parseResultStruct(backend, resOffset), pSelectedIndices = _a2.pSelectedIndices, selectedSize = _a2.selectedSize, pSelectedScores = _a2.pSelectedScores, pValidOutputs = _a2.pValidOutputs;
      backend.wasm._free(pValidOutputs);
      var selectedIndicesTensor = backend.makeOutput([selectedSize], "int32", pSelectedIndices);
      var selectedScoresTensor = backend.makeOutput([selectedSize], "float32", pSelectedScores);
      return [selectedIndicesTensor, selectedScoresTensor];
    }
    var nonMaxSuppressionV5Config = {
      kernelName: tfjsCore.NonMaxSuppressionV5,
      backendName: "wasm",
      setupFunc: setup$p,
      kernelFunc
    };
    var supportsFullBroadcast = false;
    var notEqualConfig = createBinaryKernelConfig(tfjsCore.NotEqual, supportsFullBroadcast, "bool");
    var wasmOneHot;
    function setup$o(backend) {
      wasmOneHot = backend.wasm.cwrap(tfjsCore.OneHot, null, [
        "number",
        "number",
        "number",
        "number",
        "number"
        // out_id
      ]);
    }
    function oneHot(args) {
      var inputs = args.inputs, backend = args.backend, attrs = args.attrs;
      var indices = inputs.indices;
      var dtype = attrs.dtype, depth = attrs.depth, onValue = attrs.onValue, offValue = attrs.offValue;
      var out = backend.makeOutput(__spreadArray(__spreadArray([], __read(indices.shape), false), [depth], false), dtype);
      var outId = backend.dataIdMap.get(out.dataId).id;
      var indicesData = backend.dataIdMap.get(indices.dataId);
      var indicesId = indicesData.id;
      wasmOneHot(indicesId, depth, onValue, offValue, outId);
      return out;
    }
    var oneHotConfig = {
      kernelName: tfjsCore.OneHot,
      backendName: "wasm",
      setupFunc: setup$o,
      kernelFunc: oneHot
    };
    function onesLike(args) {
      var x = args.inputs.x, backend = args.backend;
      var out = backend.makeOutput(x.shape, x.dtype);
      var outVals = backend.typedArrayFromHeap(out);
      outVals.fill(1);
      return out;
    }
    var onesLikeConfig = {
      kernelName: tfjsCore.OnesLike,
      backendName: "wasm",
      kernelFunc: onesLike
    };
    function pack(args) {
      var inputs = args.inputs, backend = args.backend, attrs = args.attrs;
      var axis = attrs.axis;
      if (inputs.length === 1) {
        return expandDims({ inputs: { input: inputs[0] }, backend, attrs: { dim: axis } });
      }
      var shape = inputs[0].shape;
      var dtype = inputs[0].dtype;
      inputs.forEach(function(t) {
        tfjsCore.util.assertShapesMatch(shape, t.shape, "All tensors passed to stack must have matching shapes");
        tfjsCore.util.assert(dtype === t.dtype, function() {
          return "All tensors passed to stack must have matching dtypes";
        });
      });
      var intermediateTensorInfos = [];
      var expandedTensors = inputs.map(function(t) {
        var expandedT = expandDims({ inputs: { input: t }, backend, attrs: { dim: axis } });
        intermediateTensorInfos.push(expandedT);
        return expandedT;
      });
      var result = concat({ inputs: expandedTensors, backend, attrs: { axis } });
      intermediateTensorInfos.forEach(function(t) {
        return backend.disposeData(t.dataId);
      });
      return result;
    }
    var packConfig = {
      kernelName: tfjsCore.Pack,
      backendName: "wasm",
      kernelFunc: pack
    };
    var wasmPadV2;
    function setup$n(backend) {
      wasmPadV2 = backend.wasm.cwrap(tfjsCore.PadV2, null, [
        "number",
        "array",
        "number",
        "number",
        "array",
        "array",
        "number",
        "number"
        // outId
      ]);
    }
    function pad(args) {
      var x = args.inputs.x, backend = args.backend, _a2 = args.attrs, paddings = _a2.paddings, constantValue = _a2.constantValue;
      var outShape = paddings.map(
        function(p, i) {
          return p[0] + x.shape[i] + p[1];
        }
        /* afterPad */
      );
      if (tfjsCore.util.sizeFromShape(x.shape) === 0) {
        return fill({
          backend,
          attrs: { shape: outShape, value: constantValue, dtype: x.dtype }
        });
      }
      var xId = backend.dataIdMap.get(x.dataId).id;
      var out = backend.makeOutput(outShape, x.dtype);
      var outTensorData = backend.dataIdMap.get(out.dataId);
      var outId = outTensorData.id;
      var xShapeBytes = new Uint8Array(new Int32Array(x.shape).buffer);
      var prePaddingsFlat = paddings.map(function(padTuple) {
        return padTuple[0];
      });
      var postPaddingsFlat = paddings.map(function(padTuple) {
        return padTuple[1];
      });
      var prePaddingsBytes = new Uint8Array(new Int32Array(prePaddingsFlat).buffer);
      var postPaddingsBytes = new Uint8Array(new Int32Array(postPaddingsFlat).buffer);
      wasmPadV2(xId, xShapeBytes, x.shape.length, CppDType[x.dtype], prePaddingsBytes, postPaddingsBytes, constantValue, outId);
      return out;
    }
    var padV2Config = {
      kernelName: tfjsCore.PadV2,
      backendName: "wasm",
      kernelFunc: pad,
      setupFunc: setup$n
    };
    var powConfig = createBinaryKernelConfig(tfjsCore.Pow);
    var wasmPrelu;
    function setup$m(backend) {
      wasmPrelu = backend.wasm.cwrap(tfjsCore.Prelu, null, [
        "number",
        "number",
        "number"
        // out_id
      ]);
    }
    function prelu(args) {
      var inputs = args.inputs, backend = args.backend;
      var x = inputs.x, alpha = inputs.alpha;
      var xId = backend.dataIdMap.get(x.dataId).id;
      var weightsId = backend.dataIdMap.get(alpha.dataId).id;
      var inputId = xId;
      var input = x;
      var castedInput = input;
      if (input.dtype !== "float32") {
        castedInput = cast({ backend, inputs: { x }, attrs: { dtype: "float32" } });
        inputId = backend.dataIdMap.get(castedInput.dataId).id;
      }
      var out = backend.makeOutput(x.shape, "float32");
      var outId = backend.dataIdMap.get(out.dataId).id;
      wasmPrelu(inputId, weightsId, outId);
      if (input.dtype !== "float32") {
        backend.disposeData(castedInput.dataId);
      }
      return out;
    }
    var preluConfig = {
      kernelName: tfjsCore.Prelu,
      backendName: "wasm",
      setupFunc: setup$m,
      kernelFunc: prelu
    };
    var wasmProd;
    function setup$l(backend) {
      wasmProd = backend.wasm.cwrap(tfjsCore.Prod, null, [
        "number",
        "number",
        "number",
        "number"
      ]);
    }
    function prod(args) {
      var backend = args.backend, inputs = args.inputs, attrs = args.attrs;
      var axis = attrs.axis, keepDims = attrs.keepDims;
      var x = inputs.x;
      var xId = backend.dataIdMap.get(x.dataId).id;
      var inputId = xId;
      var input = x;
      var _a2 = permuteAxesAndTranspose(x, axis, backend), transposed = _a2.transposed, axes = _a2.axes, originalAxes = _a2.originalAxes, inputWasTransposed = _a2.inputWasTransposed;
      var reductionAxes = axes;
      if (inputWasTransposed) {
        var transposedId = backend.dataIdMap.get(transposed.dataId).id;
        if (transposedId !== xId) {
          input = transposed;
          inputId = transposedId;
          reductionAxes = tfjsCore.backend_util.getInnerMostAxes(reductionAxes.length, input.shape.length);
        }
      }
      tfjsCore.backend_util.assertAxesAreInnerMostDims("prod", reductionAxes, input.shape.length);
      var _b = __read(tfjsCore.backend_util.computeOutAndReduceShapes(input.shape, reductionAxes), 2), outShape = _b[0], reduceShape = _b[1];
      var reduceSize = tfjsCore.util.sizeFromShape(reduceShape);
      var out = backend.makeOutput(outShape, input.dtype);
      if (tfjsCore.util.sizeFromShape(input.shape) !== 0) {
        var outId = backend.dataIdMap.get(out.dataId).id;
        wasmProd(inputId, reduceSize, CppDType[out.dtype], outId);
      }
      if (inputWasTransposed) {
        backend.disposeData(transposed.dataId);
      }
      if (keepDims) {
        var newShape = tfjsCore.backend_util.expandShapeToKeepDim(out.shape, originalAxes);
        out.shape = newShape;
      }
      return out;
    }
    var prodConfig = {
      kernelName: tfjsCore.Prod,
      backendName: "wasm",
      setupFunc: setup$l,
      kernelFunc: prod
    };
    var range = function(args) {
      var backend = args.backend, attrs = args.attrs;
      var start = attrs.start, stop = attrs.stop, step2 = attrs.step, dtype = attrs.dtype;
      var values = rangeImpl(start, stop, step2, dtype);
      var out = backend.makeOutput([values.length], dtype);
      var outVals = backend.typedArrayFromHeap(out);
      outVals.set(values);
      return out;
    };
    var rangeConfig = {
      kernelName: tfjsCore.Range,
      backendName: "wasm",
      kernelFunc: range
    };
    var realDivConfig = createBinaryKernelConfig(tfjsCore.RealDiv);
    var reciprocalConfig = createUnaryKernelConfig(tfjsCore.Reciprocal);
    var reluConfig = createUnaryKernelConfig(tfjsCore.Relu);
    var relu6Config = createUnaryKernelConfig(tfjsCore.Relu6);
    var wasmResizeBilinear;
    function setup$k(backend) {
      wasmResizeBilinear = backend.wasm.cwrap(tfjsCore.ResizeBilinear, null, [
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number"
        // outId
      ]);
    }
    function resizeBilinear(args) {
      var backend = args.backend, inputs = args.inputs, attrs = args.attrs;
      var images = inputs.images;
      var alignCorners = attrs.alignCorners, halfPixelCenters = attrs.halfPixelCenters, size = attrs.size;
      var _a2 = __read(size, 2), newHeight = _a2[0], newWidth = _a2[1];
      var _b = __read(images.shape, 4), batch = _b[0], oldHeight = _b[1], oldWidth = _b[2], numChannels = _b[3];
      var outShape = [batch, newHeight, newWidth, numChannels];
      var xData = backend.dataIdMap.get(images.dataId);
      var castedData;
      if (xData.dtype !== "float32") {
        castedData = cast({ backend, inputs: { x: images }, attrs: { dtype: "float32" } });
        xData = backend.dataIdMap.get(castedData.dataId);
      }
      var xId = xData.id;
      var out = backend.makeOutput(outShape, "float32");
      if (tfjsCore.util.sizeFromShape(images.shape) === 0) {
        return out;
      }
      var outId = backend.dataIdMap.get(out.dataId).id;
      wasmResizeBilinear(xId, batch, oldHeight, oldWidth, numChannels, newHeight, newWidth, alignCorners ? 1 : 0, halfPixelCenters ? 1 : 0, outId);
      if (castedData != null) {
        backend.disposeData(castedData.dataId);
      }
      return out;
    }
    var resizeBilinearConfig = {
      kernelName: tfjsCore.ResizeBilinear,
      backendName: "wasm",
      setupFunc: setup$k,
      kernelFunc: resizeBilinear
    };
    var wasmResizeBilinearGrad;
    function setup$j(backend) {
      wasmResizeBilinearGrad = backend.wasm.cwrap(tfjsCore.ResizeBilinearGrad, null, [
        "number",
        "number",
        "number",
        "array",
        "array",
        "boolean"
        // alignCorners
      ]);
    }
    function resizeBilinearGrad(args) {
      var inputs = args.inputs, backend = args.backend, attrs = args.attrs;
      var images = inputs.images, dy = inputs.dy;
      var alignCorners = attrs.alignCorners;
      var dx = backend.makeOutput(images.shape, "float32");
      var xData = backend.dataIdMap.get(images.dataId);
      var castedData;
      if (xData.dtype !== "float32") {
        castedData = cast({
          backend,
          inputs: { x: images },
          attrs: { dtype: "float32" }
        });
        xData = backend.dataIdMap.get(castedData.dataId);
      }
      wasmResizeBilinearGrad(backend.dataIdMap.get(images.dataId).id, backend.dataIdMap.get(dy.dataId).id, backend.dataIdMap.get(dx.dataId).id, new Uint8Array(new Int32Array(images.shape).buffer), new Uint8Array(new Int32Array(dy.shape).buffer), alignCorners);
      if (castedData != null) {
        backend.disposeData(castedData.dataId);
      }
      return dx;
    }
    var resizeBilinearGradConfig = {
      kernelName: tfjsCore.ResizeBilinearGrad,
      backendName: "wasm",
      setupFunc: setup$j,
      kernelFunc: resizeBilinearGrad
    };
    var wasmResizeNearestNeighbor;
    function setup$i(backend) {
      wasmResizeNearestNeighbor = backend.wasm.cwrap(tfjsCore.ResizeNearestNeighbor, null, [
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number"
        // outId
      ]);
    }
    function resizeNearestNeighbor(args) {
      var backend = args.backend, inputs = args.inputs, attrs = args.attrs;
      var images = inputs.images;
      var alignCorners = attrs.alignCorners, halfPixelCenters = attrs.halfPixelCenters, size = attrs.size;
      var _a2 = __read(size, 2), newHeight = _a2[0], newWidth = _a2[1];
      var _b = __read(images.shape, 4), batch = _b[0], oldHeight = _b[1], oldWidth = _b[2], numChannels = _b[3];
      var outShape = [batch, newHeight, newWidth, numChannels];
      var out = backend.makeOutput(outShape, "float32");
      if (tfjsCore.util.sizeFromShape(images.shape) === 0) {
        return out;
      }
      var xData = backend.dataIdMap.get(images.dataId);
      var castedData;
      if (xData.dtype !== "float32") {
        castedData = cast({
          backend,
          inputs: { x: images },
          attrs: { dtype: "float32" }
        });
        xData = backend.dataIdMap.get(castedData.dataId);
      }
      var xId = xData.id;
      var outId = backend.dataIdMap.get(out.dataId).id;
      wasmResizeNearestNeighbor(xId, batch, oldHeight, oldWidth, numChannels, newHeight, newWidth, alignCorners ? 1 : 0, halfPixelCenters ? 1 : 0, outId);
      if (castedData != null) {
        backend.disposeData(castedData.dataId);
      }
      return out;
    }
    var resizeNearestNeighborConfig = {
      kernelName: tfjsCore.ResizeNearestNeighbor,
      backendName: "wasm",
      setupFunc: setup$i,
      kernelFunc: resizeNearestNeighbor
    };
    var wasmResizeNearestNeighborGrad;
    function setup$h(backend) {
      wasmResizeNearestNeighborGrad = backend.wasm.cwrap(tfjsCore.ResizeNearestNeighborGrad, null, [
        "number",
        "number",
        "number",
        "array",
        "array",
        "boolean"
        // alignCorners
      ]);
    }
    function resizeNearestNeighborGrad(args) {
      var inputs = args.inputs, backend = args.backend, attrs = args.attrs;
      var images = inputs.images, dy = inputs.dy;
      var alignCorners = attrs.alignCorners;
      var dx = backend.makeOutput(images.shape, "float32");
      var xData = backend.dataIdMap.get(images.dataId);
      var castedData;
      if (xData.dtype !== "float32") {
        castedData = cast({
          backend,
          inputs: { x: images },
          attrs: { dtype: "float32" }
        });
        xData = backend.dataIdMap.get(castedData.dataId);
      }
      wasmResizeNearestNeighborGrad(backend.dataIdMap.get(images.dataId).id, backend.dataIdMap.get(dy.dataId).id, backend.dataIdMap.get(dx.dataId).id, new Uint8Array(new Int32Array(images.shape).buffer), new Uint8Array(new Int32Array(dy.shape).buffer), alignCorners);
      if (castedData != null) {
        backend.disposeData(castedData.dataId);
      }
      return dx;
    }
    var resizeNearestNeighborGradConfig = {
      kernelName: tfjsCore.ResizeNearestNeighborGrad,
      backendName: "wasm",
      setupFunc: setup$h,
      kernelFunc: resizeNearestNeighborGrad
    };
    var wasmReverse;
    function setup$g(backend) {
      wasmReverse = backend.wasm.cwrap(tfjsCore.Reverse, null, [
        "number",
        "array",
        "number",
        "array",
        "number",
        "number"
        // out_id
      ]);
    }
    function reverse(args) {
      var inputs = args.inputs, backend = args.backend, attrs = args.attrs;
      var x = inputs.x;
      var dims = attrs.dims;
      var axes = tfjsCore.util.parseAxisParam(dims, x.shape);
      if (x.shape.length === 0) {
        return identity({ inputs: { x }, backend });
      }
      var out = backend.makeOutput(x.shape, x.dtype);
      var xId = backend.dataIdMap.get(x.dataId).id;
      var outId = backend.dataIdMap.get(out.dataId).id;
      var axesBytes = new Uint8Array(new Int32Array(axes).buffer);
      var outShapeBytes = new Uint8Array(new Int32Array(x.shape).buffer);
      wasmReverse(xId, axesBytes, axes.length, outShapeBytes, x.shape.length, outId);
      var reshaped = reshape({ inputs: { x: out }, attrs: { shape: x.shape }, backend });
      backend.disposeData(out.dataId);
      return reshaped;
    }
    var reverseConfig = {
      kernelName: tfjsCore.Reverse,
      backendName: "wasm",
      kernelFunc: reverse,
      setupFunc: setup$g
    };
    var wasmRotate;
    function setup$f(backend) {
      wasmRotate = backend.wasm.cwrap(tfjsCore.RotateWithOffset, null, [
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "array",
        "number",
        "number"
        // outId
      ]);
    }
    function rotateWithOffset(args) {
      var inputs = args.inputs, backend = args.backend, attrs = args.attrs;
      var image = inputs.image;
      var radians = attrs.radians, fillValue = attrs.fillValue, center = attrs.center;
      var out = backend.makeOutput(image.shape, image.dtype);
      var imageId = backend.dataIdMap.get(image.dataId).id;
      var outId = backend.dataIdMap.get(out.dataId).id;
      var _a2 = __read(image.shape, 4), batch = _a2[0], imageHeight = _a2[1], imageWidth = _a2[2], numChannels = _a2[3];
      var _b = __read(tfjsCore.backend_util.getImageCenter(center, imageHeight, imageWidth), 2), centerX = _b[0], centerY = _b[1];
      var fillIsBlack = fillValue === 0;
      var fullOpacityValue = 255;
      var fillValues = typeof fillValue === "number" ? [fillValue, fillValue, fillValue, fillIsBlack ? 0 : fullOpacityValue] : __spreadArray(__spreadArray([], __read(fillValue), false), [fullOpacityValue], false);
      var fillBytes = new Uint8Array(new Int32Array(fillValues).buffer);
      wasmRotate(imageId, batch, imageHeight, imageWidth, numChannels, radians, centerX, centerY, fillBytes, fillValues.length, outId);
      return out;
    }
    var rotateWithOffsetConfig = {
      kernelName: tfjsCore.RotateWithOffset,
      backendName: "wasm",
      kernelFunc: rotateWithOffset,
      setupFunc: setup$f
    };
    var roundConfig = createUnaryKernelConfig(tfjsCore.Round);
    var rsqrtConfig = createUnaryKernelConfig(tfjsCore.Rsqrt);
    var wasmScatterNd;
    function setup$e(backend) {
      wasmScatterNd = backend.wasm.cwrap(tfjsCore.ScatterNd, null, [
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "array",
        "number",
        "number"
        // outId
      ]);
    }
    function scatterNd(args) {
      var backend = args.backend, inputs = args.inputs, attrs = args.attrs;
      var indices = inputs.indices, updates = inputs.updates;
      var shape = attrs.shape;
      var out = backend.makeOutput(shape, updates.dtype);
      if (tfjsCore.util.sizeFromShape(shape) === 0) {
        return out;
      }
      var _a2 = tfjsCore.scatter_util.calculateShapes(updates, indices, shape), sliceRank = _a2.sliceRank, numUpdates = _a2.numUpdates, sliceSize = _a2.sliceSize, strides = _a2.strides, outputSize = _a2.outputSize;
      var indicesData = backend.dataIdMap.get(indices.dataId);
      var indicesId = indicesData.id;
      var updatesData = backend.dataIdMap.get(updates.dataId);
      var updatesId = updatesData.id;
      var stridesBytes = new Uint8Array(new Int32Array(strides).buffer);
      var outId = backend.dataIdMap.get(out.dataId).id;
      wasmScatterNd(indicesId, updatesId, CppDType[updates.dtype], sliceRank, numUpdates, sliceSize, stridesBytes, outputSize, outId);
      return out;
    }
    var scatterNdConfig = {
      kernelName: tfjsCore.ScatterNd,
      backendName: "wasm",
      setupFunc: setup$e,
      kernelFunc: scatterNd
    };
    var wasmSearchSorted;
    function setup$d(backend) {
      wasmSearchSorted = backend.wasm.cwrap(tfjsCore.SearchSorted, null, [
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "bool",
        "number"
        // outId
      ]);
    }
    function searchSorted(args) {
      var inputs = args.inputs, backend = args.backend, attrs = args.attrs;
      var sortedSequence = inputs.sortedSequence, values = inputs.values;
      var side = attrs.side;
      if (sortedSequence.dtype !== values.dtype) {
        throw new Error("SearchSorted error: sorted_sequence must have the same dtype as values. Got ".concat(sortedSequence.dtype, " and ").concat(values.dtype));
      }
      var out = backend.makeOutput(values.shape, "int32");
      function tensorId(x) {
        return backend.dataIdMap.get(x.dataId).id;
      }
      wasmSearchSorted(
        tensorId(sortedSequence),
        tensorId(values),
        /*batchSize=*/
        sortedSequence.shape[0],
        /*sequenceSize=*/
        sortedSequence.shape[1],
        /*valuesSize=*/
        values.shape[1],
        /*dtype=*/
        CppDType[sortedSequence.dtype],
        /*isSideLeft=*/
        side === "left",
        tensorId(out)
      );
      return out;
    }
    var searchSortedConfig = {
      kernelName: tfjsCore.SearchSorted,
      backendName: "wasm",
      setupFunc: setup$d,
      kernelFunc: searchSorted
    };
    var wasmSelect;
    function setup$c(backend) {
      wasmSelect = backend.wasm.cwrap("SelectV2", null, [
        "number",
        "number",
        "number",
        "number",
        "number"
        // outId
      ]);
    }
    function select(args) {
      var inputs = args.inputs, backend = args.backend;
      var condition = inputs.condition, t = inputs.t, e = inputs.e;
      var conditionId = backend.dataIdMap.get(condition.dataId).id;
      var tId = backend.dataIdMap.get(t.dataId).id;
      var eId = backend.dataIdMap.get(e.dataId).id;
      var out = backend.makeOutput(t.shape, t.dtype);
      var outId = backend.dataIdMap.get(out.dataId).id;
      var cRank = condition.shape.length;
      var tRank = t.shape.length;
      var offset = cRank === 0 || cRank > 1 || tRank === 1 ? 1 : tfjsCore.util.sizeFromShape(t.shape.slice(1));
      wasmSelect(conditionId, tId, eId, offset, outId);
      return out;
    }
    var selectConfig = {
      kernelName: tfjsCore.Select,
      backendName: "wasm",
      kernelFunc: select,
      setupFunc: setup$c
    };
    var seluConfig = createUnaryKernelConfig(tfjsCore.Selu);
    var wasmFunc;
    function setup$b(backend) {
      wasmFunc = backend.wasm.cwrap(tfjsCore.Sigmoid, null, ["number", "number"]);
    }
    function sigmoid(args) {
      var backend = args.backend, x = args.inputs.x;
      var xId = backend.dataIdMap.get(x.dataId).id;
      var out = backend.makeOutput(x.shape, x.dtype);
      var outId = backend.dataIdMap.get(out.dataId).id;
      if (tfjsCore.util.sizeFromShape(out.shape) === 0) {
        return out;
      }
      wasmFunc(xId, outId);
      return out;
    }
    var sigmoidConfig = {
      kernelName: "Sigmoid",
      backendName: "wasm",
      setupFunc: setup$b,
      kernelFunc: sigmoid
    };
    var signConfig = createUnaryKernelConfig(tfjsCore.Sign);
    var sinConfig = createUnaryKernelConfig(tfjsCore.Sin);
    var softplusConfig = createUnaryKernelConfig(tfjsCore.Softplus);
    function spaceToBatchND(args) {
      var inputs = args.inputs, backend = args.backend, attrs = args.attrs;
      var x = inputs.x;
      var blockShape = attrs.blockShape, paddings = attrs.paddings;
      var prod2 = tfjsCore.util.sizeFromShape(blockShape);
      var completePaddings = [[0, 0]];
      completePaddings.push.apply(completePaddings, __spreadArray([], __read(paddings), false));
      for (var i = 1 + blockShape.length; i < x.shape.length; ++i) {
        completePaddings.push([0, 0]);
      }
      var paddedX = padV2Config.kernelFunc({
        inputs: { x },
        backend,
        attrs: { paddings: completePaddings, constantValue: 0 }
      });
      var reshapedPaddedShape = tfjsCore.backend_util.getReshaped(paddedX.shape, blockShape, prod2, false);
      var permutedReshapedPaddedPermutation = tfjsCore.backend_util.getPermuted(reshapedPaddedShape.length, blockShape.length, false);
      var flattenShape = tfjsCore.backend_util.getReshapedPermuted(paddedX.shape, blockShape, prod2, false);
      var reshapeInputs = { x: paddedX };
      var reshapeAttrs = { shape: reshapedPaddedShape };
      var paddedXReshaped = reshape({ inputs: reshapeInputs, backend, attrs: reshapeAttrs });
      var transposeInputs = { x: paddedXReshaped };
      var transposeAttrs = { perm: permutedReshapedPaddedPermutation };
      var paddedXT = transpose({ inputs: transposeInputs, backend, attrs: transposeAttrs });
      var resultReshapeInputs = { x: paddedXT };
      var resultReshapeAttrs = { shape: flattenShape };
      var result = reshape({ inputs: resultReshapeInputs, backend, attrs: resultReshapeAttrs });
      backend.disposeData(paddedX.dataId);
      backend.disposeData(paddedXReshaped.dataId);
      backend.disposeData(paddedXT.dataId);
      return result;
    }
    var spaceToBatchNDConfig = {
      kernelName: tfjsCore.SpaceToBatchND,
      backendName: "wasm",
      kernelFunc: spaceToBatchND
    };
    var wasmSparseFillEmptyRows;
    function setup$a(backend) {
      wasmSparseFillEmptyRows = backend.wasm.cwrap("SparseFillEmptyRows", "number", [
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number"
        // exceptionValuesId
      ]);
    }
    function sparseFillEmptyRows(args) {
      var backend = args.backend, inputs = args.inputs;
      var indices = inputs.indices, values = inputs.values, denseShape = inputs.denseShape, defaultValue = inputs.defaultValue;
      var indicesCount = indices.shape[0];
      var rank = indices.shape[1];
      var denseRows = backend.readSync(denseShape.dataId)[0];
      var maxOutputIndicesShape = [indicesCount + denseRows, rank];
      var indicesId = backend.dataIdMap.get(indices.dataId).id;
      var valuesId = backend.dataIdMap.get(values.dataId).id;
      var defaultValueId = backend.dataIdMap.get(defaultValue.dataId).id;
      var outputIndices = backend.makeOutput(maxOutputIndicesShape, indices.dtype);
      var outputIndicesId = backend.dataIdMap.get(outputIndices.dataId).id;
      var outputValues = backend.makeOutput(maxOutputIndicesShape.slice(0, 1), values.dtype);
      var outputValuesId = backend.dataIdMap.get(outputValues.dataId).id;
      var emptyRowIndicator = backend.makeOutput([denseRows], "bool");
      var emptyRowIndicatorId = backend.dataIdMap.get(emptyRowIndicator.dataId).id;
      var reverseIndexMap = backend.makeOutput([indicesCount], indices.dtype);
      var reverseIndexMapId = backend.dataIdMap.get(reverseIndexMap.dataId).id;
      var exceptionValues = backend.makeOutput([4], "int32");
      var exceptionValuesId = backend.dataIdMap.get(exceptionValues.dataId).id;
      var outputRows = wasmSparseFillEmptyRows(indicesId, valuesId, CppDType[values.dtype], indicesCount, denseRows, rank, defaultValueId, outputIndicesId, outputValuesId, emptyRowIndicatorId, reverseIndexMapId, exceptionValuesId);
      var exceptionValuesArray = backend.readSync(exceptionValues.dataId);
      var exceptionMessage;
      switch (exceptionValuesArray[0]) {
        case 1: {
          exceptionMessage = tfjsCore.backend_util.getSparseFillEmptyRowsIndicesDenseShapeMismatch(exceptionValuesArray[1]);
          break;
        }
        case 2: {
          exceptionMessage = tfjsCore.backend_util.getSparseFillEmptyRowsNegativeIndexErrorMessage(exceptionValuesArray[1], exceptionValuesArray[2]);
          break;
        }
        case 3:
          exceptionMessage = tfjsCore.backend_util.getSparseFillEmptyRowsOutOfRangeIndexErrorMessage(exceptionValuesArray[1], exceptionValuesArray[2], exceptionValuesArray[3]);
          break;
        default:
          exceptionMessage = "";
      }
      backend.disposeData(exceptionValues.dataId);
      if (exceptionMessage) {
        backend.disposeData(outputIndices.dataId);
        backend.disposeData(outputValues.dataId);
        backend.disposeData(emptyRowIndicator.dataId);
        backend.disposeData(reverseIndexMap.dataId);
        throw new Error(exceptionMessage);
      }
      var resizedIndices = outputIndices;
      var resizedValues = outputValues;
      if (outputRows !== maxOutputIndicesShape[0]) {
        resizedIndices = slice({
          inputs: { x: outputIndices },
          attrs: { begin: 0, size: [outputRows, rank] },
          backend
        });
        resizedValues = slice({
          inputs: { x: outputValues },
          attrs: { begin: 0, size: outputRows },
          backend
        });
        backend.disposeData(outputIndices.dataId);
        backend.disposeData(outputValues.dataId);
      }
      return [resizedIndices, resizedValues, emptyRowIndicator, reverseIndexMap];
    }
    var sparseFillEmptyRowsConfig = {
      kernelName: tfjsCore.SparseFillEmptyRows,
      backendName: "wasm",
      setupFunc: setup$a,
      kernelFunc: sparseFillEmptyRows
    };
    var wasmSparseReshape;
    function setup$9(backend) {
      wasmSparseReshape = backend.wasm.cwrap(tfjsCore.SparseReshape, null, [
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number"
        // exceptionValuesId
      ]);
    }
    function sparseReshape(args) {
      var backend = args.backend, inputs = args.inputs;
      var inputIndices = inputs.inputIndices, inputShape = inputs.inputShape, newShape = inputs.newShape;
      if (inputIndices.shape.length !== 2) {
        throw new Error("Input indices should be a matrix but received shape\n        ".concat(inputIndices.shape));
      }
      if (inputShape.shape.length !== 1) {
        throw new Error("Input shape should be a vector but received shape\n        ".concat(inputShape.shape));
      }
      if (newShape.shape.length !== 1) {
        throw new Error("Target shape should be a vector but received shape ".concat(newShape.shape));
      }
      var inputIndicesId = backend.dataIdMap.get(inputIndices.dataId).id;
      var inputShapeId = backend.dataIdMap.get(inputShape.dataId).id;
      var newShapeId = backend.dataIdMap.get(newShape.dataId).id;
      var nnz = inputIndices.shape[0];
      var outputRank = tfjsCore.util.sizeFromShape(newShape.shape);
      var newIndices = backend.makeOutput([nnz, outputRank], inputIndices.dtype);
      var newIndicesId = backend.dataIdMap.get(newIndices.dataId).id;
      var outputShape = backend.makeOutput([outputRank], newShape.dtype);
      var outputShapeId = backend.dataIdMap.get(outputShape.dataId).id;
      var exceptionValues = backend.makeOutput([3], "int32");
      var exceptionValuesId = backend.dataIdMap.get(exceptionValues.dataId).id;
      wasmSparseReshape(inputIndicesId, inputShapeId, newShapeId, nnz, newIndicesId, outputShapeId, exceptionValuesId);
      var exceptionValuesArray = backend.readSync(exceptionValues.dataId);
      var exceptionMessage;
      switch (exceptionValuesArray[0]) {
        case 0: {
          exceptionMessage = tfjsCore.backend_util.getSparseReshapeMultipleNegativeOneOutputDimErrorMessage(exceptionValuesArray[1], exceptionValuesArray[2]);
          break;
        }
        case 1: {
          exceptionMessage = tfjsCore.backend_util.getSparseReshapeNegativeOutputDimErrorMessage(exceptionValuesArray[1], exceptionValuesArray[2]);
          break;
        }
        case 2:
          exceptionMessage = tfjsCore.backend_util.getSparseReshapeEmptyTensorZeroOutputDimErrorMessage();
          break;
        case 3: {
          var inputShapeValues = Array.from(backend.readSync(inputShape.dataId)), outputShapeValues = Array.from(backend.readSync(outputShape.dataId));
          exceptionMessage = tfjsCore.backend_util.getSparseReshapeInputOutputMultipleErrorMessage(inputShapeValues, outputShapeValues);
          break;
        }
        case 4: {
          var inputShapeValues = Array.from(backend.readSync(inputShape.dataId)), outputShapeValues = Array.from(backend.readSync(outputShape.dataId));
          exceptionMessage = tfjsCore.backend_util.getSparseReshapeInputOutputMismatchErrorMessage(inputShapeValues, outputShapeValues);
          break;
        }
        default:
          exceptionMessage = "";
      }
      backend.disposeData(exceptionValues.dataId);
      if (exceptionMessage) {
        backend.disposeData(newIndices.dataId);
        backend.disposeData(outputShape.dataId);
        throw new Error(exceptionMessage);
      }
      return [newIndices, outputShape];
    }
    var sparseReshapeConfig = {
      kernelName: tfjsCore.SparseReshape,
      backendName: "wasm",
      setupFunc: setup$9,
      kernelFunc: sparseReshape
    };
    var wasmSparseSegmentReduction;
    function setup$8(backend) {
      wasmSparseSegmentReduction = backend.wasm.cwrap("SparseSegmentReduction", null, [
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number"
        // defaultValue
      ]);
    }
    function sparseSegmentReduction(args, isMean) {
      var backend = args.backend, inputs = args.inputs;
      var data = inputs.data, indices = inputs.indices, segmentIds = inputs.segmentIds;
      var numIndices = indices.shape[0];
      var segmentIdsBack = backend.readSync(segmentIds.dataId, numIndices - 1, numIndices)[0];
      var lastSegmentIdPlusOne = numIndices > 0 ? segmentIdsBack + 1 : 0;
      var outputRows = lastSegmentIdPlusOne;
      if (outputRows < 0) {
        throw new Error(tfjsCore.backend_util.getSparseSegmentReductionNegativeSegmentIdsErrorMessage());
      }
      var outputShape = data.shape.slice();
      outputShape[0] = outputRows;
      var dataId = backend.dataIdMap.get(data.dataId).id;
      var indicesId = backend.dataIdMap.get(indices.dataId).id;
      var segmentIdsId = backend.dataIdMap.get(segmentIds.dataId).id;
      var output = backend.makeOutput(outputShape, data.dtype);
      var outputId = backend.dataIdMap.get(output.dataId).id;
      var exceptionValues = backend.makeOutput([4], "int32");
      var exceptionValuesId = backend.dataIdMap.get(exceptionValues.dataId).id;
      wasmSparseSegmentReduction(dataId, CppDType[data.dtype], data.shape[0], indicesId, segmentIdsId, outputId, exceptionValuesId, isMean, 0);
      var exceptionValuesArray = backend.readSync(exceptionValues.dataId);
      var exceptionMessage;
      switch (exceptionValuesArray[0]) {
        case 0: {
          exceptionMessage = tfjsCore.backend_util.getSparseSegmentReductionNegativeSegmentIdsErrorMessage();
          break;
        }
        case 1: {
          exceptionMessage = tfjsCore.backend_util.getSparseSegmentReductionNonIncreasingSegmentIdsErrorMessage();
          break;
        }
        case 2:
          exceptionMessage = tfjsCore.backend_util.getSparseSegmentReductionSegmentIdOutOfRangeErrorMessage(exceptionValuesArray[1], exceptionValuesArray[2]);
          break;
        case 3:
          exceptionMessage = tfjsCore.backend_util.getSparseSegmentReductionIndicesOutOfRangeErrorMessage(exceptionValuesArray[1], exceptionValuesArray[2], exceptionValuesArray[3]);
          break;
        default:
          exceptionMessage = "";
      }
      backend.disposeData(exceptionValues.dataId);
      if (exceptionMessage) {
        backend.disposeData(output.dataId);
        throw new Error(exceptionMessage);
      }
      return output;
    }
    function sparseSegmentMean(args) {
      return sparseSegmentReduction(args, true);
    }
    var sparseSegmentMeanConfig = {
      kernelName: tfjsCore.SparseSegmentMean,
      backendName: "wasm",
      setupFunc: setup$8,
      kernelFunc: sparseSegmentMean
    };
    function sparseSegmentSum(args) {
      return sparseSegmentReduction(args, false);
    }
    var sparseSegmentSumConfig = {
      kernelName: tfjsCore.SparseSegmentSum,
      backendName: "wasm",
      setupFunc: setup$8,
      kernelFunc: sparseSegmentSum
    };
    var wasmSparseToDense;
    function setup$7(backend) {
      wasmSparseToDense = backend.wasm.cwrap(tfjsCore.SparseToDense, null, [
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "array",
        "number",
        "number"
        // outId
      ]);
    }
    function sparseToDense(args) {
      var backend = args.backend, inputs = args.inputs, attrs = args.attrs;
      var sparseIndices = inputs.sparseIndices, sparseValues = inputs.sparseValues, defaultValue = inputs.defaultValue;
      var outputShape = attrs.outputShape;
      var out = backend.makeOutput(outputShape, defaultValue.dtype);
      if (tfjsCore.util.sizeFromShape(outputShape) === 0) {
        return out;
      }
      var _a2 = tfjsCore.backend_util.calculateShapes(sparseValues, sparseIndices, outputShape), sliceRank = _a2.sliceRank, numUpdates = _a2.numUpdates, sliceSize = _a2.sliceSize, strides = _a2.strides, outputSize = _a2.outputSize;
      var sparseIndicesId = backend.dataIdMap.get(sparseIndices.dataId).id;
      var sparseValuesId = backend.dataIdMap.get(sparseValues.dataId).id;
      var defaultValueId = backend.dataIdMap.get(defaultValue.dataId).id;
      var stridesBytes = new Uint8Array(new Int32Array(strides).buffer);
      var outId = backend.dataIdMap.get(out.dataId).id;
      wasmSparseToDense(sparseIndicesId, sparseValuesId, sparseValues.shape.length, defaultValueId, CppDType[defaultValue.dtype], sliceRank, numUpdates, sliceSize, stridesBytes, outputSize, outId);
      return out;
    }
    var sparseToDenseConfig = {
      kernelName: tfjsCore.SparseToDense,
      backendName: "wasm",
      setupFunc: setup$7,
      kernelFunc: sparseToDense
    };
    function splitV(args) {
      var inputs = args.inputs, attrs = args.attrs, backend = args.backend;
      var x = inputs.x;
      var numOrSizeSplits = attrs.numOrSizeSplits, axis = attrs.axis;
      var $axis = tfjsCore.util.parseAxisParam(axis, x.shape)[0];
      var splitSizes = tfjsCore.backend_util.prepareSplitSize(x, numOrSizeSplits, $axis);
      var begin = new Array(x.shape.length).fill(0);
      var size = x.shape.slice();
      return splitSizes.map(function(s) {
        var xSliceSize = __spreadArray([], __read(size), false);
        xSliceSize[$axis] = s;
        var xSlice = slice({ inputs: { x }, attrs: { begin, size: xSliceSize }, backend });
        begin[$axis] += s;
        return xSlice;
      });
    }
    var splitVConfig = {
      kernelName: tfjsCore.SplitV,
      backendName: "wasm",
      kernelFunc: splitV
    };
    var sqrtConfig = createUnaryKernelConfig(tfjsCore.Sqrt);
    var squareConfig = createUnaryKernelConfig(tfjsCore.Square);
    var squaredDifferenceConfig = createBinaryKernelConfig(tfjsCore.SquaredDifference);
    var wasmStep;
    function setup$6(backend) {
      wasmStep = backend.wasm.cwrap(tfjsCore.Step, null, [
        "number",
        "number",
        "number",
        "number"
        // out_id
      ]);
    }
    function step(args) {
      var backend = args.backend, inputs = args.inputs, attrs = args.attrs;
      var alpha = attrs.alpha;
      var x = inputs.x;
      var xId = backend.dataIdMap.get(x.dataId).id;
      var out = backend.makeOutput(x.shape, x.dtype);
      var outId = backend.dataIdMap.get(out.dataId).id;
      wasmStep(xId, alpha, CppDType[x.dtype], outId);
      return out;
    }
    var stepConfig = {
      kernelName: tfjsCore.Step,
      backendName: "wasm",
      setupFunc: setup$6,
      kernelFunc: step
    };
    var wasmStridedSlice;
    function setup$5(backend) {
      wasmStridedSlice = backend.wasm.cwrap(tfjsCore.StridedSlice, null, [
        "number",
        "array",
        "number",
        "array",
        "array",
        "array",
        "array",
        "array",
        "number",
        "number"
        // outId
      ]);
    }
    function stridedSlice(args) {
      var backend = args.backend, inputs = args.inputs, attrs = args.attrs;
      var x = inputs.x;
      var begin = attrs.begin, end = attrs.end, strides = attrs.strides, beginMask = attrs.beginMask, endMask = attrs.endMask, ellipsisMask = attrs.ellipsisMask, newAxisMask = attrs.newAxisMask, shrinkAxisMask = attrs.shrinkAxisMask;
      var _a2 = tfjsCore.slice_util.sliceInfo(x.shape, begin, end, strides, beginMask, endMask, ellipsisMask, newAxisMask, shrinkAxisMask), finalShapeSparse = _a2.finalShapeSparse, finalShape = _a2.finalShape, isIdentity = _a2.isIdentity, sliceDim0 = _a2.sliceDim0, isSimpleSlice = _a2.isSimpleSlice, $begin = _a2.begin, $end = _a2.end, $strides = _a2.strides;
      var result;
      if (isIdentity) {
        result = reshape({ inputs: { x }, backend, attrs: { shape: finalShape } });
      } else if (sliceDim0 || isSimpleSlice) {
        tfjsCore.util.assert(x.shape.length >= 1, function() {
          return "Input must have rank at least 1, got: ".concat(x.shape.length);
        });
        var size = tfjsCore.slice_util.computeOutShape($begin, $end, $strides);
        var sliced = slice({ inputs: { x }, backend, attrs: { begin: $begin, size } });
        result = reshape({ inputs: { x: sliced }, backend, attrs: { shape: finalShape } });
        backend.disposeData(sliced.dataId);
      } else {
        var out = backend.makeOutput(finalShapeSparse, "float32");
        var xId = backend.dataIdMap.get(x.dataId).id;
        var xStridesBytes = new Uint8Array(new Int32Array(tfjsCore.util.computeStrides(x.shape)).buffer);
        var beginBytes = new Uint8Array(new Int32Array($begin).buffer);
        var endBytes = new Uint8Array(new Int32Array($end).buffer);
        var stridesBytes = new Uint8Array(new Int32Array($strides).buffer);
        var outputShapeBytes = new Uint8Array(new Int32Array(finalShapeSparse).buffer);
        var outStridesBytes = new Uint8Array(new Int32Array(tfjsCore.util.computeStrides(finalShapeSparse)).buffer);
        var outId = backend.dataIdMap.get(out.dataId).id;
        wasmStridedSlice(xId, xStridesBytes, x.shape.length, beginBytes, endBytes, stridesBytes, outputShapeBytes, outStridesBytes, finalShapeSparse.length, outId);
        result = reshape({ inputs: { x: out }, backend, attrs: { shape: finalShape } });
        backend.disposeData(out.dataId);
      }
      return result;
    }
    var stridedSliceConfig = {
      kernelName: tfjsCore.StridedSlice,
      backendName: "wasm",
      setupFunc: setup$5,
      kernelFunc: stridedSlice
    };
    function stringNGrams(args) {
      var backend = args.backend, inputs = args.inputs, attrs = args.attrs;
      var data = inputs.data, dataSplits = inputs.dataSplits;
      var separator = attrs.separator, nGramWidths = attrs.nGramWidths, leftPad = attrs.leftPad, rightPad = attrs.rightPad, padWidth = attrs.padWidth, preserveShortSequences = attrs.preserveShortSequences;
      var $data = backend.readSync(data.dataId);
      var $dataSplits = backend.readSync(dataSplits.dataId);
      var _a2 = __read(stringNGramsImpl($data, $dataSplits, separator, nGramWidths, leftPad, rightPad, padWidth, preserveShortSequences), 2), nGrams = _a2[0], nGramsSplits = _a2[1];
      var nGramsOut = backend.makeOutput([nGrams.length], "string");
      var nGramsOutData = backend.dataIdMap.get(nGramsOut.dataId);
      nGramsOutData.stringBytes = nGrams;
      var nGramsSplitsOut = backend.makeOutput(dataSplits.shape, "int32");
      var nGramsSplitsOutVals = backend.typedArrayFromHeap(nGramsSplitsOut);
      nGramsSplitsOutVals.set(nGramsSplits);
      return [nGramsOut, nGramsSplitsOut];
    }
    var stringNGramsConfig = {
      kernelName: tfjsCore.StringNGrams,
      backendName: "wasm",
      kernelFunc: stringNGrams
    };
    function stringSplit(args) {
      var backend = args.backend, inputs = args.inputs, attrs = args.attrs;
      var input = inputs.input, delimiter = inputs.delimiter;
      var skipEmpty = attrs.skipEmpty;
      var inputVals = backend.readSync(input.dataId);
      var delimiterVals = backend.readSync(delimiter.dataId);
      var _a2 = __read(stringSplitImpl(inputVals, delimiterVals[0], skipEmpty), 3), indices = _a2[0], values = _a2[1], shape = _a2[2];
      var outputSize = values.length;
      var indicesOut = backend.makeOutput([outputSize, 2], "int32");
      var indicesOutVals = backend.typedArrayFromHeap(indicesOut);
      indicesOutVals.set(indices);
      var valuesOut = backend.makeOutput([outputSize], "string");
      var valuesOutData = backend.dataIdMap.get(valuesOut.dataId);
      valuesOutData.stringBytes = values;
      var shapeOut = backend.makeOutput([2], "int32");
      var shapeOutVals = backend.typedArrayFromHeap(shapeOut);
      shapeOutVals.set(shape);
      return [indicesOut, valuesOut, shapeOut];
    }
    var stringSplitConfig = {
      kernelName: tfjsCore.StringSplit,
      backendName: "wasm",
      kernelFunc: stringSplit
    };
    function stringToHashBucketFast(args) {
      var backend = args.backend, inputs = args.inputs, attrs = args.attrs;
      var input = inputs.input;
      var numBuckets = attrs.numBuckets;
      var inputVals = backend.readSync(input.dataId);
      var values = stringToHashBucketFastImpl(inputVals, numBuckets);
      var out = backend.makeOutput(input.shape, "int32");
      var outVals = backend.typedArrayFromHeap(out);
      outVals.set(values);
      return out;
    }
    var stringToHashBucketFastConfig = {
      kernelName: tfjsCore.StringToHashBucketFast,
      backendName: "wasm",
      kernelFunc: stringToHashBucketFast
    };
    var subConfig = createBinaryKernelConfig(tfjsCore.Sub);
    var wasmSum;
    function setup$4(backend) {
      wasmSum = backend.wasm.cwrap(tfjsCore.Sum, null, [
        "number",
        "number",
        "number",
        "number"
        // out_id
      ]);
    }
    function sum(args) {
      var backend = args.backend, inputs = args.inputs, attrs = args.attrs;
      var axis = attrs.axis, keepDims = attrs.keepDims;
      var x = inputs.x;
      var xId = backend.dataIdMap.get(x.dataId).id;
      var inputId = xId;
      var input = x;
      var _a2 = permuteAxesAndTranspose(x, axis, backend), transposed = _a2.transposed, axes = _a2.axes, originalAxes = _a2.originalAxes, inputWasTransposed = _a2.inputWasTransposed;
      var reductionAxes = axes;
      if (inputWasTransposed) {
        var transposedId = backend.dataIdMap.get(transposed.dataId).id;
        if (transposedId !== xId) {
          input = transposed;
          inputId = transposedId;
          reductionAxes = tfjsCore.backend_util.getInnerMostAxes(reductionAxes.length, input.shape.length);
        }
      }
      tfjsCore.backend_util.assertAxesAreInnerMostDims("sum", reductionAxes, input.shape.length);
      var _b = __read(tfjsCore.backend_util.computeOutAndReduceShapes(input.shape, reductionAxes), 2), outShape = _b[0], reduceShape = _b[1];
      var reduceSize = tfjsCore.util.sizeFromShape(reduceShape);
      var out = backend.makeOutput(outShape, input.dtype);
      if (tfjsCore.util.sizeFromShape(input.shape) !== 0) {
        var outId = backend.dataIdMap.get(out.dataId).id;
        wasmSum(inputId, reduceSize, CppDType[out.dtype], outId);
      }
      if (inputWasTransposed) {
        backend.disposeData(transposed.dataId);
      }
      if (keepDims) {
        var newShape = tfjsCore.backend_util.expandShapeToKeepDim(out.shape, originalAxes);
        out.shape = newShape;
      }
      return out;
    }
    var sumConfig = {
      kernelName: tfjsCore.Sum,
      backendName: "wasm",
      setupFunc: setup$4,
      kernelFunc: sum
    };
    var tanConfig = createUnaryKernelConfig(tfjsCore.Tan);
    var tanhConfig = createUnaryKernelConfig(tfjsCore.Tanh);
    var wasmTensorScatterUpdate;
    function setup$3(backend) {
      wasmTensorScatterUpdate = backend.wasm.cwrap(tfjsCore.TensorScatterUpdate, null, [
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "array",
        "number",
        "number",
        "number"
        // tensorId
      ]);
    }
    function tensorScatterUpdate(args) {
      var backend = args.backend, inputs = args.inputs;
      args.attrs;
      var tensor = inputs.tensor, indices = inputs.indices, updates = inputs.updates;
      var out = backend.makeOutput(tensor.shape, tensor.dtype);
      if (tfjsCore.util.sizeFromShape(tensor.shape) === 0) {
        return out;
      }
      var _b = tfjsCore.scatter_util.calculateShapes(updates, indices, tensor.shape), sliceRank = _b.sliceRank, numUpdates = _b.numUpdates, sliceSize = _b.sliceSize, strides = _b.strides, outputSize = _b.outputSize;
      var indicesData = backend.dataIdMap.get(indices.dataId);
      var indicesId = indicesData.id;
      var updatesData = backend.dataIdMap.get(updates.dataId);
      var updatesId = updatesData.id;
      var tensorData = backend.dataIdMap.get(tensor.dataId);
      var tensorId = tensorData.id;
      var stridesBytes = new Uint8Array(new Int32Array(strides).buffer);
      var outId = backend.dataIdMap.get(out.dataId).id;
      wasmTensorScatterUpdate(indicesId, updatesId, CppDType[updates.dtype], sliceRank, numUpdates, sliceSize, stridesBytes, outputSize, outId, tensorId);
      return out;
    }
    var tensorScatterUpdateConfig = {
      kernelName: tfjsCore.TensorScatterUpdate,
      backendName: "wasm",
      setupFunc: setup$3,
      kernelFunc: tensorScatterUpdate
    };
    var wasmTile;
    function setup$2(backend) {
      wasmTile = backend.wasm.cwrap(tfjsCore.Tile, null, [
        "number",
        "array",
        "number",
        "array",
        "number",
        "number"
        // out_id
      ]);
    }
    function tile(args) {
      var inputs = args.inputs, backend = args.backend, attrs = args.attrs;
      var x = inputs.x;
      var xId = backend.dataIdMap.get(x.dataId).id;
      var reps = attrs.reps;
      var newShape = new Array(x.shape.length);
      for (var i = 0; i < newShape.length; i++) {
        newShape[i] = x.shape[i] * reps[i];
      }
      var xShapeBytes = new Uint8Array(new Int32Array(x.shape).buffer);
      var newShapeBytes = new Uint8Array(new Int32Array(newShape).buffer);
      var out = backend.makeOutput(newShape, x.dtype);
      var outId = backend.dataIdMap.get(out.dataId).id;
      wasmTile(xId, xShapeBytes, x.shape.length, newShapeBytes, newShape.length, CppDType[out.dtype], outId);
      return out;
    }
    var tileConfig = {
      kernelName: tfjsCore.Tile,
      backendName: "wasm",
      setupFunc: setup$2,
      kernelFunc: tile
    };
    var wasmTopK;
    function setup$1(backend) {
      wasmTopK = backend.wasm.cwrap(tfjsCore.TopK, null, [
        "number",
        "array",
        "number",
        "number",
        "number",
        "bool",
        "number",
        "number"
        // outIndicesId
      ]);
    }
    var topk = function(_a2) {
      var inputs = _a2.inputs, backend = _a2.backend, attrs = _a2.attrs;
      var x = inputs.x;
      var k = attrs.k, sorted = attrs.sorted;
      var xId = backend.dataIdMap.get(x.dataId).id;
      var xShapeBytes = new Uint8Array(new Int32Array(x.shape).buffer);
      var outputShape = x.shape.slice();
      outputShape[outputShape.length - 1] = k;
      var outValues = backend.makeOutput(outputShape, x.dtype);
      var outValuesId = backend.dataIdMap.get(outValues.dataId).id;
      var outIndices = backend.makeOutput(outputShape, "int32");
      var outIndicesId = backend.dataIdMap.get(outIndices.dataId).id;
      wasmTopK(xId, xShapeBytes, x.shape.length, CppDType[x.dtype], k, sorted, outValuesId, outIndicesId);
      return [outValues, outIndices];
    };
    var topKConfig = {
      kernelName: tfjsCore.TopK,
      backendName: "wasm",
      setupFunc: setup$1,
      kernelFunc: topk
    };
    var wasmTransform;
    function setup(backend) {
      wasmTransform = backend.wasm.cwrap(tfjsCore.Transform, null, [
        "number",
        "number",
        "bool",
        "number",
        "number",
        "number",
        "number",
        "number",
        "number",
        "array",
        "number",
        "array",
        "number",
        "number",
        "number",
        "number",
        "number"
        // outId
      ]);
    }
    function transform(args) {
      var backend = args.backend, inputs = args.inputs, attrs = args.attrs;
      var image = inputs.image, transforms = inputs.transforms;
      var interpolation = attrs.interpolation, fillMode = attrs.fillMode, fillValue = attrs.fillValue, outputShape = attrs.outputShape;
      var _a2 = __read(image.shape, 4), batch = _a2[0], imageHeight = _a2[1], imageWidth = _a2[2], numChannels = _a2[3];
      var _b = __read(outputShape != null ? outputShape : [imageHeight, imageWidth], 2), outHeight = _b[0], outWidth = _b[1];
      var outShape = [
        batch,
        outHeight,
        outWidth,
        numChannels
      ];
      var inputStrides = new Uint8Array(new Int32Array(tfjsCore.util.computeStrides(image.shape)).buffer);
      var outputStrides = new Uint8Array(new Int32Array(tfjsCore.util.computeStrides(outShape)).buffer);
      var out = backend.makeOutput(outShape, image.dtype);
      var outId = backend.dataIdMap.get(out.dataId).id;
      var imageData = backend.dataIdMap.get(image.dataId);
      var imageId = imageData.id;
      var transformsData = backend.dataIdMap.get(transforms.dataId);
      var transformsId = transformsData.id;
      var interpolationModeId = interpolation === "nearest" ? 1 : 2;
      var fillModeId;
      switch (fillMode) {
        case "constant":
          fillModeId = 1;
          break;
        case "reflect":
          fillModeId = 2;
          break;
        case "wrap":
          fillModeId = 3;
          break;
        case "nearest":
          fillModeId = 4;
          break;
        default:
          fillModeId = 1;
          break;
      }
      wasmTransform(imageId, transformsId, transforms.shape[0] > 1, batch, outHeight, outWidth, numChannels, imageWidth, imageHeight, inputStrides, image.shape.length - 1, outputStrides, outShape.length - 1, interpolationModeId, fillModeId, fillValue, outId);
      return out;
    }
    var transformConfig = {
      kernelName: tfjsCore.Transform,
      backendName: "wasm",
      setupFunc: setup,
      kernelFunc: transform
    };
    function unique(args) {
      var inputs = args.inputs, attrs = args.attrs, backend = args.backend;
      var axis = attrs.axis;
      var x = inputs.x;
      var _a2 = uniqueImpl(backend.readSync(x.dataId), axis, x.shape, x.dtype), outputValues = _a2.outputValues, outputShape = _a2.outputShape, indices = _a2.indices;
      return [
        backend.makeOutput(
          outputShape,
          x.dtype,
          /*memoryOffset=*/
          void 0,
          outputValues
        ),
        backend.makeOutput(
          [indices.length],
          "int32",
          /*memoryOffset=*/
          void 0,
          indices
        )
      ];
    }
    var uniqueConfig = {
      kernelName: tfjsCore.Unique,
      backendName: "wasm",
      kernelFunc: unique
    };
    function unpack(args) {
      var inputs = args.inputs, backend = args.backend, attrs = args.attrs;
      var value = inputs.value;
      var axis = attrs.axis;
      if (axis < 0) {
        axis += value.shape.length;
      }
      var numOutputs = value.shape[axis];
      var rank = value.shape.length;
      var outShape = new Array(rank - 1);
      var outIndex = 0;
      for (var i = 0; i < rank; i++) {
        if (i !== axis) {
          outShape[outIndex++] = value.shape[i];
        }
      }
      var outs = new Array(numOutputs);
      var begin = new Array(rank).fill(0);
      var size = value.shape.slice();
      size[axis] = 1;
      for (var i = 0; i < outs.length; i++) {
        begin[axis] = i;
        outs[i] = slice({ inputs: { x: value }, attrs: { begin, size }, backend });
      }
      return outs.map(function(_a2) {
        var dataId = _a2.dataId, dtype = _a2.dtype;
        return { dataId, dtype, shape: outShape };
      });
    }
    var unpackConfig = {
      kernelName: tfjsCore.Unpack,
      backendName: "wasm",
      kernelFunc: unpack
    };
    function zerosLike(args) {
      var x = args.inputs.x, backend = args.backend;
      var out = backend.makeOutput(x.shape, x.dtype);
      var outVals = backend.typedArrayFromHeap(out);
      outVals.fill(0);
      return out;
    }
    var zerosLikeConfig = {
      kernelName: tfjsCore.ZerosLike,
      backendName: "wasm",
      kernelFunc: zerosLike
    };
    var e_1;
    var _a;
    var kernelConfigs = [
      _fusedMatMulConfig,
      absConfig,
      acosConfig,
      acoshConfig,
      addConfig,
      addNConfig,
      allConfig,
      anyConfig,
      argMaxConfig,
      argMinConfig,
      asinConfig,
      asinhConfig,
      atanConfig,
      atan2Config,
      atanhConfig,
      avgPoolConfig,
      avgPool3DConfig,
      avgPool3DGradConfig,
      batchMatMulConfig,
      batchToSpaceNDConfig,
      bincountConfig,
      broadcastArgsConfig,
      castConfig,
      ceilConfig,
      clipByValueConfig,
      concatConfig,
      conv2DConfig,
      conv2DBackpropInputConfig,
      conv3DConfig,
      conv3DBackpropFilterV2Config,
      conv3DBackpropInputV2Config,
      cosConfig,
      coshConfig,
      cropAndResizeConfig,
      cumprodConfig,
      cumsumConfig,
      denseBincountConfig,
      depthToSpaceConfig,
      depthwiseConv2dNativeConfig,
      diagConfig,
      dilation2DConfig,
      dilation2DBackpropFilterConfig,
      dilation2DBackpropInputConfig,
      eluConfig,
      eluGradConfig,
      equalConfig,
      expConfig,
      expandDimsConfig,
      expm1Config,
      fillConfig,
      flipLeftRightConfig,
      floorConfig,
      floorDivConfig,
      fusedBatchNormConfig,
      fusedConv2DConfig,
      fusedDepthwiseConv2DConfig,
      gatherNdConfig,
      gatherV2Config,
      greaterConfig,
      greaterEqualConfig,
      identityConfig,
      isFiniteConfig,
      isInfConfig,
      isNaNConfig,
      leakyReluConfig,
      lessConfig,
      lessEqualConfig,
      linSpaceConfig,
      log1pConfig,
      logConfig,
      logicalAndConfig,
      logicalNotConfig,
      logicalOrConfig,
      logicalXorConfig,
      lrnConfig,
      lrnGradConfig,
      maxConfig,
      maximumConfig,
      maxPoolConfig,
      maxPool3DConfig,
      maxPool3DGradConfig,
      meanConfig,
      minConfig,
      minimumConfig,
      mirrorPadConfig,
      multinomialConfig,
      multiplyConfig,
      negConfig,
      nonMaxSuppressionV3Config,
      nonMaxSuppressionV4Config,
      nonMaxSuppressionV5Config,
      notEqualConfig,
      oneHotConfig,
      onesLikeConfig,
      packConfig,
      padV2Config,
      powConfig,
      preluConfig,
      prodConfig,
      rangeConfig,
      realDivConfig,
      reciprocalConfig,
      reluConfig,
      relu6Config,
      reshapeConfig,
      resizeBilinearConfig,
      resizeBilinearGradConfig,
      resizeNearestNeighborConfig,
      resizeNearestNeighborGradConfig,
      reverseConfig,
      rotateWithOffsetConfig,
      roundConfig,
      rsqrtConfig,
      scatterNdConfig,
      searchSortedConfig,
      selectConfig,
      seluConfig,
      sigmoidConfig,
      signConfig,
      sinConfig,
      sliceConfig,
      softmaxConfig,
      softplusConfig,
      spaceToBatchNDConfig,
      sparseFillEmptyRowsConfig,
      sparseReshapeConfig,
      sparseSegmentMeanConfig,
      sparseSegmentSumConfig,
      sparseToDenseConfig,
      splitVConfig,
      sqrtConfig,
      squareConfig,
      squaredDifferenceConfig,
      stepConfig,
      stridedSliceConfig,
      stringNGramsConfig,
      stringSplitConfig,
      stringToHashBucketFastConfig,
      subConfig,
      sumConfig,
      tanConfig,
      tanhConfig,
      tensorScatterUpdateConfig,
      tileConfig,
      topKConfig,
      transformConfig,
      transposeConfig,
      uniqueConfig,
      unpackConfig,
      zerosLikeConfig
    ];
    try {
      for (kernelConfigs_1 = __values(kernelConfigs), kernelConfigs_1_1 = kernelConfigs_1.next(); !kernelConfigs_1_1.done; kernelConfigs_1_1 = kernelConfigs_1.next()) {
        kernelConfig = kernelConfigs_1_1.value;
        tfjsCore.registerKernel(kernelConfig);
      }
    } catch (e_1_1) {
      e_1 = { error: e_1_1 };
    } finally {
      try {
        if (kernelConfigs_1_1 && !kernelConfigs_1_1.done && (_a = kernelConfigs_1.return))
          _a.call(kernelConfigs_1);
      } finally {
        if (e_1)
          throw e_1.error;
      }
    }
    var kernelConfig;
    var kernelConfigs_1;
    var kernelConfigs_1_1;
    var ENV = tfjsCore.env();
    ENV.registerFlag("WASM_HAS_SIMD_SUPPORT", function() {
      return __awaiter(void 0, void 0, void 0, function() {
        return __generator(this, function(_a2) {
          try {
            return [2, WebAssembly.validate(new Uint8Array([
              0,
              97,
              115,
              109,
              1,
              0,
              0,
              0,
              1,
              4,
              1,
              96,
              0,
              0,
              3,
              2,
              1,
              0,
              10,
              9,
              1,
              7,
              0,
              65,
              0,
              253,
              15,
              26,
              11
            ]))];
          } catch (e) {
            return [2, false];
          }
          return [
            2
            /*return*/
          ];
        });
      });
    });
    ENV.registerFlag("WASM_HAS_MULTITHREAD_SUPPORT", function() {
      return __awaiter(void 0, void 0, void 0, function() {
        return __generator(this, function(_a2) {
          if (ENV.get("IS_NODE")) {
            return [2, false];
          }
          try {
            new MessageChannel().port1.postMessage(new SharedArrayBuffer(1));
            return [2, WebAssembly.validate(new Uint8Array([
              0,
              97,
              115,
              109,
              1,
              0,
              0,
              0,
              1,
              4,
              1,
              96,
              0,
              0,
              3,
              2,
              1,
              0,
              5,
              4,
              1,
              3,
              1,
              1,
              10,
              11,
              1,
              9,
              0,
              65,
              0,
              254,
              16,
              2,
              0,
              26,
              11
            ]))];
          } catch (e) {
            return [2, false];
          }
          return [
            2
            /*return*/
          ];
        });
      });
    });
    var commonjsGlobal = typeof globalThis !== "undefined" ? globalThis : typeof window !== "undefined" ? window : typeof global !== "undefined" ? global : typeof self !== "undefined" ? self : {};
    function getDefaultExportFromCjs(x) {
      return x && x.__esModule && Object.prototype.hasOwnProperty.call(x, "default") ? x["default"] : x;
    }
    var tfjsBackendWasmThreadedSimd$1 = { exports: {} };
    (function(module3, exports2) {
      var WasmBackendModuleThreadedSimd2 = function() {
        var _scriptDir = typeof document !== "undefined" && document.currentScript ? document.currentScript.src : void 0;
        if (typeof __filename !== "undefined")
          _scriptDir = _scriptDir || __filename;
        return function(WasmBackendModuleThreadedSimd3) {
          WasmBackendModuleThreadedSimd3 = WasmBackendModuleThreadedSimd3 || {};
          function GROWABLE_HEAP_I8() {
            if (wasmMemory.buffer != buffer) {
              updateGlobalBufferAndViews(wasmMemory.buffer);
            }
            return HEAP8;
          }
          function GROWABLE_HEAP_U8() {
            if (wasmMemory.buffer != buffer) {
              updateGlobalBufferAndViews(wasmMemory.buffer);
            }
            return HEAPU8;
          }
          function GROWABLE_HEAP_I32() {
            if (wasmMemory.buffer != buffer) {
              updateGlobalBufferAndViews(wasmMemory.buffer);
            }
            return HEAP32;
          }
          function GROWABLE_HEAP_U32() {
            if (wasmMemory.buffer != buffer) {
              updateGlobalBufferAndViews(wasmMemory.buffer);
            }
            return HEAPU32;
          }
          function GROWABLE_HEAP_F64() {
            if (wasmMemory.buffer != buffer) {
              updateGlobalBufferAndViews(wasmMemory.buffer);
            }
            return HEAPF64;
          }
          var Module = typeof WasmBackendModuleThreadedSimd3 != "undefined" ? WasmBackendModuleThreadedSimd3 : {};
          var readyPromiseResolve, readyPromiseReject;
          Module["ready"] = new Promise(function(resolve2, reject) {
            readyPromiseResolve = resolve2;
            readyPromiseReject = reject;
          });
          var beforeListeners;
          if (typeof process !== "undefined" && process.listeners) {
            beforeListeners = { uncaughtException: process.listeners("uncaughtException"), unhandledRejection: process.listeners("unhandledRejection") };
          }
          var moduleOverrides = Object.assign({}, Module);
          var quit_ = function(status, toThrow) {
            throw toThrow;
          };
          var ENVIRONMENT_IS_WEB = typeof window == "object";
          var ENVIRONMENT_IS_WORKER = typeof importScripts == "function";
          var ENVIRONMENT_IS_NODE = typeof process == "object" && typeof process.versions == "object" && typeof process.versions.node == "string";
          var ENVIRONMENT_IS_PTHREAD = Module["ENVIRONMENT_IS_PTHREAD"] || false;
          var scriptDirectory = "";
          function locateFile(path) {
            if (Module["locateFile"]) {
              return Module["locateFile"](path, scriptDirectory);
            }
            return scriptDirectory + path;
          }
          var read_, readAsync, readBinary;
          function logExceptionOnExit(e) {
            if (e instanceof ExitStatus)
              return;
            var toLog = e;
            err("exiting due to exception: " + toLog);
          }
          if (ENVIRONMENT_IS_NODE) {
            var fs = require$$0;
            var nodePath = require$$1;
            if (ENVIRONMENT_IS_WORKER) {
              scriptDirectory = nodePath.dirname(scriptDirectory) + "/";
            } else {
              scriptDirectory = __dirname + "/";
            }
            read_ = function(filename, binary) {
              filename = isFileURI(filename) ? new URL(filename) : nodePath.normalize(filename);
              return fs.readFileSync(filename, binary ? void 0 : "utf8");
            };
            readBinary = function(filename) {
              var ret = read_(filename, true);
              if (!ret.buffer) {
                ret = new Uint8Array(ret);
              }
              return ret;
            };
            readAsync = function(filename, onload, onerror) {
              filename = isFileURI(filename) ? new URL(filename) : nodePath.normalize(filename);
              fs.readFile(filename, function(err2, data) {
                if (err2)
                  onerror(err2);
                else
                  onload(data.buffer);
              });
            };
            if (process["argv"].length > 1) {
              process["argv"][1].replace(/\\/g, "/");
            }
            process["argv"].slice(2);
            process["on"]("uncaughtException", function(ex) {
              if (!(ex instanceof ExitStatus)) {
                throw ex;
              }
            });
            process["on"]("unhandledRejection", function(reason) {
              throw reason;
            });
            quit_ = function(status, toThrow) {
              if (keepRuntimeAlive()) {
                process["exitCode"] = status;
                throw toThrow;
              }
              logExceptionOnExit(toThrow);
              process["exit"](status);
            };
            Module["inspect"] = function() {
              return "[Emscripten Module object]";
            };
            var nodeWorkerThreads = void 0;
            try {
              nodeWorkerThreads = require("worker_threads");
            } catch (e) {
              console.error('The "worker_threads" module is not supported in this node.js build - perhaps a newer version is needed?');
              throw e;
            }
            commonjsGlobal.Worker = nodeWorkerThreads.Worker;
          } else if (ENVIRONMENT_IS_WEB || ENVIRONMENT_IS_WORKER) {
            if (ENVIRONMENT_IS_WORKER) {
              scriptDirectory = self.location.href;
            } else if (typeof document != "undefined" && document.currentScript) {
              scriptDirectory = document.currentScript.src;
            }
            if (typeof _scriptDir !== "undefined" && _scriptDir) {
              scriptDirectory = _scriptDir;
            }
            if (scriptDirectory.indexOf("blob:") !== 0) {
              scriptDirectory = scriptDirectory.substr(0, scriptDirectory.replace(/[?#].*/, "").lastIndexOf("/") + 1);
            } else {
              scriptDirectory = "";
            }
            if (!ENVIRONMENT_IS_NODE) {
              read_ = function(url) {
                var xhr = new XMLHttpRequest();
                xhr.open("GET", url, false);
                xhr.send(null);
                return xhr.responseText;
              };
              if (ENVIRONMENT_IS_WORKER) {
                readBinary = function(url) {
                  var xhr = new XMLHttpRequest();
                  xhr.open("GET", url, false);
                  xhr.responseType = "arraybuffer";
                  xhr.send(null);
                  return new Uint8Array(xhr.response);
                };
              }
              readAsync = function(url, onload, onerror) {
                var xhr = new XMLHttpRequest();
                xhr.open("GET", url, true);
                xhr.responseType = "arraybuffer";
                xhr.onload = function() {
                  if (xhr.status == 200 || xhr.status == 0 && xhr.response) {
                    onload(xhr.response);
                    return;
                  }
                  onerror();
                };
                xhr.onerror = onerror;
                xhr.send(null);
              };
            }
          } else
            ;
          if (ENVIRONMENT_IS_NODE) {
            if (typeof performance == "undefined") {
              commonjsGlobal.performance = require$$3.performance;
            }
          }
          var defaultPrint = console.log.bind(console);
          var defaultPrintErr = console.warn.bind(console);
          if (ENVIRONMENT_IS_NODE) {
            defaultPrint = function(str) {
              return fs.writeSync(1, str + "\n");
            };
            defaultPrintErr = function(str) {
              return fs.writeSync(2, str + "\n");
            };
          }
          var out = Module["print"] || defaultPrint;
          var err = Module["printErr"] || defaultPrintErr;
          Object.assign(Module, moduleOverrides);
          moduleOverrides = null;
          if (Module["arguments"])
            Module["arguments"];
          if (Module["thisProgram"])
            Module["thisProgram"];
          if (Module["quit"])
            quit_ = Module["quit"];
          var wasmBinary;
          if (Module["wasmBinary"])
            wasmBinary = Module["wasmBinary"];
          var noExitRuntime = Module["noExitRuntime"] || true;
          if (typeof WebAssembly != "object") {
            abort("no native wasm support detected");
          }
          var wasmMemory;
          var wasmModule;
          var ABORT = false;
          var EXITSTATUS;
          function assert(condition, text) {
            if (!condition) {
              abort(text);
            }
          }
          var UTF8Decoder = typeof TextDecoder != "undefined" ? new TextDecoder("utf8") : void 0;
          function UTF8ArrayToString(heapOrArray, idx, maxBytesToRead) {
            idx >>>= 0;
            var endIdx = idx + maxBytesToRead;
            var endPtr = idx;
            while (heapOrArray[endPtr] && !(endPtr >= endIdx))
              ++endPtr;
            if (endPtr - idx > 16 && heapOrArray.buffer && UTF8Decoder) {
              return UTF8Decoder.decode(heapOrArray.buffer instanceof SharedArrayBuffer ? heapOrArray.slice(idx, endPtr) : heapOrArray.subarray(idx, endPtr));
            }
            var str = "";
            while (idx < endPtr) {
              var u0 = heapOrArray[idx++];
              if (!(u0 & 128)) {
                str += String.fromCharCode(u0);
                continue;
              }
              var u1 = heapOrArray[idx++] & 63;
              if ((u0 & 224) == 192) {
                str += String.fromCharCode((u0 & 31) << 6 | u1);
                continue;
              }
              var u2 = heapOrArray[idx++] & 63;
              if ((u0 & 240) == 224) {
                u0 = (u0 & 15) << 12 | u1 << 6 | u2;
              } else {
                u0 = (u0 & 7) << 18 | u1 << 12 | u2 << 6 | heapOrArray[idx++] & 63;
              }
              if (u0 < 65536) {
                str += String.fromCharCode(u0);
              } else {
                var ch = u0 - 65536;
                str += String.fromCharCode(55296 | ch >> 10, 56320 | ch & 1023);
              }
            }
            return str;
          }
          function UTF8ToString(ptr, maxBytesToRead) {
            ptr >>>= 0;
            return ptr ? UTF8ArrayToString(GROWABLE_HEAP_U8(), ptr, maxBytesToRead) : "";
          }
          function stringToUTF8Array(str, heap, outIdx, maxBytesToWrite) {
            outIdx >>>= 0;
            if (!(maxBytesToWrite > 0))
              return 0;
            var startIdx = outIdx;
            var endIdx = outIdx + maxBytesToWrite - 1;
            for (var i = 0; i < str.length; ++i) {
              var u = str.charCodeAt(i);
              if (u >= 55296 && u <= 57343) {
                var u1 = str.charCodeAt(++i);
                u = 65536 + ((u & 1023) << 10) | u1 & 1023;
              }
              if (u <= 127) {
                if (outIdx >= endIdx)
                  break;
                heap[outIdx++ >>> 0] = u;
              } else if (u <= 2047) {
                if (outIdx + 1 >= endIdx)
                  break;
                heap[outIdx++ >>> 0] = 192 | u >> 6;
                heap[outIdx++ >>> 0] = 128 | u & 63;
              } else if (u <= 65535) {
                if (outIdx + 2 >= endIdx)
                  break;
                heap[outIdx++ >>> 0] = 224 | u >> 12;
                heap[outIdx++ >>> 0] = 128 | u >> 6 & 63;
                heap[outIdx++ >>> 0] = 128 | u & 63;
              } else {
                if (outIdx + 3 >= endIdx)
                  break;
                heap[outIdx++ >>> 0] = 240 | u >> 18;
                heap[outIdx++ >>> 0] = 128 | u >> 12 & 63;
                heap[outIdx++ >>> 0] = 128 | u >> 6 & 63;
                heap[outIdx++ >>> 0] = 128 | u & 63;
              }
            }
            heap[outIdx >>> 0] = 0;
            return outIdx - startIdx;
          }
          function stringToUTF8(str, outPtr, maxBytesToWrite) {
            return stringToUTF8Array(str, GROWABLE_HEAP_U8(), outPtr, maxBytesToWrite);
          }
          var buffer, HEAP8, HEAPU8, HEAP32, HEAPU32, HEAPF64;
          if (ENVIRONMENT_IS_PTHREAD) {
            buffer = Module["buffer"];
          }
          function updateGlobalBufferAndViews(buf) {
            buffer = buf;
            Module["HEAP8"] = HEAP8 = new Int8Array(buf);
            Module["HEAP16"] = new Int16Array(buf);
            Module["HEAP32"] = HEAP32 = new Int32Array(buf);
            Module["HEAPU8"] = HEAPU8 = new Uint8Array(buf);
            Module["HEAPU16"] = new Uint16Array(buf);
            Module["HEAPU32"] = HEAPU32 = new Uint32Array(buf);
            Module["HEAPF32"] = new Float32Array(buf);
            Module["HEAPF64"] = HEAPF64 = new Float64Array(buf);
          }
          var INITIAL_MEMORY = Module["INITIAL_MEMORY"] || 16777216;
          if (ENVIRONMENT_IS_PTHREAD) {
            wasmMemory = Module["wasmMemory"];
            buffer = Module["buffer"];
          } else {
            if (Module["wasmMemory"]) {
              wasmMemory = Module["wasmMemory"];
            } else {
              wasmMemory = new WebAssembly.Memory({ "initial": INITIAL_MEMORY / 65536, "maximum": 4294967296 / 65536, "shared": true });
              if (!(wasmMemory.buffer instanceof SharedArrayBuffer)) {
                err("requested a shared WebAssembly.Memory but the returned buffer is not a SharedArrayBuffer, indicating that while the browser has SharedArrayBuffer it does not have WebAssembly threads support - you may need to set a flag");
                if (ENVIRONMENT_IS_NODE) {
                  err("(on node you may need: --experimental-wasm-threads --experimental-wasm-bulk-memory and/or recent version)");
                }
                throw Error("bad memory");
              }
            }
          }
          if (wasmMemory) {
            buffer = wasmMemory.buffer;
          }
          INITIAL_MEMORY = buffer.byteLength;
          updateGlobalBufferAndViews(buffer);
          var wasmTable;
          var __ATPRERUN__ = [];
          var __ATINIT__ = [];
          var __ATPOSTRUN__ = [];
          function keepRuntimeAlive() {
            return noExitRuntime;
          }
          function preRun() {
            if (Module["preRun"]) {
              if (typeof Module["preRun"] == "function")
                Module["preRun"] = [Module["preRun"]];
              while (Module["preRun"].length) {
                addOnPreRun(Module["preRun"].shift());
              }
            }
            callRuntimeCallbacks(__ATPRERUN__);
          }
          function initRuntime() {
            if (ENVIRONMENT_IS_PTHREAD)
              return;
            callRuntimeCallbacks(__ATINIT__);
          }
          function postRun() {
            if (ENVIRONMENT_IS_PTHREAD)
              return;
            if (Module["postRun"]) {
              if (typeof Module["postRun"] == "function")
                Module["postRun"] = [Module["postRun"]];
              while (Module["postRun"].length) {
                addOnPostRun(Module["postRun"].shift());
              }
            }
            callRuntimeCallbacks(__ATPOSTRUN__);
          }
          function addOnPreRun(cb) {
            __ATPRERUN__.unshift(cb);
          }
          function addOnInit(cb) {
            __ATINIT__.unshift(cb);
          }
          function addOnPostRun(cb) {
            __ATPOSTRUN__.unshift(cb);
          }
          var runDependencies = 0;
          var dependenciesFulfilled = null;
          function addRunDependency(id) {
            runDependencies++;
            if (Module["monitorRunDependencies"]) {
              Module["monitorRunDependencies"](runDependencies);
            }
          }
          function removeRunDependency(id) {
            runDependencies--;
            if (Module["monitorRunDependencies"]) {
              Module["monitorRunDependencies"](runDependencies);
            }
            if (runDependencies == 0) {
              if (dependenciesFulfilled) {
                var callback = dependenciesFulfilled;
                dependenciesFulfilled = null;
                callback();
              }
            }
          }
          function abort(what) {
            if (Module["onAbort"]) {
              Module["onAbort"](what);
            }
            what = "Aborted(" + what + ")";
            err(what);
            ABORT = true;
            EXITSTATUS = 1;
            what += ". Build with -sASSERTIONS for more info.";
            var e = new WebAssembly.RuntimeError(what);
            readyPromiseReject(e);
            throw e;
          }
          var dataURIPrefix = "data:application/octet-stream;base64,";
          function isDataURI(filename) {
            return filename.startsWith(dataURIPrefix);
          }
          function isFileURI(filename) {
            return filename.startsWith("file://");
          }
          var wasmBinaryFile;
          wasmBinaryFile = "tfjs-backend-wasm-threaded-simd.wasm";
          if (!isDataURI(wasmBinaryFile)) {
            wasmBinaryFile = locateFile(wasmBinaryFile);
          }
          function getBinary(file) {
            try {
              if (file == wasmBinaryFile && wasmBinary) {
                return new Uint8Array(wasmBinary);
              }
              if (readBinary) {
                return readBinary(file);
              }
              throw "both async and sync fetching of the wasm failed";
            } catch (err2) {
              abort(err2);
            }
          }
          function getBinaryPromise() {
            if (!wasmBinary && (ENVIRONMENT_IS_WEB || ENVIRONMENT_IS_WORKER)) {
              if (typeof fetch == "function" && !isFileURI(wasmBinaryFile)) {
                return fetch(wasmBinaryFile, { credentials: "same-origin" }).then(function(response) {
                  if (!response["ok"]) {
                    throw "failed to load wasm binary file at '" + wasmBinaryFile + "'";
                  }
                  return response["arrayBuffer"]();
                }).catch(function() {
                  return getBinary(wasmBinaryFile);
                });
              } else {
                if (readAsync) {
                  return new Promise(function(resolve2, reject) {
                    readAsync(wasmBinaryFile, function(response) {
                      resolve2(new Uint8Array(response));
                    }, reject);
                  });
                }
              }
            }
            return Promise.resolve().then(function() {
              return getBinary(wasmBinaryFile);
            });
          }
          function createWasm() {
            var info = { "env": asmLibraryArg, "wasi_snapshot_preview1": asmLibraryArg };
            function receiveInstance(instance, module4) {
              var exports4 = instance.exports;
              Module["asm"] = exports4;
              registerTLSInit(Module["asm"]["_emscripten_tls_init"]);
              wasmTable = Module["asm"]["__indirect_function_table"];
              addOnInit(Module["asm"]["__wasm_call_ctors"]);
              wasmModule = module4;
              if (!ENVIRONMENT_IS_PTHREAD) {
                var numWorkersToLoad = PThread.unusedWorkers.length;
                PThread.unusedWorkers.forEach(function(w) {
                  PThread.loadWasmModuleToWorker(w, function() {
                    if (!--numWorkersToLoad)
                      removeRunDependency();
                  });
                });
              }
            }
            if (!ENVIRONMENT_IS_PTHREAD) {
              addRunDependency();
            }
            function receiveInstantiationResult(result) {
              receiveInstance(result["instance"], result["module"]);
            }
            function instantiateArrayBuffer(receiver) {
              return getBinaryPromise().then(function(binary) {
                return WebAssembly.instantiate(binary, info);
              }).then(function(instance) {
                return instance;
              }).then(receiver, function(reason) {
                err("failed to asynchronously prepare wasm: " + reason);
                abort(reason);
              });
            }
            function instantiateAsync() {
              if (!wasmBinary && typeof WebAssembly.instantiateStreaming == "function" && !isDataURI(wasmBinaryFile) && !isFileURI(wasmBinaryFile) && !ENVIRONMENT_IS_NODE && typeof fetch == "function") {
                return fetch(wasmBinaryFile, { credentials: "same-origin" }).then(function(response) {
                  var result = WebAssembly.instantiateStreaming(response, info);
                  return result.then(receiveInstantiationResult, function(reason) {
                    err("wasm streaming compile failed: " + reason);
                    err("falling back to ArrayBuffer instantiation");
                    return instantiateArrayBuffer(receiveInstantiationResult);
                  });
                });
              } else {
                return instantiateArrayBuffer(receiveInstantiationResult);
              }
            }
            if (Module["instantiateWasm"]) {
              try {
                var exports3 = Module["instantiateWasm"](info, receiveInstance);
                return exports3;
              } catch (e) {
                err("Module.instantiateWasm callback failed with error: " + e);
                readyPromiseReject(e);
              }
            }
            instantiateAsync().catch(readyPromiseReject);
            return {};
          }
          var ASM_CONSTS = {};
          function ExitStatus(status) {
            this.name = "ExitStatus";
            this.message = "Program terminated with exit(" + status + ")";
            this.status = status;
          }
          function killThread(pthread_ptr) {
            var worker = PThread.pthreads[pthread_ptr];
            delete PThread.pthreads[pthread_ptr];
            worker.terminate();
            __emscripten_thread_free_data(pthread_ptr);
            PThread.runningWorkers.splice(PThread.runningWorkers.indexOf(worker), 1);
            worker.pthread_ptr = 0;
          }
          function cancelThread(pthread_ptr) {
            var worker = PThread.pthreads[pthread_ptr];
            worker.postMessage({ "cmd": "cancel" });
          }
          function cleanupThread(pthread_ptr) {
            var worker = PThread.pthreads[pthread_ptr];
            assert(worker);
            PThread.returnWorkerToPool(worker);
          }
          function spawnThread(threadParams) {
            var worker = PThread.getNewWorker();
            if (!worker) {
              return 6;
            }
            PThread.runningWorkers.push(worker);
            PThread.pthreads[threadParams.pthread_ptr] = worker;
            worker.pthread_ptr = threadParams.pthread_ptr;
            var msg = { "cmd": "run", "start_routine": threadParams.startRoutine, "arg": threadParams.arg, "pthread_ptr": threadParams.pthread_ptr };
            worker.runPthread = function() {
              if (ENVIRONMENT_IS_NODE) {
                worker.ref();
              }
              worker.postMessage(msg, threadParams.transferList);
              delete worker.runPthread;
            };
            if (worker.loaded) {
              worker.runPthread();
            }
            return 0;
          }
          function _proc_exit(code) {
            if (ENVIRONMENT_IS_PTHREAD)
              return _emscripten_proxy_to_main_thread_js(1, 1, code);
            EXITSTATUS = code;
            if (!keepRuntimeAlive()) {
              PThread.terminateAllThreads();
              if (Module["onExit"])
                Module["onExit"](code);
              ABORT = true;
            }
            quit_(code, new ExitStatus(code));
          }
          function exitJS(status, implicit) {
            EXITSTATUS = status;
            if (!implicit) {
              if (ENVIRONMENT_IS_PTHREAD) {
                exitOnMainThread(status);
                throw "unwind";
              }
            }
            _proc_exit(status);
          }
          var _exit = exitJS;
          function handleException(e) {
            if (e instanceof ExitStatus || e == "unwind") {
              return EXITSTATUS;
            }
            quit_(1, e);
          }
          var PThread = { unusedWorkers: [], runningWorkers: [], tlsInitFunctions: [], pthreads: {}, init: function() {
            if (ENVIRONMENT_IS_PTHREAD) {
              PThread.initWorker();
            } else {
              PThread.initMainThread();
            }
          }, initMainThread: function() {
            var pthreadPoolSize = 8;
            while (pthreadPoolSize--) {
              PThread.allocateUnusedWorker();
            }
          }, initWorker: function() {
            noExitRuntime = false;
          }, setExitStatus: function(status) {
            EXITSTATUS = status;
          }, terminateAllThreads: function() {
            var e_12, _a2, e_2, _b;
            try {
              for (var _c = __values(Object.values(PThread.pthreads)), _d = _c.next(); !_d.done; _d = _c.next()) {
                var worker = _d.value;
                PThread.returnWorkerToPool(worker);
              }
            } catch (e_1_1) {
              e_12 = { error: e_1_1 };
            } finally {
              try {
                if (_d && !_d.done && (_a2 = _c.return))
                  _a2.call(_c);
              } finally {
                if (e_12)
                  throw e_12.error;
              }
            }
            try {
              for (var _e = __values(PThread.unusedWorkers), _f = _e.next(); !_f.done; _f = _e.next()) {
                var worker = _f.value;
                worker.terminate();
              }
            } catch (e_2_1) {
              e_2 = { error: e_2_1 };
            } finally {
              try {
                if (_f && !_f.done && (_b = _e.return))
                  _b.call(_e);
              } finally {
                if (e_2)
                  throw e_2.error;
              }
            }
            PThread.unusedWorkers = [];
          }, returnWorkerToPool: function(worker) {
            var pthread_ptr = worker.pthread_ptr;
            delete PThread.pthreads[pthread_ptr];
            PThread.unusedWorkers.push(worker);
            PThread.runningWorkers.splice(PThread.runningWorkers.indexOf(worker), 1);
            worker.pthread_ptr = 0;
            if (ENVIRONMENT_IS_NODE) {
              worker.unref();
            }
            __emscripten_thread_free_data(pthread_ptr);
          }, receiveObjectTransfer: function(data) {
          }, threadInitTLS: function() {
            PThread.tlsInitFunctions.forEach(function(f) {
              return f();
            });
          }, loadWasmModuleToWorker: function(worker, onFinishedLoading) {
            var e_3, _a2;
            worker.onmessage = function(e) {
              var d = e["data"];
              var cmd = d["cmd"];
              if (worker.pthread_ptr)
                PThread.currentProxiedOperationCallerThread = worker.pthread_ptr;
              if (d["targetThread"] && d["targetThread"] != _pthread_self()) {
                var targetWorker = PThread.pthreads[d.targetThread];
                if (targetWorker) {
                  targetWorker.postMessage(d, d["transferList"]);
                } else {
                  err('Internal error! Worker sent a message "' + cmd + '" to target pthread ' + d["targetThread"] + ", but that thread no longer exists!");
                }
                PThread.currentProxiedOperationCallerThread = void 0;
                return;
              }
              if (cmd === "processProxyingQueue") {
                executeNotifiedProxyingQueue(d["queue"]);
              } else if (cmd === "spawnThread") {
                spawnThread(d);
              } else if (cmd === "cleanupThread") {
                cleanupThread(d["thread"]);
              } else if (cmd === "killThread") {
                killThread(d["thread"]);
              } else if (cmd === "cancelThread") {
                cancelThread(d["thread"]);
              } else if (cmd === "loaded") {
                worker.loaded = true;
                if (ENVIRONMENT_IS_NODE) {
                  worker.unref();
                }
                if (onFinishedLoading)
                  onFinishedLoading(worker);
                if (worker.runPthread) {
                  worker.runPthread();
                }
              } else if (cmd === "print") {
                out("Thread " + d["threadId"] + ": " + d["text"]);
              } else if (cmd === "printErr") {
                err("Thread " + d["threadId"] + ": " + d["text"]);
              } else if (cmd === "alert") {
                alert("Thread " + d["threadId"] + ": " + d["text"]);
              } else if (d.target === "setimmediate") {
                worker.postMessage(d);
              } else if (cmd === "callHandler") {
                Module[d["handler"]].apply(Module, __spreadArray([], __read(d["args"]), false));
              } else if (cmd) {
                err("worker sent an unknown command " + cmd);
              }
              PThread.currentProxiedOperationCallerThread = void 0;
            };
            worker.onerror = function(e) {
              var message = "worker sent an error!";
              err(message + " " + e.filename + ":" + e.lineno + ": " + e.message);
              throw e;
            };
            if (ENVIRONMENT_IS_NODE) {
              worker.on("message", function(data) {
                worker.onmessage({ data });
              });
              worker.on("error", function(e) {
                worker.onerror(e);
              });
              worker.on("detachedExit", function() {
              });
            }
            var handlers = [];
            var knownHandlers = ["onExit", "onAbort", "print", "printErr"];
            try {
              for (var knownHandlers_1 = __values(knownHandlers), knownHandlers_1_1 = knownHandlers_1.next(); !knownHandlers_1_1.done; knownHandlers_1_1 = knownHandlers_1.next()) {
                var handler = knownHandlers_1_1.value;
                if (Module.hasOwnProperty(handler)) {
                  handlers.push(handler);
                }
              }
            } catch (e_3_1) {
              e_3 = { error: e_3_1 };
            } finally {
              try {
                if (knownHandlers_1_1 && !knownHandlers_1_1.done && (_a2 = knownHandlers_1.return))
                  _a2.call(knownHandlers_1);
              } finally {
                if (e_3)
                  throw e_3.error;
              }
            }
            worker.postMessage({ "cmd": "load", "handlers": handlers, "urlOrBlob": Module["mainScriptUrlOrBlob"] || _scriptDir, "wasmMemory": wasmMemory, "wasmModule": wasmModule });
          }, allocateUnusedWorker: function() {
            var worker;
            var pthreadMainJs = locateFile("tfjs-backend-wasm-threaded-simd.worker.js");
            worker = new Worker(pthreadMainJs);
            PThread.unusedWorkers.push(worker);
          }, getNewWorker: function() {
            if (PThread.unusedWorkers.length == 0) {
              PThread.allocateUnusedWorker();
              PThread.loadWasmModuleToWorker(PThread.unusedWorkers[0]);
            }
            return PThread.unusedWorkers.pop();
          } };
          Module["PThread"] = PThread;
          function callRuntimeCallbacks(callbacks) {
            while (callbacks.length > 0) {
              callbacks.shift()(Module);
            }
          }
          function establishStackSpace() {
            var pthread_ptr = _pthread_self();
            var stackTop = GROWABLE_HEAP_I32()[pthread_ptr + 52 >>> 2];
            var stackSize = GROWABLE_HEAP_I32()[pthread_ptr + 56 >>> 2];
            var stackMax = stackTop - stackSize;
            _emscripten_stack_set_limits(stackTop, stackMax);
            stackRestore(stackTop);
          }
          Module["establishStackSpace"] = establishStackSpace;
          function exitOnMainThread(returnCode) {
            if (ENVIRONMENT_IS_PTHREAD)
              return _emscripten_proxy_to_main_thread_js(2, 0, returnCode);
            try {
              _exit(returnCode);
            } catch (e) {
              handleException(e);
            }
          }
          var wasmTableMirror = [];
          function getWasmTableEntry(funcPtr) {
            var func = wasmTableMirror[funcPtr];
            if (!func) {
              if (funcPtr >= wasmTableMirror.length)
                wasmTableMirror.length = funcPtr + 1;
              wasmTableMirror[funcPtr] = func = wasmTable.get(funcPtr);
            }
            return func;
          }
          function invokeEntryPoint(ptr, arg) {
            var result = getWasmTableEntry(ptr)(arg);
            if (keepRuntimeAlive()) {
              PThread.setExitStatus(result);
            } else {
              __emscripten_thread_exit(result);
            }
          }
          Module["invokeEntryPoint"] = invokeEntryPoint;
          function registerTLSInit(tlsInitFunc) {
            PThread.tlsInitFunctions.push(tlsInitFunc);
          }
          function ___emscripten_init_main_thread_js(tb) {
            __emscripten_thread_init(tb, !ENVIRONMENT_IS_WORKER, 1, !ENVIRONMENT_IS_WEB);
            PThread.threadInitTLS();
          }
          function ___emscripten_thread_cleanup(thread) {
            if (!ENVIRONMENT_IS_PTHREAD)
              cleanupThread(thread);
            else
              postMessage({ "cmd": "cleanupThread", "thread": thread });
          }
          function pthreadCreateProxied(pthread_ptr, attr, startRoutine, arg) {
            if (ENVIRONMENT_IS_PTHREAD)
              return _emscripten_proxy_to_main_thread_js(3, 1, pthread_ptr, attr, startRoutine, arg);
            return ___pthread_create_js(pthread_ptr, attr, startRoutine, arg);
          }
          function ___pthread_create_js(pthread_ptr, attr, startRoutine, arg) {
            if (typeof SharedArrayBuffer == "undefined") {
              err("Current environment does not support SharedArrayBuffer, pthreads are not available!");
              return 6;
            }
            var transferList = [];
            var error = 0;
            if (ENVIRONMENT_IS_PTHREAD && (transferList.length === 0 || error)) {
              return pthreadCreateProxied(pthread_ptr, attr, startRoutine, arg);
            }
            var threadParams = { startRoutine, pthread_ptr, arg, transferList };
            if (ENVIRONMENT_IS_PTHREAD) {
              threadParams.cmd = "spawnThread";
              postMessage(threadParams, transferList);
              return 0;
            }
            return spawnThread(threadParams);
          }
          function __emscripten_default_pthread_stack_size() {
            return 65536;
          }
          var nowIsMonotonic = true;
          function __emscripten_get_now_is_monotonic() {
            return nowIsMonotonic;
          }
          function executeNotifiedProxyingQueue(queue) {
            Atomics.store(GROWABLE_HEAP_I32(), queue >> 2, 1);
            if (_pthread_self()) {
              __emscripten_proxy_execute_task_queue(queue);
            }
            Atomics.compareExchange(GROWABLE_HEAP_I32(), queue >> 2, 1, 0);
          }
          Module["executeNotifiedProxyingQueue"] = executeNotifiedProxyingQueue;
          function __emscripten_notify_task_queue(targetThreadId, currThreadId, mainThreadId, queue) {
            if (targetThreadId == currThreadId) {
              setTimeout(function() {
                return executeNotifiedProxyingQueue(queue);
              });
            } else if (ENVIRONMENT_IS_PTHREAD) {
              postMessage({ "targetThread": targetThreadId, "cmd": "processProxyingQueue", "queue": queue });
            } else {
              var worker = PThread.pthreads[targetThreadId];
              if (!worker) {
                return;
              }
              worker.postMessage({ "cmd": "processProxyingQueue", "queue": queue });
            }
            return 1;
          }
          function __emscripten_set_offscreencanvas_size(target, width, height) {
            return -1;
          }
          function _abort() {
            abort("");
          }
          function warnOnce(text) {
            if (!warnOnce.shown)
              warnOnce.shown = {};
            if (!warnOnce.shown[text]) {
              warnOnce.shown[text] = 1;
              if (ENVIRONMENT_IS_NODE)
                text = "warning: " + text;
              err(text);
            }
          }
          function _emscripten_check_blocking_allowed() {
            if (ENVIRONMENT_IS_NODE)
              return;
            if (ENVIRONMENT_IS_WORKER)
              return;
            warnOnce("Blocking on the main thread is very dangerous, see https://emscripten.org/docs/porting/pthreads.html#blocking-on-the-main-browser-thread");
          }
          function _emscripten_date_now() {
            return Date.now();
          }
          function getHeapMax() {
            return 4294901760;
          }
          function _emscripten_get_heap_max() {
            return getHeapMax();
          }
          var _emscripten_get_now;
          if (ENVIRONMENT_IS_NODE) {
            _emscripten_get_now = function() {
              var t = process["hrtime"]();
              return t[0] * 1e3 + t[1] / 1e6;
            };
          } else
            _emscripten_get_now = function() {
              return performance.timeOrigin + performance.now();
            };
          function _emscripten_memcpy_big(dest, src, num) {
            GROWABLE_HEAP_U8().copyWithin(dest >>> 0, src >>> 0, src + num >>> 0);
          }
          function _emscripten_num_logical_cores() {
            if (ENVIRONMENT_IS_NODE)
              return require$$4.cpus().length;
            return navigator["hardwareConcurrency"];
          }
          function withStackSave(f) {
            var stack = stackSave();
            var ret = f();
            stackRestore(stack);
            return ret;
          }
          function _emscripten_proxy_to_main_thread_js(index, sync) {
            var numCallArgs = arguments.length - 2;
            var outerArgs = arguments;
            return withStackSave(function() {
              var serializedNumCallArgs = numCallArgs;
              var args = stackAlloc(serializedNumCallArgs * 8);
              var b = args >> 3;
              for (var i = 0; i < numCallArgs; i++) {
                var arg = outerArgs[2 + i];
                GROWABLE_HEAP_F64()[b + i >>> 0] = arg;
              }
              return _emscripten_run_in_main_runtime_thread_js(index, serializedNumCallArgs, args, sync);
            });
          }
          var _emscripten_receive_on_main_thread_js_callArgs = [];
          function _emscripten_receive_on_main_thread_js(index, numCallArgs, args) {
            _emscripten_receive_on_main_thread_js_callArgs.length = numCallArgs;
            var b = args >> 3;
            for (var i = 0; i < numCallArgs; i++) {
              _emscripten_receive_on_main_thread_js_callArgs[i] = GROWABLE_HEAP_F64()[b + i >>> 0];
            }
            var isEmAsmConst = index < 0;
            var func = !isEmAsmConst ? proxiedFunctionTable[index] : ASM_CONSTS[-index - 1];
            return func.apply(null, _emscripten_receive_on_main_thread_js_callArgs);
          }
          function emscripten_realloc_buffer(size) {
            try {
              wasmMemory.grow(size - buffer.byteLength + 65535 >>> 16);
              updateGlobalBufferAndViews(wasmMemory.buffer);
              return 1;
            } catch (e) {
            }
          }
          function _emscripten_resize_heap(requestedSize) {
            var oldSize = GROWABLE_HEAP_U8().length;
            requestedSize = requestedSize >>> 0;
            if (requestedSize <= oldSize) {
              return false;
            }
            var maxHeapSize = getHeapMax();
            if (requestedSize > maxHeapSize) {
              return false;
            }
            var alignUp = function(x, multiple) {
              return x + (multiple - x % multiple) % multiple;
            };
            for (var cutDown = 1; cutDown <= 4; cutDown *= 2) {
              var overGrownHeapSize = oldSize * (1 + 0.2 / cutDown);
              overGrownHeapSize = Math.min(overGrownHeapSize, requestedSize + 100663296);
              var newSize = Math.min(maxHeapSize, alignUp(Math.max(requestedSize, overGrownHeapSize), 65536));
              var replacement = emscripten_realloc_buffer(newSize);
              if (replacement) {
                return true;
              }
            }
            return false;
          }
          function _emscripten_unwind_to_js_event_loop() {
            throw "unwind";
          }
          function _fd_close(fd) {
            if (ENVIRONMENT_IS_PTHREAD)
              return _emscripten_proxy_to_main_thread_js(4, 1, fd);
            return 52;
          }
          function _fd_seek(fd, offset_low, offset_high, whence, newOffset) {
            if (ENVIRONMENT_IS_PTHREAD)
              return _emscripten_proxy_to_main_thread_js(5, 1, fd, offset_low, offset_high, whence, newOffset);
            return 70;
          }
          var printCharBuffers = [null, [], []];
          function printChar(stream, curr) {
            var buffer2 = printCharBuffers[stream];
            if (curr === 0 || curr === 10) {
              (stream === 1 ? out : err)(UTF8ArrayToString(buffer2, 0));
              buffer2.length = 0;
            } else {
              buffer2.push(curr);
            }
          }
          function _fd_write(fd, iov, iovcnt, pnum) {
            if (ENVIRONMENT_IS_PTHREAD)
              return _emscripten_proxy_to_main_thread_js(6, 1, fd, iov, iovcnt, pnum);
            var num = 0;
            for (var i = 0; i < iovcnt; i++) {
              var ptr = GROWABLE_HEAP_U32()[iov >>> 2];
              var len = GROWABLE_HEAP_U32()[iov + 4 >>> 2];
              iov += 8;
              for (var j = 0; j < len; j++) {
                printChar(fd, GROWABLE_HEAP_U8()[ptr + j >>> 0]);
              }
              num += len;
            }
            GROWABLE_HEAP_U32()[pnum >>> 2] = num;
            return 0;
          }
          function getCFunc(ident) {
            var func = Module["_" + ident];
            return func;
          }
          function writeArrayToMemory(array, buffer2) {
            GROWABLE_HEAP_I8().set(array, buffer2 >>> 0);
          }
          function ccall(ident, returnType, argTypes, args, opts) {
            var toC = { "string": function(str) {
              var ret2 = 0;
              if (str !== null && str !== void 0 && str !== 0) {
                var len = (str.length << 2) + 1;
                ret2 = stackAlloc(len);
                stringToUTF8(str, ret2, len);
              }
              return ret2;
            }, "array": function(arr) {
              var ret2 = stackAlloc(arr.length);
              writeArrayToMemory(arr, ret2);
              return ret2;
            } };
            function convertReturnValue(ret2) {
              if (returnType === "string") {
                return UTF8ToString(ret2);
              }
              if (returnType === "boolean")
                return Boolean(ret2);
              return ret2;
            }
            var func = getCFunc(ident);
            var cArgs = [];
            var stack = 0;
            if (args) {
              for (var i = 0; i < args.length; i++) {
                var converter = toC[argTypes[i]];
                if (converter) {
                  if (stack === 0)
                    stack = stackSave();
                  cArgs[i] = converter(args[i]);
                } else {
                  cArgs[i] = args[i];
                }
              }
            }
            var ret = func.apply(null, cArgs);
            function onDone(ret2) {
              if (stack !== 0)
                stackRestore(stack);
              return convertReturnValue(ret2);
            }
            ret = onDone(ret);
            return ret;
          }
          function cwrap(ident, returnType, argTypes, opts) {
            argTypes = argTypes || [];
            var numericArgs = argTypes.every(function(type) {
              return type === "number" || type === "boolean";
            });
            var numericRet = returnType !== "string";
            if (numericRet && numericArgs && !opts) {
              return getCFunc(ident);
            }
            return function() {
              return ccall(ident, returnType, argTypes, arguments);
            };
          }
          PThread.init();
          var proxiedFunctionTable = [null, _proc_exit, exitOnMainThread, pthreadCreateProxied, _fd_close, _fd_seek, _fd_write];
          var asmLibraryArg = { "__emscripten_init_main_thread_js": ___emscripten_init_main_thread_js, "__emscripten_thread_cleanup": ___emscripten_thread_cleanup, "__pthread_create_js": ___pthread_create_js, "_emscripten_default_pthread_stack_size": __emscripten_default_pthread_stack_size, "_emscripten_get_now_is_monotonic": __emscripten_get_now_is_monotonic, "_emscripten_notify_task_queue": __emscripten_notify_task_queue, "_emscripten_set_offscreencanvas_size": __emscripten_set_offscreencanvas_size, "abort": _abort, "emscripten_check_blocking_allowed": _emscripten_check_blocking_allowed, "emscripten_date_now": _emscripten_date_now, "emscripten_get_heap_max": _emscripten_get_heap_max, "emscripten_get_now": _emscripten_get_now, "emscripten_memcpy_big": _emscripten_memcpy_big, "emscripten_num_logical_cores": _emscripten_num_logical_cores, "emscripten_receive_on_main_thread_js": _emscripten_receive_on_main_thread_js, "emscripten_resize_heap": _emscripten_resize_heap, "emscripten_unwind_to_js_event_loop": _emscripten_unwind_to_js_event_loop, "exit": _exit, "fd_close": _fd_close, "fd_seek": _fd_seek, "fd_write": _fd_write, "memory": wasmMemory || Module["wasmMemory"] };
          createWasm();
          Module["___wasm_call_ctors"] = function() {
            return (Module["___wasm_call_ctors"] = Module["asm"]["__wasm_call_ctors"]).apply(null, arguments);
          };
          Module["_init"] = function() {
            return (Module["_init"] = Module["asm"]["init"]).apply(null, arguments);
          };
          Module["_init_with_threads_count"] = function() {
            return (Module["_init_with_threads_count"] = Module["asm"]["init_with_threads_count"]).apply(null, arguments);
          };
          Module["_get_threads_count"] = function() {
            return (Module["_get_threads_count"] = Module["asm"]["get_threads_count"]).apply(null, arguments);
          };
          Module["_register_tensor"] = function() {
            return (Module["_register_tensor"] = Module["asm"]["register_tensor"]).apply(null, arguments);
          };
          Module["_dispose_data"] = function() {
            return (Module["_dispose_data"] = Module["asm"]["dispose_data"]).apply(null, arguments);
          };
          Module["_dispose"] = function() {
            return (Module["_dispose"] = Module["asm"]["dispose"]).apply(null, arguments);
          };
          Module["_Abs"] = function() {
            return (Module["_Abs"] = Module["asm"]["Abs"]).apply(null, arguments);
          };
          Module["_Acos"] = function() {
            return (Module["_Acos"] = Module["asm"]["Acos"]).apply(null, arguments);
          };
          Module["_Acosh"] = function() {
            return (Module["_Acosh"] = Module["asm"]["Acosh"]).apply(null, arguments);
          };
          Module["_Add"] = function() {
            return (Module["_Add"] = Module["asm"]["Add"]).apply(null, arguments);
          };
          Module["_AddN"] = function() {
            return (Module["_AddN"] = Module["asm"]["AddN"]).apply(null, arguments);
          };
          Module["_All"] = function() {
            return (Module["_All"] = Module["asm"]["All"]).apply(null, arguments);
          };
          Module["_Any"] = function() {
            return (Module["_Any"] = Module["asm"]["Any"]).apply(null, arguments);
          };
          Module["_ArgMax"] = function() {
            return (Module["_ArgMax"] = Module["asm"]["ArgMax"]).apply(null, arguments);
          };
          Module["_ArgMin"] = function() {
            return (Module["_ArgMin"] = Module["asm"]["ArgMin"]).apply(null, arguments);
          };
          Module["_Asin"] = function() {
            return (Module["_Asin"] = Module["asm"]["Asin"]).apply(null, arguments);
          };
          Module["_Asinh"] = function() {
            return (Module["_Asinh"] = Module["asm"]["Asinh"]).apply(null, arguments);
          };
          Module["_Atan"] = function() {
            return (Module["_Atan"] = Module["asm"]["Atan"]).apply(null, arguments);
          };
          Module["_Atan2"] = function() {
            return (Module["_Atan2"] = Module["asm"]["Atan2"]).apply(null, arguments);
          };
          Module["_Atanh"] = function() {
            return (Module["_Atanh"] = Module["asm"]["Atanh"]).apply(null, arguments);
          };
          Module["_AvgPool"] = function() {
            return (Module["_AvgPool"] = Module["asm"]["AvgPool"]).apply(null, arguments);
          };
          Module["_AvgPool3D"] = function() {
            return (Module["_AvgPool3D"] = Module["asm"]["AvgPool3D"]).apply(null, arguments);
          };
          Module["_AvgPool3DGrad"] = function() {
            return (Module["_AvgPool3DGrad"] = Module["asm"]["AvgPool3DGrad"]).apply(null, arguments);
          };
          Module["_BatchMatMul"] = function() {
            return (Module["_BatchMatMul"] = Module["asm"]["BatchMatMul"]).apply(null, arguments);
          };
          Module["_Bincount"] = function() {
            return (Module["_Bincount"] = Module["asm"]["Bincount"]).apply(null, arguments);
          };
          Module["_Ceil"] = function() {
            return (Module["_Ceil"] = Module["asm"]["Ceil"]).apply(null, arguments);
          };
          Module["_ClipByValue"] = function() {
            return (Module["_ClipByValue"] = Module["asm"]["ClipByValue"]).apply(null, arguments);
          };
          Module["_Conv2D"] = function() {
            return (Module["_Conv2D"] = Module["asm"]["Conv2D"]).apply(null, arguments);
          };
          Module["_Conv2DBackpropInput"] = function() {
            return (Module["_Conv2DBackpropInput"] = Module["asm"]["Conv2DBackpropInput"]).apply(null, arguments);
          };
          Module["_Conv3D"] = function() {
            return (Module["_Conv3D"] = Module["asm"]["Conv3D"]).apply(null, arguments);
          };
          Module["_Conv3DBackpropFilterV2"] = function() {
            return (Module["_Conv3DBackpropFilterV2"] = Module["asm"]["Conv3DBackpropFilterV2"]).apply(null, arguments);
          };
          Module["_Conv3DBackpropInputV2"] = function() {
            return (Module["_Conv3DBackpropInputV2"] = Module["asm"]["Conv3DBackpropInputV2"]).apply(null, arguments);
          };
          Module["_Cos"] = function() {
            return (Module["_Cos"] = Module["asm"]["Cos"]).apply(null, arguments);
          };
          Module["_Cosh"] = function() {
            return (Module["_Cosh"] = Module["asm"]["Cosh"]).apply(null, arguments);
          };
          Module["_CropAndResize"] = function() {
            return (Module["_CropAndResize"] = Module["asm"]["CropAndResize"]).apply(null, arguments);
          };
          Module["_Cumprod"] = function() {
            return (Module["_Cumprod"] = Module["asm"]["Cumprod"]).apply(null, arguments);
          };
          Module["_Cumsum"] = function() {
            return (Module["_Cumsum"] = Module["asm"]["Cumsum"]).apply(null, arguments);
          };
          Module["_DenseBincount"] = function() {
            return (Module["_DenseBincount"] = Module["asm"]["DenseBincount"]).apply(null, arguments);
          };
          Module["_DepthToSpace"] = function() {
            return (Module["_DepthToSpace"] = Module["asm"]["DepthToSpace"]).apply(null, arguments);
          };
          Module["_DepthwiseConv2dNative"] = function() {
            return (Module["_DepthwiseConv2dNative"] = Module["asm"]["DepthwiseConv2dNative"]).apply(null, arguments);
          };
          Module["_Diag"] = function() {
            return (Module["_Diag"] = Module["asm"]["Diag"]).apply(null, arguments);
          };
          Module["_Dilation2D"] = function() {
            return (Module["_Dilation2D"] = Module["asm"]["Dilation2D"]).apply(null, arguments);
          };
          Module["_Dilation2DBackpropFilter"] = function() {
            return (Module["_Dilation2DBackpropFilter"] = Module["asm"]["Dilation2DBackpropFilter"]).apply(null, arguments);
          };
          Module["_Dilation2DBackpropInput"] = function() {
            return (Module["_Dilation2DBackpropInput"] = Module["asm"]["Dilation2DBackpropInput"]).apply(null, arguments);
          };
          Module["_Elu"] = function() {
            return (Module["_Elu"] = Module["asm"]["Elu"]).apply(null, arguments);
          };
          Module["_EluGrad"] = function() {
            return (Module["_EluGrad"] = Module["asm"]["EluGrad"]).apply(null, arguments);
          };
          Module["_Equal"] = function() {
            return (Module["_Equal"] = Module["asm"]["Equal"]).apply(null, arguments);
          };
          Module["_Exp"] = function() {
            return (Module["_Exp"] = Module["asm"]["Exp"]).apply(null, arguments);
          };
          Module["_Expm1"] = function() {
            return (Module["_Expm1"] = Module["asm"]["Expm1"]).apply(null, arguments);
          };
          Module["_FlipLeftRight"] = function() {
            return (Module["_FlipLeftRight"] = Module["asm"]["FlipLeftRight"]).apply(null, arguments);
          };
          Module["_Floor"] = function() {
            return (Module["_Floor"] = Module["asm"]["Floor"]).apply(null, arguments);
          };
          Module["_FloorDiv"] = function() {
            return (Module["_FloorDiv"] = Module["asm"]["FloorDiv"]).apply(null, arguments);
          };
          Module["_FusedBatchNorm"] = function() {
            return (Module["_FusedBatchNorm"] = Module["asm"]["FusedBatchNorm"]).apply(null, arguments);
          };
          Module["_FusedConv2D"] = function() {
            return (Module["_FusedConv2D"] = Module["asm"]["FusedConv2D"]).apply(null, arguments);
          };
          Module["_FusedDepthwiseConv2D"] = function() {
            return (Module["_FusedDepthwiseConv2D"] = Module["asm"]["FusedDepthwiseConv2D"]).apply(null, arguments);
          };
          Module["_Gather"] = function() {
            return (Module["_Gather"] = Module["asm"]["Gather"]).apply(null, arguments);
          };
          Module["_GatherNd"] = function() {
            return (Module["_GatherNd"] = Module["asm"]["GatherNd"]).apply(null, arguments);
          };
          Module["_Greater"] = function() {
            return (Module["_Greater"] = Module["asm"]["Greater"]).apply(null, arguments);
          };
          Module["_GreaterEqual"] = function() {
            return (Module["_GreaterEqual"] = Module["asm"]["GreaterEqual"]).apply(null, arguments);
          };
          Module["_IsFinite"] = function() {
            return (Module["_IsFinite"] = Module["asm"]["IsFinite"]).apply(null, arguments);
          };
          Module["_IsInf"] = function() {
            return (Module["_IsInf"] = Module["asm"]["IsInf"]).apply(null, arguments);
          };
          Module["_IsNan"] = function() {
            return (Module["_IsNan"] = Module["asm"]["IsNan"]).apply(null, arguments);
          };
          Module["_LRN"] = function() {
            return (Module["_LRN"] = Module["asm"]["LRN"]).apply(null, arguments);
          };
          Module["_LRNGrad"] = function() {
            return (Module["_LRNGrad"] = Module["asm"]["LRNGrad"]).apply(null, arguments);
          };
          Module["_LeakyRelu"] = function() {
            return (Module["_LeakyRelu"] = Module["asm"]["LeakyRelu"]).apply(null, arguments);
          };
          Module["_Less"] = function() {
            return (Module["_Less"] = Module["asm"]["Less"]).apply(null, arguments);
          };
          Module["_LessEqual"] = function() {
            return (Module["_LessEqual"] = Module["asm"]["LessEqual"]).apply(null, arguments);
          };
          Module["_LinSpace"] = function() {
            return (Module["_LinSpace"] = Module["asm"]["LinSpace"]).apply(null, arguments);
          };
          Module["_Log"] = function() {
            return (Module["_Log"] = Module["asm"]["Log"]).apply(null, arguments);
          };
          Module["_Log1p"] = function() {
            return (Module["_Log1p"] = Module["asm"]["Log1p"]).apply(null, arguments);
          };
          Module["_LogicalAnd"] = function() {
            return (Module["_LogicalAnd"] = Module["asm"]["LogicalAnd"]).apply(null, arguments);
          };
          Module["_LogicalNot"] = function() {
            return (Module["_LogicalNot"] = Module["asm"]["LogicalNot"]).apply(null, arguments);
          };
          Module["_LogicalOr"] = function() {
            return (Module["_LogicalOr"] = Module["asm"]["LogicalOr"]).apply(null, arguments);
          };
          Module["_LogicalXor"] = function() {
            return (Module["_LogicalXor"] = Module["asm"]["LogicalXor"]).apply(null, arguments);
          };
          Module["_Max"] = function() {
            return (Module["_Max"] = Module["asm"]["Max"]).apply(null, arguments);
          };
          Module["_MaxPool"] = function() {
            return (Module["_MaxPool"] = Module["asm"]["MaxPool"]).apply(null, arguments);
          };
          Module["_MaxPool3D"] = function() {
            return (Module["_MaxPool3D"] = Module["asm"]["MaxPool3D"]).apply(null, arguments);
          };
          Module["_MaxPool3DGrad"] = function() {
            return (Module["_MaxPool3DGrad"] = Module["asm"]["MaxPool3DGrad"]).apply(null, arguments);
          };
          Module["_Maximum"] = function() {
            return (Module["_Maximum"] = Module["asm"]["Maximum"]).apply(null, arguments);
          };
          Module["_Mean"] = function() {
            return (Module["_Mean"] = Module["asm"]["Mean"]).apply(null, arguments);
          };
          Module["_Min"] = function() {
            return (Module["_Min"] = Module["asm"]["Min"]).apply(null, arguments);
          };
          Module["_Minimum"] = function() {
            return (Module["_Minimum"] = Module["asm"]["Minimum"]).apply(null, arguments);
          };
          Module["_MirrorPad"] = function() {
            return (Module["_MirrorPad"] = Module["asm"]["MirrorPad"]).apply(null, arguments);
          };
          Module["_Multinomial"] = function() {
            return (Module["_Multinomial"] = Module["asm"]["Multinomial"]).apply(null, arguments);
          };
          Module["_Multiply"] = function() {
            return (Module["_Multiply"] = Module["asm"]["Multiply"]).apply(null, arguments);
          };
          Module["_Neg"] = function() {
            return (Module["_Neg"] = Module["asm"]["Neg"]).apply(null, arguments);
          };
          Module["_NonMaxSuppressionV3"] = function() {
            return (Module["_NonMaxSuppressionV3"] = Module["asm"]["NonMaxSuppressionV3"]).apply(null, arguments);
          };
          Module["_NonMaxSuppressionV4"] = function() {
            return (Module["_NonMaxSuppressionV4"] = Module["asm"]["NonMaxSuppressionV4"]).apply(null, arguments);
          };
          Module["_NonMaxSuppressionV5"] = function() {
            return (Module["_NonMaxSuppressionV5"] = Module["asm"]["NonMaxSuppressionV5"]).apply(null, arguments);
          };
          Module["_NotEqual"] = function() {
            return (Module["_NotEqual"] = Module["asm"]["NotEqual"]).apply(null, arguments);
          };
          Module["_OneHot"] = function() {
            return (Module["_OneHot"] = Module["asm"]["OneHot"]).apply(null, arguments);
          };
          Module["_PadV2"] = function() {
            return (Module["_PadV2"] = Module["asm"]["PadV2"]).apply(null, arguments);
          };
          Module["_Pow"] = function() {
            return (Module["_Pow"] = Module["asm"]["Pow"]).apply(null, arguments);
          };
          Module["_Prelu"] = function() {
            return (Module["_Prelu"] = Module["asm"]["Prelu"]).apply(null, arguments);
          };
          Module["_Prod"] = function() {
            return (Module["_Prod"] = Module["asm"]["Prod"]).apply(null, arguments);
          };
          Module["_RealDiv"] = function() {
            return (Module["_RealDiv"] = Module["asm"]["RealDiv"]).apply(null, arguments);
          };
          Module["_Reciprocal"] = function() {
            return (Module["_Reciprocal"] = Module["asm"]["Reciprocal"]).apply(null, arguments);
          };
          Module["_Relu"] = function() {
            return (Module["_Relu"] = Module["asm"]["Relu"]).apply(null, arguments);
          };
          Module["_Relu6"] = function() {
            return (Module["_Relu6"] = Module["asm"]["Relu6"]).apply(null, arguments);
          };
          Module["_ResizeBilinear"] = function() {
            return (Module["_ResizeBilinear"] = Module["asm"]["ResizeBilinear"]).apply(null, arguments);
          };
          Module["_ResizeBilinearGrad"] = function() {
            return (Module["_ResizeBilinearGrad"] = Module["asm"]["ResizeBilinearGrad"]).apply(null, arguments);
          };
          Module["_ResizeNearestNeighbor"] = function() {
            return (Module["_ResizeNearestNeighbor"] = Module["asm"]["ResizeNearestNeighbor"]).apply(null, arguments);
          };
          Module["_ResizeNearestNeighborGrad"] = function() {
            return (Module["_ResizeNearestNeighborGrad"] = Module["asm"]["ResizeNearestNeighborGrad"]).apply(null, arguments);
          };
          Module["_Reverse"] = function() {
            return (Module["_Reverse"] = Module["asm"]["Reverse"]).apply(null, arguments);
          };
          Module["_RotateWithOffset"] = function() {
            return (Module["_RotateWithOffset"] = Module["asm"]["RotateWithOffset"]).apply(null, arguments);
          };
          Module["_Round"] = function() {
            return (Module["_Round"] = Module["asm"]["Round"]).apply(null, arguments);
          };
          Module["_Rsqrt"] = function() {
            return (Module["_Rsqrt"] = Module["asm"]["Rsqrt"]).apply(null, arguments);
          };
          Module["_ScatterNd"] = function() {
            return (Module["_ScatterNd"] = Module["asm"]["ScatterNd"]).apply(null, arguments);
          };
          Module["_SearchSorted"] = function() {
            return (Module["_SearchSorted"] = Module["asm"]["SearchSorted"]).apply(null, arguments);
          };
          Module["_SelectV2"] = function() {
            return (Module["_SelectV2"] = Module["asm"]["SelectV2"]).apply(null, arguments);
          };
          Module["_Selu"] = function() {
            return (Module["_Selu"] = Module["asm"]["Selu"]).apply(null, arguments);
          };
          Module["_Sigmoid"] = function() {
            return (Module["_Sigmoid"] = Module["asm"]["Sigmoid"]).apply(null, arguments);
          };
          Module["_Sign"] = function() {
            return (Module["_Sign"] = Module["asm"]["Sign"]).apply(null, arguments);
          };
          Module["_Sin"] = function() {
            return (Module["_Sin"] = Module["asm"]["Sin"]).apply(null, arguments);
          };
          Module["_Softmax"] = function() {
            return (Module["_Softmax"] = Module["asm"]["Softmax"]).apply(null, arguments);
          };
          Module["_Softplus"] = function() {
            return (Module["_Softplus"] = Module["asm"]["Softplus"]).apply(null, arguments);
          };
          Module["_SparseFillEmptyRows"] = function() {
            return (Module["_SparseFillEmptyRows"] = Module["asm"]["SparseFillEmptyRows"]).apply(null, arguments);
          };
          Module["_SparseReshape"] = function() {
            return (Module["_SparseReshape"] = Module["asm"]["SparseReshape"]).apply(null, arguments);
          };
          Module["_SparseSegmentReduction"] = function() {
            return (Module["_SparseSegmentReduction"] = Module["asm"]["SparseSegmentReduction"]).apply(null, arguments);
          };
          Module["_SparseToDense"] = function() {
            return (Module["_SparseToDense"] = Module["asm"]["SparseToDense"]).apply(null, arguments);
          };
          Module["_Sqrt"] = function() {
            return (Module["_Sqrt"] = Module["asm"]["Sqrt"]).apply(null, arguments);
          };
          Module["_Square"] = function() {
            return (Module["_Square"] = Module["asm"]["Square"]).apply(null, arguments);
          };
          Module["_SquaredDifference"] = function() {
            return (Module["_SquaredDifference"] = Module["asm"]["SquaredDifference"]).apply(null, arguments);
          };
          Module["_Step"] = function() {
            return (Module["_Step"] = Module["asm"]["Step"]).apply(null, arguments);
          };
          Module["_StridedSlice"] = function() {
            return (Module["_StridedSlice"] = Module["asm"]["StridedSlice"]).apply(null, arguments);
          };
          Module["_Sub"] = function() {
            return (Module["_Sub"] = Module["asm"]["Sub"]).apply(null, arguments);
          };
          Module["_Sum"] = function() {
            return (Module["_Sum"] = Module["asm"]["Sum"]).apply(null, arguments);
          };
          Module["_Tan"] = function() {
            return (Module["_Tan"] = Module["asm"]["Tan"]).apply(null, arguments);
          };
          Module["_Tanh"] = function() {
            return (Module["_Tanh"] = Module["asm"]["Tanh"]).apply(null, arguments);
          };
          Module["_TensorScatterUpdate"] = function() {
            return (Module["_TensorScatterUpdate"] = Module["asm"]["TensorScatterUpdate"]).apply(null, arguments);
          };
          Module["_Tile"] = function() {
            return (Module["_Tile"] = Module["asm"]["Tile"]).apply(null, arguments);
          };
          Module["_TopK"] = function() {
            return (Module["_TopK"] = Module["asm"]["TopK"]).apply(null, arguments);
          };
          Module["_Transform"] = function() {
            return (Module["_Transform"] = Module["asm"]["Transform"]).apply(null, arguments);
          };
          Module["_Transpose"] = function() {
            return (Module["_Transpose"] = Module["asm"]["Transpose"]).apply(null, arguments);
          };
          Module["__FusedMatMul"] = function() {
            return (Module["__FusedMatMul"] = Module["asm"]["_FusedMatMul"]).apply(null, arguments);
          };
          Module["_malloc"] = function() {
            return (Module["_malloc"] = Module["asm"]["malloc"]).apply(null, arguments);
          };
          Module["_free"] = function() {
            return (Module["_free"] = Module["asm"]["free"]).apply(null, arguments);
          };
          Module["__emscripten_tls_init"] = function() {
            return (Module["__emscripten_tls_init"] = Module["asm"]["_emscripten_tls_init"]).apply(null, arguments);
          };
          var _pthread_self = Module["_pthread_self"] = function() {
            return (_pthread_self = Module["_pthread_self"] = Module["asm"]["pthread_self"]).apply(null, arguments);
          };
          Module["___errno_location"] = function() {
            return (Module["___errno_location"] = Module["asm"]["__errno_location"]).apply(null, arguments);
          };
          var __emscripten_thread_init = Module["__emscripten_thread_init"] = function() {
            return (__emscripten_thread_init = Module["__emscripten_thread_init"] = Module["asm"]["_emscripten_thread_init"]).apply(null, arguments);
          };
          Module["__emscripten_thread_crashed"] = function() {
            return (Module["__emscripten_thread_crashed"] = Module["asm"]["_emscripten_thread_crashed"]).apply(null, arguments);
          };
          Module["_emscripten_main_thread_process_queued_calls"] = function() {
            return (Module["_emscripten_main_thread_process_queued_calls"] = Module["asm"]["emscripten_main_thread_process_queued_calls"]).apply(null, arguments);
          };
          Module["_emscripten_main_browser_thread_id"] = function() {
            return (Module["_emscripten_main_browser_thread_id"] = Module["asm"]["emscripten_main_browser_thread_id"]).apply(null, arguments);
          };
          var _emscripten_run_in_main_runtime_thread_js = Module["_emscripten_run_in_main_runtime_thread_js"] = function() {
            return (_emscripten_run_in_main_runtime_thread_js = Module["_emscripten_run_in_main_runtime_thread_js"] = Module["asm"]["emscripten_run_in_main_runtime_thread_js"]).apply(null, arguments);
          };
          Module["_emscripten_dispatch_to_thread_"] = function() {
            return (Module["_emscripten_dispatch_to_thread_"] = Module["asm"]["emscripten_dispatch_to_thread_"]).apply(null, arguments);
          };
          var __emscripten_proxy_execute_task_queue = Module["__emscripten_proxy_execute_task_queue"] = function() {
            return (__emscripten_proxy_execute_task_queue = Module["__emscripten_proxy_execute_task_queue"] = Module["asm"]["_emscripten_proxy_execute_task_queue"]).apply(null, arguments);
          };
          var __emscripten_thread_free_data = Module["__emscripten_thread_free_data"] = function() {
            return (__emscripten_thread_free_data = Module["__emscripten_thread_free_data"] = Module["asm"]["_emscripten_thread_free_data"]).apply(null, arguments);
          };
          var __emscripten_thread_exit = Module["__emscripten_thread_exit"] = function() {
            return (__emscripten_thread_exit = Module["__emscripten_thread_exit"] = Module["asm"]["_emscripten_thread_exit"]).apply(null, arguments);
          };
          var _emscripten_stack_set_limits = Module["_emscripten_stack_set_limits"] = function() {
            return (_emscripten_stack_set_limits = Module["_emscripten_stack_set_limits"] = Module["asm"]["emscripten_stack_set_limits"]).apply(null, arguments);
          };
          var stackSave = Module["stackSave"] = function() {
            return (stackSave = Module["stackSave"] = Module["asm"]["stackSave"]).apply(null, arguments);
          };
          var stackRestore = Module["stackRestore"] = function() {
            return (stackRestore = Module["stackRestore"] = Module["asm"]["stackRestore"]).apply(null, arguments);
          };
          var stackAlloc = Module["stackAlloc"] = function() {
            return (stackAlloc = Module["stackAlloc"] = Module["asm"]["stackAlloc"]).apply(null, arguments);
          };
          Module["dynCall_iijjiiii"] = function() {
            return (Module["dynCall_iijjiiii"] = Module["asm"]["dynCall_iijjiiii"]).apply(null, arguments);
          };
          Module["dynCall_jiji"] = function() {
            return (Module["dynCall_jiji"] = Module["asm"]["dynCall_jiji"]).apply(null, arguments);
          };
          Module["keepRuntimeAlive"] = keepRuntimeAlive;
          Module["wasmMemory"] = wasmMemory;
          Module["cwrap"] = cwrap;
          Module["ExitStatus"] = ExitStatus;
          Module["PThread"] = PThread;
          var calledRun;
          dependenciesFulfilled = function runCaller() {
            if (!calledRun)
              run();
            if (!calledRun)
              dependenciesFulfilled = runCaller;
          };
          function run(args) {
            if (runDependencies > 0) {
              return;
            }
            if (ENVIRONMENT_IS_PTHREAD) {
              readyPromiseResolve(Module);
              initRuntime();
              startWorker(Module);
              return;
            }
            preRun();
            if (runDependencies > 0) {
              return;
            }
            function doRun() {
              if (calledRun)
                return;
              calledRun = true;
              Module["calledRun"] = true;
              if (ABORT)
                return;
              initRuntime();
              readyPromiseResolve(Module);
              if (Module["onRuntimeInitialized"])
                Module["onRuntimeInitialized"]();
              postRun();
            }
            if (Module["setStatus"]) {
              Module["setStatus"]("Running...");
              setTimeout(function() {
                setTimeout(function() {
                  Module["setStatus"]("");
                }, 1);
                doRun();
              }, 1);
            } else {
              doRun();
            }
          }
          if (Module["preInit"]) {
            if (typeof Module["preInit"] == "function")
              Module["preInit"] = [Module["preInit"]];
            while (Module["preInit"].length > 0) {
              Module["preInit"].pop()();
            }
          }
          run();
          var listenersAdded;
          if (beforeListeners) {
            listenersAdded = { uncaughtException: process.listeners("uncaughtException").filter(function(listener) {
              return !beforeListeners.uncaughtException.indexOf(listener) > -1;
            }), unhandledRejection: process.listeners("unhandledRejection").filter(function(listener) {
              return !beforeListeners.unhandledRejection.indexOf(listener) > -1;
            }) };
          }
          var actualModule;
          if (typeof WasmBackendModule !== "undefined") {
            actualModule = WasmBackendModule;
          } else if (typeof WasmBackendModuleThreadedSimd3 !== "undefined") {
            actualModule = WasmBackendModuleThreadedSimd3;
          } else {
            throw new Error("Could not find wasm module in post.js");
          }
          if (listenersAdded) {
            var tmpDispose = actualModule["_dispose"];
            actualModule["_dispose"] = function() {
              tmpDispose();
              listenersAdded.uncaughtException.forEach(function(listener) {
                process.removeListener("uncaughtException", listener);
              });
              listenersAdded.unhandledRejection.forEach(function(listener) {
                process.removeListener("unhandledRejection", listener);
              });
            };
          }
          return WasmBackendModuleThreadedSimd3.ready;
        };
      }();
      module3.exports = WasmBackendModuleThreadedSimd2;
    })(tfjsBackendWasmThreadedSimd$1);
    var tfjsBackendWasmThreadedSimdExports = tfjsBackendWasmThreadedSimd$1.exports;
    var tfjsBackendWasmThreadedSimd = /* @__PURE__ */ getDefaultExportFromCjs(tfjsBackendWasmThreadedSimdExports);
    var wasmFactoryThreadedSimd_import = /* @__PURE__ */ _mergeNamespaces({
      __proto__: null,
      default: tfjsBackendWasmThreadedSimd
    }, [tfjsBackendWasmThreadedSimdExports]);
    var wasmWorkerContents = '"use strict";var Module={};var ENVIRONMENT_IS_NODE=typeof process=="object"&&typeof process.versions=="object"&&typeof process.versions.node=="string";if(ENVIRONMENT_IS_NODE){var nodeWorkerThreads=require("worker_threads");var parentPort=nodeWorkerThreads.parentPort;parentPort.on("message",data=>onmessage({data:data}));var fs=require("fs");Object.assign(global,{self:global,require:require,Module:Module,location:{href:__filename},Worker:nodeWorkerThreads.Worker,importScripts:function(f){(0,eval)(fs.readFileSync(f,"utf8")+"//# sourceURL="+f)},postMessage:function(msg){parentPort.postMessage(msg)},performance:global.performance||{now:function(){return Date.now()}}})}var initializedJS=false;var pendingNotifiedProxyingQueues=[];function threadPrintErr(){var text=Array.prototype.slice.call(arguments).join(" ");if(ENVIRONMENT_IS_NODE){fs.writeSync(2,text+"\n");return}console.error(text)}function threadAlert(){var text=Array.prototype.slice.call(arguments).join(" ");postMessage({cmd:"alert",text:text,threadId:Module["_pthread_self"]()})}var err=threadPrintErr;self.alert=threadAlert;Module["instantiateWasm"]=(info,receiveInstance)=>{var instance=new WebAssembly.Instance(Module["wasmModule"],info);receiveInstance(instance);Module["wasmModule"]=null;return instance.exports};self.onunhandledrejection=e=>{throw e.reason??e};self.startWorker=instance=>{Module=instance;postMessage({"cmd":"loaded"})};self.onmessage=e=>{try{if(e.data.cmd==="load"){Module["wasmModule"]=e.data.wasmModule;for(const handler of e.data.handlers){Module[handler]=function(){postMessage({cmd:"callHandler",handler:handler,args:[...arguments]})}}Module["wasmMemory"]=e.data.wasmMemory;Module["buffer"]=Module["wasmMemory"].buffer;Module["ENVIRONMENT_IS_PTHREAD"]=true;if(typeof e.data.urlOrBlob=="string"){importScripts(e.data.urlOrBlob)}else{var objectUrl=URL.createObjectURL(e.data.urlOrBlob);importScripts(objectUrl);URL.revokeObjectURL(objectUrl)}WasmBackendModuleThreadedSimd(Module)}else if(e.data.cmd==="run"){Module["__emscripten_thread_init"](e.data.pthread_ptr,0,0,1);Module["establishStackSpace"]();Module["PThread"].receiveObjectTransfer(e.data);Module["PThread"].threadInitTLS();if(!initializedJS){pendingNotifiedProxyingQueues.forEach(queue=>{Module["executeNotifiedProxyingQueue"](queue)});pendingNotifiedProxyingQueues=[];initializedJS=true}try{Module["invokeEntryPoint"](e.data.start_routine,e.data.arg)}catch(ex){if(ex!="unwind"){if(ex instanceof Module["ExitStatus"]){if(Module["keepRuntimeAlive"]()){}else{Module["__emscripten_thread_exit"](ex.status)}}else{throw ex}}}}else if(e.data.cmd==="cancel"){if(Module["_pthread_self"]()){Module["__emscripten_thread_exit"](-1)}}else if(e.data.target==="setimmediate"){}else if(e.data.cmd==="processProxyingQueue"){if(initializedJS){Module["executeNotifiedProxyingQueue"](e.data.queue)}else{pendingNotifiedProxyingQueues.push(e.data.queue)}}else if(e.data.cmd){err("worker.js received unknown command "+e.data.cmd);err(e.data)}}catch(ex){if(Module["__emscripten_thread_crashed"]){Module["__emscripten_thread_crashed"]()}throw ex}};';
    var tfjsBackendWasm$1 = { exports: {} };
    (function(module3, exports2) {
      var WasmBackendModule2 = function() {
        var _scriptDir = typeof document !== "undefined" && document.currentScript ? document.currentScript.src : void 0;
        if (typeof __filename !== "undefined")
          _scriptDir = _scriptDir || __filename;
        return function(WasmBackendModule3) {
          WasmBackendModule3 = WasmBackendModule3 || {};
          var Module = typeof WasmBackendModule3 != "undefined" ? WasmBackendModule3 : {};
          var readyPromiseResolve, readyPromiseReject;
          Module["ready"] = new Promise(function(resolve2, reject) {
            readyPromiseResolve = resolve2;
            readyPromiseReject = reject;
          });
          var beforeListeners;
          if (typeof process !== "undefined" && process.listeners) {
            beforeListeners = { uncaughtException: process.listeners("uncaughtException"), unhandledRejection: process.listeners("unhandledRejection") };
          }
          var moduleOverrides = Object.assign({}, Module);
          var ENVIRONMENT_IS_WEB = typeof window == "object";
          var ENVIRONMENT_IS_WORKER = typeof importScripts == "function";
          var ENVIRONMENT_IS_NODE = typeof process == "object" && typeof process.versions == "object" && typeof process.versions.node == "string";
          var scriptDirectory = "";
          function locateFile(path) {
            if (Module["locateFile"]) {
              return Module["locateFile"](path, scriptDirectory);
            }
            return scriptDirectory + path;
          }
          var read_, readAsync, readBinary;
          if (ENVIRONMENT_IS_NODE) {
            var fs = require$$0;
            var nodePath = require$$1;
            if (ENVIRONMENT_IS_WORKER) {
              scriptDirectory = nodePath.dirname(scriptDirectory) + "/";
            } else {
              scriptDirectory = __dirname + "/";
            }
            read_ = function(filename, binary) {
              filename = isFileURI(filename) ? new URL(filename) : nodePath.normalize(filename);
              return fs.readFileSync(filename, binary ? void 0 : "utf8");
            };
            readBinary = function(filename) {
              var ret = read_(filename, true);
              if (!ret.buffer) {
                ret = new Uint8Array(ret);
              }
              return ret;
            };
            readAsync = function(filename, onload, onerror) {
              filename = isFileURI(filename) ? new URL(filename) : nodePath.normalize(filename);
              fs.readFile(filename, function(err2, data) {
                if (err2)
                  onerror(err2);
                else
                  onload(data.buffer);
              });
            };
            if (process["argv"].length > 1) {
              process["argv"][1].replace(/\\/g, "/");
            }
            process["argv"].slice(2);
            process["on"]("uncaughtException", function(ex) {
              if (!(ex instanceof ExitStatus)) {
                throw ex;
              }
            });
            process["on"]("unhandledRejection", function(reason) {
              throw reason;
            });
            Module["inspect"] = function() {
              return "[Emscripten Module object]";
            };
          } else if (ENVIRONMENT_IS_WEB || ENVIRONMENT_IS_WORKER) {
            if (ENVIRONMENT_IS_WORKER) {
              scriptDirectory = self.location.href;
            } else if (typeof document != "undefined" && document.currentScript) {
              scriptDirectory = document.currentScript.src;
            }
            if (_scriptDir) {
              scriptDirectory = _scriptDir;
            }
            if (scriptDirectory.indexOf("blob:") !== 0) {
              scriptDirectory = scriptDirectory.substr(0, scriptDirectory.replace(/[?#].*/, "").lastIndexOf("/") + 1);
            } else {
              scriptDirectory = "";
            }
            {
              read_ = function(url) {
                var xhr = new XMLHttpRequest();
                xhr.open("GET", url, false);
                xhr.send(null);
                return xhr.responseText;
              };
              if (ENVIRONMENT_IS_WORKER) {
                readBinary = function(url) {
                  var xhr = new XMLHttpRequest();
                  xhr.open("GET", url, false);
                  xhr.responseType = "arraybuffer";
                  xhr.send(null);
                  return new Uint8Array(xhr.response);
                };
              }
              readAsync = function(url, onload, onerror) {
                var xhr = new XMLHttpRequest();
                xhr.open("GET", url, true);
                xhr.responseType = "arraybuffer";
                xhr.onload = function() {
                  if (xhr.status == 200 || xhr.status == 0 && xhr.response) {
                    onload(xhr.response);
                    return;
                  }
                  onerror();
                };
                xhr.onerror = onerror;
                xhr.send(null);
              };
            }
          } else
            ;
          var out = Module["print"] || console.log.bind(console);
          var err = Module["printErr"] || console.warn.bind(console);
          Object.assign(Module, moduleOverrides);
          moduleOverrides = null;
          if (Module["arguments"])
            Module["arguments"];
          if (Module["thisProgram"])
            Module["thisProgram"];
          if (Module["quit"])
            Module["quit"];
          var wasmBinary;
          if (Module["wasmBinary"])
            wasmBinary = Module["wasmBinary"];
          Module["noExitRuntime"] || true;
          if (typeof WebAssembly != "object") {
            abort("no native wasm support detected");
          }
          var wasmMemory;
          var ABORT = false;
          var UTF8Decoder = typeof TextDecoder != "undefined" ? new TextDecoder("utf8") : void 0;
          function UTF8ArrayToString(heapOrArray, idx, maxBytesToRead) {
            idx >>>= 0;
            var endIdx = idx + maxBytesToRead;
            var endPtr = idx;
            while (heapOrArray[endPtr] && !(endPtr >= endIdx))
              ++endPtr;
            if (endPtr - idx > 16 && heapOrArray.buffer && UTF8Decoder) {
              return UTF8Decoder.decode(heapOrArray.subarray(idx, endPtr));
            }
            var str = "";
            while (idx < endPtr) {
              var u0 = heapOrArray[idx++];
              if (!(u0 & 128)) {
                str += String.fromCharCode(u0);
                continue;
              }
              var u1 = heapOrArray[idx++] & 63;
              if ((u0 & 224) == 192) {
                str += String.fromCharCode((u0 & 31) << 6 | u1);
                continue;
              }
              var u2 = heapOrArray[idx++] & 63;
              if ((u0 & 240) == 224) {
                u0 = (u0 & 15) << 12 | u1 << 6 | u2;
              } else {
                u0 = (u0 & 7) << 18 | u1 << 12 | u2 << 6 | heapOrArray[idx++] & 63;
              }
              if (u0 < 65536) {
                str += String.fromCharCode(u0);
              } else {
                var ch = u0 - 65536;
                str += String.fromCharCode(55296 | ch >> 10, 56320 | ch & 1023);
              }
            }
            return str;
          }
          function UTF8ToString(ptr, maxBytesToRead) {
            ptr >>>= 0;
            return ptr ? UTF8ArrayToString(HEAPU8, ptr, maxBytesToRead) : "";
          }
          function stringToUTF8Array(str, heap, outIdx, maxBytesToWrite) {
            outIdx >>>= 0;
            if (!(maxBytesToWrite > 0))
              return 0;
            var startIdx = outIdx;
            var endIdx = outIdx + maxBytesToWrite - 1;
            for (var i = 0; i < str.length; ++i) {
              var u = str.charCodeAt(i);
              if (u >= 55296 && u <= 57343) {
                var u1 = str.charCodeAt(++i);
                u = 65536 + ((u & 1023) << 10) | u1 & 1023;
              }
              if (u <= 127) {
                if (outIdx >= endIdx)
                  break;
                heap[outIdx++ >>> 0] = u;
              } else if (u <= 2047) {
                if (outIdx + 1 >= endIdx)
                  break;
                heap[outIdx++ >>> 0] = 192 | u >> 6;
                heap[outIdx++ >>> 0] = 128 | u & 63;
              } else if (u <= 65535) {
                if (outIdx + 2 >= endIdx)
                  break;
                heap[outIdx++ >>> 0] = 224 | u >> 12;
                heap[outIdx++ >>> 0] = 128 | u >> 6 & 63;
                heap[outIdx++ >>> 0] = 128 | u & 63;
              } else {
                if (outIdx + 3 >= endIdx)
                  break;
                heap[outIdx++ >>> 0] = 240 | u >> 18;
                heap[outIdx++ >>> 0] = 128 | u >> 12 & 63;
                heap[outIdx++ >>> 0] = 128 | u >> 6 & 63;
                heap[outIdx++ >>> 0] = 128 | u & 63;
              }
            }
            heap[outIdx >>> 0] = 0;
            return outIdx - startIdx;
          }
          function stringToUTF8(str, outPtr, maxBytesToWrite) {
            return stringToUTF8Array(str, HEAPU8, outPtr, maxBytesToWrite);
          }
          var buffer, HEAP8, HEAPU8, HEAPU32;
          function updateGlobalBufferAndViews(buf) {
            buffer = buf;
            Module["HEAP8"] = HEAP8 = new Int8Array(buf);
            Module["HEAP16"] = new Int16Array(buf);
            Module["HEAP32"] = new Int32Array(buf);
            Module["HEAPU8"] = HEAPU8 = new Uint8Array(buf);
            Module["HEAPU16"] = new Uint16Array(buf);
            Module["HEAPU32"] = HEAPU32 = new Uint32Array(buf);
            Module["HEAPF32"] = new Float32Array(buf);
            Module["HEAPF64"] = new Float64Array(buf);
          }
          Module["INITIAL_MEMORY"] || 16777216;
          var __ATPRERUN__ = [];
          var __ATINIT__ = [];
          var __ATPOSTRUN__ = [];
          function preRun() {
            if (Module["preRun"]) {
              if (typeof Module["preRun"] == "function")
                Module["preRun"] = [Module["preRun"]];
              while (Module["preRun"].length) {
                addOnPreRun(Module["preRun"].shift());
              }
            }
            callRuntimeCallbacks(__ATPRERUN__);
          }
          function initRuntime() {
            callRuntimeCallbacks(__ATINIT__);
          }
          function postRun() {
            if (Module["postRun"]) {
              if (typeof Module["postRun"] == "function")
                Module["postRun"] = [Module["postRun"]];
              while (Module["postRun"].length) {
                addOnPostRun(Module["postRun"].shift());
              }
            }
            callRuntimeCallbacks(__ATPOSTRUN__);
          }
          function addOnPreRun(cb) {
            __ATPRERUN__.unshift(cb);
          }
          function addOnInit(cb) {
            __ATINIT__.unshift(cb);
          }
          function addOnPostRun(cb) {
            __ATPOSTRUN__.unshift(cb);
          }
          var runDependencies = 0;
          var dependenciesFulfilled = null;
          function addRunDependency(id) {
            runDependencies++;
            if (Module["monitorRunDependencies"]) {
              Module["monitorRunDependencies"](runDependencies);
            }
          }
          function removeRunDependency(id) {
            runDependencies--;
            if (Module["monitorRunDependencies"]) {
              Module["monitorRunDependencies"](runDependencies);
            }
            if (runDependencies == 0) {
              if (dependenciesFulfilled) {
                var callback = dependenciesFulfilled;
                dependenciesFulfilled = null;
                callback();
              }
            }
          }
          function abort(what) {
            if (Module["onAbort"]) {
              Module["onAbort"](what);
            }
            what = "Aborted(" + what + ")";
            err(what);
            ABORT = true;
            what += ". Build with -sASSERTIONS for more info.";
            var e = new WebAssembly.RuntimeError(what);
            readyPromiseReject(e);
            throw e;
          }
          var dataURIPrefix = "data:application/octet-stream;base64,";
          function isDataURI(filename) {
            return filename.startsWith(dataURIPrefix);
          }
          function isFileURI(filename) {
            return filename.startsWith("file://");
          }
          var wasmBinaryFile;
          wasmBinaryFile = "tfjs-backend-wasm.wasm";
          if (!isDataURI(wasmBinaryFile)) {
            wasmBinaryFile = locateFile(wasmBinaryFile);
          }
          function getBinary(file) {
            try {
              if (file == wasmBinaryFile && wasmBinary) {
                return new Uint8Array(wasmBinary);
              }
              if (readBinary) {
                return readBinary(file);
              }
              throw "both async and sync fetching of the wasm failed";
            } catch (err2) {
              abort(err2);
            }
          }
          function getBinaryPromise() {
            if (!wasmBinary && (ENVIRONMENT_IS_WEB || ENVIRONMENT_IS_WORKER)) {
              if (typeof fetch == "function" && !isFileURI(wasmBinaryFile)) {
                return fetch(wasmBinaryFile, { credentials: "same-origin" }).then(function(response) {
                  if (!response["ok"]) {
                    throw "failed to load wasm binary file at '" + wasmBinaryFile + "'";
                  }
                  return response["arrayBuffer"]();
                }).catch(function() {
                  return getBinary(wasmBinaryFile);
                });
              } else {
                if (readAsync) {
                  return new Promise(function(resolve2, reject) {
                    readAsync(wasmBinaryFile, function(response) {
                      resolve2(new Uint8Array(response));
                    }, reject);
                  });
                }
              }
            }
            return Promise.resolve().then(function() {
              return getBinary(wasmBinaryFile);
            });
          }
          function createWasm() {
            var info = { "env": asmLibraryArg, "wasi_snapshot_preview1": asmLibraryArg };
            function receiveInstance(instance, module4) {
              var exports4 = instance.exports;
              Module["asm"] = exports4;
              wasmMemory = Module["asm"]["memory"];
              updateGlobalBufferAndViews(wasmMemory.buffer);
              Module["asm"]["__indirect_function_table"];
              addOnInit(Module["asm"]["__wasm_call_ctors"]);
              removeRunDependency();
            }
            addRunDependency();
            function receiveInstantiationResult(result) {
              receiveInstance(result["instance"]);
            }
            function instantiateArrayBuffer(receiver) {
              return getBinaryPromise().then(function(binary) {
                return WebAssembly.instantiate(binary, info);
              }).then(function(instance) {
                return instance;
              }).then(receiver, function(reason) {
                err("failed to asynchronously prepare wasm: " + reason);
                abort(reason);
              });
            }
            function instantiateAsync() {
              if (!wasmBinary && typeof WebAssembly.instantiateStreaming == "function" && !isDataURI(wasmBinaryFile) && !isFileURI(wasmBinaryFile) && !ENVIRONMENT_IS_NODE && typeof fetch == "function") {
                return fetch(wasmBinaryFile, { credentials: "same-origin" }).then(function(response) {
                  var result = WebAssembly.instantiateStreaming(response, info);
                  return result.then(receiveInstantiationResult, function(reason) {
                    err("wasm streaming compile failed: " + reason);
                    err("falling back to ArrayBuffer instantiation");
                    return instantiateArrayBuffer(receiveInstantiationResult);
                  });
                });
              } else {
                return instantiateArrayBuffer(receiveInstantiationResult);
              }
            }
            if (Module["instantiateWasm"]) {
              try {
                var exports3 = Module["instantiateWasm"](info, receiveInstance);
                return exports3;
              } catch (e) {
                err("Module.instantiateWasm callback failed with error: " + e);
                readyPromiseReject(e);
              }
            }
            instantiateAsync().catch(readyPromiseReject);
            return {};
          }
          function ExitStatus(status) {
            this.name = "ExitStatus";
            this.message = "Program terminated with exit(" + status + ")";
            this.status = status;
          }
          function callRuntimeCallbacks(callbacks) {
            while (callbacks.length > 0) {
              callbacks.shift()(Module);
            }
          }
          function _abort() {
            abort("");
          }
          function getHeapMax() {
            return 4294901760;
          }
          function _emscripten_get_heap_max() {
            return getHeapMax();
          }
          function _emscripten_memcpy_big(dest, src, num) {
            HEAPU8.copyWithin(dest >>> 0, src >>> 0, src + num >>> 0);
          }
          function emscripten_realloc_buffer(size) {
            try {
              wasmMemory.grow(size - buffer.byteLength + 65535 >>> 16);
              updateGlobalBufferAndViews(wasmMemory.buffer);
              return 1;
            } catch (e) {
            }
          }
          function _emscripten_resize_heap(requestedSize) {
            var oldSize = HEAPU8.length;
            requestedSize = requestedSize >>> 0;
            var maxHeapSize = getHeapMax();
            if (requestedSize > maxHeapSize) {
              return false;
            }
            var alignUp = function(x, multiple) {
              return x + (multiple - x % multiple) % multiple;
            };
            for (var cutDown = 1; cutDown <= 4; cutDown *= 2) {
              var overGrownHeapSize = oldSize * (1 + 0.2 / cutDown);
              overGrownHeapSize = Math.min(overGrownHeapSize, requestedSize + 100663296);
              var newSize = Math.min(maxHeapSize, alignUp(Math.max(requestedSize, overGrownHeapSize), 65536));
              var replacement = emscripten_realloc_buffer(newSize);
              if (replacement) {
                return true;
              }
            }
            return false;
          }
          function _fd_close(fd) {
            return 52;
          }
          function _fd_seek(fd, offset_low, offset_high, whence, newOffset) {
            return 70;
          }
          var printCharBuffers = [null, [], []];
          function printChar(stream, curr) {
            var buffer2 = printCharBuffers[stream];
            if (curr === 0 || curr === 10) {
              (stream === 1 ? out : err)(UTF8ArrayToString(buffer2, 0));
              buffer2.length = 0;
            } else {
              buffer2.push(curr);
            }
          }
          function _fd_write(fd, iov, iovcnt, pnum) {
            var num = 0;
            for (var i = 0; i < iovcnt; i++) {
              var ptr = HEAPU32[iov >>> 2];
              var len = HEAPU32[iov + 4 >>> 2];
              iov += 8;
              for (var j = 0; j < len; j++) {
                printChar(fd, HEAPU8[ptr + j >>> 0]);
              }
              num += len;
            }
            HEAPU32[pnum >>> 2] = num;
            return 0;
          }
          function getCFunc(ident) {
            var func = Module["_" + ident];
            return func;
          }
          function writeArrayToMemory(array, buffer2) {
            HEAP8.set(array, buffer2 >>> 0);
          }
          function ccall(ident, returnType, argTypes, args, opts) {
            var toC = { "string": function(str) {
              var ret2 = 0;
              if (str !== null && str !== void 0 && str !== 0) {
                var len = (str.length << 2) + 1;
                ret2 = stackAlloc(len);
                stringToUTF8(str, ret2, len);
              }
              return ret2;
            }, "array": function(arr) {
              var ret2 = stackAlloc(arr.length);
              writeArrayToMemory(arr, ret2);
              return ret2;
            } };
            function convertReturnValue(ret2) {
              if (returnType === "string") {
                return UTF8ToString(ret2);
              }
              if (returnType === "boolean")
                return Boolean(ret2);
              return ret2;
            }
            var func = getCFunc(ident);
            var cArgs = [];
            var stack = 0;
            if (args) {
              for (var i = 0; i < args.length; i++) {
                var converter = toC[argTypes[i]];
                if (converter) {
                  if (stack === 0)
                    stack = stackSave();
                  cArgs[i] = converter(args[i]);
                } else {
                  cArgs[i] = args[i];
                }
              }
            }
            var ret = func.apply(null, cArgs);
            function onDone(ret2) {
              if (stack !== 0)
                stackRestore(stack);
              return convertReturnValue(ret2);
            }
            ret = onDone(ret);
            return ret;
          }
          function cwrap(ident, returnType, argTypes, opts) {
            argTypes = argTypes || [];
            var numericArgs = argTypes.every(function(type) {
              return type === "number" || type === "boolean";
            });
            var numericRet = returnType !== "string";
            if (numericRet && numericArgs && !opts) {
              return getCFunc(ident);
            }
            return function() {
              return ccall(ident, returnType, argTypes, arguments);
            };
          }
          var asmLibraryArg = { "abort": _abort, "emscripten_get_heap_max": _emscripten_get_heap_max, "emscripten_memcpy_big": _emscripten_memcpy_big, "emscripten_resize_heap": _emscripten_resize_heap, "fd_close": _fd_close, "fd_seek": _fd_seek, "fd_write": _fd_write };
          createWasm();
          Module["___wasm_call_ctors"] = function() {
            return (Module["___wasm_call_ctors"] = Module["asm"]["__wasm_call_ctors"]).apply(null, arguments);
          };
          Module["_init"] = function() {
            return (Module["_init"] = Module["asm"]["init"]).apply(null, arguments);
          };
          Module["_init_with_threads_count"] = function() {
            return (Module["_init_with_threads_count"] = Module["asm"]["init_with_threads_count"]).apply(null, arguments);
          };
          Module["_get_threads_count"] = function() {
            return (Module["_get_threads_count"] = Module["asm"]["get_threads_count"]).apply(null, arguments);
          };
          Module["_register_tensor"] = function() {
            return (Module["_register_tensor"] = Module["asm"]["register_tensor"]).apply(null, arguments);
          };
          Module["_dispose_data"] = function() {
            return (Module["_dispose_data"] = Module["asm"]["dispose_data"]).apply(null, arguments);
          };
          Module["_dispose"] = function() {
            return (Module["_dispose"] = Module["asm"]["dispose"]).apply(null, arguments);
          };
          Module["_Abs"] = function() {
            return (Module["_Abs"] = Module["asm"]["Abs"]).apply(null, arguments);
          };
          Module["_Acos"] = function() {
            return (Module["_Acos"] = Module["asm"]["Acos"]).apply(null, arguments);
          };
          Module["_Acosh"] = function() {
            return (Module["_Acosh"] = Module["asm"]["Acosh"]).apply(null, arguments);
          };
          Module["_Add"] = function() {
            return (Module["_Add"] = Module["asm"]["Add"]).apply(null, arguments);
          };
          Module["_AddN"] = function() {
            return (Module["_AddN"] = Module["asm"]["AddN"]).apply(null, arguments);
          };
          Module["_All"] = function() {
            return (Module["_All"] = Module["asm"]["All"]).apply(null, arguments);
          };
          Module["_Any"] = function() {
            return (Module["_Any"] = Module["asm"]["Any"]).apply(null, arguments);
          };
          Module["_ArgMax"] = function() {
            return (Module["_ArgMax"] = Module["asm"]["ArgMax"]).apply(null, arguments);
          };
          Module["_ArgMin"] = function() {
            return (Module["_ArgMin"] = Module["asm"]["ArgMin"]).apply(null, arguments);
          };
          Module["_Asin"] = function() {
            return (Module["_Asin"] = Module["asm"]["Asin"]).apply(null, arguments);
          };
          Module["_Asinh"] = function() {
            return (Module["_Asinh"] = Module["asm"]["Asinh"]).apply(null, arguments);
          };
          Module["_Atan"] = function() {
            return (Module["_Atan"] = Module["asm"]["Atan"]).apply(null, arguments);
          };
          Module["_Atan2"] = function() {
            return (Module["_Atan2"] = Module["asm"]["Atan2"]).apply(null, arguments);
          };
          Module["_Atanh"] = function() {
            return (Module["_Atanh"] = Module["asm"]["Atanh"]).apply(null, arguments);
          };
          Module["_AvgPool"] = function() {
            return (Module["_AvgPool"] = Module["asm"]["AvgPool"]).apply(null, arguments);
          };
          Module["_AvgPool3D"] = function() {
            return (Module["_AvgPool3D"] = Module["asm"]["AvgPool3D"]).apply(null, arguments);
          };
          Module["_AvgPool3DGrad"] = function() {
            return (Module["_AvgPool3DGrad"] = Module["asm"]["AvgPool3DGrad"]).apply(null, arguments);
          };
          Module["_BatchMatMul"] = function() {
            return (Module["_BatchMatMul"] = Module["asm"]["BatchMatMul"]).apply(null, arguments);
          };
          Module["_Bincount"] = function() {
            return (Module["_Bincount"] = Module["asm"]["Bincount"]).apply(null, arguments);
          };
          Module["_Ceil"] = function() {
            return (Module["_Ceil"] = Module["asm"]["Ceil"]).apply(null, arguments);
          };
          Module["_ClipByValue"] = function() {
            return (Module["_ClipByValue"] = Module["asm"]["ClipByValue"]).apply(null, arguments);
          };
          Module["_Conv2D"] = function() {
            return (Module["_Conv2D"] = Module["asm"]["Conv2D"]).apply(null, arguments);
          };
          Module["_Conv2DBackpropInput"] = function() {
            return (Module["_Conv2DBackpropInput"] = Module["asm"]["Conv2DBackpropInput"]).apply(null, arguments);
          };
          Module["_Conv3D"] = function() {
            return (Module["_Conv3D"] = Module["asm"]["Conv3D"]).apply(null, arguments);
          };
          Module["_Conv3DBackpropFilterV2"] = function() {
            return (Module["_Conv3DBackpropFilterV2"] = Module["asm"]["Conv3DBackpropFilterV2"]).apply(null, arguments);
          };
          Module["_Conv3DBackpropInputV2"] = function() {
            return (Module["_Conv3DBackpropInputV2"] = Module["asm"]["Conv3DBackpropInputV2"]).apply(null, arguments);
          };
          Module["_Cos"] = function() {
            return (Module["_Cos"] = Module["asm"]["Cos"]).apply(null, arguments);
          };
          Module["_Cosh"] = function() {
            return (Module["_Cosh"] = Module["asm"]["Cosh"]).apply(null, arguments);
          };
          Module["_CropAndResize"] = function() {
            return (Module["_CropAndResize"] = Module["asm"]["CropAndResize"]).apply(null, arguments);
          };
          Module["_Cumprod"] = function() {
            return (Module["_Cumprod"] = Module["asm"]["Cumprod"]).apply(null, arguments);
          };
          Module["_Cumsum"] = function() {
            return (Module["_Cumsum"] = Module["asm"]["Cumsum"]).apply(null, arguments);
          };
          Module["_DenseBincount"] = function() {
            return (Module["_DenseBincount"] = Module["asm"]["DenseBincount"]).apply(null, arguments);
          };
          Module["_DepthToSpace"] = function() {
            return (Module["_DepthToSpace"] = Module["asm"]["DepthToSpace"]).apply(null, arguments);
          };
          Module["_DepthwiseConv2dNative"] = function() {
            return (Module["_DepthwiseConv2dNative"] = Module["asm"]["DepthwiseConv2dNative"]).apply(null, arguments);
          };
          Module["_Diag"] = function() {
            return (Module["_Diag"] = Module["asm"]["Diag"]).apply(null, arguments);
          };
          Module["_Dilation2D"] = function() {
            return (Module["_Dilation2D"] = Module["asm"]["Dilation2D"]).apply(null, arguments);
          };
          Module["_Dilation2DBackpropFilter"] = function() {
            return (Module["_Dilation2DBackpropFilter"] = Module["asm"]["Dilation2DBackpropFilter"]).apply(null, arguments);
          };
          Module["_Dilation2DBackpropInput"] = function() {
            return (Module["_Dilation2DBackpropInput"] = Module["asm"]["Dilation2DBackpropInput"]).apply(null, arguments);
          };
          Module["_Elu"] = function() {
            return (Module["_Elu"] = Module["asm"]["Elu"]).apply(null, arguments);
          };
          Module["_EluGrad"] = function() {
            return (Module["_EluGrad"] = Module["asm"]["EluGrad"]).apply(null, arguments);
          };
          Module["_Equal"] = function() {
            return (Module["_Equal"] = Module["asm"]["Equal"]).apply(null, arguments);
          };
          Module["_Exp"] = function() {
            return (Module["_Exp"] = Module["asm"]["Exp"]).apply(null, arguments);
          };
          Module["_Expm1"] = function() {
            return (Module["_Expm1"] = Module["asm"]["Expm1"]).apply(null, arguments);
          };
          Module["_FlipLeftRight"] = function() {
            return (Module["_FlipLeftRight"] = Module["asm"]["FlipLeftRight"]).apply(null, arguments);
          };
          Module["_Floor"] = function() {
            return (Module["_Floor"] = Module["asm"]["Floor"]).apply(null, arguments);
          };
          Module["_FloorDiv"] = function() {
            return (Module["_FloorDiv"] = Module["asm"]["FloorDiv"]).apply(null, arguments);
          };
          Module["_FusedBatchNorm"] = function() {
            return (Module["_FusedBatchNorm"] = Module["asm"]["FusedBatchNorm"]).apply(null, arguments);
          };
          Module["_FusedConv2D"] = function() {
            return (Module["_FusedConv2D"] = Module["asm"]["FusedConv2D"]).apply(null, arguments);
          };
          Module["_FusedDepthwiseConv2D"] = function() {
            return (Module["_FusedDepthwiseConv2D"] = Module["asm"]["FusedDepthwiseConv2D"]).apply(null, arguments);
          };
          Module["_Gather"] = function() {
            return (Module["_Gather"] = Module["asm"]["Gather"]).apply(null, arguments);
          };
          Module["_GatherNd"] = function() {
            return (Module["_GatherNd"] = Module["asm"]["GatherNd"]).apply(null, arguments);
          };
          Module["_Greater"] = function() {
            return (Module["_Greater"] = Module["asm"]["Greater"]).apply(null, arguments);
          };
          Module["_GreaterEqual"] = function() {
            return (Module["_GreaterEqual"] = Module["asm"]["GreaterEqual"]).apply(null, arguments);
          };
          Module["_IsFinite"] = function() {
            return (Module["_IsFinite"] = Module["asm"]["IsFinite"]).apply(null, arguments);
          };
          Module["_IsInf"] = function() {
            return (Module["_IsInf"] = Module["asm"]["IsInf"]).apply(null, arguments);
          };
          Module["_IsNan"] = function() {
            return (Module["_IsNan"] = Module["asm"]["IsNan"]).apply(null, arguments);
          };
          Module["_LRN"] = function() {
            return (Module["_LRN"] = Module["asm"]["LRN"]).apply(null, arguments);
          };
          Module["_LRNGrad"] = function() {
            return (Module["_LRNGrad"] = Module["asm"]["LRNGrad"]).apply(null, arguments);
          };
          Module["_LeakyRelu"] = function() {
            return (Module["_LeakyRelu"] = Module["asm"]["LeakyRelu"]).apply(null, arguments);
          };
          Module["_Less"] = function() {
            return (Module["_Less"] = Module["asm"]["Less"]).apply(null, arguments);
          };
          Module["_LessEqual"] = function() {
            return (Module["_LessEqual"] = Module["asm"]["LessEqual"]).apply(null, arguments);
          };
          Module["_LinSpace"] = function() {
            return (Module["_LinSpace"] = Module["asm"]["LinSpace"]).apply(null, arguments);
          };
          Module["_Log"] = function() {
            return (Module["_Log"] = Module["asm"]["Log"]).apply(null, arguments);
          };
          Module["_Log1p"] = function() {
            return (Module["_Log1p"] = Module["asm"]["Log1p"]).apply(null, arguments);
          };
          Module["_LogicalAnd"] = function() {
            return (Module["_LogicalAnd"] = Module["asm"]["LogicalAnd"]).apply(null, arguments);
          };
          Module["_LogicalNot"] = function() {
            return (Module["_LogicalNot"] = Module["asm"]["LogicalNot"]).apply(null, arguments);
          };
          Module["_LogicalOr"] = function() {
            return (Module["_LogicalOr"] = Module["asm"]["LogicalOr"]).apply(null, arguments);
          };
          Module["_LogicalXor"] = function() {
            return (Module["_LogicalXor"] = Module["asm"]["LogicalXor"]).apply(null, arguments);
          };
          Module["_Max"] = function() {
            return (Module["_Max"] = Module["asm"]["Max"]).apply(null, arguments);
          };
          Module["_MaxPool"] = function() {
            return (Module["_MaxPool"] = Module["asm"]["MaxPool"]).apply(null, arguments);
          };
          Module["_MaxPool3D"] = function() {
            return (Module["_MaxPool3D"] = Module["asm"]["MaxPool3D"]).apply(null, arguments);
          };
          Module["_MaxPool3DGrad"] = function() {
            return (Module["_MaxPool3DGrad"] = Module["asm"]["MaxPool3DGrad"]).apply(null, arguments);
          };
          Module["_Maximum"] = function() {
            return (Module["_Maximum"] = Module["asm"]["Maximum"]).apply(null, arguments);
          };
          Module["_Mean"] = function() {
            return (Module["_Mean"] = Module["asm"]["Mean"]).apply(null, arguments);
          };
          Module["_Min"] = function() {
            return (Module["_Min"] = Module["asm"]["Min"]).apply(null, arguments);
          };
          Module["_Minimum"] = function() {
            return (Module["_Minimum"] = Module["asm"]["Minimum"]).apply(null, arguments);
          };
          Module["_MirrorPad"] = function() {
            return (Module["_MirrorPad"] = Module["asm"]["MirrorPad"]).apply(null, arguments);
          };
          Module["_Multinomial"] = function() {
            return (Module["_Multinomial"] = Module["asm"]["Multinomial"]).apply(null, arguments);
          };
          Module["_Multiply"] = function() {
            return (Module["_Multiply"] = Module["asm"]["Multiply"]).apply(null, arguments);
          };
          Module["_Neg"] = function() {
            return (Module["_Neg"] = Module["asm"]["Neg"]).apply(null, arguments);
          };
          Module["_NonMaxSuppressionV3"] = function() {
            return (Module["_NonMaxSuppressionV3"] = Module["asm"]["NonMaxSuppressionV3"]).apply(null, arguments);
          };
          Module["_NonMaxSuppressionV4"] = function() {
            return (Module["_NonMaxSuppressionV4"] = Module["asm"]["NonMaxSuppressionV4"]).apply(null, arguments);
          };
          Module["_NonMaxSuppressionV5"] = function() {
            return (Module["_NonMaxSuppressionV5"] = Module["asm"]["NonMaxSuppressionV5"]).apply(null, arguments);
          };
          Module["_NotEqual"] = function() {
            return (Module["_NotEqual"] = Module["asm"]["NotEqual"]).apply(null, arguments);
          };
          Module["_OneHot"] = function() {
            return (Module["_OneHot"] = Module["asm"]["OneHot"]).apply(null, arguments);
          };
          Module["_PadV2"] = function() {
            return (Module["_PadV2"] = Module["asm"]["PadV2"]).apply(null, arguments);
          };
          Module["_Pow"] = function() {
            return (Module["_Pow"] = Module["asm"]["Pow"]).apply(null, arguments);
          };
          Module["_Prelu"] = function() {
            return (Module["_Prelu"] = Module["asm"]["Prelu"]).apply(null, arguments);
          };
          Module["_Prod"] = function() {
            return (Module["_Prod"] = Module["asm"]["Prod"]).apply(null, arguments);
          };
          Module["_RealDiv"] = function() {
            return (Module["_RealDiv"] = Module["asm"]["RealDiv"]).apply(null, arguments);
          };
          Module["_Reciprocal"] = function() {
            return (Module["_Reciprocal"] = Module["asm"]["Reciprocal"]).apply(null, arguments);
          };
          Module["_Relu"] = function() {
            return (Module["_Relu"] = Module["asm"]["Relu"]).apply(null, arguments);
          };
          Module["_Relu6"] = function() {
            return (Module["_Relu6"] = Module["asm"]["Relu6"]).apply(null, arguments);
          };
          Module["_ResizeBilinear"] = function() {
            return (Module["_ResizeBilinear"] = Module["asm"]["ResizeBilinear"]).apply(null, arguments);
          };
          Module["_ResizeBilinearGrad"] = function() {
            return (Module["_ResizeBilinearGrad"] = Module["asm"]["ResizeBilinearGrad"]).apply(null, arguments);
          };
          Module["_ResizeNearestNeighbor"] = function() {
            return (Module["_ResizeNearestNeighbor"] = Module["asm"]["ResizeNearestNeighbor"]).apply(null, arguments);
          };
          Module["_ResizeNearestNeighborGrad"] = function() {
            return (Module["_ResizeNearestNeighborGrad"] = Module["asm"]["ResizeNearestNeighborGrad"]).apply(null, arguments);
          };
          Module["_Reverse"] = function() {
            return (Module["_Reverse"] = Module["asm"]["Reverse"]).apply(null, arguments);
          };
          Module["_RotateWithOffset"] = function() {
            return (Module["_RotateWithOffset"] = Module["asm"]["RotateWithOffset"]).apply(null, arguments);
          };
          Module["_Round"] = function() {
            return (Module["_Round"] = Module["asm"]["Round"]).apply(null, arguments);
          };
          Module["_Rsqrt"] = function() {
            return (Module["_Rsqrt"] = Module["asm"]["Rsqrt"]).apply(null, arguments);
          };
          Module["_ScatterNd"] = function() {
            return (Module["_ScatterNd"] = Module["asm"]["ScatterNd"]).apply(null, arguments);
          };
          Module["_SearchSorted"] = function() {
            return (Module["_SearchSorted"] = Module["asm"]["SearchSorted"]).apply(null, arguments);
          };
          Module["_SelectV2"] = function() {
            return (Module["_SelectV2"] = Module["asm"]["SelectV2"]).apply(null, arguments);
          };
          Module["_Selu"] = function() {
            return (Module["_Selu"] = Module["asm"]["Selu"]).apply(null, arguments);
          };
          Module["_Sigmoid"] = function() {
            return (Module["_Sigmoid"] = Module["asm"]["Sigmoid"]).apply(null, arguments);
          };
          Module["_Sign"] = function() {
            return (Module["_Sign"] = Module["asm"]["Sign"]).apply(null, arguments);
          };
          Module["_Sin"] = function() {
            return (Module["_Sin"] = Module["asm"]["Sin"]).apply(null, arguments);
          };
          Module["_Softmax"] = function() {
            return (Module["_Softmax"] = Module["asm"]["Softmax"]).apply(null, arguments);
          };
          Module["_Softplus"] = function() {
            return (Module["_Softplus"] = Module["asm"]["Softplus"]).apply(null, arguments);
          };
          Module["_SparseFillEmptyRows"] = function() {
            return (Module["_SparseFillEmptyRows"] = Module["asm"]["SparseFillEmptyRows"]).apply(null, arguments);
          };
          Module["_SparseReshape"] = function() {
            return (Module["_SparseReshape"] = Module["asm"]["SparseReshape"]).apply(null, arguments);
          };
          Module["_SparseSegmentReduction"] = function() {
            return (Module["_SparseSegmentReduction"] = Module["asm"]["SparseSegmentReduction"]).apply(null, arguments);
          };
          Module["_SparseToDense"] = function() {
            return (Module["_SparseToDense"] = Module["asm"]["SparseToDense"]).apply(null, arguments);
          };
          Module["_Sqrt"] = function() {
            return (Module["_Sqrt"] = Module["asm"]["Sqrt"]).apply(null, arguments);
          };
          Module["_Square"] = function() {
            return (Module["_Square"] = Module["asm"]["Square"]).apply(null, arguments);
          };
          Module["_SquaredDifference"] = function() {
            return (Module["_SquaredDifference"] = Module["asm"]["SquaredDifference"]).apply(null, arguments);
          };
          Module["_Step"] = function() {
            return (Module["_Step"] = Module["asm"]["Step"]).apply(null, arguments);
          };
          Module["_StridedSlice"] = function() {
            return (Module["_StridedSlice"] = Module["asm"]["StridedSlice"]).apply(null, arguments);
          };
          Module["_Sub"] = function() {
            return (Module["_Sub"] = Module["asm"]["Sub"]).apply(null, arguments);
          };
          Module["_Sum"] = function() {
            return (Module["_Sum"] = Module["asm"]["Sum"]).apply(null, arguments);
          };
          Module["_Tan"] = function() {
            return (Module["_Tan"] = Module["asm"]["Tan"]).apply(null, arguments);
          };
          Module["_Tanh"] = function() {
            return (Module["_Tanh"] = Module["asm"]["Tanh"]).apply(null, arguments);
          };
          Module["_TensorScatterUpdate"] = function() {
            return (Module["_TensorScatterUpdate"] = Module["asm"]["TensorScatterUpdate"]).apply(null, arguments);
          };
          Module["_Tile"] = function() {
            return (Module["_Tile"] = Module["asm"]["Tile"]).apply(null, arguments);
          };
          Module["_TopK"] = function() {
            return (Module["_TopK"] = Module["asm"]["TopK"]).apply(null, arguments);
          };
          Module["_Transform"] = function() {
            return (Module["_Transform"] = Module["asm"]["Transform"]).apply(null, arguments);
          };
          Module["_Transpose"] = function() {
            return (Module["_Transpose"] = Module["asm"]["Transpose"]).apply(null, arguments);
          };
          Module["__FusedMatMul"] = function() {
            return (Module["__FusedMatMul"] = Module["asm"]["_FusedMatMul"]).apply(null, arguments);
          };
          Module["_malloc"] = function() {
            return (Module["_malloc"] = Module["asm"]["malloc"]).apply(null, arguments);
          };
          Module["_free"] = function() {
            return (Module["_free"] = Module["asm"]["free"]).apply(null, arguments);
          };
          Module["___errno_location"] = function() {
            return (Module["___errno_location"] = Module["asm"]["__errno_location"]).apply(null, arguments);
          };
          var stackSave = Module["stackSave"] = function() {
            return (stackSave = Module["stackSave"] = Module["asm"]["stackSave"]).apply(null, arguments);
          };
          var stackRestore = Module["stackRestore"] = function() {
            return (stackRestore = Module["stackRestore"] = Module["asm"]["stackRestore"]).apply(null, arguments);
          };
          var stackAlloc = Module["stackAlloc"] = function() {
            return (stackAlloc = Module["stackAlloc"] = Module["asm"]["stackAlloc"]).apply(null, arguments);
          };
          Module["dynCall_iijjiiii"] = function() {
            return (Module["dynCall_iijjiiii"] = Module["asm"]["dynCall_iijjiiii"]).apply(null, arguments);
          };
          Module["dynCall_jiji"] = function() {
            return (Module["dynCall_jiji"] = Module["asm"]["dynCall_jiji"]).apply(null, arguments);
          };
          Module["cwrap"] = cwrap;
          var calledRun;
          dependenciesFulfilled = function runCaller() {
            if (!calledRun)
              run();
            if (!calledRun)
              dependenciesFulfilled = runCaller;
          };
          function run(args) {
            if (runDependencies > 0) {
              return;
            }
            preRun();
            if (runDependencies > 0) {
              return;
            }
            function doRun() {
              if (calledRun)
                return;
              calledRun = true;
              Module["calledRun"] = true;
              if (ABORT)
                return;
              initRuntime();
              readyPromiseResolve(Module);
              if (Module["onRuntimeInitialized"])
                Module["onRuntimeInitialized"]();
              postRun();
            }
            if (Module["setStatus"]) {
              Module["setStatus"]("Running...");
              setTimeout(function() {
                setTimeout(function() {
                  Module["setStatus"]("");
                }, 1);
                doRun();
              }, 1);
            } else {
              doRun();
            }
          }
          if (Module["preInit"]) {
            if (typeof Module["preInit"] == "function")
              Module["preInit"] = [Module["preInit"]];
            while (Module["preInit"].length > 0) {
              Module["preInit"].pop()();
            }
          }
          run();
          var listenersAdded;
          if (beforeListeners) {
            listenersAdded = { uncaughtException: process.listeners("uncaughtException").filter(function(listener) {
              return !beforeListeners.uncaughtException.indexOf(listener) > -1;
            }), unhandledRejection: process.listeners("unhandledRejection").filter(function(listener) {
              return !beforeListeners.unhandledRejection.indexOf(listener) > -1;
            }) };
          }
          var actualModule;
          if (typeof WasmBackendModule3 !== "undefined") {
            actualModule = WasmBackendModule3;
          } else if (typeof WasmBackendModuleThreadedSimd !== "undefined") {
            actualModule = WasmBackendModuleThreadedSimd;
          } else {
            throw new Error("Could not find wasm module in post.js");
          }
          if (listenersAdded) {
            var tmpDispose = actualModule["_dispose"];
            actualModule["_dispose"] = function() {
              tmpDispose();
              listenersAdded.uncaughtException.forEach(function(listener) {
                process.removeListener("uncaughtException", listener);
              });
              listenersAdded.unhandledRejection.forEach(function(listener) {
                process.removeListener("unhandledRejection", listener);
              });
            };
          }
          return WasmBackendModule3.ready;
        };
      }();
      module3.exports = WasmBackendModule2;
    })(tfjsBackendWasm$1);
    var tfjsBackendWasmExports = tfjsBackendWasm$1.exports;
    var tfjsBackendWasm = /* @__PURE__ */ getDefaultExportFromCjs(tfjsBackendWasmExports);
    var wasmFactory_import = /* @__PURE__ */ _mergeNamespaces({
      __proto__: null,
      default: tfjsBackendWasm
    }, [tfjsBackendWasmExports]);
    var wasmFactoryThreadedSimd = tfjsBackendWasmThreadedSimd || wasmFactoryThreadedSimd_import;
    var wasmFactory = tfjsBackendWasm || wasmFactory_import;
    var BackendWasm = (
      /** @class */
      function(_super) {
        __extends(BackendWasm2, _super);
        function BackendWasm2(wasm) {
          var _this = _super.call(this) || this;
          _this.wasm = wasm;
          _this.dataIdNextNumber = 1;
          _this.wasm.tfjs.initWithThreadsCount(threadsCount);
          actualThreadsCount = _this.wasm.tfjs.getThreadsCount();
          _this.dataIdMap = new tfjsCore.DataStorage(_this, tfjsCore.engine());
          return _this;
        }
        BackendWasm2.prototype.write = function(values, shape, dtype) {
          var dataId = { id: this.dataIdNextNumber++ };
          this.move(dataId, values, shape, dtype, 1);
          return dataId;
        };
        BackendWasm2.prototype.numDataIds = function() {
          return this.dataIdMap.numDataIds();
        };
        BackendWasm2.prototype.time = function(f) {
          return __awaiter(this, void 0, void 0, function() {
            var start, kernelMs;
            return __generator(this, function(_a2) {
              start = tfjsCore.util.now();
              f();
              kernelMs = tfjsCore.util.now() - start;
              return [2, { kernelMs }];
            });
          });
        };
        BackendWasm2.prototype.move = function(dataId, values, shape, dtype, refCount) {
          var id = this.dataIdNextNumber++;
          if (dtype === "string") {
            var stringBytes = values;
            this.dataIdMap.set(dataId, { id, stringBytes, shape, dtype, memoryOffset: null, refCount });
            return;
          }
          var size = tfjsCore.util.sizeFromShape(shape);
          var numBytes = size * tfjsCore.util.bytesPerElement(dtype);
          var memoryOffset = this.wasm._malloc(numBytes) >>> 0;
          this.dataIdMap.set(dataId, { id, memoryOffset, shape, dtype, refCount });
          this.wasm.tfjs.registerTensor(id, size, memoryOffset);
          if (values != null) {
            this.wasm.HEAPU8.set(new Uint8Array(values.buffer, values.byteOffset, numBytes), memoryOffset);
          }
        };
        BackendWasm2.prototype.read = function(dataId) {
          return __awaiter(this, void 0, void 0, function() {
            return __generator(this, function(_a2) {
              return [2, this.readSync(dataId)];
            });
          });
        };
        BackendWasm2.prototype.readSync = function(dataId, start, end) {
          var _a2 = this.dataIdMap.get(dataId), memoryOffset = _a2.memoryOffset, dtype = _a2.dtype, shape = _a2.shape, stringBytes = _a2.stringBytes;
          if (dtype === "string") {
            if ((start == null || start === 0) && (end == null || end >= stringBytes.length)) {
              return stringBytes;
            }
            return stringBytes.slice(start, end);
          }
          start = start || 0;
          end = end || tfjsCore.util.sizeFromShape(shape);
          var bytesPerElement = tfjsCore.util.bytesPerElement(dtype);
          var bytes = this.wasm.HEAPU8.slice(memoryOffset + start * bytesPerElement, memoryOffset + end * bytesPerElement);
          return typedArrayFromBuffer(bytes.buffer, dtype);
        };
        BackendWasm2.prototype.disposeData = function(dataId, force) {
          if (force === void 0) {
            force = false;
          }
          if (this.dataIdMap.has(dataId)) {
            var data = this.dataIdMap.get(dataId);
            data.refCount--;
            if (!force && data.refCount > 0) {
              return false;
            }
            this.wasm._free(data.memoryOffset);
            this.wasm.tfjs.disposeData(data.id);
            this.dataIdMap.delete(dataId);
          }
          return true;
        };
        BackendWasm2.prototype.refCount = function(dataId) {
          if (this.dataIdMap.has(dataId)) {
            var tensorData = this.dataIdMap.get(dataId);
            return tensorData.refCount;
          }
          return 0;
        };
        BackendWasm2.prototype.incRef = function(dataId) {
          var data = this.dataIdMap.get(dataId);
          if (data != null) {
            data.refCount++;
          }
        };
        BackendWasm2.prototype.floatPrecision = function() {
          return 32;
        };
        BackendWasm2.prototype.getMemoryOffset = function(dataId) {
          return this.dataIdMap.get(dataId).memoryOffset;
        };
        BackendWasm2.prototype.dispose = function() {
          this.wasm.tfjs.dispose();
          if ("PThread" in this.wasm) {
            this.wasm.PThread.terminateAllThreads();
          }
          this.wasm = null;
        };
        BackendWasm2.prototype.memory = function() {
          return { unreliable: false };
        };
        BackendWasm2.prototype.makeOutput = function(shape, dtype, memoryOffset, values) {
          var dataId;
          if (memoryOffset == null) {
            dataId = this.write(values !== null && values !== void 0 ? values : null, shape, dtype);
          } else {
            var id = this.dataIdNextNumber++;
            dataId = { id };
            this.dataIdMap.set(dataId, { id, memoryOffset, shape, dtype, refCount: 1 });
            var size = tfjsCore.util.sizeFromShape(shape);
            this.wasm.tfjs.registerTensor(id, size, memoryOffset);
          }
          return { dataId, shape, dtype };
        };
        BackendWasm2.prototype.typedArrayFromHeap = function(_a2) {
          var shape = _a2.shape, dtype = _a2.dtype, dataId = _a2.dataId;
          var buffer = this.wasm.HEAPU8.buffer;
          var memoryOffset = this.dataIdMap.get(dataId).memoryOffset;
          var size = tfjsCore.util.sizeFromShape(shape);
          switch (dtype) {
            case "float32":
              return new Float32Array(buffer, memoryOffset, size);
            case "int32":
              return new Int32Array(buffer, memoryOffset, size);
            case "bool":
              return new Uint8Array(buffer, memoryOffset, size);
            default:
              throw new Error("Unknown dtype ".concat(dtype));
          }
        };
        return BackendWasm2;
      }(tfjsCore.KernelBackend)
    );
    function createInstantiateWasmFunc(path) {
      return function(imports, callback) {
        tfjsCore.util.fetch(path, { credentials: "same-origin" }).then(function(response) {
          if (!response["ok"]) {
            imports.env.a("failed to load wasm binary file at '".concat(path, "'"));
          }
          response.arrayBuffer().then(function(binary) {
            WebAssembly.instantiate(binary, imports).then(function(output) {
              callback(output.instance, output.module);
            });
          });
        });
        return {};
      };
    }
    function getPathToWasmBinary(simdSupported, threadsSupported, wasmModuleFolder) {
      if (wasmPath != null) {
        return wasmPath;
      }
      var path = "tfjs-backend-wasm.wasm";
      if (simdSupported && threadsSupported) {
        path = "tfjs-backend-wasm-threaded-simd.wasm";
      } else if (simdSupported) {
        path = "tfjs-backend-wasm-simd.wasm";
      }
      if (wasmFileMap != null) {
        if (wasmFileMap[path] != null) {
          return wasmFileMap[path];
        }
      }
      return wasmModuleFolder + path;
    }
    function init() {
      return __awaiter(this, void 0, void 0, function() {
        var _a2, simdSupported, threadsSupported;
        return __generator(this, function(_b) {
          switch (_b.label) {
            case 0:
              return [4, Promise.all([
                tfjsCore.env().getAsync("WASM_HAS_SIMD_SUPPORT"),
                tfjsCore.env().getAsync("WASM_HAS_MULTITHREAD_SUPPORT")
              ])];
            case 1:
              _a2 = __read.apply(void 0, [_b.sent(), 2]), simdSupported = _a2[0], threadsSupported = _a2[1];
              return [2, new Promise(function(resolve2, reject) {
                var factoryConfig = {};
                factoryConfig.locateFile = function(path, prefix) {
                  if (path.endsWith(".worker.js")) {
                    var response = wasmWorkerContents.replace(/\n/g, "\\n");
                    var blob = new Blob([response], { type: "application/javascript" });
                    return URL.createObjectURL(blob);
                  }
                  if (path.endsWith(".wasm")) {
                    return getPathToWasmBinary(simdSupported, threadsSupported, wasmPathPrefix != null ? wasmPathPrefix : prefix);
                  }
                  return prefix + path;
                };
                if (customFetch) {
                  factoryConfig.instantiateWasm = createInstantiateWasmFunc(getPathToWasmBinary(simdSupported, threadsSupported, wasmPathPrefix != null ? wasmPathPrefix : ""));
                }
                var initialized = false;
                factoryConfig.onAbort = function() {
                  if (initialized) {
                    return;
                  }
                  if (initAborted) {
                    return;
                  }
                  initAborted = true;
                  var rejectMsg = "Make sure the server can serve the `.wasm` file relative to the bundled js file. For more details see https://github.com/tensorflow/tfjs/blob/master/tfjs-backend-wasm/README.md#using-bundlers";
                  reject({ message: rejectMsg });
                };
                var wasm;
                if (threadsSupported && simdSupported && wasmPath == null) {
                  factoryConfig.mainScriptUrlOrBlob = new Blob(["var WasmBackendModuleThreadedSimd = " + wasmFactoryThreadedSimd.toString()], { type: "text/javascript" });
                  wasm = wasmFactoryThreadedSimd(factoryConfig);
                } else {
                  wasm = wasmFactory(factoryConfig);
                }
                wasm.then(function(module3) {
                  initialized = true;
                  initAborted = false;
                  var voidReturnType = null;
                  module3.tfjs = {
                    init: module3.cwrap("init", null, []),
                    initWithThreadsCount: module3.cwrap("init_with_threads_count", null, ["number"]),
                    getThreadsCount: module3.cwrap("get_threads_count", "number", []),
                    registerTensor: module3.cwrap("register_tensor", null, [
                      "number",
                      "number",
                      "number"
                      // memoryOffset
                    ]),
                    disposeData: module3.cwrap("dispose_data", voidReturnType, ["number"]),
                    dispose: module3.cwrap("dispose", voidReturnType, [])
                  };
                  resolve2({ wasm: module3 });
                }).catch(reject);
              })];
          }
        });
      });
    }
    function typedArrayFromBuffer(buffer, dtype) {
      switch (dtype) {
        case "float32":
          return new Float32Array(buffer);
        case "int32":
          return new Int32Array(buffer);
        case "bool":
          return new Uint8Array(buffer);
        default:
          throw new Error("Unknown dtype ".concat(dtype));
      }
    }
    var wasmBinaryNames = [
      "tfjs-backend-wasm.wasm",
      "tfjs-backend-wasm-simd.wasm",
      "tfjs-backend-wasm-threaded-simd.wasm"
    ];
    var wasmPath = null;
    var wasmPathPrefix = null;
    var wasmFileMap = {};
    var initAborted = false;
    var customFetch = false;
    function setWasmPath(path, usePlatformFetch) {
      if (usePlatformFetch === void 0) {
        usePlatformFetch = false;
      }
      tfjsCore.deprecationWarn("setWasmPath has been deprecated in favor of setWasmPaths and will be removed in a future release.");
      if (initAborted) {
        throw new Error("The WASM backend was already initialized. Make sure you call `setWasmPath()` before you call `tf.setBackend()` or `tf.ready()`");
      }
      wasmPath = path;
      customFetch = usePlatformFetch;
    }
    function setWasmPaths(prefixOrFileMap, usePlatformFetch) {
      if (usePlatformFetch === void 0) {
        usePlatformFetch = false;
      }
      if (initAborted) {
        throw new Error("The WASM backend was already initialized. Make sure you call `setWasmPaths()` before you call `tf.setBackend()` or `tf.ready()`");
      }
      if (typeof prefixOrFileMap === "string") {
        wasmPathPrefix = prefixOrFileMap;
      } else {
        wasmFileMap = prefixOrFileMap;
        var missingPaths = wasmBinaryNames.filter(function(name) {
          return wasmFileMap[name] == null;
        });
        if (missingPaths.length > 0) {
          throw new Error("There were no entries found for the following binaries: " + "".concat(missingPaths.join(","), ". Please either call setWasmPaths with a ") + "map providing a path for each binary, or with a string indicating the directory where all the binaries can be found.");
        }
      }
      customFetch = usePlatformFetch;
    }
    var threadsCount = -1;
    var actualThreadsCount = -1;
    function setThreadsCount(numThreads) {
      threadsCount = numThreads;
    }
    function getThreadsCount() {
      if (actualThreadsCount === -1) {
        throw new Error("WASM backend not initialized.");
      }
      return actualThreadsCount;
    }
    var version2 = "4.5.0";
    var WASM_PRIORITY = 2;
    tfjsCore.registerBackend("wasm", function() {
      return __awaiter(void 0, void 0, void 0, function() {
        var wasm;
        return __generator(this, function(_a2) {
          switch (_a2.label) {
            case 0:
              return [4, init()];
            case 1:
              wasm = _a2.sent().wasm;
              return [2, new BackendWasm(wasm)];
          }
        });
      });
    }, WASM_PRIORITY);
    exports.BackendWasm = BackendWasm;
    exports.getThreadsCount = getThreadsCount;
    exports.setThreadsCount = setThreadsCount;
    exports.setWasmPath = setWasmPath;
    exports.setWasmPaths = setWasmPaths;
    exports.version_wasm = version2;
  }
});

// lib/index.ts
var lib_exports = {};
__export(lib_exports, {
  io: () => io2,
  version: () => version
});
module.exports = __toCommonJS(lib_exports);
var import_tfjs_core = __toESM(require_tf_core_node());

// lib/fileSystem.ts
var tf = __toESM(require_tf_core_node());
var import_promises = require("fs/promises");
var import_path = require("path");

// lib/toArrayBuffer.ts
function toArrayBuffer(buf) {
  if (Array.isArray(buf)) {
    let totalLength = 0;
    for (const buffer of buf) {
      totalLength += buffer.length;
    }
    const ab = new ArrayBuffer(totalLength);
    const view = new Uint8Array(ab);
    let pos = 0;
    for (const buffer of buf) {
      pos += buffer.copy(view, pos);
    }
    return ab;
  } else {
    return buf.buffer.slice(buf.byteOffset, buf.byteOffset + buf.byteLength);
  }
}

// lib/fileSystem.ts
function doesNotExistHandler(name) {
  return (e) => {
    switch (e.code) {
      case "ENOENT":
        throw new Error(`${name} ${e.path} does not exist: loading failed`);
      default:
        throw e;
    }
  };
}
var NodeFileSystem = class {
  /**
   * Constructor of the NodeFileSystem IOHandler.
   * @param path A single path or an Array of paths.
   *   For saving: expects a single path pointing to an existing or nonexistent
   *     directory. If the directory does not exist, it will be
   *     created.
   *   For loading:
   *     - If the model has JSON topology (e.g., `tf.Model`), a single path
   *       pointing to the JSON file (usually named `model.json`) is expected.
   *       The JSON file is expected to contain `modelTopology` and/or
   *       `weightsManifest`. If `weightManifest` exists, the values of the
   *       weights will be loaded from relative paths (relative to the directory
   *       of `model.json`) as contained in `weightManifest`.
   *     - If the model has binary (protocol buffer GraphDef) topology,
   *       an Array of two paths is expected: the first path should point to the
   *       .pb file and the second path should point to the weight manifest
   *       JSON file.
   */
  constructor(path) {
    this.MODEL_JSON_FILENAME = "model.json";
    this.WEIGHTS_BINARY_FILENAME = "weights.bin";
    if (Array.isArray(path)) {
      tf.util.assert(
        path.length === 2,
        () => `file paths must have a length of 2, (actual length is ${path.length}).`
      );
      this.path = path.map((p) => (0, import_path.resolve)(p));
    } else {
      this.path = (0, import_path.resolve)(path);
    }
  }
  async save(modelArtifacts) {
    if (Array.isArray(this.path)) {
      throw new Error("Cannot perform saving to multiple paths.");
    }
    await this.createOrVerifyDirectory();
    if (modelArtifacts.modelTopology instanceof ArrayBuffer) {
      throw new Error(
        "NodeFileSystem.save() does not support saving model topology in binary format yet."
      );
    } else {
      const weightsBinPath = (0, import_path.join)(this.path, this.WEIGHTS_BINARY_FILENAME);
      const weightsManifest = [
        {
          paths: [this.WEIGHTS_BINARY_FILENAME],
          weights: modelArtifacts.weightSpecs
        }
      ];
      const modelJSON = {
        modelTopology: modelArtifacts.modelTopology,
        weightsManifest,
        format: modelArtifacts.format,
        generatedBy: modelArtifacts.generatedBy,
        convertedBy: modelArtifacts.convertedBy
      };
      if (modelArtifacts.trainingConfig != null) {
        modelJSON.trainingConfig = modelArtifacts.trainingConfig;
      }
      if (modelArtifacts.signature != null) {
        modelJSON.signature = modelArtifacts.signature;
      }
      if (modelArtifacts.userDefinedMetadata != null) {
        modelJSON.userDefinedMetadata = modelArtifacts.userDefinedMetadata;
      }
      const modelJSONPath = (0, import_path.join)(this.path, this.MODEL_JSON_FILENAME);
      await (0, import_promises.writeFile)(modelJSONPath, JSON.stringify(modelJSON), "utf8");
      await (0, import_promises.writeFile)(
        weightsBinPath,
        Buffer.from(modelArtifacts.weightData),
        "binary"
      );
      return {
        // TODO(cais): Use explicit tf.io.ModelArtifactsInfo type below once it
        // is available.
        // tslint:disable-next-line:no-any
        modelArtifactsInfo: tf.io.getModelArtifactsInfoForJSON(modelArtifacts)
      };
    }
  }
  async load() {
    return Array.isArray(this.path) ? this.loadBinaryModel() : this.loadJSONModel();
  }
  async loadBinaryModel() {
    const topologyPath = this.path[0];
    const weightManifestPath = this.path[1];
    const topology = await (0, import_promises.stat)(topologyPath).catch(
      doesNotExistHandler("Topology Path")
    );
    const weightManifest = await (0, import_promises.stat)(weightManifestPath).catch(
      doesNotExistHandler("Weight Manifest Path")
    );
    if (!topology.isFile()) {
      throw new Error("File specified for topology is not a file!");
    }
    if (!weightManifest.isFile()) {
      throw new Error("File specified for the weight manifest is not a file!");
    }
    const modelTopology = await (0, import_promises.readFile)(this.path[0]);
    const weightsManifest = JSON.parse(await (0, import_promises.readFile)(this.path[1], "utf8"));
    const modelArtifacts = {
      modelTopology
    };
    const [weightSpecs, weightData] = await this.loadWeights(
      weightsManifest,
      this.path[1]
    );
    modelArtifacts.weightSpecs = weightSpecs;
    modelArtifacts.weightData = weightData;
    return modelArtifacts;
  }
  async loadJSONModel() {
    const path = this.path;
    const info = await (0, import_promises.stat)(path).catch(doesNotExistHandler("Path"));
    if (info.isFile()) {
      const modelJSON = JSON.parse(await (0, import_promises.readFile)(path, "utf8"));
      return tf.io.getModelArtifactsForJSON(
        modelJSON,
        (weightsManifest) => this.loadWeights(weightsManifest, path)
      );
    } else {
      throw new Error(
        "The path to load from must be a file. Loading from a directory is not supported."
      );
    }
  }
  async loadWeights(weightsManifest, path) {
    const dirName = (0, import_path.dirname)(path);
    const buffers = [];
    const weightSpecs = [];
    for (const group of weightsManifest) {
      for (const path2 of group.paths) {
        const weightFilePath = (0, import_path.join)(dirName, path2);
        const buffer = await (0, import_promises.readFile)(weightFilePath).catch(
          doesNotExistHandler("Weight file")
        );
        buffers.push(buffer);
      }
      weightSpecs.push(...group.weights);
    }
    return [weightSpecs, toArrayBuffer(buffers)];
  }
  /**
   * For each item in `this.path`, creates a directory at the path or verify
   * that the path exists as a directory.
   */
  async createOrVerifyDirectory() {
    const paths = Array.isArray(this.path) ? this.path : [this.path];
    for (const path of paths) {
      try {
        await (0, import_promises.mkdir)(path);
      } catch (e) {
        if (e.code === "EEXIST") {
          if ((await (0, import_promises.stat)(path)).isFile()) {
            throw new Error(
              `Path ${path} exists as a file. The path must be nonexistent or point to a directory.`
            );
          }
        } else {
          throw e;
        }
      }
    }
  }
};
NodeFileSystem.URL_SCHEME = "file://";
var nodeFileSystemRouter = (url) => {
  if (Array.isArray(url)) {
    if (url.every(
      (urlElement) => urlElement.startsWith(NodeFileSystem.URL_SCHEME)
    )) {
      return new NodeFileSystem(
        url.map(
          (urlElement) => urlElement.slice(NodeFileSystem.URL_SCHEME.length)
        )
      );
    } else {
      return null;
    }
  } else {
    if (url.startsWith(NodeFileSystem.URL_SCHEME)) {
      return new NodeFileSystem(url.slice(NodeFileSystem.URL_SCHEME.length));
    } else {
      return null;
    }
  }
};
function fileSystem(path) {
  return new NodeFileSystem(path);
}

// lib/index.ts
var import_tfjs_core2 = __toESM(require_tf_core_node());
var import_tfjs_converter = __toESM(require_tf_converter_node());
var import_tfjs_backend_wasm = __toESM(require_tf_backend_wasm_node());
__reExport(lib_exports, __toESM(require_tf_core_node()), module.exports);
__reExport(lib_exports, __toESM(require_tf_converter_node()), module.exports);
__reExport(lib_exports, __toESM(require_tf_backend_wasm_node()), module.exports);
(0, import_tfjs_core.setBackend)("wasm");
import_tfjs_core.io.registerLoadRouter(nodeFileSystemRouter);
import_tfjs_core.io.registerSaveRouter(nodeFileSystemRouter);
var io2 = __spreadProps(__spreadValues({}, import_tfjs_core.io), {
  fileSystem
});
var version = {
  "tfjs-core": import_tfjs_core2.version_core,
  "tfjs-backend-wasm": import_tfjs_backend_wasm.version_wasm,
  "tfjs-converter": import_tfjs_converter.version_converter
};
// Annotate the CommonJS export names for ESM import in node:
0 && (module.exports = {
  io,
  version
});
/**
 * @license
 * Copyright 2018 Google LLC. All Rights Reserved.
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 * =============================================================================
 */
/*! Bundled license information:

@tensorflow/tfjs-core/dist/tf-core.node.js:
  (**
   * @license
   * Copyright 2023 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
  (**
   * @license
   * Copyright 2023 Google LLC.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
  (**
   * @license
   * Copyright 2017 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
  (**
   * @license
   * Copyright 2019 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
  (**
   * @license
   * Copyright 2020 Google Inc. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
  (**
   * @license
   * Copyright 2021 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
  (**
   * @license
   * Copyright 2022 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the 'License');
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an 'AS IS' BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
  (**
   * @license
   * Copyright 2022 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
  (**
   * @license
   * Copyright 2022 Google LLC.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
  (** @license See the LICENSE file. *)

@tensorflow/tfjs-converter/dist/tf-converter.node.js:
  (**
   * @license
   * Copyright 2023 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
  (**
   * @license
   * Copyright 2021 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
  (**
   * @license
   * Copyright 2019 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   *
   * =============================================================================
   *)
  (**
   * @license
   * Copyright 2019 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
  (**
   * @license
   * Copyright 2023 Google LLC.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
  (**
   * @license
   * Copyright 2017 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
  (**
   * @license
   * Copyright 2020 Google Inc. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
  (**
   * @license
   * Copyright 2022 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the 'License');
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an 'AS IS' BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
  (**
   * @license
   * Copyright 2022 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
  (**
   * @license
   * Copyright 2022 Google LLC.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
  (** @license See the LICENSE file. *)

@tensorflow/tfjs-backend-wasm/dist/tf-backend-wasm.node.js:
  (**
   * @license
   * Copyright 2023 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
  (**
   * @license
   * Copyright 2019 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
  (**
   * @license
   * Copyright 2023 Google LLC.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
  (**
   * @license
   * Copyright 2020 Google Inc. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
  (**
   * @license
   * Copyright 2021 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
  (**
   * @license
   * Copyright 2022 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
  (**
   * @license
   * Copyright 2022 The TensorFlow Authors. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the License);
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an AS IS BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
  (**
   * @license
   * Copyright 2022 The TensorFlow Authors. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
  (** @license See the LICENSE file. *)
*/
